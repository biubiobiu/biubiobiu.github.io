<!doctype html><html><head><title>Gluon-nn模块</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="Gluon-nn模块"><meta property="og:description" content="模型基类-Block from mxnet.gluon import Block, nn from mxnet import ndarray as F class Model(Block): def __init__(self, **kwargs): super(Model, self).__init__(**kwargs) # use name_scope to give child Blocks appropriate names. with self.name_scope(): self.dense0 = nn.Dense(20) self.dense1 = nn.Dense(20) def forward(self, x): x = F.relu(self.dense0(x)) return F.relu(self.dense1(x)) model = Model() model.initialize(ctx=mx.cpu(0)) model(F.zeros((10, 10), ctx=mx.cpu(0))) class Block(builtins.object)
网络的最基础的类，搭建网络时必须继承此Block类 —————————————————
Block的两个参数：
 prefix : str; 前缀的作用就像一个命名空间。在父模块的作用域下创建的子模块都有父模块的前缀(prefix). params : ParameterDict or None; 共享参数。
例如：dense1共享dense0的参数。
dense0 = nn."><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0030_module_gluon_nn/"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/notes.css><link rel=stylesheet href=/css/navigators/sidebar.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/notes data-filter=all>笔记</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/notes/computer_algorithm/>Computer Algorithm</a><ul><li><a href=/zh-cn/notes/computer_algorithm/0010_data_struct/ title=数据结构>数据结构</a></li><li><a href=/zh-cn/notes/computer_algorithm/0015_comm_ideas/ title=常见算法思路>常见算法思路</a></li><li><a href=/zh-cn/notes/computer_algorithm/0020_tree_search/ title=二叉树-遍历>二叉树-遍历</a></li><li><a href=/zh-cn/notes/computer_algorithm/0030_five_algorithms/ title=五大常用算法>五大常用算法</a></li><li><a href=/zh-cn/notes/computer_algorithm/0040_sliding_window/ title=滑动窗口>滑动窗口</a></li><li><a href=/zh-cn/notes/computer_algorithm/0050_graph_search/ title=图的搜索>图的搜索</a></li><li><a href=/zh-cn/notes/computer_algorithm/0450_leedcode_classic.zh-ch/ title=LeedCode-经典>LeedCode-经典</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/notes/mxnet/>MxNet</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/notes/mxnet/ndarray/>NdArray</a><ul><li><a href=/zh-cn/notes/mxnet/ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li><li><a href=/zh-cn/notes/mxnet/ndarray/0020_technic_gather/ title=NdArray技巧搜集>NdArray技巧搜集</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/notes/mxnet/gluon/>Gluon</a><ul class=active><li><a href=/zh-cn/notes/mxnet/gluon/0010_gluon_summary/ title=Gluon实例>Gluon实例</a></li><li><a href=/zh-cn/notes/mxnet/gluon/0020_module_gather/ title=Gluon模块简介>Gluon模块简介</a></li><li><a class=active href=/zh-cn/notes/mxnet/gluon/0030_module_gluon_nn/ title=Gluon-nn模块>Gluon-nn模块</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid note-card-holder" id=note-card-holder><div class=note-card><div class=item><h5 class=note-title><span>模型基类-Block</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet.gluon <span style=color:#f92672>import</span> Block, nn
<span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> ndarray <span style=color:#66d9ef>as</span> F

<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Model</span>(Block):
	<span style=color:#66d9ef>def</span> __init__(self, <span style=color:#f92672>**</span>kwargs):
		super(Model, self)<span style=color:#f92672>.</span>__init__(<span style=color:#f92672>**</span>kwargs)
		<span style=color:#75715e># use name_scope to give child Blocks appropriate names.</span>
		<span style=color:#66d9ef>with</span> self<span style=color:#f92672>.</span>name_scope():
			self<span style=color:#f92672>.</span>dense0 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>20</span>)
			self<span style=color:#f92672>.</span>dense1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>20</span>)

	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
		x <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>dense0(x))
		<span style=color:#66d9ef>return</span> F<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>dense1(x))

model <span style=color:#f92672>=</span> Model()
model<span style=color:#f92672>.</span>initialize(ctx<span style=color:#f92672>=</span>mx<span style=color:#f92672>.</span>cpu(<span style=color:#ae81ff>0</span>))
model(F<span style=color:#f92672>.</span>zeros((<span style=color:#ae81ff>10</span>, <span style=color:#ae81ff>10</span>), ctx<span style=color:#f92672>=</span>mx<span style=color:#f92672>.</span>cpu(<span style=color:#ae81ff>0</span>)))

</code></pre></div><p>class Block(builtins.object)<br>网络的最基础的类，搭建网络时必须继承此Block类<br>—————————————————<br>Block的两个参数：<br></p><ul><li><code>prefix</code> : str; 前缀的作用就像一个命名空间。在父模块的作用域下创建的子模块都有父模块的前缀(prefix).</li><li><code>params</code> : ParameterDict or None; 共享参数。<br>　　例如：dense1共享dense0的参数。<br>　　　　dense0 = nn.Dense(20)<br>　　　　dense1 = nn.Dense(20, params=dense0.collect_params())</li></ul><p>—————————————————<br>Block的方法：</p><ul><li><code>collect_params</code>(self, select=None) 返回一个<code>ParameterDict</code>类。默认包含所有的参数；同时也可以正则匹配:<br>例如：选出特定的参数 [&lsquo;conv1_weight&rsquo;, &lsquo;conv1_bias&rsquo;, &lsquo;fc_weight&rsquo;, &lsquo;fc_bias&rsquo;]<br>即：model.collect_params(&lsquo;conv1_weight|conv1_bias|fc_weight|fc_bias&rsquo;)<br>　　<code>Parameters</code>：空 或者 正则表达式<br>　　<code>Returns</code>: py:class:ParameterDict</li><li><code>forward</code>(self, *args) 完成前向计算，输入是NDArray列表<br>　　Parameters：*args : list of NDArray</li><li><code>hybridize</code>(self, active=True, **kwargs) 激活/不激活HybridBlock的递归<br>　　Parameters： bool, default True</li><li><code>initialize</code>(self, init=&lt;mxnet.initializer.Uniform object>, ctx=None, verbose=False, force_reinit=False)<br>　　对模型的参数初始化，默认是均匀分布。<br>　　等价于：block.collect_params().initialize(&mldr;)<br>　　Parameters：<br>　　　　init : Initializer 初始化方法<br>　　　　ctx : 设备 或者 设备列表。会把模型copy到所有指定的设备上<br>　　　　verbose : bool, default False 是否在初始化时粗略地打印细节。<br>　　　　force_reinit : bool, default False 是否重新初始化，即使已经初始化</li><li><code>load_parameters</code>(self, filename, ctx=None, allow_missing=False, ignore_extra=False, cast_dtype=False, dtype_source=&lsquo;current&rsquo;)<br>　　加载模型参数从 用<code>save_parameters</code>保存的模型文件中。<br>　　Parameters：<br>　　　　filename : str 模型文件路径<br>　　　　ctx : 设备 或者设备列表。默认使用CPU<br>　　　　allow_missing : bool, default False 是否默默跳过模型文件中不存<br>　　　　　　在的模型参数。<br>　　　　ignore_extra : bool, default False 是否默默忽略模型中不存在的参<br>　　　　　　数(模型文件中有，模型定义中没有)<br>　　　　cast_dtype : bool, default False 从checkpointload模型时，是否根<br>　　　　　　据传入转换NDArray的数据类型<br>　　　　dtype_source : str, default &lsquo;current&rsquo; 枚举值：{&lsquo;current&rsquo;, &lsquo;saved&rsquo;}<br>　　　　　　只有再cast_dtype=True时有效，指定模型参数的数据类型</li><li><code>name_scope</code>(self) 返回一个命名空间，用来管理Block和参数names。<br>　　必须在with语句中使用：<br>　　with self.name_scope():<br>　　　　self.dense = nn.Dense(20)</li><li><code>register_child</code>(self, block, name=None) 将block注册为子节点，block的属<br>　　性将自动注册。</li><li><code>save_parameters</code>(self, filename) 保持模型参数到磁盘。该方法只保存模型<br>　　参数的权重，不保存模型的结构。如果想要保存模型的结构，请使<br>　　用:py:meth:<code>HybridBlock.export</code>.<br>　　Parameters：Path to file.</li><li><code>summary</code>(self, *inputs) 打印模型的输出和参数的摘要。模型必须被初始化</li></ul><p>—————————————————<br>数据描述：</p><ul><li><code>name</code> :py:class:Block 的名字</li><li><code>params</code>：返回一个参数字典（不包含子节点的参数）</li><li><code>prefix</code>：返回py:class:Block的前缀</li></ul></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>模型参数-Parameter</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>ctx <span style=color:#f92672>=</span> mx<span style=color:#f92672>.</span>gpu(<span style=color:#ae81ff>0</span>)
x <span style=color:#f92672>=</span> mx<span style=color:#f92672>.</span>nd<span style=color:#f92672>.</span>zeros((<span style=color:#ae81ff>16</span>, <span style=color:#ae81ff>100</span>), ctx<span style=color:#f92672>=</span>ctx)
w <span style=color:#f92672>=</span> mx<span style=color:#f92672>.</span>gluon<span style=color:#f92672>.</span>Parameter(<span style=color:#e6db74>&#39;fc_weight&#39;</span>, shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>100</span>), init<span style=color:#f92672>=</span>mx<span style=color:#f92672>.</span>init<span style=color:#f92672>.</span>Xavier())
b <span style=color:#f92672>=</span> mx<span style=color:#f92672>.</span>gluon<span style=color:#f92672>.</span>Parameter(<span style=color:#e6db74>&#39;fc_bias&#39;</span>, shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>64</span>,), init<span style=color:#f92672>=</span>mx<span style=color:#f92672>.</span>init<span style=color:#f92672>.</span>Zero())
w<span style=color:#f92672>.</span>initialize(ctx<span style=color:#f92672>=</span>ctx)
b<span style=color:#f92672>.</span>initialize(ctx<span style=color:#f92672>=</span>ctx)
out <span style=color:#f92672>=</span> mx<span style=color:#f92672>.</span>nd<span style=color:#f92672>.</span>FullyConnected(x, w<span style=color:#f92672>.</span>data(ctx), b<span style=color:#f92672>.</span>data(ctx), num_hidden<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>)
</code></pre></div><p>class:Parameter 一个存放Blocks的参数的权重的容器。初始化后<code>Parameter.initialize(...)</code>，会copy所有参数权重到每个设备上。如果<code>grad_req</code>不为null，在每个设备上，该容器会拥有一个梯度向量。</p><p>Parameter(name,<br>　　　　　grad_req=&lsquo;write&rsquo;,<br>　　　　　shape=None,<br>　　　　　dtype=&lt;class &lsquo;numpy.float32&rsquo;>,<br>　　　　　lr_mult=1.0,<br>　　　　　wd_mult=1.0,<br>　　　　　init=None,<br>　　　　　allow_deferred_init=False,<br>　　　　　differentiable=True,<br>　　　　　stype=&lsquo;default&rsquo;,<br>　　　　　grad_stype=&lsquo;default&rsquo;)</p><p>形参：<br>——————————</p><ul><li><code>name</code> :
str类型；参数的名字。</li><li><code>grad_req</code> : 枚举值：{&lsquo;write&rsquo;, &lsquo;add&rsquo;, &lsquo;null&rsquo;}, 默认值：&lsquo;write&rsquo;。指定怎么更新梯度到梯度向量。<br>　　<code>'write'</code>:每次把梯度值写到 梯度向量中<br>　　<code>'add'</code>: 每次把计算的梯度值add到梯度向量中. 在每次迭代之前，<br>　　　　你需要手动调用<code>zero_grad()</code>来清理梯度缓存。<br>　　<code>'null'</code>: 参数不需要计算梯度，不会分配梯度向量。</li><li><code>shape</code> : int or tuple of int, default None. 参数的尺寸.</li><li><code>dtype</code> : numpy.dtype or str, default &lsquo;float32&rsquo;. 参数的数据类型</li><li><code>lr_mult</code> : float, default 1.0, 学习率.</li><li><code>wd_mult</code> : float, default 1.0, 权重衰减率 L2</li><li><code>init</code> : Initializer, default None. 参数的初始化，默认全局初始化</li><li><code>stype</code>: 枚举值: {&lsquo;default&rsquo;, &lsquo;row_sparse&rsquo;, &lsquo;csr&rsquo;}, defaults to &lsquo;default&rsquo;. 参数的存储类型。</li><li><code>grad_stype</code>: 枚举值: {&lsquo;default&rsquo;, &lsquo;row_sparse&rsquo;, &lsquo;csr&rsquo;}, defaults to &lsquo;default&rsquo;. 参数梯度的存储类型</li></ul><p>属性:<br>——————————</p><ul><li><code>grad_req</code> : 枚举值:{&lsquo;write&rsquo;, &lsquo;add&rsquo;, &lsquo;null&rsquo;} 可以在初始化之前/之后设置。当不需要计算参数的梯度时，设置为<code>null</code>，以节省内存和计算量。</li><li><code>lr_mult</code> : float 学习率</li><li><code>wd_mult</code> : float 权重衰减率</li></ul><p>定义的函数：<br>——————————</p><ul><li><p><code>cast(self, dtype)</code> 转换参数的值/梯度的数据类型。<br>　　dtype : str or numpy.dtype 新的数据类型</p></li><li><p><code>data(self, ctx=None)</code> 获取这个参数在设备<code>ctx</code>上的值，参数必须已经初始化了。<br>　　ctx : 指定设备<br>　　Returns：NDArray on ctx</p></li><li><p><code>grad(self, ctx=None)</code> 获取这个参数在设备<code>ctx</code>上的梯度值。<br>　　ctx : 指定设备</p></li><li><p><code>initialize</code>(self, init=None, ctx=None,<br>　　default_init=&lt;mxnet.initializer.Uniform>,<br>　　force_reinit=False) 初始化参数和梯度向量<br>　　<code>init</code> : Initializer 初始化参数的值<br>　　<code>ctx</code> : 设备/设备列表, 默认使用:py:meth:<code>context.current_context()</code>.<br>　　<code>default_init</code> : Initializer 当:py:func:<code>init</code>和:py:meth:<code>Parameter.init</code>都为none时，使用该默认的初始化.<br>　　<code>force_reinit</code> : bool, default False 当参数已经被初始化，是否再次初始化。</p></li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>weight <span style=color:#f92672>=</span> mx<span style=color:#f92672>.</span>gluon<span style=color:#f92672>.</span>Parameter(<span style=color:#e6db74>&#39;weight&#39;</span>, shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>))
weight<span style=color:#f92672>.</span>initialize(ctx<span style=color:#f92672>=</span>mx<span style=color:#f92672>.</span>cpu(<span style=color:#ae81ff>0</span>))
weight<span style=color:#f92672>.</span>data()
<span style=color:#75715e>#　　[[-0.01068833  0.01729892]</span>
<span style=color:#75715e>#　　 [ 0.02042518 -0.01618656]]</span>
<span style=color:#75715e>#　　&lt;NDArray 2x2 @cpu(0)&gt;</span>
weight<span style=color:#f92672>.</span>grad()
<span style=color:#75715e>#　　[[ 0.  0.]</span>
<span style=color:#75715e>#　　 [ 0.  0.]]</span>
<span style=color:#75715e>#　　&lt;NDArray 2x2 @cpu(0)&gt;</span>
weight<span style=color:#f92672>.</span>initialize(ctx<span style=color:#f92672>=</span>[mx<span style=color:#f92672>.</span>gpu(<span style=color:#ae81ff>0</span>), mx<span style=color:#f92672>.</span>gpu(<span style=color:#ae81ff>1</span>)])
weight<span style=color:#f92672>.</span>data(mx<span style=color:#f92672>.</span>gpu(<span style=color:#ae81ff>0</span>))
<span style=color:#75715e>#　　[[-0.00873779 -0.02834515]</span>
<span style=color:#75715e>#　　 [ 0.05484822 -0.06206018]]</span>
<span style=color:#75715e>#　　&lt;NDArray 2x2 @gpu(0)&gt;</span>
weight<span style=color:#f92672>.</span>data(mx<span style=color:#f92672>.</span>gpu(<span style=color:#ae81ff>1</span>))
<span style=color:#75715e>#　　[[-0.00873779 -0.02834515]</span>
<span style=color:#75715e>#　　 [ 0.05484822 -0.06206018]]</span>
<span style=color:#75715e>#　　&lt;NDArray 2x2 @gpu(1)&gt;</span>
</code></pre></div><ul><li><code>list_ctx(self)</code> 返回参数初始化在那些设备上</li><li><code>list_data(self)</code> 按照顺序返回所有设备上的参数值
　　Returns: list of NDArrays</li><li><code>list_grad(self)</code> 按照顺序返回所有设备上的梯度值</li><li><code>list_row_sparse_data(self, row_id)</code> 按照顺序返回所有设备上的 <code>行稀疏</code>的参数。<br>　　row_id: 指定看哪一行的数据<br>　　Returns: list of NDArrays</li><li><code>reset_ctx(self, ctx)</code> 重新设定设备，把参数copy到该设备上<br>　　ctx : Context or list of Context, default <code>context.current_context()</code></li><li><code>row_sparse_data(self, row_id)</code><br>　　row_id: NDArray 指定看哪一行的数据<br>　　Returns: NDArray on row_id&rsquo;s context</li><li><code>set_data(self, data)</code> 在所有设备上，设置该参数的值。</li><li><code>var(self)</code> 返回一个代表该参数的符号</li><li><code>zero_grad(self)</code> 将所有设备上的梯度缓存清零</li></ul><p>数据描述:<br>——————————</p><ul><li><code>dtype</code> 参数的数据类型</li><li><code>grad_req</code></li><li><code>shape</code> 参数的尺寸</li></ul></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>模型参数-访问</span></h5><div class=card><div class=card-body><p><code>ToTensor</code>：将图像数据从uint8格式变换成32位浮点数格式，并除以255使得所有像素的数值均在0到1之间</p><code>transform_first函数</code>：数据集的函数。将<code>ToTensor</code>的变换应用在每个数据样本（图像和标签）的第一个元素，即图像之上.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
<span style=color:#f92672>from</span> mxnet.gluon <span style=color:#f92672>import</span> nn

</code></pre></div></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>网络设计</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
<span style=color:#f92672>from</span> mxnet.gluon <span style=color:#f92672>import</span> nn
</code></pre></div></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>模型初始化</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
<span style=color:#f92672>from</span> mxnet.gluon <span style=color:#f92672>import</span> nn
</code></pre></div></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>模型初始化</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
<span style=color:#f92672>from</span> mxnet.gluon <span style=color:#f92672>import</span> nn
</code></pre></div></div></div></div></div></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/imagesloaded.pkgd.min.js></script><script src=/js/note.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>