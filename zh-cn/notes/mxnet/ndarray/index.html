<!doctype html><html><head><title>NdArray</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="NdArray"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/notes.css><link rel=stylesheet href=/css/navigators/sidebar.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="flag-icon flag-icon-zh-cn"></span>简体中文</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/notes/mxnet/ndarray><span class="flag-icon flag-icon-gb"></span>English</a></div></li><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/notes data-filter=all>笔记</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/notes/computer_algorithm/>Computer Algorithm</a><ul><li><a href=/zh-cn/notes/computer_algorithm/0010_data_struct/ title=数据结构>数据结构</a></li><li><a href=/zh-cn/notes/computer_algorithm/0015_comm_ideas/ title=常见算法思路>常见算法思路</a></li><li><a href=/zh-cn/notes/computer_algorithm/0020_tree_search/ title=二叉树-遍历>二叉树-遍历</a></li><li><a href=/zh-cn/notes/computer_algorithm/0030_five_algorithms/ title=五大常用算法>五大常用算法</a></li><li><a href=/zh-cn/notes/computer_algorithm/0040_sliding_window/ title=滑动窗口>滑动窗口</a></li><li><a href=/zh-cn/notes/computer_algorithm/0050_graph_search/ title=图的搜索>图的搜索</a></li><li><a href=/zh-cn/notes/computer_algorithm/0450_leedcode_classic.zh-ch/ title=LeedCode-经典>LeedCode-经典</a></li><li><a href=/zh-cn/notes/computer_algorithm/0500_leedcode_list/ title=LeedCode刷库记录>LeedCode刷库记录</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/notes/mxnet/>MxNet</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/notes/mxnet/ndarray/>NdArray</a><ul class=active><li><a href=/zh-cn/notes/mxnet/ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li><li><a href=/zh-cn/notes/mxnet/ndarray/0020_technic_gather/ title=NdArray技巧搜集>NdArray技巧搜集</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/notes/mxnet/gluon/>Gluon</a><ul><li><a href=/zh-cn/notes/mxnet/gluon/0010_gluon_summary/ title=Gluon实例>Gluon实例</a></li><li><a href=/zh-cn/notes/mxnet/gluon/0020_module_gather/ title=Gluon模块简介>Gluon模块简介</a></li><li><a href=/zh-cn/notes/mxnet/gluon/0030_module_gluon_nn/ title=Gluon-nn模块>Gluon-nn模块</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid note-card-holder" id=note-card-holder><div class=note-card><div class=item><h5 class=note-title><span>查阅文档</span></h5><div class=card><div class=card-body><p>怎么查阅相关文档？ <a href=https://mxnet.apache.org/ target=blank>官网</a></p><h3 id=1-查阅模块里的所有函数和类>1. 查阅<code>模块</code>里的所有函数和类</h3><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
<span style=color:#66d9ef>print</span>(dir(nd<span style=color:#f92672>.</span>random))
</code></pre></div><ol><li>__开头和结尾的函数 (python的特别对象) 可以忽略</li><li>_开头的函数 (一般为内部函数) 可以忽略</li><li>其余成员，可以根据名字 大致猜出是什么意思。</li></ol><h3 id=2-查阅特定函数和类的使用>2. 查阅特定<code>函数和类</code>的使用</h3><p>想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>help(nd<span style=color:#f92672>.</span>ones_like)
</code></pre></div><p>注意：</p></p><ol><li>jupyter记事本里，使用<code>?</code>来将文档显示在另外一个窗口中。例如：<code>nd.ones_like?</code> 与 <code>help(nd.ones_like)</code>效果一样。<code>nd.ones_like??</code>会额外显示该函数实现的代码。</li></ol></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>内存开销</span></h5><div class=card><div class=card-body><ol><li><p>原始操作</p>首先来个例子：Y = Y + X &ndash;> 每个操作会新开内存来存储运算结果。
上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。
内存使用情况：</p>内存id_x &lt;&ndash; X</p>内存id_y &lt;&ndash; Y</p>内存id_x+y &lt;&ndash; Y</p></li><li><p>Y[:] = X + Y 或者 Y += X</p>通过<code>[:]</code>把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。
内存使用情况：</p>内存id_x &lt;&ndash; X</p>内存id_y &lt;&ndash; Y</p>内存id_x+y &ndash;> 把<code>内存id_x+y</code>中数值复制到<code>内存id_y</code>中</p></li><li><p>使用运算符全名函数中的out参数</p>可以避免临时内存开销，使用运算符全名函数：<code>nd.elemwise_add(X, Y, out=Y)</code>。内存使用情况：</p>内存id_x &lt;&ndash; X</p>内存id_y &lt;&ndash; Y</p>内存id_y &lt;&ndash; 直接存放 X+Y 的计算结果</p></li></ol></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>自动求梯度</span></h5><div class=card><div class=card-body><p>MXNet提供的autograd模块，可以自动求梯度(gradient)</p></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> autograd, nd
<span style=color:#75715e># 1. 创建变量 x，并赋初值</span>
x <span style=color:#f92672>=</span> nd<span style=color:#f92672>.</span>arrange(<span style=color:#ae81ff>4</span>)<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>1</span>))
<span style=color:#75715e># 2. 为了求变量x的梯度，先调用attach_grad函数来申请存储梯度所需要的内存 </span>
x<span style=color:#f92672>.</span>attach_grad()
<span style=color:#75715e># 3. 为了减少计算和内存开销，默认条件下MXNet是不会记录：求梯度的计算，</span>
<span style=color:#75715e>#    需要调用record函数来要求MXNet记录与求梯度有关的计算。</span>
<span style=color:#66d9ef>print</span>(autograd<span style=color:#f92672>.</span>is_training())    <span style=color:#75715e># False</span>
<span style=color:#66d9ef>with</span> autograd<span style=color:#f92672>.</span>record():
  <span style=color:#66d9ef>print</span>(autograd<span style=color:#f92672>.</span>is_training())  <span style=color:#75715e># True</span>
  y <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>nd<span style=color:#f92672>.</span>dot(x<span style=color:#f92672>.</span>T, x)
<span style=color:#75715e># 4. 调用backward函数自动求梯度。y必须是一个标量，</span>
<span style=color:#75715e>#  如果y不是标量：MXNet会先对y中元素求和，然后对该和值求有关x的梯度</span>
y<span style=color:#f92672>.</span>backward() 

</code></pre></div><p>注意：</p></p><ol><li>在调用record函数后，MXNet会记录并计算梯度；</li><li>默认情况下，autograd会改变运行模式：从预测模式转为训练模式。可以通过调用is_training函数来查看。</li></ol></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>样例</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
</code></pre></div></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>sum/mean等操作 - 保留原维度数</span></h5><div class=card><div class=card-body><p><code>keepdims</code>: 保留原维度数。例如：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>softmax</span>(X):
    X_exp <span style=color:#f92672>=</span> X<span style=color:#f92672>.</span>exp()  <span style=color:#75715e># shape = (n, m)</span>
    <span style=color:#75715e># shape = (n, 1) 而并不是 (n,)</span>
    partition <span style=color:#f92672>=</span> X_exp<span style=color:#f92672>.</span>sum(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, keepdims<span style=color:#f92672>=</span>True)  
    <span style=color:#66d9ef>return</span> X_exp <span style=color:#f92672>/</span> partition  <span style=color:#75715e># 这里应用了广播机制</span>
X <span style=color:#f92672>=</span> nd<span style=color:#f92672>.</span>random<span style=color:#f92672>.</span>normal(shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>5</span>))
X_prob <span style=color:#f92672>=</span> softmax(X)

</code></pre></div></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>B的值作为A的索引 - 取值</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
y_hat <span style=color:#f92672>=</span> nd<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>0.1</span>, <span style=color:#ae81ff>0.3</span>, <span style=color:#ae81ff>0.6</span>], [<span style=color:#ae81ff>0.3</span>, <span style=color:#ae81ff>0.2</span>, <span style=color:#ae81ff>0.5</span>]])
y <span style=color:#f92672>=</span> nd<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>], dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;int32&#39;</span>)
nd<span style=color:#f92672>.</span>pick(y_hat, y)
<span style=color:#75715e># 结果: [0.1, 0.5]</span>

<span style=color:#75715e># 应用的实例：交叉熵的实现</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>cross_entropy</span>(y_hat, y):
    <span style=color:#66d9ef>return</span> <span style=color:#f92672>-</span>nd<span style=color:#f92672>.</span>pick(y_hat, y)<span style=color:#f92672>.</span>log()
</code></pre></div></div></div></div></div><div class=note-card><div class=item><h5 class=note-title><span>样例</span></h5><div class=card><div class=card-body><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> mxnet <span style=color:#f92672>import</span> nd
</code></pre></div></div></div></div></div></div><div class=paginator></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/imagesloaded.pkgd.min.js></script><script src=/js/note.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>