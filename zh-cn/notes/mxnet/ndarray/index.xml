<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NdArray on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/</link><description>Recent content in NdArray on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><atom:link href="https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/index.xml" rel="self" type="application/rss+xml"/><item><title>NdArray使用</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0010_ndarray_summary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0010_ndarray_summary/</guid><description>查阅文档 怎么查阅相关文档？ 官网
1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random)) __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。 2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。
help(nd.ones_like) 注意：
jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。 内存开销 原始操作 首先来个例子：Y = Y + X &amp;ndash;&amp;gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：
内存id_x &amp;lt;&amp;ndash; X 内存id_y &amp;lt;&amp;ndash; Y 内存id_x+y &amp;lt;&amp;ndash; Y
Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x &amp;lt;&amp;ndash; X 内存id_y &amp;lt;&amp;ndash; Y 内存id_x+y &amp;ndash;&amp;gt; 把内存id_x+y中数值复制到内存id_y中</description></item><item><title>NdArray技巧搜集</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0020_technic_gather/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0020_technic_gather/</guid><description>sum/mean等操作 - 保留原维度数 keepdims: 保留原维度数。例如：
from mxnet import nd def softmax(X): X_exp = X.exp() # shape = (n, m) # shape = (n, 1) 而并不是 (n,) partition = X_exp.sum(axis=1, keepdims=True) return X_exp / partition # 这里应用了广播机制 X = nd.random.normal(shape=(2, 5)) X_prob = softmax(X) B的值作为A的索引 - 取值 from mxnet import nd y_hat = nd.array([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) y = nd.array([0, 2], dtype=&amp;#39;int32&amp;#39;) nd.pick(y_hat, y) # 结果: [0.</description></item></channel></rss>