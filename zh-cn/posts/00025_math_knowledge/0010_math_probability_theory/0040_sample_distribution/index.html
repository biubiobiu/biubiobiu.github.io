<!doctype html><html><head><title>样本及抽样分布</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="样本及抽样分布"><meta property="og:description" content="-- 前面介绍了概率论的基本内容，接下来以概率论为基础，根据试验或观察得到的数据，来研究随机现象，对研究对象的客观规律性做出种种合理的估计和判断。
数理统计：的内容包括：如何收集、整理数据资料；如何对所得的数据资料进行分析、研究，从而对研究的对象的性质、特点做出判断。在数理统计中，我们研究的随机变量，其分布是未知的，或者是不完全知道的。人们是通过对所研究的随机变量进行重复独立的观察，得到许多观察值，对这些数据进行分析，从而对所研究的随机变量的分布作出种种推断。
一、随机样本 总体：试验的全部可能的观察值。
个体：每一个可能观察值。
容量：总体中所包含的个体的个数。
定义：
设 $X$ 是具有分布函数 $F$ 的随机变量，若 $X_1, X_2, &mldr;, X_n$ 是具有同一分布函数 $F$ 的相互独立的随机变量，则称 $X_1, X_2, &mldr;, X_n$ 为从分布函数 $F$ (或者总体 $F$、或 总体 $X$) 得到的容量为 $n$ 的简单随机样本，简称 样本。它们的观察值 $x_1, x_2, &mldr;, x_n$ 称为样本值，又称为 $X$ 的 $n$ 个独立的观察值。
也可以将样本看成是一个随机向量，写成 $(X_1, X_2, &mldr;, X_n)$。由定义得：若 $X_1, X_2, &mldr;, X_n$ 为 $F$ 的一个样本，则 $X_1, X_2, &mldr;, X_n$ 相互独立，且它们的分布函数都是 $F$ ，所以 $(X_1, X_2, &mldr;, X_n)$ 的分布函数为： $$ F^*(x_1, x_2, &mldr;, x_n) = \prod^n_{i=1} F(x_i) $$"><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/"><meta property="article:published_time" content="2023-08-01T06:00:20+08:00"><meta property="article:modified_time" content="2023-08-01T06:00:20+08:00"><meta name=description content="样本及抽样分布"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00020_toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/00020_toha-tutorial/0010_toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00025_math_knowledge/>数学知识</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/>概率论</a><ul class=active><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/ title=基本概念>基本概念</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/ title=随机变量及其分布>随机变量及其分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/ title=大数定律>大数定律</a></li><li><a class=active href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/ title=样本及抽样分布>样本及抽样分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/ title=假设检验>假设检验</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/ title=方差分析及回归分析>方差分析及回归分析</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/ title=随机过程>随机过程</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/ title=马尔科夫链>马尔科夫链</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/ title=平稳随机过程>平稳随机过程</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/>凸优化</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/ title=基本概念>基本概念</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00030_deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/ title=深度学习开篇>深度学习开篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/ title=深度学习-结构>深度学习-结构</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0015_deeplearning_norm/ title=归一化>归一化</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0020_deeplearing_init/ title=初始化>初始化</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0200_cam/ title=CAM>CAM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00033_reinforce/>强化学习</a><ul><li><a href=/zh-cn/posts/00033_reinforce/0001_reinforce_summary/ title=综述>综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/>env</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/ title=py-env>py-env</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/ title=cuda>cuda</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ title=内置模块>内置模块</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/ title=进阶操作>进阶操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/ title=异常>异常</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/ title=文件读取>文件读取</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/ title=importlib>importlib</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/ title=ipdb>ipdb</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/ title=正则-re>正则-re</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/ title=堆-heapq>堆-heapq</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/ title=requests>requests</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/ title=logging>logging</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/ title=argparse>argparse</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/ title=PIL>PIL</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/ title=OpenCV>OpenCV</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/ title=Tensor和变量>Tensor和变量</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0070_hive/>数据库</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0070_hive/0010_sql/ title=MySQL>MySQL</a></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0070_hive/0020_hive/>Hive</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0070_hive/0020_hive/0010_hive_build/ title=创建库/表>创建库/表</a></li><li><a href=/zh-cn/posts/00035_programming_language/0070_hive/0020_hive/0020_hive_func/ title=常见函数>常见函数</a></li><li><a href=/zh-cn/posts/00035_programming_language/0070_hive/0020_hive/0030_hive_common/ title=常用操作>常用操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0070_hive/0020_hive/0040_hive_datatype/ title=数据类型>数据类型</a></li><li><a href=/zh-cn/posts/00035_programming_language/0070_hive/0020_hive/0050_hive_regular/ title=正则匹配>正则匹配</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0010_backbone/>基础</a><ul><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0050_detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0060_image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0020_rnn/>RNN</a><ul><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0030_transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0001_attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/ title=Transformer>Transformer</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0030_position/ title=位置编码>位置编码</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0080_gpt/>GPT</a><ul><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/ title=GPT综述>GPT综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/ title=GPT-1>GPT-1</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0100_bert/>Bert</a><ul><li><a href=/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/ title=Bert综述>Bert综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/ title=Bert家族>Bert家族</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0120_t5/>T5</a><ul><li><a href=/zh-cn/posts/00200_nlp/0120_t5/0010_t5_summary/ title=T5综述>T5综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0150_bart/>BART</a><ul><li><a href=/zh-cn/posts/00200_nlp/0150_bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0200_electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/00200_nlp/0200_electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/1000_code/>CODE</a><ul><li><a href=/zh-cn/posts/00200_nlp/1000_code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/>AIGC</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0005_summary/>AIGC综述</a><ul><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/ title=综述>综述</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0002_aigc_data/ title=LLM-数据集>LLM-数据集</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/ title=模型应用策略>模型应用策略</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/ title=大模型训练框架>大模型训练框架</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/ title=混合精度训练>混合精度训练</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/ title=模型小型化>模型小型化</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/ title=生成式-问题>生成式-问题</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0025_aigc_eval/ title=生成模型-评估>生成模型-评估</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0010_generate_text/>文本生成</a><ul><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/ title=GPT>GPT</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/ title=LLaMa>LLaMa</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/ title=PaLM>PaLM</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/ title=ChatGLM>ChatGLM</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/ title=Claude>Claude</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/ title=Cohere>Cohere</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/ title=Falcon>Falcon</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/ title=Vicuna>Vicuna</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0020_generate_image/>图像生成</a><ul><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1000_summary/ title=综述>综述</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1002_gan_summary/ title=GAN>GAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/ title=CAN>CAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/ title=DALL-E>DALL-E</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/ title=VQGAN>VQGAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/ title=Diffusion>Diffusion</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/ title=Midjourney>Midjourney</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/ title=Imagen>Imagen</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00400_vlp/>多模态</a><ul><li><a href=/zh-cn/posts/00400_vlp/0001_vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00400_vlp/0005_clip/ title=CLIP>CLIP</a></li><li><a href=/zh-cn/posts/00400_vlp/0010_mllm/ title=MLLM>MLLM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00500_video/>视频理解</a><ul><li><a href=/zh-cn/posts/00500_video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>August 1, 2023</p></div><div class=title><h1>样本及抽样分布</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/%E6%A6%82%E7%8E%87%E8%AE%BA class="btn, btn-sm">概率论</a></li><li class=rounded><a href=/zh-cn/tags/%E9%87%87%E6%A0%B7 class="btn, btn-sm">采样</a></li><li class=rounded><a href=/zh-cn/tags/%E5%88%86%E5%B8%83 class="btn, btn-sm">分布</a></li></ul></div><div class=post-content id=post-content><p>前面介绍了概率论的基本内容，接下来以概率论为基础，根据试验或观察得到的数据，来研究随机现象，对研究对象的客观规律性做出种种合理的估计和判断。</p><p><font color=#f00000>数理统计</font>：的内容包括：如何收集、整理数据资料；如何对所得的数据资料进行分析、研究，从而对研究的对象的性质、特点做出判断。在数理统计中，我们研究的随机变量，其分布是未知的，或者是不完全知道的。人们是通过对所研究的随机变量进行重复独立的观察，得到许多观察值，对这些数据进行分析，从而对所研究的随机变量的分布作出种种推断。</p><h2 id=一随机样本>一、随机样本</h2><div class="alert alert-info"><strong><p><strong>总体</strong>：试验的全部可能的观察值。<br><strong>个体</strong>：每一个可能观察值。<br><strong>容量</strong>：总体中所包含的个体的个数。<br></p><p><strong>定义</strong>：<br>设 $X$ 是具有分布函数 $F$ 的随机变量，若 $X_1, X_2, &mldr;, X_n$ 是具有同一分布函数 $F$ 的相互独立的随机变量，则称 $X_1, X_2, &mldr;, X_n$ 为从分布函数 $F$ (或者总体 $F$、或 总体 $X$) 得到的<font color=#f00000>容量为 $n$ 的简单随机样本</font>，简称 <font color=#f00000>样本</font>。它们的观察值 $x_1, x_2, &mldr;, x_n$ 称为<font color=#f00000>样本值</font>，又称为 $X$ 的 $n$ 个独立的<font color=#f00000>观察值</font>。<br></p><p>也可以将样本看成是一个随机向量，写成 $(X_1, X_2, &mldr;, X_n)$。由定义得：若 $X_1, X_2, &mldr;, X_n$ 为 $F$ 的一个样本，则 $X_1, X_2, &mldr;, X_n$ 相互独立，且它们的分布函数都是 $F$ ，所以 $(X_1, X_2, &mldr;, X_n)$ 的分布函数为：
$$
F^*(x_1, x_2, &mldr;, x_n) = \prod^n_{i=1} F(x_i)
$$</p><p>概率密度函数：
$$
f^*(x_1, x_2, &mldr;, x_n) = \prod^n_{i=1} f(x_i)
$$</p></strong></div><h2 id=二抽样分布>二、抽样分布</h2><p>样本是进行统计推断的依据，在应用时，往往不是直接使用样本本身，而是针对不同的问题构造样本的适当函数，利用这些样本的函数进行统计推断。<br></p><div class="alert alert-info"><strong><p><font color=#a020f0>定义</font>:<br>设 $X_1, X_2, &mldr;, X_n$ 是来自总体 $X$ 的一个样本，$g(X_1, X_2, &mldr;, X_n)$ 是 $X_1, X_2, &mldr;, X_n$ 的函数，若 $g$ 函数中不含未知参数，则称 $g(X_1, X_2, &mldr;, X_n)$ 是一<font color=#f00000>统计量</font><br></p><p>即：统计量 $g(X_1, X_2, &mldr;, X_n)$ 是随机变量 $X_1, X_2, &mldr;, X_n$ 的函数，因此，统计量是一个随机变量。<br></p><p>设：$x_1, x_2, &mldr;, x_n$ 是相应样本 $X_1, X_2, &mldr;, X_n$ 的样本值，则称 $g(x_1, x_2, &mldr;, x_n)$ 是 $g(X_1, X_2, &mldr;, X_n)$ 的观察值。<br></p><p><font color=#a020f0>常用的统计量</font>:<br></p><p><font color=#f00000>样本均值</font>
$$
\bar{X} = \frac{1}{n} \sum^n_{i=1} X_i
$$</p><p><font color=#f00000>样本方差</font>
$$
S^2 = \frac{1}{n-1} \sum^n_{i=1} (X_i - \bar{X})^2 = \frac{1}{n-1} (\sum^n_{i=1} X^2_i - n \bar{X}^2)
$$</p><p><font color=#f00000>样本标准层</font>
$$
S = \sqrt{S^2} = \sqrt{\frac{1}{n-1} (\sum^n_{i=1} X^2_i - n \bar{X}^2)}
$$</p><p><font color=#f00000>样本 $k$ 阶(原点)矩</font>
$$
A_k = \frac{1}{n} \sum^n_{i=1} X^k_i, k = 1, 2, &mldr;
$$
若：总体 $X$ 的 $k$ 阶矩 $E(X^k) \overset{\mathrm{记作}}{==} \mu_k$<br>则：由辛钦大数定理知：当 $n \to \infty$ 时，$A_k \overset{\mathrm{P}}{\to} \mu_k, k=1, 2, &mldr;$<br>依概率收敛的序列的性质知道：$g(A_1, A_2, &mldr;, A_k) \overset{\mathrm{P}}{\to} g(\mu_1, \mu_2, &mldr;, \mu_k)$。其中，$g$ 为连续函数。这就是 <font color=#f00000>矩估计法</font> 的理论基础。</p><p><font color=#f00000>样本 $k$ 阶中心矩</font>
$$
B_k = \frac{1}{n} \sum^n_{i=1}(X_i - \bar{X})^k, k = 2, 3, &mldr;
$$</p></strong></div><hr><div class="alert alert-success"><strong><p><font color=#a020f0>经验分布函数</font> ：与 总体分布函数$F(x)$ 相应的统计量<br>它的作法如下：<br>设：$X_1, X_2, &mldr;, X_n$ 是 总体 $F$ 的一个样本，用 $S(x), -\infty &lt; x &lt; \infty$ 表示 $X_1, X_2, &mldr;, X_n$ 中不大于 $x$ 的随机变量的个数。定义 经验分布函数 $F_n(x)$ 为
$$
F_n(x) = \frac{1}{n} S(x), -\infty &lt; x &lt; \infty
$$</p><p>对于一个样本值，其经验分布函数 $F_n(x)$ 的观察值是很容易得到的。<br></p><p>格里汶科（Glivenko）在1933年证明了一下结论：<br>对于任一实数 $x$，当 $n \to \infty$ 时，$F_n(x)$ 以概率 1 一致收敛于分布函数 $F(x)$，即：
$$
P\{ \lim\limits_{n \to \infty} sup_{-\infty &lt; x &lt; \infty} |F_n(x) - F(x)| = 0 \} = 1
$$</p><p>因此，对于任一实数 $x$ 当 $n$ 充分大时，经验分布函数的任一个观察值 $F_n(x)$ 与总体分布函数 $F(x)$ 只有微小的差别，从而在实际上可当做 $F(x)$ 来使用。</p></strong></div><hr><div class="alert alert-info"><strong><p>统计量的分布 称为 <font color=#f00000>抽样分布</font><br></p><ol><li>当总体的分布函数已知时，抽样分布是确定的，然而要求出统计量的精确分布，一般来说比较困难。</li><li>使用统计量进行统计推断时，常需知道它的分布。</li></ol><p>下面介绍来自正态总体的几个常用统计量的分布：</p></strong></div><h3 id=1chi2分布>1、$\chi^2$分布</h3><p>设 $X_1, X_2, &mldr;, X_n$ 是来自总体 $N(0, 1)$ 的样本，则称统计量：
$$
\chi^2 = X_1^2 + X_2^2 + &mldr; + X_n^2
$$</p><p>服从自由度为 $n$ 的 $\chi^2$ 分布，记为 $\chi^2 \sim \chi^2(n)$<br></p><p>$\chi^2(n)$ 分布的概率密度为
$$
f(y) = \begin{cases} \frac{1}{2^{\frac{n}{2}} \Gamma(\frac{n}{2})} y^{\frac{n}{2}-1} e^{-\frac{y}{2}} & y > 0 \\ 0 & 其他 \end{cases}
$$</p><p>图形如下图：</p><p align=center><img src=/datasets/posts/maths/chi_n.png width=60% height=60%></p><div class="alert alert-success"><strong><p>由：$\chi^2(1)$ 分布，就是 $\Gamma(\frac{1}{2}, 2)$ 分布<br></p><p>由：定义 $X_i^2 \sim \chi^2(1)$，即：$X_i^2 \sim \Gamma(\frac{1}{2}, 2), i = 1, 2, &mldr;, n$<br></p><p>由：$X_1, X_2, &mldr;, X_n$ 的独立性知，$X^2_1, X^2_2, &mldr;, X^2_n$ 相互独立<br></p><p>由：$\Gamma$ 分布的可加性。<br></p><p>可得：
$$
\chi^2 = \sum^n_{i=1} X^2_i \sim \Gamma(\frac{n}{2}, 2)
$$</p><p>根据 $\Gamma$ 分布的可加性，得 $\chi^2$ 分布的可加性如下：</p><ol><li><p><font color=#f00000>$\chi^2$ 分布的可加性</font>：设 $\chi^2_1 \sim \chi^2(n_1), \chi^2_2 \sim \chi^2(n_2)$，并且 $\chi^2_1, \chi^2_2$ 相互独立，则有：$\chi^2_1 + \chi^2_2 \sim \chi^2(n_1 + n_2) \sim \Gamma(\frac{n_1+n_2}{2}, 2)$</p></li><li><p><font color=#f00000>$\chi^2$ 分布的期望和方差</font>：若 $\chi^2 \sim \chi^2(n)$，则有<br>$E(\chi^2) = n, D(\chi^2) = 2n$</p></li><li><p><font color=#f00000>$\chi^2$ 分布的分位点</font>：对于给定的正数 $\alpha, 0 &lt; \alpha &lt; 1$ ，如果满足条件
$$
P\{ \chi^2 > \chi^2_\alpha(n) \} = \int^\infty_{\chi^2_\alpha(n)} f(y) dy = \alpha
$$
则，点 $\chi^2_\alpha(n)$ 为 $\chi^2(n)$ 分布的上 $\alpha$ 分位点，如图所示：<p align=center><img src=/datasets/posts/maths/chi_0.png width=40% height=40%></p>费希尔(R.A.Fisher)曾证明，当 $n$ 充分大时，近似地有
$$
\chi^2_\alpha(n) \approx \frac{1}{2}(z_\alpha + \sqrt{2n-1})^2
$$
其中，$z_\alpha$ 是标准正态分布的上 $\alpha$ 分位点。</p></li></ol></strong></div><h3 id=2t-分布>2、$t$ 分布</h3><p>设 $X \sim N(0, 1), Y \sim \chi^2(n)$ ，且 $X, Y$ 相互独立，则称<font color=#f00000>随机变量 $t = \frac{X}{\sqrt{Y/n}}$ 服从自由度为 $n$ 的 $t$ 分布</font>，记为 $t \sim t(n)$<br></p><p>$t$ 分布 又称学生式(Student) 分布，$t(n)$ 分布的概率密度函数为：
$$
h(t) = \frac{\Gamma[\frac{n+1}{2}]}{\sqrt{n\pi} \Gamma[\frac{n}{2}]} (1+\frac{t^2}{n})^{-\frac{n+1}{2}}, -\infty &lt; t &lt; \infty
$$</p><p align=center><img src=/datasets/posts/maths/t_nor.png width=50% height=50%></p><p>从图中可以看到，$h(t)$ 的图形是关于 $t=0$ 对称，当$n$ 充分大时，$t$ 分布近似于 $N(0, 1)$ 分布。即：
$$
\lim\limits_{n \to \infty} h(t) = \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}}
$$</p><p><font color=#f00000>$t$ 分布的分位点</font>：当 $n > 45$时，对于常数为 $\alpha$ 的值，就用正态近似
$$
t_\alpha(n) \approx z_\alpha
$$</p><p align=center><img src=/datasets/posts/maths/t_nor_0.png width=50% height=50%></p><h3 id=3f-分布>3、$F$ 分布</h3><p>设 $U \sim \chi^2(n_1), V \sim \chi^2(n_2)$，且 $U, V$ 相互独立，则称随机变量 $F = \frac{U/n_1}{V/n_2}$ 服从自由度为 $(n_1, n_2)$ 的 $F$ 分布，记为 $F \sim F(n_1, n_2)$。<br></p><p>$F(n_1, n_2)$ 分布的概率密度为：
$$
\psi(y) = \begin{cases} \frac{\Gamma[\frac{n_1+n_2}{2}] \frac{n_1}{n_2} y^{\frac{n_1}{2}-1}}{\Gamma(\frac{n_1}{2}) \Gamma(\frac{n_2}{2}) [1+\frac{n_1y}{n_2}]^{\frac{n_1+n_2}{2}}}
& y > 0 \\ 0 & 其他 \end{cases}
$$</p><p>画出 $\psi(y)$ 的图形：</p><p align=center><img src=/datasets/posts/maths/psi_0.png width=50% height=50%></p><p><font color=#f00000>$F$ 分布的分位点</font>：有个重要额性质
$$
F_{1-\alpha}(n_1, n_2) = \frac{1}{F_\alpha(n_2, n_1)}
$$</p><p align=center><img src=/datasets/posts/maths/psi_1.png width=50% height=50%></p><h3 id=4正态总体的样本均值样本方差的分布>4、正态总体的样本均值/样本方差的分布</h3><p>设 总体 $X$ （不管服从什么分布，只要均值和方差都存在）的均值为 $\mu$，方差为 $\sigma^2$。<br>$X_1, X_2, &mldr;, X_n$ 是来自 $X$ 的一个样本，其中，$\bar{X}$ ：样本均值；$S^2$ ：样本方差。<br>则：
$$
E(\bar{X}) = \mu, D(\bar{X}) = \frac{\sigma^2}{n}
$$
而
$$
E(S^2) = E[\frac{1}{n-1}(\sum^n_{i=1}X_i^2 - n\bar{X}^2)] = \frac{1}{n-1} [\sum^n_{i=1}E(X^2_i) - n E(\bar{X}^2)] = \frac{1}{n-1} [\sum^n_{i=1}(\sigma^2 + \mu^2) - n(\frac{\sigma^2}{n} + \mu^2)] = \sigma^2
$$</p><div class="alert alert-success"><strong><p>设 $X \sim N(\mu, \sigma^2)$ ，则 $\bar{X} = \frac{1}{n} \sum^n_{i=1}X_i$ 也服从正态分布，有以下定理：<br></p><p><font color=#a020f0>定理一</font>：<br>设 $X_1, X_2, &mldr;, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，$\bar{X}$ 是样本均值，则有
$$
\bar{X} \sim N(\mu, \frac{\sigma^2}{n})
$$</p><p><font color=#a020f0>定理二</font>：<br>设 $X_1, X_2, &mldr;, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，$\bar{X}$ 是样本均值，$S^2$ 是样本方差，则 $\bar{X}$ 与 $S^2$ 相互独立。 且
$$
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$</p><p><font color=#a020f0>定理三</font>：<br>设 $X_1, X_2, &mldr;, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，$\bar{X}$ 是样本均值，$S^2$ 是样本方差，则有
$$
\frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)
$$
证明 由
$$
\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim N(0, 1), \frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)
$$</p><p><font color=#a020f0>定理四</font>：<br>设 $X_1, X_2, &mldr;, X_{n_1}$ 与 $Y_1, Y_2, &mldr;, Y_{n_2}$ 分别是来自正态总体 $N(\mu_1, \sigma^2_1)$ 和 $N(\mu_2, \sigma^2_2)$ 的样本，且这两个样本相互独立。<br></p><p>设 样本均值：$\bar{X} = \frac{1}{n_1} \sum^{n_1}_{i=1} X_i$<br></p><p>样本均值：$\bar{Y} = \frac{1}{n_2} \sum^{n_2}_{i=1} Y_i$<br></p><p>样本方差：$S^2_1 = \frac{1}{n_1 - 1} \sum^{n_1}_{i=1}(X_i - \bar{X})^2$<br></p><p>样本方差：$S^2_2 = \frac{1}{n_2 - 1} \sum^{n_2}_{i=1}(Y_i - \bar{Y})^2$<br></p><p>则有：$\frac{S_1^2 / S_2^2}{\sigma^2_1 / \sigma^2_2} \sim F(n_1 - 1, n_2 - 1)$<br></p><p>当 $\sigma^2_1 = \sigma^2_2 = \sigma^2$ 时：
$$
\frac{(\bar{X}-\bar{Y})-(\mu_1 - \mu_2)}{S_w \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \sim t(n_1 + n_2 -2)
$$</p><p>其中，$S^2_w = \frac{(n_1 - 1)S^2_1 + (n_2 - 1)S^2_2}{n_1 + n_2 - 2}$</p></strong></div></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00025_math_knowledge%2f0010_math_probability_theory%2f0040_sample_distribution%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00025_math_knowledge%2f0010_math_probability_theory%2f0040_sample_distribution%2f&text=%e6%a0%b7%e6%9c%ac%e5%8f%8a%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00025_math_knowledge%2f0010_math_probability_theory%2f0040_sample_distribution%2f&title=%e6%a0%b7%e6%9c%ac%e5%8f%8a%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00025_math_knowledge%2f0010_math_probability_theory%2f0040_sample_distribution%2f&title=%e6%a0%b7%e6%9c%ac%e5%8f%8a%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=%e6%a0%b7%e6%9c%ac%e5%8f%8a%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83 https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00025_math_knowledge%2f0010_math_probability_theory%2f0040_sample_distribution%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=%e6%a0%b7%e6%9c%ac%e5%8f%8a%e6%8a%bd%e6%a0%b7%e5%88%86%e5%b8%83&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00025_math_knowledge%2f0010_math_probability_theory%2f0040_sample_distribution%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/ title=大数定律 class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>大数定律</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/ title=假设检验 class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>假设检验</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一随机样本>一、随机样本</a></li><li><a href=#二抽样分布>二、抽样分布</a><ul><li><a href=#1chi2分布>1、$\chi^2$分布</a></li><li><a href=#2t-分布>2、$t$ 分布</a></li><li><a href=#3f-分布>3、$F$ 分布</a></li><li><a href=#4正态总体的样本均值样本方差的分布>4、正态总体的样本均值/样本方差的分布</a></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script><script src=/js/mermaid-8.14.0.min.js></script><script>mermaid.initialize({startOnLoad:true});</script></body></html>