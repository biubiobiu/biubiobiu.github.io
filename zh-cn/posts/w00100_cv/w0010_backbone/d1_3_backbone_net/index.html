<!doctype html><html><head><title>backbone net</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="backbone net"><meta property="og:description" content="卷积神经网络的发展历程：
一、Backbone 1. LeNet 论文
LeNet：名字来源于第一作者Yann LeCun。是一个奠基性的网络，第一次将卷积神经网络推上舞台。
 卷积层+最大池化：卷积层用来识别图像里的空间模式；最大池化用来降低卷积层对位置的敏感度。卷积层块由两个这样的基本单位重复堆叠构成。 LeNet可以在早起的小数据集上取得较好的效果，但是在更大的真实数据集上表现并不如人意。一方面：神经网络计算复杂，在GPU没有大量普及的20世纪90年代，训练一个多通道、多层、含有大量参数的卷积神经网络是很难完成的；另一方面：当年并没有深入研究参数初始化和非凸优化算法，导致复杂的神经网络的训练通常比较困难。 特征本身是由学习得来的，为了表征足够复杂的输入，特征本身应该分级表示。想要学习到复杂的多级特征，需要大量的带有标签的数据，这样才能表现得比其他经典方法要好。早期研究只基于小的公开数据集，自2009年ImageNet数据集创建以来，传统方法不再有优势。  输入：32*32  C1-卷积层：卷积层尺寸：6 * 28 * 28；卷积核尺寸：6 * 1 * 5 * 5；可训练参数：(5 * 5 + 1) * 6 S2-池化层：池化尺寸：2 * 2；步幅：2；方式：4个输入相加，然后乘以个可训练参数，加上个可训练参数，最后通过sigmoid；输出尺寸：6 * 14 * 14；可训练 参数：2 * 6 C3-卷积层：输出尺寸：16 * 10 * 10；卷积核尺寸: 16 * 6 * 5 * 5;
组合方式：前6个map - 以S2中3个相邻的feature map
再6个map - 以S2中4个相邻的feature map
再3个map - 以S2中不相邻的4个feature map
再1个map - 以S2中所有feature map   S4-池化层：输出尺寸：16 * 5 * 5；池化尺寸：2 * 2；步幅：2"><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/w00100_cv/w0010_backbone/d1_3_backbone_net/"><meta property="article:published_time" content="2021-09-09T06:00:20+06:00"><meta property="article:modified_time" content="2021-09-09T06:00:20+06:00"><meta name=description content="backbone net"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00020_toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/w00020_toha-tutorial/w0010_toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/w00020_toha-tutorial/w0011_write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/w00020_toha-tutorial/w0013_markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/w00020_toha-tutorial/w0015_latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/w00020_toha-tutorial/w0020_shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00025_math_knowledge/>数学知识</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/>概率论</a><ul><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0010_basic-conception/ title=基本概念>基本概念</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0020_distribution_of_variables/ title=随机变量及其分布>随机变量及其分布</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0030_law_of_large_numbers/ title=大数定律>大数定律</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0040_sample_distribution/ title=样本及抽样分布>样本及抽样分布</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0050_parameter_estimation/ title=假设检验>假设检验</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0060_analysis_variance_regression/ title=方差分析及回归分析>方差分析及回归分析</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0070_stochastic_process/ title=随机过程>随机过程</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0080_markov_process/ title=马尔科夫链>马尔科夫链</a></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0010_math_probability_theory/w0090_stationary_stochastic_process/ title=平稳随机过程>平稳随机过程</a></li></ul></li><li><a href=/zh-cn/posts/w00025_math_knowledge/w0020_math_convex_optimization_theory/ title=凸优化>凸优化</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00030_deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/w00030_deeplearning_summary/w0005_deeplearning_start/ title=深度学习开篇>深度学习开篇</a></li><li><a href=/zh-cn/posts/w00030_deeplearning_summary/w0010_draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/w00030_deeplearning_summary/w0020_cam/ title=CAM>CAM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0035_python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0020_internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0020_internal_lib/w0010_encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0020_internal_lib/w0020_basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0020_internal_lib/w0030_advance_operator/ title=进阶操作>进阶操作</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0050_sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0050_sdk_lib/w0020_multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0035_python/w0050_sdk_lib/w0030_importlib/ title=importlib>importlib</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0040_tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0040_tf/w0010_compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/w00035_programming_language/w0040_tf/w0010_compat/w0010_tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0040_tf/w0010_compat/w0020_tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0050_pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/w00035_programming_language/w0050_pytorch/w0010_torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0050_pytorch/w0020_basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0050_pytorch/w0030_mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0050_pytorch/w0040_tensor/ title=Tensor>Tensor</a></li><li><a href=/zh-cn/posts/w00035_programming_language/w0050_pytorch/w0050_train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0060_mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00035_programming_language/w0060_mxnet/w0010_ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/w00035_programming_language/w0060_mxnet/w0010_ndarray/w0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/w00100_cv/>CV</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/w00100_cv/w0010_backbone/>基础</a><ul class=active><li><a href=/zh-cn/posts/w00100_cv/w0010_backbone/d1_1_backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/w00100_cv/w0010_backbone/d1_2_optimizer/ title=optimizer>optimizer</a></li><li><a class=active href=/zh-cn/posts/w00100_cv/w0010_backbone/d1_3_backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00100_cv/w0020_contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/w00100_cv/w0020_contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00100_cv/w0030_vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/w00100_cv/w0030_vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00100_cv/w0050_detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/w00100_cv/w0050_detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00100_cv/w0055_semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/w00100_cv/w0055_semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00100_cv/w0060_image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/w00100_cv/w0060_image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/w00100_cv/w0060_image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0010_word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0010_word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0020_rnn/>RNN</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0020_rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/w00200_nlp/w0020_rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/w00200_nlp/w0020_rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/w00200_nlp/w0020_rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0030_transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0030_transformer/attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/w00200_nlp/w0030_transformer/transformer_summary/ title=Transformer>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0080_gpt/>GPT</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0080_gpt/gpt_summary/ title=GPT综述>GPT综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0100_bert/>Bert</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0100_bert/bert_summary/ title=Bert综述>Bert综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0150_bart/>BART</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0150_bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w0200_electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w0200_electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00200_nlp/w1000_code/>CODE</a><ul><li><a href=/zh-cn/posts/w00200_nlp/w1000_code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00300_aigc/>AIGC</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00300_aigc/w0010_aigc_summary/>简介</a><ul><li><a href=/zh-cn/posts/w00300_aigc/w0010_aigc_summary/a_aigc_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00300_aigc/w0020_diffusion_model/>Diffusion Model</a><ul><li><a href=/zh-cn/posts/w00300_aigc/w0020_diffusion_model/w10_diffusion_summary_/ title=模型介绍>模型介绍</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00400_vlp/>多模态</a><ul><li><a href=/zh-cn/posts/w00400_vlp/vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/w00400_vlp/clip/ title=CLIP>CLIP</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/w00500_video/>视频理解</a><ul><li><a href=/zh-cn/posts/w00500_video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>September 9, 2021</p></div><div class=title><h1>backbone net</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/backbone class="btn, btn-sm">backbone</a></li><li class=rounded><a href=/zh-cn/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C class="btn, btn-sm">卷积神经网络</a></li></ul></div><div class=post-content id=post-content><p>卷积神经网络的发展历程：</p><p align=center><img src=/datasets/posts/cnn/cnn_net_summary.jpg title=卷积神经网络 width=80% height=80% alt=卷积神经网络></p><h2 id=一backbone>一、Backbone</h2><h3 id=1-lenet>1. LeNet</h3><p><a href=https://www.researchgate.net/publication/2985446_Gradient-Based_Learning_Applied_to_Document_Recognition target=blank>论文</a></p><p>LeNet：名字来源于第一作者Yann LeCun。是一个奠基性的网络，第一次将卷积神经网络推上舞台。</p><ul><li>卷积层+最大池化：卷积层用来识别图像里的空间模式；最大池化用来降低卷积层对位置的敏感度。卷积层块由两个这样的基本单位重复堆叠构成。</li><li>LeNet可以在早起的小数据集上取得较好的效果，但是在更大的真实数据集上表现并不如人意。一方面：神经网络计算复杂，在GPU没有大量普及的20世纪90年代，训练一个多通道、多层、含有大量参数的卷积神经网络是很难完成的；另一方面：当年并没有深入研究参数初始化和非凸优化算法，导致复杂的神经网络的训练通常比较困难。</li><li>特征本身是由学习得来的，为了表征足够复杂的输入，<code>特征本身应该分级表示</code>。想要学习到复杂的多级特征，需要大量的带有标签的数据，这样才能表现得比其他经典方法要好。早期研究只基于小的公开数据集，自2009年ImageNet数据集创建以来，传统方法不再有优势。</li></ul><p align=center><img src=/datasets/posts/cnn/lenet.jpg title=LeNet alt=LeNet></p>输入：32*32<ul><li>C1-卷积层：卷积层尺寸：6 * 28 * 28；卷积核尺寸：6 * 1 * 5 * 5；可训练参数：(5 * 5 + 1) * 6</li><li>S2-池化层：池化尺寸：2 * 2；步幅：2；方式：4个输入相加，然后乘以个可训练参数，加上个可训练参数，最后通过sigmoid；输出尺寸：6 * 14 * 14；可训练 参数：2 * 6</li><li>C3-卷积层：输出尺寸：16 * 10 * 10；卷积核尺寸: 16 * 6 * 5 * 5;<br>　　　　　　组合方式：前6个map - 以S2中3个相邻的feature map<br>　　　　　　　　　　　再6个map - 以S2中4个相邻的feature map<br>　　　　　　　　　　　再3个map - 以S2中不相邻的4个feature map<br>　　　　　　　　　　　再1个map - 以S2中所有feature map</li></ul><p align=center><img src=/datasets/posts/cnn/lenet_1.png title=组合方式 alt=组合方式></p><ul><li>S4-池化层：输出尺寸：16 * 5 * 5；池化尺寸：2 * 2；步幅：2<br>　　　　　采样方式：4个输入相加，然后乘个可训参数，加上个可训参数，最后通过sigmoid</li><li>C5-卷积层：输出尺寸：120*1；卷积核：120 * 16 * 5 * 5；可训参数：120 * (16 * 5 * 5 + 1)</li><li>F6-全连接层：输出尺寸：84；对应一个 7 * 12的比特图；可训参数：84 * (120+1)</li><li>Output层-全连接层：输出尺寸：10；分别代表数字0~9</li></ul><h3 id=2-alexnet>2. AlexNet</h3><p><a href=https://dl.acm.org/doi/pdf/10.1145/3065386 target=blank>论文</a></p><p>2012年AlexNet横空出世，这个名字来源于一作的姓名(Alex Krizhevsky)，是Hinton实验室提出的，是卷积神经网络在大规模数据集上的开篇巨作。它赢得了2012年ImageNet图像识别挑战赛，首次证明了学习到的特征可以超越手工设计的特征，使视觉从业者从人工提取特征的特征工程中解脱出来，转向 从数据中自动提取需要的特征，做数据驱动。</p><p align=center><img src=/datasets/posts/cnn/alexnet.png title=AlexNet alt=AlexNet></p><p>卷积层：卷积核11 * 11；步幅4；输出：96 * 54 *54<br>pool层：pool尺寸3 * 3；步幅2；输出：96 * 26 * 26<br>卷积层：卷积核5 * 5；填充2；输出：256 * 26 * 26<br>pool层：pool尺寸3 * 3；步幅2；输出：265 * 12 * 12<br>卷积层：卷积核3 * 3；填充1；输出：384 * 12 * 12<br>卷积层：卷积核3 * 3；填充1；输出：384 * 12 * 12<br>卷积层：卷积核3 * 3；填充1；输出：256 * 12 * 12<br>pool层：pool尺寸3 * 3；步幅2；输出：256 * 5 * 5<br>全连接层：4096；DropOut(0.5)<br>全连接层：4096；DropOut(0.5)<br>输出层：1000</p><p>创新点：</p><ol><li>加深了网络深度</li><li>激活函数由sigmoid转换为Relu，作用：加快收敛速度；引入非线性，增强非线性的映射能力</li><li>使用DropOut，控制模型复杂度</li><li>数据增广：翻转、裁剪、颜色变化，进一步扩大数据集来缓解过拟合。</li><li>使用GPU计算</li><li>局部相应归一化(LRN)：N 表示通道数，在通道维度做局部归一化。比如在第i通道(x,y)像素点做归一化：前后n/2个通道上做局部归一化。</li></ol><h3 id=3-vgg>3. VGG</h3><p><a href=https://arxiv.org/abs/1409.1556 target=blank>论文</a></p><p>AlexNet：指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则，没有指导后来者如何设计新的网络。<br>VGG(牛津Visual Geometry Group 实验室)：提供了可以通过<code>重复使用简单的基础块来构建深度模型</code>的思路。证明了网络深度对性能的影响。在
LSVRC2014比赛分类项目的第二名。</p><p align=center><img src=/datasets/posts/cnn/vgg.png title=VGG alt=VGG></p><p>创新点：</p><ol><li>使用3*3的卷积核替换大尺寸卷积核。增加了网络深度，证明了网络深度对精度的影响</li><li>使用基础块 搭建网络的 思路</li></ol><h3 id=4-nin>4. NiN</h3><p><a href=https://arxiv.org/abs/1312.4400 target=blank>论文</a></p><p>NiN(network in network)：提出了一个新思路。串联多个(卷积层+全连接层构成的小网络) 来构建一个深层网络。使用1*1的卷积层来替代全连接层，从而使得空间信息能够传递到后面层。 NiN基础块如下：</p><p align=center><img src=/datasets/posts/cnn/nin.png title=NiN alt=NiN></p><p>模块堆叠：</p><table><thead><tr><th style=text-align:left>NiN基础块</th><th style=text-align:left>池化层</th><th style=text-align:left>NiN基础块</th><th style=text-align:left>池化层</th><th style=text-align:left>NiN基础块</th><th style=text-align:left>池化层</th><th style=text-align:left>NiN基础块</th><th style=text-align:left>全局平均池化层</th><th style=text-align:left>Flatten</th></tr></thead></table><p>创新点：</p><ol><li>使用1*1的卷积层 来替换全连接层，对准确率提升有效果。</li><li>串联多个小网络，搭建一个深层网络</li></ol><h3 id=5-googlenet>5. GoogLeNet</h3><p><a href=https://arxiv.org/abs/1409.4842 target=blank>论文</a> ImageNet分类Top5错误率：6.67%<br></p><p>GoogLeNet 在ImageNet LSVRC2014比赛分类项目的第一名，名字上向LeNet致敬。GoogLeNet吸收了NiN网络串联的思想，并在此基础上做了很大改进。GoogLeNet采用了模块化的结构(Inception结构，名字与电影《盗梦空间》Inception同名)，方便添加和修改。</p><p align=center><img src=/datasets/posts/cnn/googlenet.png title=GoogLeNet alt=GoogLeNet></p><p>模块堆叠：</p><table><thead><tr><th style=text-align:left>Conv2D MaxPool2D</th><th style=text-align:left>Conv2D Conv2D MaxPool2D</th><th style=text-align:left>Inception Inception MaxPool2D</th><th style=text-align:left>Inception Inception Inception Inception Inception MaxPool2D</th><th style=text-align:left>Inception Inception 全局平均池化层</th></tr></thead></table><p>创新点：</p><ol><li>Inception模块里有4条并行的线路：1 * 1、3 * 3、5 * 5 的卷积层是用来抽取不同空间尺寸下的特征信息，其中中间两条线路会对输入先做1*1的卷积，是为了减少输入通道数，减低复杂度；第四条线路则使用3 * 3最大池化层，后接1 * 1卷积层来改变通道数。4条线路使用了合适的填充来保障<code>输入与输出的尺寸一致</code>。</li><li>采用4条线路并行，是想提取不同空间尺寸的特征信息，那种信息更有用，在模型训练时让数据自己选择。</li><li>GoogLeNet跟VGG一样，在主体卷积部分使用5个模块(block)，每个模块之间使用步幅为2的3 * 3最大池化层来减小输出宽高。</li></ol><h3 id=6-resnet>6. ResNet</h3><p><a href=https://arxiv.org/abs/1512.03385 target=blank>论文</a> ImageNet分类Top5错误率：3.57%<br></p><p>随着网络逐渐加深，模型的误差不降反曾。ResNet针对这个问题，在2015年的ImageNet LSVRC-2015比赛中夺魁。以前的网络，网络层拟合的是映射f(x)，而ResNet的网络层拟合的是残差：f(x)-x。残差映射更易于捕捉恒等映射的细微波动。</p><p align=center><img src=/datasets/posts/cnn/resnet.png title=ResNet alt=ResNet></p><h3 id=7-resnext>7. ResNeXt</h3><p><a href=https://arxiv.org/abs/1611.05431 target=blank>ResNeXt</a>是ResNet和Inception的结合体，是2016年的ImageNet LSVRC-2016比赛的亚军。<br></p><h3 id=8-senet>8. SENet</h3><p><a href=https://arxiv.org/abs/1709.01507 target=blank>SENet</a>(2017)是ImageNet 2017（ImageNet收官赛）的冠军模型，ImageNet分类Top5错误率：2.25%<br></p><p align=center><img src=/datasets/posts/cnn/SEnet.png width=70% height=70% title=SEnet alt=SEnet></p><p>主要思想：</p><ol><li>Squeeze部分。即为压缩部分，原始feature map的维度为 H x W x C，Squeeze做的事情是把H x W x C压缩为1 x 1 x C，相当于把H x W压缩成一维了，实际中一般是用global average pooling实现的。H x W压缩成一维后，相当于这一维参数获得了之前H x W全局的视野，感受区域更广。</li><li>Excitation部分。得到Squeeze的1 x 1 x C的表示后，加入一个FC全连接层（Fully Connected），对每个通道的重要性进行预测，得到不同channel的重要性大小后再作用（激励）到之前的feature map的对应channel上，再进行后续操作</li></ol><p>提升很大，并且代价很小，通过对通道进行加权，强调有效信息，抑制无效信息，注意力机制，并且是一个通用方法。</p><h3 id=9-densenet>9. DenseNet</h3><p><a href=https://arxiv.org/abs/1608.06993 target=blank>论文</a>(2017)</p><p>受ResNet影响，DenseNet将输入和输出拼接在一起；ResNet是：输入+输出。DenseNet的主要构建模块：稠密快(dense block)和过渡层(transition layer)<br>稠密块：主要定义输入和输出是如何连接的<br>过渡层：用来调控通道数，h/w 尺寸。由于输入和输出拼接在一起，通道数增加，需要过渡层来调控。</p><p align=center><img src=/datasets/posts/cnn/densenet.png title=DenseNet alt=DenseNet></p><p>主要结论：</p><ol><li>一些较早层提取出的特征仍然可能被较深层直接使用</li><li>过渡层 输出大量冗余特征</li><li>最后的分类层，虽然使用了之前的多层信息，但更偏向于使用最后几个feature map，说明在网络的最后几层，某些high-level的特征可能被产生</li></ol><h3 id=10-sknet>10. SKNet</h3><p><a href=https://arxiv.org/abs/1903.06586 target=blank>SKNet</a>(2019) 是对SENet的改进。
SENet 在channel维度上做attention，而SKNet在SENet的基础上又引入了kernel维度上的attention，除此之外，还利用诸如分组卷积和多路卷积的trike来平衡计算量。</p><h3 id=11-cspnet>11. CSPNet</h3><p><a href=https://arxiv.org/abs/1911.11 target=blank>CSPNet</a>(2019)
作者想提出一个计算量小效果还好的网络结构。具体来说作者希望：</p><ul><li>增强CNN的学习能力</li><li>减少计算量</li><li>降低内存占用</li></ul><p>作者把 CSPNet 应用到分类和检测任务中，发现性能都有所提升，特别是在检测任务中提升更为明显。这也是为什么后续的 YOLOv4 和 YOLOv5 的 backbone 都是基于 CSPNet 修改的</p><h3 id=12-efficientnet>12. EfficientNet</h3><p><a href=https://arxiv.org/abs/1905.11946 target=blank>EfficientNet</a>(2019)</p><h3 id=12-vovnet>12. VoVNet</h3><p><a href=https://arxiv.org/abs/1904.09730 target=blank>VoVNet</a>(2019) 基于DenseNet，实现实时目标检测。<br><a href=https://arxiv.org/abs/1911.06667 target=blank>VoVNet2</a>(2020)</p><h3 id=13-repvgg>13. RepVGG</h3><p><a href=https://arxiv.org/abs/2101.03697 target=blank>RepVGG</a>(2021)</p><h3 id=14-vit>14. ViT</h3><p><a href=https://arxiv.org/abs/2010.11929 target=blank>ViT</a>(2021)</p><h2 id=二各领域的backbone>二、各领域的Backbone</h2><h3 id=1-提升速度的backbone>1、 提升速度的Backbone</h3><h4 id=1-squeezenet>1. SqueezeNet</h4><p><a href=https://arxiv.org/abs/1602.07360 target=blank>SqueezeNet</a>(2016) 的主要思想：</p><ol><li>多用 1x1 的卷积核，而少用 3x3 的卷积核</li><li>在用 3x3 卷积的时候尽量减少 channel 的数量，从而减少参数量</li><li>延后用 pooling，因为 pooling 会减小 feature map size，延后用 pooling， 这样可以使 size 到后面才减小，而前面的层可以保持一个较大的 size，从而起到提高精度的作用。</li></ol><h4 id=2-mobilenet>2. MobileNet</h4><p><a href=https://arxiv.org/abs/1704.04861 target=blank>MobileNet </a>(2017) 是通过优化卷积操作来达到轻量化的目的的，具体来说，文中通过 Deepwise Conv（其实是Deepwise Conv + Pointwise Conv）代替原始的卷积操作实现，从而达到减少计算的目的（通常所使用的是 3×3 的卷积核，计算量会下降到原来的九分之一到八分之一）<br></p><h4 id=3-shufflenet>3. ShuffleNet</h4><p><a href=https://arxiv.org/abs/1707.01083 target=blank>ShuffleNet</a>(2017) 的核心思想是对卷积进行分组，从而减少计算量，但是由于分组相当于将卷积操作局限在某些固定的输入上，为了解决这个问题采用 shuffle 操作将输入打乱，从而解决这个问题。<br></p><h3 id=2-目标检测的backbone>2、 目标检测的Backbone</h3><h4 id=1>1.</h4><h4 id=2-darknet>2. Darknet</h4><p>YOLO作者自己写的一个深度学习框架叫<a href=https://arxiv.org/abs/1506.02640 target=blank>Darknet</a></p><h4 id=3detnet>3.DetNet</h4><p>旷视2018年提出的<a href=https://arxiv.org/abs/1804.06215 target=blank>DetNet</a>，是一个目标检测的backbone</p><h3 id=3-姿态识别的backbone>3、 姿态识别的Backbone</h3><p><a href=https://arxiv.org/abs/1603.06937 target=blank>《Stacked Hourglass Networks for Human Pose Estimation》</a>(2016)</p></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fw00100_cv%2fw0010_backbone%2fd1_3_backbone_net%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fw00100_cv%2fw0010_backbone%2fd1_3_backbone_net%2f&text=backbone%20net&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fw00100_cv%2fw0010_backbone%2fd1_3_backbone_net%2f&title=backbone%20net" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fw00100_cv%2fw0010_backbone%2fd1_3_backbone_net%2f&title=backbone%20net" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=backbone%20net https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fw00100_cv%2fw0010_backbone%2fd1_3_backbone_net%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=backbone%20net&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fw00100_cv%2fw0010_backbone%2fd1_3_backbone_net%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/w00100_cv/w0010_backbone/d1_2_optimizer/ title=optimizer class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>optimizer</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/w00100_cv/w0020_contrastive_learning/contrastive_learning/ title="contrastive learning" class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>contrastive learning</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一backbone>一、Backbone</a><ul><li><a href=#1-lenet>1. LeNet</a></li><li><a href=#2-alexnet>2. AlexNet</a></li><li><a href=#3-vgg>3. VGG</a></li><li><a href=#4-nin>4. NiN</a></li><li><a href=#5-googlenet>5. GoogLeNet</a></li><li><a href=#6-resnet>6. ResNet</a></li><li><a href=#7-resnext>7. ResNeXt</a></li><li><a href=#8-senet>8. SENet</a></li><li><a href=#9-densenet>9. DenseNet</a></li><li><a href=#10-sknet>10. SKNet</a></li><li><a href=#11-cspnet>11. CSPNet</a></li><li><a href=#12-efficientnet>12. EfficientNet</a></li><li><a href=#12-vovnet>12. VoVNet</a></li><li><a href=#13-repvgg>13. RepVGG</a></li><li><a href=#14-vit>14. ViT</a></li></ul></li><li><a href=#二各领域的backbone>二、各领域的Backbone</a><ul><li><a href=#1-提升速度的backbone>1、 提升速度的Backbone</a><ul><li><a href=#1-squeezenet>1. SqueezeNet</a></li><li><a href=#2-mobilenet>2. MobileNet</a></li><li><a href=#3-shufflenet>3. ShuffleNet</a></li></ul></li><li><a href=#2-目标检测的backbone>2、 目标检测的Backbone</a><ul><li><a href=#1>1.</a></li><li><a href=#2-darknet>2. Darknet</a></li><li><a href=#3detnet>3.DetNet</a></li></ul></li><li><a href=#3-姿态识别的backbone>3、 姿态识别的Backbone</a></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script></body></html>