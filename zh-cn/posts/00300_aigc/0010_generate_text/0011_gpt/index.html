<!doctype html><html><head><title>GPT</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="GPT"><meta property="og:description" content="一、简介 二、GPT-1 GPT(2018-06) 详细参考
其创造性的提出以Transformer的解码器来训练生成式模型，后面Bert的作者估计是看到了这篇论文，据说两个月时间就发表了以Transformer编码器训练的Bert模型。总结下GPT-1模型：
 GPT-1 使用了一个仅有解码器的 Transformer 结构，每一个作为一个Layer，共有12层； 使用了一个 768 维的嵌入向量来表示输入序列中的每个词或标记，使用了 12 个并行的注意力头（attention heads）； 使用Adam优化器进行模型训练，在训练过程中，使用了学习率的 warmup 阶段和余弦退火调度机制，以平衡训练速度和模型性能； 模型权重被初始化为均值为 0、标准差为 0.02 的正态分布（N(0, 0.02)），使用字节对编码（Byte Pair Encoding，BPE）来对文本进行分词处理，分词后得到的词汇表大小为 40000； 激活函数是 GELU； 文本输入序列固定长度是512； 参数量 117M; 使用了学习得到的位置嵌入向量(position embedding)，而不是Attention is All You Need中使用的正弦位置嵌入向量；  三、GPT-2 GPT-2(2019-02)
GPT-2的改进:
GPT-2 是GPT语言模型开始变大的地方，这是 OpenAI 第一次训练超过 1B 个参数的模型。 通过提升模型的规模，来凸显GPT的优势。在 GPT-1 中，作者训练了单个模型，但在这里，作者训练了一系列模型。 与GPT-1相比，架构上有如下差异：
 层归一化操作，有原来的post-norm换成了pre-norm，以加速训练和提高模型性能。此外，在最后一个自注意力块的输出上添加了额外的层归一化； 在权重初始化时，通过 $\frac{1}{\sqrt n}$ 进行缩放。这种缩放有助于减少梯度更新的方差，使训练过程更加稳定； 扩大了其词汇表的大小，词汇表大小约为 50,000（相比于约 40,000）； 增大文本输入序列长度 1024（相比于 512）这使得模型能够更好地理解和生成更长的文本； batch size大小为 512（相比于 64）较大的批次大小有助于提高训练效率和模型并行计算的能力。 最大的模型具有约 15 亿个参数。 数据集：GPT-2 构造了一个新数据集，WebText。全部来自于 Reddit 的外链，而且是那些获得至少三个赞的外链，经过清洗、去重后，得到8百万网页共计 40GB 文本数据。 WebText 数据集的特点在于全面而干净。  GPT-2的不同版本:"><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/"><meta property="article:published_time" content="2023-08-05T12:30:40+08:00"><meta property="article:modified_time" content="2023-08-05T12:30:40+08:00"><meta name=description content="GPT"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00020_toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/00020_toha-tutorial/0010_toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/>数学知识</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/>概率论</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/ title=基本概念>基本概念</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/ title=随机变量及其分布>随机变量及其分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/ title=大数定律>大数定律</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/ title=样本及抽样分布>样本及抽样分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/ title=假设检验>假设检验</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/ title=方差分析及回归分析>方差分析及回归分析</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/ title=随机过程>随机过程</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/ title=马尔科夫链>马尔科夫链</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/ title=平稳随机过程>平稳随机过程</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/>凸优化</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/ title=基本概念>基本概念</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00030_deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/ title=深度学习开篇>深度学习开篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/ title=深度学习-结构>深度学习-结构</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0015_deeplearning_norm/ title=归一化>归一化</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0020_deeplearing_init/ title=初始化>初始化</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0200_cam/ title=CAM>CAM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00033_reinforce/>强化学习</a><ul><li><a href=/zh-cn/posts/00033_reinforce/0001_reinforce_summary/ title=综述>综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/>env</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/ title=py-env>py-env</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/ title=cuda>cuda</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ title=内置模块>内置模块</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/ title=进阶操作>进阶操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/ title=异常>异常</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/ title=文件读取>文件读取</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/ title=importlib>importlib</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/ title=ipdb>ipdb</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/ title=正则-re>正则-re</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/ title=堆-heapd>堆-heapd</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/ title=requests>requests</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/ title=logging>logging</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/ title=argparse>argparse</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/ title=PIL>PIL</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/ title=OpenCV>OpenCV</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/ title=Tensor和变量>Tensor和变量</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0010_backbone/>基础</a><ul><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0050_detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0060_image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0020_rnn/>RNN</a><ul><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0030_transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0001_attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/ title=Transformer>Transformer</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0030_position/ title=位置编码>位置编码</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0080_gpt/>GPT</a><ul><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/ title=GPT综述>GPT综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/ title=GPT-1>GPT-1</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0100_bert/>Bert</a><ul><li><a href=/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/ title=Bert综述>Bert综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/ title=Bert家族>Bert家族</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0120_t5/>T5</a><ul><li><a href=/zh-cn/posts/00200_nlp/0120_t5/0010_t5_summary/ title=T5综述>T5综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0150_bart/>BART</a><ul><li><a href=/zh-cn/posts/00200_nlp/0150_bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0200_electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/00200_nlp/0200_electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/1000_code/>CODE</a><ul><li><a href=/zh-cn/posts/00200_nlp/1000_code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00300_aigc/>AIGC</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0005_summary/>AIGC综述</a><ul><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/ title=综述>综述</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/ title=模型应用策略>模型应用策略</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/ title=大模型训练框架>大模型训练框架</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/ title=混合精度训练>混合精度训练</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/ title=模型小型化>模型小型化</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/ title=生成式-问题>生成式-问题</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00300_aigc/0010_generate_text/>文本生成</a><ul class=active><li><a class=active href=/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/ title=GPT>GPT</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/ title=LLaMa>LLaMa</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/ title=PaLM>PaLM</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/ title=ChatGLM>ChatGLM</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/ title=Claude>Claude</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/ title=Cohere>Cohere</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/ title=Falcon>Falcon</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/ title=Vicuna>Vicuna</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0020_generate_image/>图像生成</a><ul><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1000_gan_summary/ title=GAN>GAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/ title=CAN>CAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/ title=DALL-E>DALL-E</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/ title=VQGAN>VQGAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/ title=Diffusion>Diffusion</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/ title=Midjourney>Midjourney</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/ title=Imagen>Imagen</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00400_vlp/>多模态</a><ul><li><a href=/zh-cn/posts/00400_vlp/0001_vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00400_vlp/0005_clip/ title=CLIP>CLIP</a></li><li><a href=/zh-cn/posts/00400_vlp/0010_mllm/ title=MLLM>MLLM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00500_video/>视频理解</a><ul><li><a href=/zh-cn/posts/00500_video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>August 5, 2023</p></div><div class=title><h1>GPT</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/aigc class="btn, btn-sm">aigc</a></li><li class=rounded><a href=/zh-cn/tags/gpt class="btn, btn-sm">GPT</a></li></ul></div><div class=post-content id=post-content><h2 id=一简介>一、简介</h2><h2 id=二gpt-1>二、GPT-1</h2><p><a href=https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf target=blank>GPT(2018-06)</a><br></p><p><a href=/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail>详细参考</a><br></p><p>其创造性的提出以Transformer的解码器来训练生成式模型，后面Bert的作者估计是看到了这篇论文，据说两个月时间就发表了以Transformer编码器训练的Bert模型。总结下GPT-1模型：</p><ol><li>GPT-1 使用了一个仅有解码器的 Transformer 结构，每一个作为一个Layer，共有12层；</li><li>使用了一个 768 维的嵌入向量来表示输入序列中的每个词或标记，使用了 12 个并行的注意力头（attention heads）；</li><li>使用Adam优化器进行模型训练，在训练过程中，使用了学习率的 warmup 阶段和余弦退火调度机制，以平衡训练速度和模型性能；</li><li>模型权重被初始化为均值为 0、标准差为 0.02 的正态分布（N(0, 0.02)），使用字节对编码（Byte Pair Encoding，BPE）来对文本进行分词处理，分词后得到的词汇表大小为 40000；</li><li>激活函数是 GELU；</li><li>文本输入序列固定长度是512；</li><li>参数量 117M;</li><li>使用了学习得到的位置嵌入向量(position embedding)，而不是Attention is All You Need中使用的正弦位置嵌入向量；</li></ol><h2 id=三gpt-2>三、GPT-2</h2><p><a href=https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf target=blank>GPT-2(2019-02)</a></p><p><strong>GPT-2的改进</strong>:</p><p>GPT-2 是GPT语言模型开始变大的地方，这是 OpenAI 第一次训练超过 1B 个参数的模型。
<font color=#f00000>通过提升模型的规模，来凸显GPT的优势</font>。在 GPT-1 中，作者训练了单个模型，但在这里，作者训练了一系列模型。
与GPT-1相比，架构上有如下差异：</p><p align=center><img src=/datasets/posts/nlp/gpt1-2.png width=70% height=70%></p><ol><li>层归一化操作，有原来的post-norm换成了pre-norm，<font color=#f00000>以加速训练和提高模型性能</font>。此外，在最后一个自注意力块的输出上添加了额外的层归一化；</li><li>在权重初始化时，通过 $\frac{1}{\sqrt n}$ 进行缩放。这种缩放<font color=#f00000>有助于减少梯度更新的方差，使训练过程更加稳定</font>；</li><li>扩大了其词汇表的大小，词汇表大小约为 <font color=#f00000>50,000</font>（相比于约 40,000）；</li><li>增大文本输入序列长度 1024（相比于 512）这使得模型能够更好地理解和生成更长的文本；</li><li>batch size大小为 512（相比于 64）较大的批次大小有助于提高训练效率和模型并行计算的能力。</li><li>最大的模型具有约 15 亿个参数。</li><li>数据集：GPT-2 构造了一个新数据集，<a href=https://paperswithcode.com/dataset/webtext target=bland>WebText</a>。全部来自于 Reddit 的外链，而且是那些获得至少三个赞的外链，经过清洗、去重后，得到8百万网页共计 <font color=#f00000>40GB 文本数据</font>。
WebText 数据集的特点在于<font color=#f00000>全面而干净</font>。</li></ol><p><strong>GPT-2的不同版本</strong>:</p><table><thead><tr><th style=text-align:left>模型</th><th style=text-align:left>Layers</th><th style=text-align:left>d_size</th><th style=text-align:left>ff_size</th><th style=text-align:left>Heads</th><th style=text-align:left>Parameters</th></tr></thead><tbody><tr><td style=text-align:left>GPT2-base</td><td style=text-align:left>12</td><td style=text-align:left>768</td><td style=text-align:left>3072</td><td style=text-align:left>12</td><td style=text-align:left>1.17亿</td></tr><tr><td style=text-align:left>GPT2-medium</td><td style=text-align:left>24</td><td style=text-align:left>1024</td><td style=text-align:left>4096</td><td style=text-align:left>16</td><td style=text-align:left>3.45亿</td></tr><tr><td style=text-align:left>GPT2-large</td><td style=text-align:left>36</td><td style=text-align:left>1280</td><td style=text-align:left>5120</td><td style=text-align:left>20</td><td style=text-align:left>7.74亿</td></tr><tr><td style=text-align:left>GPT2-xl</td><td style=text-align:left>48</td><td style=text-align:left>1600</td><td style=text-align:left>6400</td><td style=text-align:left>25</td><td style=text-align:left>15.58亿</td></tr></tbody></table><h2 id=四gpt-3>四、GPT-3</h2><p><a href=https://arxiv.org/pdf/2005.14165.pdf target=blank>GPT-3(2020-05)</a><br>GPT-3是大语言模型开始受到关注的开始。在论文中，作者训练了 10 个模型，参数范围从 1.25亿 个参数（“GPT-3 Small”）到 175B 个参数（“GPT-3”）。</p><p align=center><img src=/datasets/posts/nlp/gpt-3-model.png width=90% height=90%></p><p>在GPT-3中，模型的架构与GPT-2完全相同。唯一的区别是它们在transformer的各层中使用了<font color=#f00000>“交替的稠密和本地带状稀疏注意力模式”</font>。简单来说，GPT-3在注意力机制上进行了优化，引入了稀疏注意力的概念。<br></p><blockquote><ol><li>传统的点积注意力在计算复杂度上较高，而稀疏注意力可以提供更高的扩展性，并且在处理长序列时具有更高的效率。这种改进使得GPT-3能够更好地处理长文本输入，并且在计算效率和模型表现方面有所提升。</li><li>GPT-3引入稀疏注意力的原因尚不清楚，也许是因为计算限制造成的，论文中并没详细的说明如何如何使用模型并行性训练模型，使得论文更难以复现。</li></ol></blockquote><h2 id=五chatgptinstructgpt>五、chatGPT/InstructGPT</h2><p>chatGPT(2022-12)<br><a href=https://arxiv.org/pdf/2203.02155.pdf target=bland>InstructGPT</a><br></p><p>ChatGPT的博客中讲到ChatGPT和InstructGPT的训练方式相同，不同点仅仅是它们采集数据上有所不同，但是并没有更多的资料来讲数据采集上有哪些细节上的不同。</p><p align=center><img src=/datasets/posts/nlp/InstructGPT_0.png width=90% height=90% title=InstructGPT alt=InstructGPT></p><p>通过人类的反馈，在GPT3上做微调。</p><h3 id=1sft模型>1、SFT模型</h3><p>设计了一些prompt，<font color=#f00000>人工写答案</font>，搜集一批数据，用来fine-tune GPT3，得到一个SFT模型 (Supervised Fine-tune)，即：有监督的微调</p><h3 id=2rw模型>2、RW模型：</h3><p>由于SFT的标注数据，成本比较大。这搞一个便宜点的。</p><ol><li>设计一批prompt，每条prompt用GPT3采用很多条结果（生成模型的输出是概率性的，每次结果大概率是不一样的，generate有参数可以控制这些概率性）</li><li><font color=#f00000>人工标注：每个prompt的生成结果的排序</font> （打分标注，可比写答案的标注快多了）</li><li>训练一个奖励模型，这个奖励模型 就是对GPT3-6B的输出 进行打分，这个输出的分数 满足 人工标注的顺序。<br><ul><li>作者没有采用GPT-175B模型，是因为在训练的过程中175B的不稳定，loss容易爆炸。<br></li><li>由于标注的是排序，RW模型的输出是score，所以有一个排序到score的映射。比如：一个prompt有K个答案。从k个答案中选2个，有 $C^2_k$种 结果对。每个结果对都是有人工标注的顺序的，在计算loss的时候保证这个顺序就行。每个prompt有 $C^2_k$ 个结果对，在算loss的时候，这 $C^2_k$ 个结果对一起计算。<br></li><li>loss的话是一个标准的 Pairwise的 Ranking Loss
$$loss(\theta) = - \frac{1}{C^2_k} E_{x,y_w,y_l \in D} log(\sigma[r_\theta (x, y_w) - r_\theta (x, y_l)])$$
其中，$r_\theta ()$ 表示GPT3-6B的输出score值，$\sigma()$ 表示 Sigmoid函数。学习的目标是最大化这个loss。</li></ul></li></ol><h3 id=3强化学习sft模型>3、强化学习SFT模型</h3><p><strong>在强化学习的框架下调整SFT模型</strong>：<br>用PPO强化学习方法，fine-tune 之前的SFT模型，得出的模型就是InstructGPT，大小只有1.3B。<br>作者尝试把预训练的梯度整合到PPO中，如下：
$$
objective(\phi) = E_{(x,y) \in D_{\pi_\phi^{RL}}} [r_\theta(x, y) - \beta log(\frac{\pi^{RL}_\phi(y|x)}{\pi^{SFT}(y|x)})] +
$$</p><p>$$
\gamma E_{x \in D_{pretrain}} [log(\pi^{RL}_\phi(x))]
$$</p><p>其中，$r_{\theta}()$ 就是第二步的RM模型；$\pi_\phi^{RL}$ 表示新的环境；$\pi_\phi^{SFT}$ 表示原来的环境；<br>$log(\frac{\pi^{RL}_\phi(y|x)}{\pi^{SFT}(y|x)}) $ 表示新环境 与 旧环境差异，是一个正则项，作者希望与旧环境不能差异太大，所以添加了这个，类似KL散度。<br></p><p>$ E_{x \in D_{pretrain}} [log(\pi^{RL}_\phi(x))]$ 表示原GPT3预训练时的损失函数，目的是防止模型遗忘。</p><p>在训练之前，是用第一步的SFT模型来初始化，$\pi_\phi^{SFT}$ 就是原来的SFT模型。<br></p><p align=center><img src=/datasets/posts/nlp/InstructGPT_1.png width=90% height=90% title=InstructGPT alt=InstructGPT></p>从结果来看：还是人工打标的数据对模型的提升较大。可以看到经过监督训练的1.3B的模型，效果是好于175B的大模型。<h2 id=四gpt-4>四、GPT-4</h2><p><a href=https://arxiv.org/abs/2303.08774 target=bland>《GPT-4 Technical Report》</a></p><h2 id=相关>相关</h2><p><strong>RLHF</strong><br>RLHF的相关技术，首次出自这篇文章：
<a href=https://arxiv.org/abs/1909.08593 target=bland>《Fine-Tuning Language Models from Human Preferences》</a>
该论文的作者Tom创建Anthropic公司，是该公司的CEO。<br>后续，Anthropic公司发布了自己的大语言模型Claude，可以了解一下。<br></p><p><strong>KL散度</strong>：<br>$$
D_{KL}(p||q) = E_p[log \frac{p}{q}] = \sum {p log \frac{p}{q}}
$$</p><p>其中，$p$ 分布往往是多峰。$D_{KL}(p||q)$ 与 $D_{KL}(q||p)$ 是不一样的<br></p><ol><li>$D_{KL}(p||q)$ 表示前向散度，在监督学习中使用</li><li>$D_{KL}(q||p)$ 表示反向散度，在强化学习中使用</li></ol></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00300_aigc%2f0010_generate_text%2f0011_gpt%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00300_aigc%2f0010_generate_text%2f0011_gpt%2f&text=GPT&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00300_aigc%2f0010_generate_text%2f0011_gpt%2f&title=GPT" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00300_aigc%2f0010_generate_text%2f0011_gpt%2f&title=GPT" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=GPT https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00300_aigc%2f0010_generate_text%2f0011_gpt%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=GPT&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00300_aigc%2f0010_generate_text%2f0011_gpt%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/ title=生成式-问题 class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>生成式-问题</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/ title=LLaMa class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>LLaMa</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一简介>一、简介</a></li><li><a href=#二gpt-1>二、GPT-1</a></li><li><a href=#三gpt-2>三、GPT-2</a></li><li><a href=#四gpt-3>四、GPT-3</a></li><li><a href=#五chatgptinstructgpt>五、chatGPT/InstructGPT</a><ul><li><a href=#1sft模型>1、SFT模型</a></li><li><a href=#2rw模型>2、RW模型：</a></li><li><a href=#3强化学习sft模型>3、强化学习SFT模型</a></li></ul></li><li><a href=#四gpt-4>四、GPT-4</a></li><li><a href=#相关>相关</a></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script><script src=/js/mermaid-8.14.0.min.js></script><script>mermaid.initialize({startOnLoad:true});</script></body></html>