<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>文本生成 on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/</link><description>Recent content in 文本生成 on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/index.xml" rel="self" type="application/rss+xml"/><item><title>ChatGLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/</guid><description>一、简介 二、网络结构</description></item><item><title>Claude</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/</guid><description>一、简介 Anthropic公司推出的Claude。
二、网络结构</description></item><item><title>Cohere</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/</guid><description>一、简介 二、网络结构</description></item><item><title>Falcon</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/</guid><description>一、简介 二、网络结构</description></item><item><title>GPT</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/</guid><description>一、简介 二、InstructGPT InstructGPT 通过人类的反馈，在GPT3上做微调。
1、SFT模型 设计了一些prompt，人工写答案，搜集一批数据，用来fine-tune GPT3，得到一个SFT模型 (Supervised Fine-tune)，即：有监督的微调
2、RW模型： 由于SFT的标注数据，成本比较大。这搞一个便宜点的。
设计一批prompt，每条prompt用GPT3采用很多条结果（生成模型的输出是概率性的，每次结果大概率是不一样的，generate有参数可以控制这些概率性） 人工标注：每个prompt的生成结果的排序 （打分标注，可比写答案的标注快多了） 训练一个奖励模型，这个奖励模型 就是对GPT3-6B的输出 进行打分，这个输出的分数 满足 人工标注的顺序。
作者没有采用GPT-175B模型，是因为在训练的过程中175B的不稳定，loss容易爆炸。
由于标注的是排序，RW模型的输出是score，所以有一个排序到score的映射。比如：一个prompt有K个答案。从k个答案中选2个，有 $C^2_k$种 结果对。每个结果对都是有人工标注的顺序的，在计算loss的时候保证这个顺序就行。每个prompt有 $C^2_k$ 个结果对，在算loss的时候，这 $C^2_k$ 个结果对一起计算。
loss的话是一个标准的 Pairwise的 Ranking Loss $$loss(\theta) = - \frac{1}{C^2_k} E_{x,y_w,y_l \in D} log(\sigma[r_\theta (x, y_w) - r_\theta (x, y_l)])$$ 其中，$r_\theta ()$ 表示GPT3-6B的输出score值，$\sigma()$ 表示 Sigmoid函数。学习的目标是最大化这个loss。 3、强化学习SFT模型 在强化学习的框架下调整SFT模型：
用PPO强化学习方法，fine-tune 之前的SFT模型，得出的模型就是InstructGPT，大小只有1.3B。
作者尝试把预训练的梯度整合到PPO中，如下： $$ objective(\phi) = E_{(x,y) \in D_{\pi_\phi^{RL}}} [r_\theta(x, y) - \beta log(\frac{\pi^{RL}_\phi(y|x)}{\pi^{SFT}(y|x)})] + $$</description></item><item><title>LLaMa</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/</guid><description>一、简介 二、网络结构 1、LLaMa 2、LLaMa 2 数据方面
LLaMa2训练了2000B的tokens，训练语料比LLaMa多了40% 2000B 个token的预训练集，提供了良好的性能和成本权衡；对最真实的来源进行上采样，以增加知识并抑制幻觉，保持真实 调查数据，以便用户更好地了解模型的潜在能力和局限性，保证安全。 上下文长度从2048提升到了4096 LLaMa2-chat 模型还接受了超过100w的人类标注的训练数据 开源数据选了 LLaMa2 使用监督微调 LLaMa2-chat 使用人类反馈强化学习(RLHF)进行迭代细化；包括拒绝采样、近端策略优化 网络方面
RMSNorm 归一化 FFN中用swiGLU激活函数替换原来的Relu 旋转位置编码 RoPE 增加上下文长度 分组查询注意力 GQA 原始的 多头注意力：MHA 具有单个KV投影的原始多查询格式：MQA 具有8个KV投影的分组查询注意力变体：GQA 训练方面 预训练细节：
用AdamW优化器进行训练，其中： $β_1 =0.9，β_2 = 0.95，eps = 10−5$。 使用余弦调整学习率，预热2000steps，$lr$ 衰减到峰值的10% 使用0.1的权重衰减 、1.0的梯度裁剪 精调细节：
余弦学习率，$lr=2e-5$ 权重衰减0.1，batch_size=64，序列长度为4096 训练2个epoch 引入Ghost Attention 有助于控制多轮对话</description></item><item><title>PaLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/</guid><description>一、简介 1、PaLM 1 《PaLM: Scaling Language Modeling with Pathways》 这篇文章87页，并没有深度的讨论模型算法的结构，数据的清洗技巧，或者是训练的方式（估计感觉这块的创新性不是特别明显，也不是文章的主要目的）。 而是花了大量的篇幅去评估这个模型在multi-task的能力，比如翻译，代码修改，生成，问答等等。
其中模型版本于训练集大小：
Google PaLM 是一个 540B 参数密集型 Transformer 语言模型，在 780B 高质量、多样化文本的标记上进行训练。 它已经针对 3 种不同的尺寸进行了训练：8B、62B 和 540B，使用 6144 TPU v4 芯片使用 Pathways，这是一种新的 ML 系统，可跨多个 TPU（张量处理单元）Pod 进行高效训练。 当它被引入时，它在数百个 NLU 和 NLG 基准测试中产生了 SOTA 小样本学习结果。 这包括 Big-Bench 任务的性能大幅提升，以及多语言 NLG 和源代码生成功能的显着改进。 它还被证明可以使用思维链提示来解释笑话或逻辑推理，从而产生很好的解释。
PaLM超越了许多之前的SOTA。作者归功于
更好的数据的清理， 更多的数据， 模型规模的进一步提升。 模型算法的改进比较少，从Model Architecture那一章看出，其实模型结构的变化并不明显，在激活层，ShareEmbedding，PosEmbedding等模块做了一些结构优选。核心的TransformerBlock的变种选择也更多是为了优化模型的训练效率。谷歌作为搜索技术的天花板，数据清洗的积累，以及对于数据的理解肯定是OpenAI这些公司无法比拟的。个人感觉这块是个比较明显的优势。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 2、PaLM 2 《PaLM 2 Technical Report》 这篇报告-总结：</description></item><item><title>Vicuna</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/</guid><description>一、简介 二、网络结构</description></item></channel></rss>