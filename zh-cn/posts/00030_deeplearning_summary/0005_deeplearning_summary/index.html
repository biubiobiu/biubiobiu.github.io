<!doctype html><html><head><title>深度学习开篇</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="深度学习开篇"><meta property="og:description" content="Markdown rendering samples"><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/"><meta property="article:published_time" content="2021-08-05T12:30:40+08:00"><meta property="article:modified_time" content="2021-08-05T12:30:40+08:00"><meta name=description content="Markdown rendering samples"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00020_toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/00020_toha-tutorial/0010_toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/>数学知识</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/>概率论</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/ title=基本概念>基本概念</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/ title=随机变量及其分布>随机变量及其分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/ title=大数定律>大数定律</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/ title=样本及抽样分布>样本及抽样分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/ title=假设检验>假设检验</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/ title=方差分析及回归分析>方差分析及回归分析</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/ title=随机过程>随机过程</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/ title=马尔科夫链>马尔科夫链</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/ title=平稳随机过程>平稳随机过程</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/>凸优化</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/ title=基本概念>基本概念</a></li></ul></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00030_deeplearning_summary/>深度学习</a><ul class=active><li><a class=active href=/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/ title=深度学习开篇>深度学习开篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/ title=深度学习-结构>深度学习-结构</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0200_cam/ title=CAM>CAM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/>env</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/ title=py-env>py-env</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/ title=cuda>cuda</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ title=内置模块>内置模块</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/ title=进阶操作>进阶操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/ title=异常>异常</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/ title=文件读取>文件读取</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/ title=importlib>importlib</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/ title=ipdb>ipdb</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/ title=正则-re>正则-re</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/ title=堆-heapd>堆-heapd</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/ title=requests>requests</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/ title=logging>logging</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/ title=argparse>argparse</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/ title=PIL>PIL</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/ title=OpenCV>OpenCV</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/ title=Tensor和变量>Tensor和变量</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0010_backbone/>基础</a><ul><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0050_detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0060_image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0020_rnn/>RNN</a><ul><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0030_transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/transformer_summary/ title=Transformer>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0080_gpt/>GPT</a><ul><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/ title=GPT综述>GPT综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/ title=GPT-1>GPT-1</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0100_bert/>Bert</a><ul><li><a href=/zh-cn/posts/00200_nlp/0100_bert/bert_summary/ title=Bert综述>Bert综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0150_bart/>BART</a><ul><li><a href=/zh-cn/posts/00200_nlp/0150_bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0200_electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/00200_nlp/0200_electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/1000_code/>CODE</a><ul><li><a href=/zh-cn/posts/00200_nlp/1000_code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/>AIGC</a><ul><li><a href=/zh-cn/posts/00300_aigc/0010_aigc_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00300_aigc/0012_generate_summary/ title=生成模型-简介>生成模型-简介</a></li><li><a href=/zh-cn/posts/00300_aigc/0015_llama_summary/ title=LLaMa>LLaMa</a></li><li><a href=/zh-cn/posts/00300_aigc/0100_diffusion_summary_/ title=模型介绍>模型介绍</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00400_vlp/>多模态</a><ul><li><a href=/zh-cn/posts/00400_vlp/vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00400_vlp/clip/ title=CLIP>CLIP</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00500_video/>视频理解</a><ul><li><a href=/zh-cn/posts/00500_video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>August 5, 2021</p></div><div class=title><h1>深度学习开篇</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 class="btn, btn-sm">机器学习</a></li><li class=rounded><a href=/zh-cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0 class="btn, btn-sm">深度学习</a></li><li class=rounded><a href=/zh-cn/tags/%E7%AE%80%E4%BB%8B class="btn, btn-sm">简介</a></li></ul></div><div class=post-content id=post-content><p><a href=https://openaccess.thecvf.com/menu target=blank>论文入口</a></p><h2 id=一机器学习>一、机器学习</h2><div class="alert alert-info"><strong><p>目前，人工智能研究领域主要体现在一下几个方面：</p><ol><li><p>智能感知：通过模拟人的感知能力（视觉、听觉、嗅觉）对外部信息进行感知和识别，并能够对信息进行加工和处理，从而做出反应。</p></li><li><p>智能学习：学习是人工智能的主要标志和获取知识的重要手段，研究机器通过模拟人的学习能力，如何从小样本、大数据中学习，主要有：</p><ul><li>监督学习：（Supervised Learning）表示机器学习的数据是带有标记的，这些标记可以包括：数据类别、数据属性、特征点位置等。这些标记作为预期效果，不断修正机器的预测结果。常见的监督学习有<font color=#f00000>分类、回归、结构化学习</font>。</li><li>半监督学习：（Semi-Supervised Learning）利用少量标注数据和大量无标注数据进行学习的方式。常用的半监督学习算法有：<font color=#f00000>自训练、协同训练</font></li><li>非监督学习：（Unsupervised Learning）表示机器学习的数据是没有标记的。常见的无监督学习有：<font color=#f00000>聚类、降维</font></li><li>强化学习：（Reinforcement Learning）通过智能体和环境的交互，不断学习并调整策略的机器学习算法。这种算法带有一种激励机制，如果智能体根据环境做出一个正确的动作，则施予一定的“正激励”；如果是错误的动作，则给与一定的“负激励”。通过不断地累加激励，以获取激励最大化的回报。做火热的应用就是 <font color=#f00000>AlphaGo Zero</font></li></ul></li><li><p>认知推理：模拟人的认知能力，主要研究知识表示、推理、规划、决策等，主要有自然语言处理、脑科学。</p></li></ol></strong></div><h2 id=二表征学习>二、表征学习</h2><div class="alert alert-success"><strong><p><strong>表征</strong>：为了提高机器学习系统的准确率，需要将输入信息转化为有效的特征，或者更一般性地称为 <font color=#f00000>表征（Representation）</font><br></p><p><strong>表征学习</strong>：如果有一种算法可以自动地学习有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫做 <font color=#f00000>表征学习</font>。
表征学习的关键是解决语义鸿沟（Semantic Gap）问题。即：输入数据的底层特征与高层语义信息之间的不一致性和差异性。<br>机器学习中经常用两种方式表示特征：局部表示(Local Representation)、分布式表示(Distributed Representation)。<br>比如：颜色的表示。</p><ol><li>局部表示：也称为离散表示或者符号表示，比如：one-hot向量的形式。假设所有颜色 构成一个词表 $\bold V$，此时，可以用一个 $|\bold V|$ 维的one-hot向量来表示一中颜色。但是，one-hot向量的维数很高，且不能扩展，如果有一种新的颜色，就需要增加一维来表示。不同颜色之间的相似度都为0，无法直到“红色”和“中国红”的相似度要高于“红色”和“黑色”的相似度。</li><li>分布式表示：另一种表示颜色的方法是用RGB值来表示颜色，不同颜色对应RGB三维空间中的一个点。分布式表示通常可以表示<font color=#f00000>低维的稠密向量</font>。</li></ol><p><strong>嵌入</strong>：神经网络将高维的<font color=#a020f0>局部表示空间</font> $\R^{|\bold V|}$，映射到一个非常低维的<font color=#a00000>分布式表示空间</font> $\R^{D}$。在这个低维空间中，每个特征不再是坐标轴上的点，而是分散在整个低维空间中，在机器学习中，这个过程也成为<font color=#a00000>嵌入（Embedding）</font>。比如：自然语言中词的分布式表示也经常叫做词嵌入。<br></p><p>要学习到一种好的高层次语义表示（一般为分布式表示），通常只有从底层特征开始，经过多步非线性转换才能得到。<font color=#a00000>深层结构</font>的优点是可以提高特征的重用性，从而指数级增强表示能力。因此，<a href=https://arxiv.org/pdf/1206.5538.pdf target=bland>表示学习的关键是构建具有一定深度的多层次特征表示</a>。</p></strong></div><h2 id=三深度学习>三、深度学习</h2><p>深度学习是机器学习的一个重要的、新的研究领域，源于对神经网络的进一步研究，通常采用包含多个隐藏层的神经网络结构，目的是建立、模拟人脑学习过程。<br></p><p>在描述深度学习之前，先回顾下机器学习和深度学习的关系。</p><ol><li><p><strong>机器学习</strong>：研究如何使用计算机系统利用经验改善性能。在机器学习的众多研究方向中，<code>表征学习</code>关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出。</p></li><li><p><strong>深度学习</strong>：是具有多级表示的表征学习方法。在每一级，深度学习通过简单的函数将该级的<code>表示</code>变换为更高级的<code>表示</code>。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合函数足够多时，就可以表达非常复杂的变换。<br>作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。逐级表示越来越抽象的概念或模式。<font color=#a00000>高层特征是由底层特征通过推演归纳得到。</font><br>深度学习可通过学习一种深层非线性网络结构来表征输入数据，实现复杂函数逼近，具有很强的从少数样本集中学习数据集本质特征的能力。深度学习的主要思想：通过自学习的方法，学习到训练数据的结构，并在该结构上进行有监督训练微调。
以图像为例，它的输入是一堆原始像素值，模型中逐级表示为：<div class=mermaid align=left style=background-color:none;border-radius:5px>graph LR;
A(特定位置和角度的边缘) --> B(由边缘组合得出的花纹)
B --> C(由多种花纹进一步汇合得到的特定部位)
C --> D(由特定部位组合得到的整个目标)</div></p></li></ol><h3 id=1神经元>1、神经元</h3><p>神经元模型：</p><ol><li>每个神经元都是一个多输入、单输出的信息处理单元</li><li>神经元输入分兴奋性输入和抑制性输入两种类型</li><li>神经元具有空间整合特性和阈值特性</li><li>神经元输入与输出间有固定的时滞，主要取决于突触延迟</li><li>忽略时间整合作用和不应期</li><li>神经元本身是非时变的，即：其突触时延和突触强度均为常数</li></ol><div class=mermaid align=center style=background-color:none;border-radius:5px>graph LR;
A1(x<sub>1</sub>) --> |输入| B1(W<sub>k1</sub>)
A2(x<sub>2</sub>) --> |输入| B2(W<sub>k2</sub>)
A3(x<sub>3</sub>) --> |输入| B3(W<sub>k3</sub>)
B1 --> |权值| C(求和节点)
B2 --> |权值| C(求和节点)
B3 --> |权值| C(求和节点)
C(求和节点) --> |v<sub>k</sub>| D(激活函数)
D --> |y<sub>k</sub>| E(输出)</div><h2 id=四学习方式>四、学习方式</h2><h3 id=1多阶段>1、多阶段</h3><p>在一些复杂任务重，传统机器学习方法需要将一个任务的输入和输出人为地切割成很多子模块（或者多个阶段），每个子模块分开学习。比如：要完成一个自然语言理解任务，一般需要：<div class=mermaid align=left style=background-color:none;border-radius:5px>graph LR;
A(分词) --> B(词性标注)
B --> C(句法分析)
C --> D(语义分析)
D --> E(语义推理)</div></p><p>这种学习方式有两个问题：</p><ol><li>每个模块都需要单独优化，并且其优化目标和任务总体目标并不能保证一致。</li><li>错误传播，即：前一步的错误会对后续的模型造成很大的影响。</li></ol><h3 id=2端到端>2、端到端</h3><p>训练过程中不进行分模块或分阶段训练，而是直接优化任务的总体目标。中间过程不需要人为干预，无需其他额外信息。因此，端到端学习，需要解决贡献度分配问题。目前大部分采用神经网路模型的深度学习都是端到端学习。</p><h2 id=五学术会议>五、学术会议</h2><table><thead><tr><th style=text-align:left>简称</th><th style=text-align:left>介绍</th></tr></thead><tbody><tr><td style=text-align:left>ICLR</td><td style=text-align:left>国际表征学习大会（International Conference on Learning Representations）: 主要聚焦深度学习</td></tr><tr><td style=text-align:left>NeurIPS</td><td style=text-align:left>神经信息处理系统大会（Annual Conference on Neural Information Processing Systems）：交叉学科会议，但偏重于机器学习，主要包括神经信息处理、统计方法、学习理论及应用</td></tr><tr><td style=text-align:left>ICML</td><td style=text-align:left>国际机器学习会议（International Conference on Machine Learning）：机器学习顶级会议。深度学习作为近年来的热点，也占据了ICML</td></tr><tr><td style=text-align:left>IJCAI</td><td style=text-align:left>国际人工智能联合会议（International Joint Conference on Artificial Intelligence）：人工智能领域顶尖的综合性会议，历史悠久，从1969年开始举办。</td></tr><tr><td style=text-align:left>AAAI</td><td style=text-align:left>国际人工智能协会（AAAI Conference on Artificial Intelligence）：人工智能领域的顶级会议，每年二月份左右召开，一般在北美。</td></tr><tr><td style=text-align:left></td><td style=text-align:left>人工智能的子领域 - 专业学术会议</td></tr><tr><td style=text-align:left>CVPR</td><td style=text-align:left>IEEE国际计算机视觉与模式识别会议（IEEE Conference on Computer Vision and Pattern Recognition）</td></tr><tr><td style=text-align:left>ICCV</td><td style=text-align:left>计算机视觉国际大会（International Conference on Computer Vision）</td></tr><tr><td style=text-align:left>ACL</td><td style=text-align:left>国际计算语音学协会（Annual Meeting of the Association for Computational Linguistics）</td></tr><tr><td style=text-align:left>EMNLP</td><td style=text-align:left>自然语言处理实证方法会议（Conference on Empirical Methods in Natural Language Processing）</td></tr></tbody></table></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00030_deeplearning_summary%2f0005_deeplearning_summary%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00030_deeplearning_summary%2f0005_deeplearning_summary%2f&text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%bc%80%e7%af%87&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00030_deeplearning_summary%2f0005_deeplearning_summary%2f&title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%bc%80%e7%af%87" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00030_deeplearning_summary%2f0005_deeplearning_summary%2f&title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%bc%80%e7%af%87" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%bc%80%e7%af%87 https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00030_deeplearning_summary%2f0005_deeplearning_summary%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%bc%80%e7%af%87&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00030_deeplearning_summary%2f0005_deeplearning_summary%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/ title=基本概念 class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>基本概念</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/ title=深度学习-结构 class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>深度学习-结构</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一机器学习>一、机器学习</a></li><li><a href=#二表征学习>二、表征学习</a></li><li><a href=#三深度学习>三、深度学习</a><ul><li><a href=#1神经元>1、神经元</a></li></ul></li><li><a href=#四学习方式>四、学习方式</a><ul><li><a href=#1多阶段>1、多阶段</a></li><li><a href=#2端到端>2、端到端</a></li></ul></li><li><a href=#五学术会议>五、学术会议</a></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script><script src=/js/mermaid-8.14.0.min.js></script><script>mermaid.initialize({startOnLoad:true});</script></body></html>