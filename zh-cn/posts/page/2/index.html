<!doctype html><html><head><title>博文</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="博文"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/"><meta property="og:updated_time" content="2022-09-09T06:00:20+06:00"><link rel=stylesheet href=/css/layouts/list.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="flag-icon flag-icon-zh-cn"></span>简体中文</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/posts><span class="flag-icon flag-icon-gb"></span>English</a></div></li><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/toha-tutorial/toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/toha-tutorial/write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/toha-tutorial/markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/toha-tutorial/latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/toha-tutorial/shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/deeplearning_summary/draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/deeplearning_summary/cam/ title=CAM>CAM</a></li><li><a href=/zh-cn/posts/deeplearning_summary/deeplearning_start/ title=深度学习开篇>深度学习开篇</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/programming_language/python/internal_lib/encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/programming_language/python/internal_lib/basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/programming_language/python/internal_lib/advance_operator/ title=进阶操作>进阶操作</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/programming_language/python/sdk_lib/multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/programming_language/python/sdk_lib/importlib/ title=importlib>importlib</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/tf/compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/programming_language/pytorch/torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/tensor/ title=Tensor>Tensor</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/mxnet/ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/programming_language/mxnet/ndarray/ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/backbone/>基础</a><ul><li><a href=/zh-cn/posts/cv/backbone/backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/cv/backbone/optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/cv/backbone/backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/cv/contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/cv/vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/cv/detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/cv/semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/cv/image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/cv/image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/nlp/word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/rnn/>RNN</a><ul><li><a href=/zh-cn/posts/nlp/rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/nlp/rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/nlp/rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/nlp/rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/nlp/transformer/attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/nlp/transformer/transformer_summary/ title=Transformer>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/gpt/>GPT</a><ul><li><a href=/zh-cn/posts/nlp/gpt/gpt_summary/ title=GPT综述>GPT综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/bert/>Bert</a><ul><li><a href=/zh-cn/posts/nlp/bert/bert_summary/ title=Bert综述>Bert综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/bart/>BART</a><ul><li><a href=/zh-cn/posts/nlp/bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/nlp/electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/code/>CODE</a><ul><li><a href=/zh-cn/posts/nlp/code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/vlp/>多模态</a><ul><li><a href=/zh-cn/posts/vlp/vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/vlp/clip/ title=CLIP>CLIP</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/video/>视频理解</a><ul><li><a href=/zh-cn/posts/video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/zh-cn/posts/cv/backbone/backbone_net/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>backbone net</h5><p class="card-text post-summary">卷积神经网络的发展历程：
一、Backbone 1. LeNet 论文
LeNet：名字来源于第一作者Yann LeCun。是一个奠基性的网络，第一次将卷积神经网络推上舞台。
卷积层+最大池化：卷积层用来识别图像里的空间模式；最大池化用来降低卷积层对位置的敏感度。卷积层块由两个这样的基本单位重复堆叠构成。 LeNet可以在早起的小数据集上取得较好的效果，但是在更大的真实数据集上表现并不如人意。一方面：神经网络计算复杂，在GPU没有大量普及的20世纪90年代，训练一个多通道、多层、含有大量参数的卷积神经网络是很难完成的；另一方面：当年并没有深入研究参数初始化和非凸优化算法，导致复杂的神经网络的训练通常比较困难。 特征本身是由学习得来的，为了表征足够复杂的输入，特征本身应该分级表示。想要学习到复杂的多级特征，需要大量的带有标签的数据，这样才能表现得比其他经典方法要好。早期研究只基于小的公开数据集，自2009年ImageNet数据集创建以来，传统方法不再有优势。 输入：32*32 C1-卷积层：卷积层尺寸：6 * 28 * 28；卷积核尺寸：6 * 1 * 5 * 5；可训练参数：(5 * 5 + 1) * 6 S2-池化层：池化尺寸：2 * 2；步幅：2；方式：4个输入相加，然后乘以个可训练参数，加上个可训练参数，最后通过sigmoid；输出尺寸：6 * 14 * 14；可训练 参数：2 * 6 C3-卷积层：输出尺寸：16 * 10 * 10；卷积核尺寸: 16 * 6 * 5 * 5;
组合方式：前6个map - 以S2中3个相邻的feature map
再6个map - 以S2中4个相邻的feature map
再3个map - 以S2中不相邻的4个feature map
再1个map - 以S2中所有feature map S4-池化层：输出尺寸：16 * 5 * 5；池化尺寸：2 * 2；步幅：2</p></div><div class=card-footer><span class=float-left>September 9, 2021</span>
<a href=/zh-cn/posts/cv/backbone/backbone_net/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/cv/backbone/backbone_cnn/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>CNN</h5><p class="card-text post-summary">一、卷积 实际上，卷积操作需要对卷积核进行上下/左右翻转，然后用卷积核对输入进行滑动计算。由于网络学习目的是要"学习"出一个近最优解的权重，即：近最优解情况下卷积核的值，所以在卷积操作时，也就没必要在做翻转操作，反正卷积核的值是要被"调教"的，最终的卷积核的状态：可以看成是已经被上下/左右翻转过了。卷积操作也就变成互相关运算。
卷积层解决的问题：
卷积层保留输入图片的形状，使图像的像素在高/宽两个方向上的相关性均可能被有效识别。 卷积层通过滑动窗口，将同一卷积核与不同位置的输入重复计算，参数共享，避免参数尺寸过大。 在卷积操作时，会有两个超参数：填充(padding)和步幅(stride)，根据输入尺寸和卷积核改变输出形状：
假设：输入尺寸：nh * nw，卷积核尺寸：kh * kw
填充(padding)：在输入高和宽的两侧填充元素(通常是0)，一般来说：在高的两侧一共填充ph行；在宽的两侧一同填充pw列，一般填充的是偶数，即：nn.Conv2D(padding=(ph/2, pw/2)) 步幅(stride)：在滑动计算时，每次滑动的步长，假设：在高上步幅为sh，在宽上步幅为sw 则：输出尺寸： $$ \tag{公式1} o_h = \frac{n_h-k_h+p_h+s_h} {s_h }, o_w = \frac{n_w-k_w+p_w+s_w} {s_w } $$
1. 1*1卷积层 1*1卷积层：被看作是卷积操作的全连接层。这是为什么呢？
1*1卷积的计算发生在通道维度上：输出的每个元素，来自输入中相同位置的元素在不同通道之间按权重叠加。假设我们将通道维度当作特征维度，将宽高维度上的元素看作数据样本，那么1*1卷积层的作用与全连接等价。 二、池化层 池化层(pooling)：缓解卷积层对位置的过渡敏感性。
浅层网络获取的是图像的细节信息，比如：纹理特征、边缘；高层网络获取的是图像的整体特征。池化层把感受野扩大，把图像的整体特征传递下去，网络越深感受野越大 池化层一般是最大池化或者平均池化，类比生物学的神经细胞：只有电解质信号超过一定阈值，才能激活下一个神经元，才能把信号传递下去。 三、批量归一化 batch normalization：在一个batch内，算出平均值a, 方差：b^2；然后对每个样本做归一化：c*(x-a)/b+d。其中c、d是需要训练的。
$$ x_{i+1} = \gamma \frac{x_i - \mu}{\sigma} + \beta $$ 由于数据的差异性，在卷积后可能会存在较大的波动。$\frac{x_i - \mu}{\sigma}$ 的作用就是把数据统一拉回N(0,1)的标准正态分布；但是每个特征的分布不一定是标准正态分布，所以添加了可学习的参数：$\gamma, \beta$。 通过训练来调节实际的均值 $\beta$ 和标准差 $\gamma$ ，不过 $\beta$ 和 $\gamma$ 是在一定的范围内，不能波动太大。</p></div><div class=card-footer><span class=float-left>September 9, 2021</span>
<a href=/zh-cn/posts/cv/backbone/backbone_cnn/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/cv/backbone/optimizer/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>optimizer</h5><p class="card-text post-summary">在深度学习中，通过最小化损失函数使得训练误差最小化，由于损失函数一般都会比较复杂，很难直接求解析解，而是需要基于数值方法的优化算法找到近似解，即：数值解。在局域数值方法的优化算法中，损失函数就是目标函数(Objective Function)，
1. 梯度下降法 梯度下降(gradient descent)的工作原理，以一维为例： 假设连续可导的函数 $f:\Reals \to \Reals$ 的输入和输出都是标量，给定绝对值足够小的数 $\epsilon$ ，根据泰勒展开式，近似： $$ f(x+\epsilon) \approx f(x) + \epsilon f'(x) $$ 其中 $f'(x)$ 表示函数在x处的梯度。找到一个常数 $\eta > 0$，使得 $\lvert \eta f'(x) \rvert$ 足够小，那么可以将 $\epsilon$ 提换为 $-\eta f'(x)$，得到： $$ f(x-\eta f'(x)) \approx f(x) - \eta f'(x)^{2} $$ 所以 $$ f(x-\eta f'(x)) \lesssim f(x) $$ 这就意味着，可以通过 $x \gets x-\eta f'(x)$ 来迭代x，函数 $f(x)$ 的值可能会降低。在梯度下降中，先取一个初始值 $x_0$ 和学习率 $\eta>0$，然后不断通过上式迭代x，直到停止条件。学习率 $\eta$ 是一个超参数，需要人工设定，如果学习率过小：会导致x更新缓慢从而需要更多的迭代次数；如果学习率过大，泰勒展开式不再成立，可能会出现振荡，无法保证会迭代出近似最优解。
在每次迭代中，由于训练集较大，不可能把所有样本都加载到内存中，通常是随机均匀采样多个样本组成一个小批量，然后使用这个小批量来计算梯度，完成一次迭代，即：小批量随机梯度下降(batch gradient descent)。
设：目标函数 $f(x): \Reals^{d} \to \Reals$ 小批量数据集 $\text{\ss}$ 梯度计算： $$ g_t \gets \nabla f_{\text{\ss}_{t}}=\frac {1} {\lvert \text{\ss} \rvert} \displaystyle\sum_{i \in \text{\ss}_{t}} \nabla f_i(x_{t-1}) $$</p></div><div class=card-footer><span class=float-left>September 9, 2021</span>
<a href=/zh-cn/posts/cv/backbone/optimizer/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/deeplearning_summary/draw_map_for_dl/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>神经网络画图篇</h5><p class="card-text post-summary">一、简介 一图抵万言！本篇介绍神经网络的可视化工具和绘图软件。
二、示意图 1、NN SVG 提供三种典型的神经网络绘图风格，个性化参数多；交互式绘图。 NN-SVG是由麻省理工学院弗兰克尔生物工程实验室开发的。可以绘制的图包括以节点形式展示的FCNN style，这个特别适合传统的全连接神经网络的绘制。
Github
Demo
2、PlotNeuralNet 底层基于latex的宏指令绘制，上层提供基于python的描述框架，绘制脚本简单。可以绘制复杂的网络结构。
PlotNeuralNet 是由萨尔大学计算机科学专业的一个学生开发的，目前主要支持的是卷积神经网络，其中卷积层、池化层、bottleneck、skip-connection、up-conv、Softmax等常规的层在代码中都有定义，但缺少RNN相关的可视化层展示。
Github
三、计算图 1、Netron Netron是一个神经网络可视化包，支持绝大多数神经网络操作。该功能包可以为不同节点显示不同的颜色，卷积层用蓝色显示，池化层和归一化层用绿色显示，数学操作用黑色显示。在使用方面，可以直接访问网页端，上传模型文件，就可以看到网络结构图，并可以进一步利用pip安装并引入到程序中通过浏览器查看模型的变化。
Github
Demo</p></div><div class=card-footer><span class=float-left>September 9, 2021</span>
<a href=/zh-cn/posts/deeplearning_summary/draw_map_for_dl/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/transformer/attention/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Attention</h5><p class="card-text post-summary">一、Attention机制 如何有选择地引导注意力：
非自主性提示： 基于环境中物体的突出性和易见性。比如 《辛德勒的名单》中的镜头：黑白镜头中的穿红衣服的小女孩。
自主性提示： 选择受到 认知、意识的控制。
在不受自我意识控制的情况下，与环境差别最大的事物，就越显眼、易见。
在受到自我意识控制的情况下，意识偏向那个，就选择那个
查询(query)：自主性提示，类似于自我意识。
键(key)：非自主提示，类似于事物的突出性、易见性。
值(value)：感官输入，类似于具体的事物-值。
attention机制可以认为是一个这样的函数：
$$ f(\bold{q_j}) = \sum_{i=1}^m \alpha(\bold{q}_j, \bold{k}_i) \bold{v}_i$$ 由$ \bold{V}$ 的各个向量的加权平均，组成一个新的向量 $f(q_j)$。其中，权重的计算是通过 query向量和每个key向量 计算出来的，这个计算方式可以有多种，比如：加性注意力、缩放点积注意力
$\bold{Q} \in \R^{n \times q}$: 查询矩阵，是由N个向量组成，每个向量有q个元素
K-V: M个键值对集合。
$\bold{K} \in \R^{m \times k}$: M个键向量组成的矩阵，每个键向量(k维)：就是每个字的标签信息
$\bold{V} \in \R^{m \times v}$: M个值向量组成的矩阵，每个值向量(v维)：就是每个字的embeding
1、加性注意力 $$\alpha(\bold{q}_j, \bold{k}_i) = \bold{w}_v^T tanh(\bold{W}_q \bold{q}_j + \bold{W}_k \bold{k}_i)$$ 其中，$\bold{w}_v^T \in \R^h, \bold{W}_q \in \R^{h \times q}, \bold{W}_k \in \R^{h \times k}$ 是需要训练的。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/transformer/attention/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/bart/bart_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>BART综述</h5><p class="card-text post-summary">一、背景 二、BART BART的全称是
三、总结</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/bart/bart_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/bert/bert_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Bert综述</h5><p class="card-text post-summary">一、背景 在使用预训练模型，处理下游任务时，有两类策略：基于特征(feature-based)、基于微调(fine-tuning)
基于特征：比如：ELMo，在使用时，对每个下游任务，创建一个跟这个任务相关的神经网络；预训练作为额外的特征跟输入一起输入到模型，预训练的额外特征可能会对要训练的模型有指导作用。 基于微调：比如：GPT，预训练模型在下游使用时，不需要改动太多，类似于视觉模型的fine-tuning，预训练完成特征提取，预训练模型后面添加个简单的网络用于实现具体任务。 1、上下文敏感 在自然语言中，有丰富的多义现象，一个词到底是什么意思，需要参考上下文才能判断。流行的上下文敏感表示：
TagLM(language-model-augmented sequence tagger 语言模型增强的序列标记器) CoVe(Context Vectors 上下文向量) ELMo(Embeddings from Language Models 来自语言模型的嵌入) ELMo 将来自预训练LSTM的所有中间层表示组合为输出表示 ELMo的表示，将作为添加特征添加到下游任务的有监督模型中 2、从特定任务到通用任务 ELMo显著改进了自然语言任务，但每个解决方案仍然依赖于一个特定的任务架构。怎么设计一个模型，让各个自然语言任务通用呢？
GPT(Generative Pre Training 生成式预训练)：在Transformer的基础上，为上下文敏感设计了通用的模型。
预训练一个用于表示文本序列的语言模型 当将GPT应用于下游任务时，语言模型的后面接一个线性输出层，以预测任务的标签。GPT的下游任务的监督学习过程，只对预训练Transformer解码器中的所有参数做微调。 GPT只能从左到右 二、BERT BERT的全称是Bidirectional Encoder Representation from Transformers, 即双向Transformer的Encoder。Bert结合了ELMo和GPT的有点，其主要贡献：
双向的重要性 基于微调的掩码语言模型(Masked Language Modeling)：BERT随机遮掩词元，并使用来自双向上下文的词元以自监督的方式预测该遮掩词元。 1、构造输入 token embedding: 格式：&lt;CLS>第一个文本序列&lt;SEP>第二个文本序列&lt;SEP>
segment embedding: 用来区分句子
position embedding: 在bert中 位置嵌入 是可学习的
def get_tokens_and_segments(tokens_a, tokens_b=None): """获取输入序列的词元及其片段索引""" tokens = ['&lt;cls>'] + tokens_a + ['&lt;sep>'] # 0和1分别标记片段A和B segments = [0] * (len(tokens_a) + 2) if tokens_b is not None: tokens += tokens_b + ['&lt;sep>'] segments += [1] * (len(tokens_b) + 1) return tokens, segments 2、MLM 词元维度</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/bert/bert_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/code/bart_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>code解析</h5><p class="card-text post-summary">一、transformers Hugging Face公司发布的transformers包，能够超级方便的引入训练模型：BERT、GPT2、&mldr; transformers英文文档 transformers中文文档
二、Tokenizer from transformers import BertTokenizerFast, BertTokenizer from transformers import GPT2TokenizerFast, GPT2LMHeadModel # 初始化tokenizer tokenizer = BertTokenizerFast(vocab_file=args.vocab_path, sep_token="[SEP]", pad_token="[PAD]", cls_token="[CLS]") # 对比 tokenizer.encode() 与 tokenizer.tokenize() sentence = "Hello, my son is cuting." input_ids_1 = tokenizer.encode(sentence, add_special_tokens=False) # add_special_tokens=True 将句子转换成对应模型的输入形式，默认开启。就是首尾加上[cls]、[sep]。即：tensor([ 101, 7592, 1010, 2026, 2365, 2003, 3013, 2075, 1012, 102]) # add_special_tokens=False 首尾先不加[cls]、[sep] input_tokens = tokenizer.tokenize(sentence) # ['hello', ',', 'my', 'son', 'is', 'cut', '##ing', '.'] input_ids_2 = tokenizer.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/code/bart_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/electra/electra_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>ELECTRA综述</h5><p class="card-text post-summary">一、背景 二、ELECTRA ELECTRA的全称是Efficiently Learning an Encoder that Classifies Token Replacements Accurately。最主要的贡献是提出了新的预训练任务和框架，把生成式的Masked language model(MLM)预训练任务改成了判别式的Replaced token detection(RTD)任务，判断当前token是否被语言模型提换过。
三、总结</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/electra/electra_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/gpt/gpt_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>GPT综述</h5><p class="card-text post-summary">一、简介 参考
评估指标：
困惑度：困惑度（perplexity）的基本思想是：给测试集的句子赋予较高概率值的语言模型较好,当语言模型训练完之后，测试集中的句子都是正常的句子，那么训练好的模型就是在测试集上的概率越高越好，公式如下 $PP(W)=P(w_1w_2&mldr;w_N)^{\frac{-1}{N}}$ 。由公式可知，句子概率越大，语言模型越好，迷惑度越小。困惑度p可以理解为，如果每个时间步都根据语言模型计算的概率分布随机挑词，那么平均情况下，挑多少个词才能挑到正确的那个 Prompt ranking accuracy：这个指标的定义和评价方法，来自《Hierarchical Neural Story Generation》。主要是关注引导语和生成的故事之间的相关性。具体做法是：在测试集中选择一对（p，g），p表示引导语，g表示生成的故事，在随机选取其他的引导语p1-p9，然后计算p和g的likelihood。条件一：（p，g）的相似性比（p1，g）的相似性大。 那么就取10000个测试集中的（p，g），满足条件一的部分占比，就称为Prompt ranking accuracy。 句子嵌入的相似度：计算引导语和生成的故事的句子嵌入（用GloVe取每个词的平均嵌入值）的余弦相似度。 评价连贯性：连贯性的评价方法，来自《Modeling local coherence: An entity-based approach》，主要思想是，在测试数据集中，对于一个故事s0，选择前面15个句子，打乱顺序，生成14个乱序的故事s1-s14。然后用语言模型计算s0-s14的可能性。对于s1-s14，如果可能性大于s0，就称为反例。 错误率定义为反例的占比。 评价单词的重复性和rareness 二、GPT GPT(2018-06)
三、GPT-2 GPT-2(2019-02)
GPT-2去掉了fine-tuning层：不再针对不同任务分别进行微调建模，而是不定义这个模型应该做什么任务，模型会自动识别出来需要做什么任务。这就好比一个人博览群书，你问他什么类型的问题，他都可以顺手拈来，GPT-2就是这样一个博览群书的模型。在Pretrain部分基本与GPT方法相同，在Fine-tune部分把第二阶段的Fine-tuning有监督训练具体NLP任务，换成了无监督训练具体任务，这样使得预训练和Fine-tuning的结构完全一致。当问题的输入和输出均为文字时，只需要用特定方法组织不同类型的有标注数据即可代入模型，如对于问答使用“问题+答案+文档”的组织形式，对于翻译使用“英文+法文”形式。用前文预测后文，而非使用标注数据调整模型参数。这样既使用了统一的结构做训练，又可适配不同类型的任务。虽然学习速度较慢，但也能达到相对不错的效果。 增加网络参数：GPT-2将Transformer堆叠的层数增加到48层，隐层的维度为1600，参数量更是达到了15亿。(Bert的参数量也才只有3亿)。base版-12层-117M，medium版-24层-345M，large版-36层-774M，xl版-48层-1558M。 调整transformer：将layer normalization放到每个sub-block之前，并在最后一个Self-attention后再增加一个layer normalization。 四、GPT-3 GPT-3(2020-05)
五、chatGPT chatGPT(2022-12)
BART(Bidirectional and Auto-Regressive Transformers，双向自回归转换器)
prompt
Google T5 (Text-to-Text Transfer Transformer)
Masked language model(MLM) Replaced token detection(RTD)
参考 GPT-chatbot</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/gpt/gpt_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/rnn/gru/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>GRU网络</h5><p class="card-text post-summary">一、简介 RNNs中，需要的信息都放在隐藏层，当序列太长时，隐藏层累积了太多的信息，对前面太久的信息，就不容易获取到了。
另外，有些信息不太重要，有些词比较重要，所以，设计了：
更新门： $Z_t$ 有助于捕获序列中的长期依赖关系。当$Z_t = 0$时，并不是就没有$H_{t-1}$的信息了，而是$H_{t-1}$的信息通过正常的计算$H_t$的途径进来；而当$Z_t > 0$时，$H_{t-1}$的信息可以绕过正常的计算途径，直接添加到$H_t$中。
重置门： $R_t$ 有助于捕获序列中的短期依赖关系。$\tilde{H_t}$ 的计算跟RNNs计算相似，就是加了 $R_t$ 来限制 $H_{t-1}$，本来RNNs对太久的信息就不容易获取，所以 $R_t$ 的作用：是否忘掉历史没用的信息。
$$R_t = sigmoid(X_tW_{xr}+H_{t-1}W_{hr}+b_r)$$ $$Z_t = sigmoid(X_tW_{xz}+H_{t-1}W_{hz}+b_z)$$ $$\tilde{H_t} = tanh(X_tW_{xh} + (R_t \odot H_{t-1})W_{hh} + b_h)$$ $$H_t = Z_t \odot H_{t-1} + (1-Z_t)\odot \tilde{H_t}$$
其中，$R_t$ ：表示在更新候选隐状态时，需要多少历史隐状态信息，$Z_t$ ：表示在算真正的隐状态时，需要多少新输入的$X_t$的信息，这两个的维度与隐状态是一致的。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/rnn/gru/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/rnn/lstm/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>LSTM网络</h5><p class="card-text post-summary">一、简介 长短期记忆网络(LSTM)
忘记门：$F_t = sigmoid(X_tW_{xf}+H_{t-1}W_{hf}+b_f)$ 输入门：$I_t = sigmoid(X_tW_{xi}+H_{t-1}W_{hi}+b_i)$ 输出门：$O_t = sigmoid(X_tW_{xo}+H_{t-1}W_{ho}+b_o)$ 候选记忆单元：$\tilde{C_t} = tanh(X_tW_{xc} + (R_t \odot H_{t-1})W_{hc} + b_c)$ 记忆单元：$C_t = F_t \odot C_{t-1} + I_t\odot \tilde{C_t}$ 隐状态：$H_t = O_t \odot tanh(C_t)$ 其中，$F_t, I_t, O_t, C_t, H_t, \in \R^{n \times d}$</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/rnn/lstm/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/zh-cn/posts/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/zh-cn/posts/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/zh-cn/posts/>1</a></li><li class="page-item active"><a class=page-link href=/zh-cn/posts/page/2/>2</a></li><li class=page-item><a class=page-link href=/zh-cn/posts/page/3/>3</a></li><li class=page-item><a class=page-link href=/zh-cn/posts/page/4/>4</a></li><li class=page-item><a href=/zh-cn/posts/page/3/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/zh-cn/posts/page/4/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=/js/list.js></script></body></html>