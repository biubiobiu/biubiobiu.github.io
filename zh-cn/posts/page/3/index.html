<!doctype html><html><head><title>博文</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="博文"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/"><meta property="og:updated_time" content="2022-05-09T06:00:20+06:00"><link rel=stylesheet href=/css/layouts/list.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="flag-icon flag-icon-zh-cn"></span>简体中文</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/posts><span class="flag-icon flag-icon-gb"></span>English</a></div></li><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/toha-tutorial/toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/toha-tutorial/write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/toha-tutorial/markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/toha-tutorial/latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/toha-tutorial/shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/deeplearning_summary/draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/deeplearning_summary/deeplearning_start/ title=深度学习开篇>深度学习开篇</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/programming_language/python/internal_lib/encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/programming_language/python/internal_lib/basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/programming_language/python/internal_lib/advance_operator/ title=进阶操作>进阶操作</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/programming_language/python/sdk_lib/multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/programming_language/python/sdk_lib/importlib/ title=importlib>importlib</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/tf/compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/programming_language/pytorch/torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/tensor/ title=Tensor>Tensor</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/mxnet/ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/programming_language/mxnet/ndarray/ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/backbone/>基础</a><ul><li><a href=/zh-cn/posts/cv/backbone/backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/cv/backbone/optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/cv/backbone/backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/cv/contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/cv/vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/cv/detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/cv/semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/cv/image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/cv/image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/nlp/word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/rnn/>RNN</a><ul><li><a href=/zh-cn/posts/nlp/rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/nlp/rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/nlp/rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/nlp/rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/nlp/transformer/attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/nlp/transformer/transformer_summary/ title=Transformer>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/gpt/>GPT</a><ul><li><a href=/zh-cn/posts/nlp/gpt/gpt_summary/ title=GPT综述>GPT综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/bert/>Bert</a><ul><li><a href=/zh-cn/posts/nlp/bert/bert_summary/ title=Bert综述>Bert综述</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/vlp/>多模态</a><ul><li><a href=/zh-cn/posts/vlp/vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/vlp/clip/ title=CLIP>CLIP</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/video/>视频理解</a><ul><li><a href=/zh-cn/posts/video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/zh-cn/posts/programming_language/python/internal_lib/basic_operator/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>基础操作</h5><p class="card-text post-summary">一、数据类型与操作 操作 说明 del A[i] 删除列表A中下标为i的元素，其后的每个元素都前移一个位置 列表-删除 A.pop() 弹出列表尾部元素，相当于出栈 列表-删除 A.pop(i) 弹出列表中任何位置出的元素 列表-删除 A.remove('a') 有时候不知道索引号，只知道要删除的值；remove只删除第一个指定的值 列表-删除 A.sort(reverse=True) 对列表A从大到小排序，列表A被永久改变 列表-排序 B=sorted(A) 排序后，A没有被改变 列表-排序 A.reverse() A列表被永久的翻转了一下 列表-翻转 二、*和**的作用 * 在函数定义/调用时的应用
在函数定义时：*让python创建一个名为topping的空元组，并将收到的所有值封装在这个元组中。 def make_pizza(size, *topping): # 定义 .</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/python/internal_lib/basic_operator/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/programming_language/python/internal_lib/encode_mode/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>字符编码</h5><p class="card-text post-summary">一、字符编码 ASCII：计算机是美国人发明的，所以最早只考虑了简单的26个字母和一些控制字符，所以只用7-bit组合出128个组合，编号0~127，存储的时候凑成了一个byte。这个组合没有考虑其他国家，比如汉字就不只128个，于是中国为汉字编码发明了GB2312编码，其他国家也有自己的各种编码，互不兼容。
为了统一，提出了unicode编码，包含了各个国家的文字，对每个字符都用2个byte来表示，英文的话就在前面加0。
unicode对于英文就会有些浪费，为了解决这个问题，为了节约硬盘空间/ 网络带宽，又发明了utf-8编码，1个字符可能会被编码成1~6个字节，英文还是1个字节，汉字变成了3个字节，只有在生僻字才会在4个字节。
字符 ASCII unicode utf-8 A 01000001 00000000 01000001 01000001 中 01001110 00101101 11100100 10111000 10101101 字符应用层的形式 字符在内存的形式 字符在硬盘/网络中的形式 二、解析/转换 图片在网络中获取下来是二进制的格式(bytes)；或者通过 open('***.jpg', &lsquo;rb&rsquo;) 读取的图片也是二进制的格式
bytes格式 &lt;-> str
bytes: 是(二进制)数字序列，是utf-8的编码形式。该格式的变量是不可修改的。 str &ndash;> bytes : 使用str.encode()方法 bytes &ndash;> str : 使用bytes.decode()方法 bytearray(): 该格式的变量是可以修改的 a = '人生苦短' # 此时b的格式是bytes，是不能修改的，即不能操作：b[:6] = '生命'.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/python/internal_lib/encode_mode/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/programming_language/python/sdk_lib/multiprocessing/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>并行操作</h5><p class="card-text post-summary">一、线程与进程 进程 线程 进程：是一个应用程序在处理机上的一次执行过程，是具有一定独立功能的程序在某数据集上的一次运行，是一个动态的概念。进程是系统进行资源分配和调度的独立单位。 线程：是进程中的一个实体，是CPU调度和分派的基本单位，线程自己基本上不拥有系统资源，它与同属于一个进程内的其他线程共享进程的全部资源。 地址空间 进程有自己独立的地址空间 进程中至少有一个线程，它们共享进程的地址空间 资源 进程是资源分配和拥有的单位 进程内的多个线程共享进程的资源 调度 线程是进程内的一个执行单元，也是进程内的可调度实体，也是处理器调度的基本单位 二、多线程 1、threading模块 python主要是通过thread和threading这两个模块来实现多线程，thread模块是比较底层的模块，threading模块是对thread做了一些封装，使用更方便。但是由于GIL的存在，无法使用threading充分利用CPU资源，如果想充分发挥多核CPU的计算能力，需要使用multiprocessing模块
python 3.x 已经摒弃了python 2.x中采用函数式thread模块来产生线程的方式。而是通过threading模块创建新的线程：
通过threading.Thread(Target=可执行方法)
import threading pro_list = [] mult_image_label_list = [] for index, img_list in enumerate(mult_image_label_list): # 创建线程 t1 = threading.Thread(target=函数名, args=(index, img_list)) pro_list.append(t1) for thread in pro_list: # 将线程设置为保护线程，否则会被无限挂起。 thread.setDaemon(True) thread.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/python/sdk_lib/multiprocessing/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/cv/image-matting/image-matting-summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>抠图综述</h5><p class="card-text post-summary">It&rsquo;s coming soon.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/cv/image-matting/image-matting-summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_train/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>模型训练</h5><p class="card-text post-summary">一、tf.layers tf.layers模块在TensorFlow2.0中已经被完全移除了，用tf.keras.layers定义层是新的标准。
二、tf.losses tf.losses模块包含了经常使用的、能够实现独热编码的损失函数。
三、tf.train 1. Optimizer TensorFlow提供的优化器
优化器 功能 tf.train.Optimizer tf.train.GradientDescentOptimizer tf.train.AdadeltaOptimizer tf.train.AdagtadOptimizer tf.train.AdagradDAOptimizer tf.train.MomentumOptimizer tf.train.AdamOptimizer tf.train.FtrlOptimizer tf.train.ProximalGradientDescentOptimizer tf.train.ProximalAdagradOptimizer tf.train.RMSProOptimizer Optimizer类与其子类的继承关系：
def minimize(self, loss, # 损失值， tensor # 全局训练步数，随着模型迭代优化自增， variable global_step=None, # 待训练模型参数的列表， list var_list=None, # 计算梯度和更新参数模型时的并行化程度，可选值GATE_OP,GATE_NONE,GATE_GRAPH # GATE_NONE 无同步，最大化并行执行效率，将梯度计算和模型参数更新完全并行化。 # GATE_OP，操作级同步，对于每个操作，分别确保所有梯度在使用前都计算完成。 # GATE_GRAPH，图级同步，最小化并行执行效率，确保所有模型参数的梯度计算完成。 gate_gradients=GATE_OP, # 聚集梯度值的方法， Enum aggregation_methed=None, # 是否将梯度计算放置到对应操作所在同一个设备，默认否，Boolean colocate_gradients_with_ops=False, # 优化器在数据流图中的名称，string nmae=None, # 损失值的梯度 grad_loss=None) 属性 功能介绍 _name 表示优化器的名称 _use_locking 表示是否在并发更新模型参数时加锁 minimize 最小化损失函数，该方法会依次调用compute_gradients和apply_gradients compute_gradients 计算模型所有参数的梯度值,返回&lt;梯度，响应参数>的键值对列表 apply_gradients 将梯度值更新到对应的模型参数，优化器的apply_gradients成员方法内部会调用tf.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_train/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/cv/detect_object/object_detection_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>简介</h5><p class="card-text post-summary">一、简介 It&rsquo;s coming soon.
二、网络 1、R-CNN 《Rich feature hierarchies for accurate object detection and semantic segmentation》(2013)
2、SPPNet 《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》(2014)
3、Fast R-CNN 《Fast R-CNN》(2015)
4、Faster R-CNN 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》(2016)
5、FPN 《Feature Pyramid Networks for Object Detection》(2017)
4、YOLO 《You Only Look Once: Unified, Real-Time Object Detection》(2016)
5、YOLO V2 《YOLO9000: Better, Faster, Stronger》(2016)
6、YOLO V3 《YOLOv3: An Incremental Improvement》(2018)</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/cv/detect_object/object_detection_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/cv/semantic_segmentation/object_detection_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>简介</h5><p class="card-text post-summary">一、简介 It&rsquo;s coming soon.
二、网络-基于编码器-解码器 1、FCN 《Fully Convolutional Networks for Semantic Segmentation》(2015) 要说语义分割整体实现精度大的跨越还是在FCN（全卷积神经网络）提出之后。它完全改变了之前需要一个窗口来将语义分割任务转变为图片分类任务的观念，FCN完全丢弃了图片分类任务中全连接层，从头到尾都只使用到了卷积层。从FCN后，基于编码器解码器结构的经典网络结构如同雨后春笋般冒了出来
2、U-Net 《U-Net: Convolutional Networks for Biomedical Image Segmentation》(2015) Unet网络是在医学影像分割中最常用的模型。它的典型特点是，它是U型对称结构，左侧是卷积层，右侧是上采样层（典型的编码器解码器结构）。
另一个特点是，Unet网络的每个卷积层得到的特征图都会concatenate到对应的上采样层，从而实现对每层特征图都有效使用到后续计算中。也就是文中所说的skip-connection。这样，同其他的一些网络结构比如FCN比较，Unet避免了直接在高级feature map中进行监督和loss计算，而是结合了低级feature map中的特征，从而可以使得最终所得到的feature map中既包含了high-level 的feature，也包含很多的low-level的feature，实现了不同scale下feature的融合，提高模型的结果精确度。
3、SegNet 《SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation》(2015) 是一个由剑桥大学团队开发的图像分割的开源项目，该项目可以对图像中的物体所在区域进行分割，例如车，马路，行人等，并且精确到像素级别
4、Deeplab V1 《Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs》(2015) 2015 年的ICLR上提出DeepLab V1是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。它将DenseCRFs作为网络的后处理方法。采用DenseCRFs作为后处理的方法，简单来说，就是对一个像素进行分类的时候，不仅考虑DCNN的输出，而且考虑该像素点周围像素点的值，这样语义分割结果边界清楚。
5、Deeplab V2 《DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs》(2017) 在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是重复的池化和下采样降低了分辨率。但是另一方面，重复的池化和下采样扩大了感受野，而感受野的扩大对语义分割任务来说也是至关重要的。针对这一问题，DeepLab v2采用的空洞卷积算法扩展感受野，与此同时不会降低特征图的分辨率。此外，deeplab v2基于空洞卷积，设计了ASPP模块。它组合了不同dilation rate的空洞卷积所产生的特征图。这样，不同空洞卷积产生的不同感受野的特征图被组合在了一起，从而获取了更加丰富的上下文信息。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/cv/semantic_segmentation/object_detection_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/programming_language/pytorch/torch_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>简介</h5><p class="card-text post-summary">官方文档
torch目录下，树状图:
├── quasirandom.py
├── random.py random模块
├── serialization.py
├── storage.py
├── tensor.py Tensor模块
├── functional.py
│
├── cuda
│　├── comm.py
│　├── error.py
│　├── memory.py
│　├── nccl.py
│　├── nvtx.py
│　├── profiler.py
│　├── random.py
│　├── sparse.py
│　└── streams.py
│
├── nn
│　├── backends
│　├── cpp.py
│　├── functional.py
│　├── grad.py
│　├── init.py
│　├── intrinsic
│　│　├── modules</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/pytorch/torch_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/nlp/rnn/encode_decode/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>编解码架构</h5><p class="card-text post-summary">一、编码器-解码器 架构 机器翻译：是把一个序列转换为另一个序列。为处理这种类型的输入和输出，设计这样的架构：
编码器：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。
解码器：将固定形状的编码状态映射到长度可变的序列。
二、seq2seq Ilya Sutskever 等人设计的seq2seq：将编码器最后一时间步的state，作为解码器第一时间步的state使用。
Kyunghyun Cho 等人设计的seq2seq，将编码器最后一时间步的state，作为解码器每一个时间步的输入序列的一部分。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/nlp/rnn/encode_decode/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/programming_language/python/internal_lib/advance_operator/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>进阶操作</h5><p class="card-text post-summary">一、环境变量 1、临时环境变量 操作 说明 功能 os.environ['WORKON_HOME']="变量" 设置环境变量 os.environ.get('WORKON_HOME') 获取环境变量-方法1 os.getenv('path') 获取环境变量-方法2-推荐 del os.environ['WORKON_HOME'] 删除环境变量 os.environ['HOMEPATH'] 当前用户主目录 os.environ['TEMP'] 临时目录路径 os.environ['PATHEXT'] 可以执行文件 os.environ['SYSTEMROOT'] 系统主目录 os.environ['LOGONSERVER'] 机器名 os.environ['PROMPT'] 设置提示符 2、永久环境变量 操作 说明 功能 path = r"路径"</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/python/internal_lib/advance_operator/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>静态图</h5><p class="card-text post-summary">在TensorFlow 2中使用兼容性模块，必须使用tf.compat.v1替换tf，并且在导入TensorFlow软件包后添加一行tf.compat.v1.disable_eager_execution()函数来关闭eager执行模式。
import tensorflow as tf tf.compat.v1.disable_eager_execution() 简介 数据流是一种编程模型，被广泛地应用于并行计算中。TF使用数据流图来表示计算中各个运算之间的关系，在数据流图中，节点：表示计算单元(即：操作tf.Operation)；边：表示被计算单元消费/生产的数据(即：tf.Tensor)。 数据流图，可以被导出成一个可移植的、编程语言不相关的表示(ProtoBuf)，这种表示可以被其他语言使用，来创建一个图并在会话中使用它。
def graph_demo(): a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[10, 0, 0], [0, 0.5, 0], [0, 0, 2]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) y = tf.add(tf.matmul(a, b), c, name='result') writer = tf.summary.FileWriter(os.path.join(root_dir, 'log/matmul'), tf.get_default_graph()) writer.close() return y # 在终端启动TensorBoard对图进行可视化 tensorboard --logdir log/matmul 上例中创建一个数据流图，然后用TensorBoard对这个图进行可视化。
tf.summary.FileWriter 创建了一个tf.summary.SummaryWriter来保存一个图像化表示，这个writer对象创建时，初始化参数包括：a.该图像化表示的存储路径；b.一个tf.Graph对象，可以使用tf.get_default_graph函数返回默认图 tf.get_default_graph 函数，返回默认图。 在执行时，调用TF API创建数据流图，这个阶段并没有进行计算。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/toha-tutorial/latax_formula/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Katex公式</h5><p class="card-text post-summary">官方文档
线上工具
一、基础篇 1. 输入公式 行内公式： 格式：$数学公式$ 例如：$x^2=1$ : $x^2=1$
行间公式：
$$
数学公式
$$
例如: $$f(x)=\int_{-\infty}^\infty\widehat f\xi\ e^{2\pi i\xi x}\ d\xi$$ $$f(x)=\int_{-\infty}^\infty\widehat f\xi\ e^{2\pi i\xi x}\ d\xi$$
二、进阶篇 1. 声调/变音符号 \dot{a}, \ddot{a}, \acute{a}, \grave{a}
$\dot{a}, \ddot{a}, \acute{a}, \grave{a}$
\check{a}, \breve{a}, \tilde{a}, \bar{a}
$\check{a}, \breve{a}, \tilde{a}, \bar{a}$
\hat{a}, \widehat{a}, \vec{a}, \tilde{a}, \widetilde{a}
$\hat{a}, \widehat{a}, \vec{a}, \tilde{a}, \widetilde{a}$
a', a''
$a', a''$
2. 标准函数 指数/上下标</p></div><div class=card-footer><span class=float-left>June 8, 2021</span>
<a href=/zh-cn/posts/toha-tutorial/latax_formula/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/zh-cn/posts/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/zh-cn/posts/page/2/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/zh-cn/posts/>1</a></li><li class=page-item><a class=page-link href=/zh-cn/posts/page/2/>2</a></li><li class="page-item active"><a class=page-link href=/zh-cn/posts/page/3/>3</a></li><li class=page-item><a class=page-link href=/zh-cn/posts/page/4/>4</a></li><li class=page-item><a href=/zh-cn/posts/page/4/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/zh-cn/posts/page/4/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=/js/list.js></script></body></html>