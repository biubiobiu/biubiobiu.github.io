<!doctype html><html><head><title>Attention</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="Attention"><meta property="og:description" content="一、Attention机制 如何有选择地引导注意力：
非自主性提示： 基于环境中物体的突出性和易见性。比如 《辛德勒的名单》中的镜头：黑白镜头中的穿红衣服的小女孩。
自主性提示： 选择受到 认知、意识的控制。
在不受自我意识控制的情况下，与环境差别最大的事物，就越显眼、易见。
在受到自我意识控制的情况下，意识偏向那个，就选择那个
 查询(query)：自主性提示，类似于自我意识。
键(key)：非自主提示，类似于事物的突出性、易见性。
值(value)：感官输入，类似于具体的事物-值。
   attention机制可以认为是一个这样的函数：
$$ f(\bold{q_j}) = \sum_{i=1}^m \alpha(\bold{q}_j, \bold{k}_i) \bold{v}_i$$ 由$ \bold{V}$ 的各个向量的加权平均，组成一个新的向量 $f(q_j)$。其中，权重的计算是通过 query向量和每个key向量 计算出来的，这个计算方式可以有多种，比如：加性注意力、缩放点积注意力
$\bold{Q} \in \R^{n \times q}$: 查询矩阵，是由N个向量组成，每个向量有q个元素
K-V: M个键值对集合。
$\bold{K} \in \R^{m \times k}$: M个键向量组成的矩阵，每个键向量(k维)：就是每个字的标签信息
$\bold{V} \in \R^{m \times v}$: M个值向量组成的矩阵，每个值向量(v维)：就是每个字的embeding
1、加性注意力 $$\alpha(\bold{q}_j, \bold{k}_i) = \bold{w}_v^T tanh(\bold{W}_q \bold{q}_j + \bold{W}_k \bold{k}_i)$$ 其中，$\bold{w}_v^T \in \R^h, \bold{W}_q \in \R^{h \times q}, \bold{W}_k \in \R^{h \times k}$ 是需要训练的。"><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/nlp/transformer/attention/"><meta property="article:published_time" content="2021-09-08T06:00:20+06:00"><meta property="article:modified_time" content="2021-09-08T06:00:20+06:00"><meta name=description content="Attention"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/toha-tutorial/toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/toha-tutorial/write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/toha-tutorial/markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/toha-tutorial/latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/toha-tutorial/shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/deeplearning_summary/draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/deeplearning_summary/deeplearning_start/ title=深度学习开篇>深度学习开篇</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/>编程语言</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/programming_language/python/internal_lib/encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/programming_language/python/internal_lib/basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/programming_language/python/internal_lib/advance_operator/ title=进阶操作>进阶操作</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/python/sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/programming_language/python/sdk_lib/multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/programming_language/python/sdk_lib/importlib/ title=importlib>importlib</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/tf/compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/programming_language/tf/compat/tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/programming_language/pytorch/torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/tensor/ title=Tensor>Tensor</a></li><li><a href=/zh-cn/posts/programming_language/pytorch/train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/programming_language/mxnet/ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/programming_language/mxnet/ndarray/ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/backbone/>基础</a><ul><li><a href=/zh-cn/posts/cv/backbone/backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/cv/backbone/optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/cv/backbone/backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/cv/contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/cv/vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/cv/detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/cv/semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/cv/image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/cv/image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/cv/image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/nlp/>NLP</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/nlp/word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/rnn/>RNN</a><ul><li><a href=/zh-cn/posts/nlp/rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/nlp/rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/nlp/rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/nlp/rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/nlp/transformer/>Transformer</a><ul class=active><li><a class=active href=/zh-cn/posts/nlp/transformer/attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/nlp/transformer/transformer_summary/ title=Transformer>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/gpt/>GPT</a><ul><li><a href=/zh-cn/posts/nlp/gpt/gpt_summary/ title=GPT综述>GPT综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/nlp/bert/>Bert</a><ul><li><a href=/zh-cn/posts/nlp/bert/bert_summary/ title=Bert综述>Bert综述</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/vlp/>多模态</a><ul><li><a href=/zh-cn/posts/vlp/vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/vlp/clip/ title=CLIP>CLIP</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/video/>视频理解</a><ul><li><a href=/zh-cn/posts/video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>September 8, 2021</p></div><div class=title><h1>Attention</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/nlp class="btn, btn-sm">NLP</a></li><li class=rounded><a href=/zh-cn/tags/attention class="btn, btn-sm">attention</a></li></ul></div><div class=post-content id=post-content><h2 id=一attention机制>一、Attention机制</h2><p>如何有选择地引导注意力：<br><strong>非自主性提示：</strong> 基于环境中物体的突出性和易见性。比如 《辛德勒的名单》中的镜头：黑白镜头中的穿红衣服的小女孩。<br><strong>自主性提示：</strong> 选择受到 认知、意识的控制。<br></p><div class=row><div class="col col-sm-12 col-lg-6"><p align=center><img src=https://s2.loli.net/2022/05/15/NG8ySY5hHvCODEL.jpg width=80% height=80% title=attention alt=attention></p>在不受自我意识控制的情况下，与环境差别最大的事物，就越显眼、易见。<br>在受到自我意识控制的情况下，意识偏向那个，就选择那个<br></div><div class="col col-sm-12 col-lg-6"><p align=center><img src=https://s2.loli.net/2022/05/15/wr6U4eubTy3fqaJ.jpg width=100% height=100% title=attention alt=attention></p>查询(query)：自主性提示，类似于自我意识。<br>键(key)：非自主提示，类似于事物的突出性、易见性。<br>值(value)：感官输入，类似于具体的事物-值。<br></div></div><hr><p>attention机制可以认为是一个这样的函数：<br></p><p>$$ f(\bold{q_j}) = \sum_{i=1}^m \alpha(\bold{q}_j, \bold{k}_i) \bold{v}_i$$
由$ \bold{V}$ 的各个向量的加权平均，组成一个新的向量 $f(q_j)$。其中，权重的计算是通过 query向量和每个key向量 计算出来的，这个计算方式可以有多种，比如：<code>加性注意力、缩放点积注意力</code></p><p>$\bold{Q} \in \R^{n \times q}$: 查询矩阵，是由N个向量组成，每个向量有q个元素<br>K-V: M个键值对集合。<br>$\bold{K} \in \R^{m \times k}$: <code>M个键向量</code>组成的矩阵，每个键向量(k维)：就是每个字的标签信息<br>$\bold{V} \in \R^{m \times v}$: <code>M个值向量</code>组成的矩阵，每个值向量(v维)：就是每个字的embeding<br></p><h3 id=1加性注意力>1、加性注意力</h3><p>$$\alpha(\bold{q}_j, \bold{k}_i) = \bold{w}_v^T tanh(\bold{W}_q \bold{q}_j + \bold{W}_k \bold{k}_i)$$
其中，$\bold{w}_v^T \in \R^h, \bold{W}_q \in \R^{h \times q}, \bold{W}_k \in \R^{h \times k}$ 是需要训练的。</p><h3 id=2缩放点积注意力sdpa>2、缩放点积注意力(SDPA)</h3><p>attention机制的SDPA(缩放点积注意力Scaled Dot-Product Attention)实现方式，计算效率更高，但是点积操作要求 $\bold{q}$ 和 $\bold{k}$ 具有相同的长度。<br>假设：$\bold{q}$ 和 $\bold{k}$ 的所有元素都是独立的随机变量，并且满足标准正态分布 $N(0,1)$<br>那么：两个向量的点积，服从正态分布 $N(0, d)$，其中 $d$ 就是$\bold{q}$(或者$\bold{k}$)的长度。<br>所以：点积后，除以 $\sqrt{d}$，即：
$$\alpha(\bold{q}_j, \bold{k}_i) = \frac{\bold{q}_j^T \bold{k}_i}{\sqrt{d}}$$
基于n个查询、m个键值对，计算注意力，其中：
$\bold{Q} \in \R^{n \times d}$、$\bold{K} \in \R^{m \times d}$、$\bold{V} \in \R^{m \times v}$ 的缩放点积注意力：
$$softmax(\frac{\bold{Q} \bold{K}^T}{\sqrt{d}}) \bold{V} \in \R^{n \times v}$$</p><p>具体操作：<br></p><ol><li>$\bold{Q}$的每个向量 $\bold{q}_i$ 做如下操作:<ol><li>计算第i个向量 $q_i$ 与M个键向量的相似度(内积)，生成一个1*M的向量</li><li>对该向量做softmax操作(概率化)</li><li>用概率化后的值做<code>M个值向量</code>权重系数，做加权求和，生成一个加权后的embeding</li></ol></li><li>$\bold{Q}$的向量个数：表示需要多少个加权后的embeding，即：$\tilde{V}$</li></ol><p align=center><img src=/datasets/posts/nlp/SDPA.jpg width=60% height=60% title=SDPA alt=SDPA></p><h3 id=3多头注意力mha>3、多头注意力(MHA)</h3><p>在实践中，当给定 query、key、value时，我们希望模型可以基于相同的注意力机制，学习到不同的行为，然后将不同的行为作为知识组合起来，以捕获序列内各种范围的依赖关系。因此，允许注意力机制组合使用 query、key、value的<code>不同子空间表示</code>，可能是有益的。所以，对给定的query、key、value，经过不同的<code>线性变换</code>获取其子空间表示，然后并行地送入注意力机制，最后把各个子空间的输出拼接起来，再通过一个可以学习的线性变换产生最终输出。</p><p>MHA(多头注意力Multi-Head Attention) 实现方式：多路融合的SDPA，具体操作：<br></p><ol><li>对Q、K、V矩阵做多次线性变换，例如：第i次变换的生成结果 $Q'_i, K'_i, V'_i$</li><li>利用第i次线性变换后的 $Q'_i, K'_i, V'_i$，做SDPA操作，得到 $\tilde{V_i}$</li><li>对所有的 $\tilde{V_i}$，在列方向上concat拼接起来</li></ol><p align=center><img src=/datasets/posts/nlp/MHA.jpg width=60% height=60% title=MHA alt=MHA></p><h3 id=4实际模式>4、实际模式</h3><table><thead><tr><th style=text-align:left>QKV的关系</th><th></th></tr></thead><tbody><tr><td style=text-align:left>$Q \neq K \neq V$</td><td style=text-align:left>QKV模式</td></tr><tr><td style=text-align:left>$Q \neq K=V$</td><td style=text-align:left>QVV模式</td></tr><tr><td style=text-align:left>$Q=K=V$</td><td style=text-align:left>VVV模式，即：<code>自注意力</code>，自己即是查询向量，也是key向量；表示句子内部与自己相似的权重比较大</td></tr></tbody></table><h3 id=5在seq2seq的应用>5、在seq2seq的应用</h3><p>在seq2seq架构中，编码器生成各个时间步的上下文变量state，最后一时间步的state作为解码器的state。然而，有个问题：在解码器 解码某个词元时，并非所有输入词元都需要，或者说并非所有输入词元的贡献都一样，肯定是有的输入词元的贡献大一些。所以，在解码时能不能让贡献大的输入词元的state权重大一些呢？<br></p><p><a href=https://arxiv.org/abs/1409.0473 target=blank>Bahdanau</a>等人提出了一个没有严格单向对齐限制的可微注意力模型。在预测词元时，如果不是跟所有输入词元都相关，模型使用<code>仅跟当前预测相关的部分输入序列</code>。</p><p align=center><img src=https://s2.loli.net/2022/05/16/djMJCF9H3ZLY41x.jpg width=60% height=60% title=MHA alt=MHA></p><p>$$c_{t'} = \sum_{t=1}^T \alpha(s_{t'-1}, h_t) h_t$$
在解码时，需要 上一时间步的隐状态 $s_{t'-1}$ 和 上一时间步的真实值。添加attention的话，就要修改 $s_{t'-1}$，让其是 编码器各个隐状态的加权和，这就是attention的操作，即：</p><ul><li>用解码器上一时间步的隐状态 $s_{t'-1}$ 作为查询</li><li>编码器各个隐状态 $h_t$ 其中 $t \in [1, n]$</li><li>$\alpha()$ 函数，采用<code>加性注意力</code></li></ul></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fnlp%2ftransformer%2fattention%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fnlp%2ftransformer%2fattention%2f&text=Attention&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fnlp%2ftransformer%2fattention%2f&title=Attention" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fnlp%2ftransformer%2fattention%2f&title=Attention" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=Attention https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fnlp%2ftransformer%2fattention%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=Attention&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2fnlp%2ftransformer%2fattention%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/nlp/rnn/encode_decode/ title=编解码架构 class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>编解码架构</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/nlp/transformer/transformer_summary/ title=Transformer class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Transformer</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一attention机制>一、Attention机制</a><ul><li><a href=#1加性注意力>1、加性注意力</a></li><li><a href=#2缩放点积注意力sdpa>2、缩放点积注意力(SDPA)</a></li><li><a href=#3多头注意力mha>3、多头注意力(MHA)</a></li><li><a href=#4实际模式>4、实际模式</a></li><li><a href=#5在seq2seq的应用>5、在seq2seq的应用</a></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script></body></html>