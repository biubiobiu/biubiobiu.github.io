<!doctype html><html><head><title>cuda</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="cuda"><meta property="og:description" content="一、简介 1、CUDA CUDA：英伟达开发的一个通用并行计算平台和编程模型，能让你调用GPU的指令集及其并行计算单元。基于cuda编程可以利用GPU的并行计算引擎来更高效地计算。
特点：
 GPU有更多的计算核心，适合数据并行的计算密集型任务。 CPU有较少的运算核心，适合实现复杂的逻辑计算，用于控制密集型任务。 对比一下：  CPU &ndash; 线程是重量级的，上下文切换开销较大。 负责处理逻辑复杂的串行程序 GPU &ndash; 由于存在较多核心，线程是轻量级的。负责处理数据密集型的并行机选程序    2、CUDA编程模型 CUDA编程模型是一个异构模型，需要CPU和GPU协同工作，在CUDA中有两个重要的概念：host和device。
host: CPU + 其内存
device: GPU + 其内存
典型的CUDA程序的执行流程：
 分配host内存，并进行数据初始化 分配device内存，并从host将数据copy到device上 调用CUDA的核函数在device上完成指定的运算 将device上的运算结果copy到host上 释放device和host上分配的内存。  3、cuDNN cuDNN: CUDA Deep Neural Network软件库，是一个用于深度神经网络的GPU加速原语库。
TensorRT: 是一套用于高性能深度学习接口的SDK，其包含深度学习接口优化器、运行时优化器，能为深度学习接口提供低延迟和高通量的特性。
二、CUDA安装 1、驱动安装 NVIDIA驱动
关键点：CUDA和显卡驱动没有一一对应的关系，一般情况下安装最新的驱动。
2、CUDA安装 CUDA下载
CUDA: 只是一个工具包，在同一设备上可以安装多个不同的版本，比如：9.0，10.0，11.0。一般情况下安装最新的驱动，然后根据自己的需求选择不同CUDA工具包就行了。但在离线安装CUDA时会绑定CUDA和驱动程序，所以在使用多个CUDA的时候就不要选择离线安装CUDA了。
安装步骤:
 不用选择太高的cuda版本，太高反而兼容性不好，要兼顾Tensorflow等架构的版本 安装包下载后，一路默认安装就好。检查是否安装成功：nvcc -V cuda的安装包中包含NVIDIA驱动，安装时取消勾选安装驱动，只安装工具包就行  CUDA安装后，配置环境变量：
CUDA10.1是之前安装的，CUDA11.1是之后安装的，所以默认CUDA10.1的环境变量在CUA11.1之前，CUDA_PATH环境变量被CUDA11.1覆盖
CUDA版本切换：
切换CUDA版本时，只需要切换环境变量中CUDA的顺序即可，比如让CUDA11.1生效，则CUDA11.1环境变量在CUDA10.1之前。
3、cuDNN安装 cuDNN下载
cuDNN：是一个SDK，是一个专门用于神经网路的加速包，它跟CUDA没有一一对应的关系。即：每个CUDA版本可能有好几个cuDNN版本，一般有一个最新版本的cuDNN版本与CUDA对应更好。
安装步骤：
 根据cuda版本选择对应的cudnn版本；不同系统，选择不同的型号。 下载的不是安装包，而是压缩文件，解压后将对应的文件拷贝到cuda安装路径对应的目录中。默认安装的路径：  复制 cudnn\bin\cudnn64_5."><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/"><meta property="article:published_time" content="2021-12-08T16:00:20+08:00"><meta property="article:modified_time" content="2021-12-08T16:00:20+08:00"><meta name=description content="cuda"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00020_toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/00020_toha-tutorial/0010_toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/>数学知识</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/>概率论</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/ title=基本概念>基本概念</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/ title=随机变量及其分布>随机变量及其分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/ title=大数定律>大数定律</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/ title=样本及抽样分布>样本及抽样分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/ title=假设检验>假设检验</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/ title=方差分析及回归分析>方差分析及回归分析</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/ title=随机过程>随机过程</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/ title=马尔科夫链>马尔科夫链</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/ title=平稳随机过程>平稳随机过程</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/>凸优化</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/ title=基本概念>基本概念</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00030_deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/ title=深度学习开篇>深度学习开篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/ title=深度学习-结构>深度学习-结构</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0015_deeplearning_norm/ title=归一化>归一化</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0020_deeplearing_init/ title=初始化>初始化</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0200_cam/ title=CAM>CAM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00033_reinforce/>强化学习</a><ul><li><a href=/zh-cn/posts/00033_reinforce/0001_reinforce_summary/ title=综述>综述</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00035_programming_language/>编程语言</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00035_programming_language/0035_python/>Python</a><ul class=active><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/>env</a><ul class=active><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/ title=py-env>py-env</a></li><li><a class=active href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/ title=cuda>cuda</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ title=内置模块>内置模块</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/ title=进阶操作>进阶操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/ title=异常>异常</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/ title=文件读取>文件读取</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/ title=importlib>importlib</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/ title=ipdb>ipdb</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/ title=正则-re>正则-re</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/ title=堆-heapd>堆-heapd</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/ title=requests>requests</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/ title=logging>logging</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/ title=argparse>argparse</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/ title=PIL>PIL</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/ title=OpenCV>OpenCV</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/>PyTorch</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/ title=Tensor和变量>Tensor和变量</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0010_backbone/>基础</a><ul><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0050_detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0060_image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0020_rnn/>RNN</a><ul><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0030_transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0001_attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/ title=Transformer>Transformer</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/0030_position/ title=位置编码>位置编码</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0080_gpt/>GPT</a><ul><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/ title=GPT综述>GPT综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/ title=GPT-1>GPT-1</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0100_bert/>Bert</a><ul><li><a href=/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/ title=Bert综述>Bert综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/ title=Bert家族>Bert家族</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0120_t5/>T5</a><ul><li><a href=/zh-cn/posts/00200_nlp/0120_t5/0010_t5_summary/ title=T5综述>T5综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0150_bart/>BART</a><ul><li><a href=/zh-cn/posts/00200_nlp/0150_bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0200_electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/00200_nlp/0200_electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/1000_code/>CODE</a><ul><li><a href=/zh-cn/posts/00200_nlp/1000_code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/>AIGC</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0005_summary/>AIGC综述</a><ul><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/ title=综述>综述</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/ title=模型应用策略>模型应用策略</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/ title=大模型训练框架>大模型训练框架</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/ title=混合精度训练>混合精度训练</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/ title=模型小型化>模型小型化</a></li><li><a href=/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/ title=生成式-问题>生成式-问题</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0010_generate_text/>文本生成</a><ul><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/ title=GPT>GPT</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/ title=LLaMa>LLaMa</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/ title=PaLM>PaLM</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/ title=ChatGLM>ChatGLM</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/ title=Claude>Claude</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/ title=Cohere>Cohere</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/ title=Falcon>Falcon</a></li><li><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/ title=Vicuna>Vicuna</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/0020_generate_image/>图像生成</a><ul><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1000_gan_summary/ title=GAN>GAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/ title=CAN>CAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/ title=DALL-E>DALL-E</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/ title=VQGAN>VQGAN</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/ title=Diffusion>Diffusion</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/ title=Midjourney>Midjourney</a></li><li><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/ title=Imagen>Imagen</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00400_vlp/>多模态</a><ul><li><a href=/zh-cn/posts/00400_vlp/0001_vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00400_vlp/0005_clip/ title=CLIP>CLIP</a></li><li><a href=/zh-cn/posts/00400_vlp/0010_mllm/ title=MLLM>MLLM</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00500_video/>视频理解</a><ul><li><a href=/zh-cn/posts/00500_video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>December 8, 2021</p></div><div class=title><h1>cuda</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/python class="btn, btn-sm">python</a></li><li class=rounded><a href=/zh-cn/tags/cuda class="btn, btn-sm">cuda</a></li></ul></div><div class=post-content id=post-content><h2 id=一简介>一、简介</h2><h3 id=1cuda>1、CUDA</h3><p>CUDA：英伟达开发的一个通用并行计算平台和编程模型，能让你调用GPU的指令集及其并行计算单元。基于cuda编程可以利用GPU的并行计算引擎来更高效地计算。<br>特点：</p><ol><li>GPU有更多的计算核心，适合数据并行的<font color=#a020f0>计算密集型任务</font>。</li><li>CPU有较少的运算核心，适合实现复杂的逻辑计算，用于<font color=#a020f0>控制</font>密集型任务。</li><li>对比一下：<ul><li>CPU &ndash; 线程是重量级的，上下文切换开销较大。 负责处理逻辑复杂的串行程序</li><li>GPU &ndash; 由于存在较多核心，线程是轻量级的。负责处理数据密集型的并行机选程序</li></ul></li></ol><h3 id=2cuda编程模型>2、CUDA编程模型</h3><p>CUDA编程模型是一个异构模型，需要CPU和GPU协同工作，在CUDA中有两个重要的概念：host和device。<br>host: CPU + 其内存<br>device: GPU + 其内存<br></p><p>典型的CUDA程序的执行流程：</p><ol><li>分配host内存，并进行数据初始化</li><li>分配device内存，并从host将数据copy到device上</li><li>调用CUDA的核函数在device上完成指定的运算</li><li>将device上的运算结果copy到host上</li><li>释放device和host上分配的内存。</li></ol><h3 id=3cudnn>3、cuDNN</h3><p>cuDNN: CUDA Deep Neural Network软件库，是一个用于深度神经网络的GPU加速原语库。<br>TensorRT: 是一套用于高性能深度学习接口的SDK，其包含深度学习接口优化器、运行时优化器，能为深度学习接口提供低延迟和高通量的特性。</p><h2 id=二cuda安装>二、CUDA安装</h2><h3 id=1驱动安装>1、驱动安装</h3><p><a href=https://www.nvidia.cn/geforce/drivers/ target=bland>NVIDIA驱动</a><br></p><p>关键点：CUDA和显卡驱动没有一一对应的关系，一般情况下安装最新的驱动。</p><h3 id=2cuda安装>2、CUDA安装</h3><p><a href=https://developer.nvidia.com/cuda-toolkit-archive target=bland>CUDA下载</a><br></p><p>CUDA: 只是一个工具包，在同一设备上可以安装多个不同的版本，比如：9.0，10.0，11.0。一般情况下安装最新的驱动，然后根据自己的需求选择不同CUDA工具包就行了。但在离线安装CUDA时会绑定CUDA和驱动程序，所以在使用多个CUDA的时候就不要选择离线安装CUDA了。<br></p><p>安装步骤:<br></p><ol><li>不用选择太高的cuda版本，太高反而兼容性不好，要兼顾Tensorflow等架构的版本</li><li>安装包下载后，一路默认安装就好。检查是否安装成功：nvcc -V</li><li>cuda的安装包中包含NVIDIA驱动，安装时取消勾选安装驱动，只安装工具包就行</li></ol><p align=center><img src=/datasets/posts/language/cuda_install.png width=90% height=90% title=cuda alt=cuda></p><p>CUDA安装后，配置环境变量：</p><p align=center><img src=/datasets/posts/language/cuda_path.png width=90% height=90% title=cuda alt=cuda></p><p>CUDA10.1是之前安装的，CUDA11.1是之后安装的，所以默认CUDA10.1的环境变量在CUA11.1之前，CUDA_PATH环境变量被CUDA11.1覆盖</p><p align=center><img src=/datasets/posts/language/cuda_version_1.png width=90% height=90% title=cuda alt=cuda></p><p><strong>CUDA版本切换：</strong><br>切换CUDA版本时，只需要切换环境变量中CUDA的顺序即可，比如让CUDA11.1生效，则CUDA11.1环境变量在CUDA10.1之前。</p><p align=center><img src=/datasets/posts/language/cuda_version_check.png width=90% height=90% title=cuda alt=cuda></p><h3 id=3cudnn安装>3、cuDNN安装</h3><p><a href=https://developer.nvidia.com/rdp/cudnn-archive target=bland>cuDNN下载</a><br>cuDNN：是一个SDK，是一个专门用于神经网路的加速包，它跟CUDA没有一一对应的关系。即：每个CUDA版本可能有好几个cuDNN版本，一般有一个最新版本的cuDNN版本与CUDA对应更好。<br></p><p>安装步骤：<br></p><ol><li>根据cuda版本选择对应的cudnn版本；不同系统，选择不同的型号。</li><li>下载的不是安装包，而是压缩文件，解压后将对应的文件拷贝到cuda安装路径对应的目录中。默认安装的路径：<ol><li>复制 cudnn\bin\cudnn64_5.dll 到 C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\bin\</li><li>复制 cudnn\include\cudnn.h 到 C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\include\</li><li>复制 cudnn\lib\x64\cudnn.lib 到 C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0\lib\x64\</li></ol></li></ol><h3 id=4cuda版本切换>4、CUDA版本切换</h3><ol><li>需要哪个版本时，就把环境变量中 CUDA_PATH、NVCUDASAMPLES_ROOT修改成相应的路径<br>不用哪个版本时，就把环境变量中的path路径，修改为非实际路径</li><li>创建不同的虚拟环境，在虚拟环境中分别安装不同版本的TensorFlow，TensorFlow会根据自身版本的需求找到对应的cuda版本。在需要使用哪个版本时，激活哪个虚拟环境。<ol><li>创建虚拟环境： conda create -n py37 python=3.7</li><li>进入该虚拟环境 &ndash;> 进入该虚拟环境的路径：cd E:\ProgramFiles\anaconda3\envs\py37</li><li>mkdir .\etc\conda\activate.d<br>mkdir .\etc\conda\deactivate.d</li><li>在activate.d中创建env_vars.bat，内容<br>@set CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin<br>@set CUDA_INCLUDE=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\include<br>@set CUDA_LIB64=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\extras\CUPTI\lib64<br>@set CUDA_NVVP=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp<br>@set CUDA_lib=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64<br>@set OLD_PATH=%PATH%<br>@set PATH=%CUDA_PATH%;%CUDA_NVVP%;%CUDA_lib%;%PATH%;%CUDA_INCLUDE%;%CUDA_LIB64%;</li><li>在deactivate.d中创建同名文件env_vars.bat，内容<br>@set PATH=%OLD_PATH%</li></ol></li></ol><h3 id=5tftorch版本--cuda版本--cudnn版本>5、TF/torch版本 & CUDA版本 & cuDNN版本</h3><p><a href=https://pytorch.org/get-started/previous-versions/ target=bland>PyTorch 版本与CUDA的对应关系</a><br></p><table><thead><tr><th style=text-align:left>torch版本</th><th style=text-align:left></th><th style=text-align:left>示例</th></tr></thead><tbody><tr><td style=text-align:left>v1.8.0</td><td style=text-align:left>conda 安装</td><td style=text-align:left># CUDA 10.2<br>conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=10.2 -c pytorch<br># CUDA 11.1<br>conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge<br># CPU Only<br>conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cpuonly -c pytorch<br></td></tr><tr><td style=text-align:left></td><td style=text-align:left>pip 安装</td><td style=text-align:left># CUDA 11.0<br>pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CUDA 10.2<br>pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0<br># CPU only<br>pip install torch==1.8.0+cpu torchvision==0.9.0+cpu torchaudio==0.8.0 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br></td></tr><tr><td style=text-align:left>v1.7.1</td><td style=text-align:left>conda 安装</td><td style=text-align:left># CUDA 9.2<br>conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=9.2 -c pytorch<br># CUDA 10.1<br>conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.1 -c pytorch<br># CUDA 10.2<br>conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=10.2 -c pytorch<br># CUDA 11.0<br>conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch<br># CPU Only<br>conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cpuonly -c pytorch<br></td></tr><tr><td style=text-align:left></td><td style=text-align:left>pip 安装</td><td style=text-align:left># CUDA 11.0<br>pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CUDA 10.2<br>pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2<br># CUDA 10.1<br>pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CUDA 9.2<br>pip install torch==1.7.1+cu92 torchvision==0.8.2+cu92 torchaudio==0.7.2 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CPU only<br>pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br></td></tr><tr><td style=text-align:left>v1.7.0</td><td style=text-align:left>conda 安装</td><td style=text-align:left># CUDA 9.2<br>conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=9.2 -c pytorch<br># CUDA 10.1<br>conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=10.1 -c pytorch<br># CUDA 10.2<br>conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=10.2 -c pytorch<br># CUDA 11.0<br>conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=11.0 -c pytorch<br># CPU Only<br>conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cpuonly -c pytorch<br></td></tr><tr><td style=text-align:left></td><td style=text-align:left>pip 安装</td><td style=text-align:left># CUDA 11.0<br>pip install torch==1.7.0+cu110 torchvision==0.8.0+cu110 torchaudio==0.7.0 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CUDA 10.2<br>pip install torch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0<br># CUDA 10.1<br>pip install torch==1.7.0+cu101 torchvision==0.8.0+cu101 torchaudio==0.7.0 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CUDA 9.2<br>pip install torch==1.7.0+cu92 torchvision==0.8.0+cu92 torchaudio==0.7.0 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br># CPU only<br>pip install torch==1.7.0+cpu torchvision==0.8.0+cpu torchaudio==0.7.0 -f <a href=https://download.pytorch.org/whl/torch_stable.html>https://download.pytorch.org/whl/torch_stable.html</a><br></td></tr><tr><td style=text-align:left></td><td style=text-align:left></td><td></td></tr></tbody></table><table><thead><tr><th style=text-align:left>TF版本</th><th style=text-align:left>Python版本</th><th style=text-align:left>编译器</th><th style=text-align:left>构建工具</th><th style=text-align:left>CUDA</th><th style=text-align:left>cnDNN</th></tr></thead><tbody><tr><td style=text-align:left>tensorflow-gpu-2.4.0</td><td style=text-align:left>3.6~3.8</td><td style=text-align:left>MSVC 2019</td><td style=text-align:left>Bazel 3.1.0</td><td style=text-align:left>8.0</td><td style=text-align:left>11.0</td></tr><tr><td style=text-align:left>tensorflow-gpu-2.3.0</td><td style=text-align:left>3.5~3.8</td><td style=text-align:left>MSVC 2019</td><td style=text-align:left>Bazel 3.1.0</td><td style=text-align:left>7.6</td><td style=text-align:left>10.1</td></tr><tr><td style=text-align:left>tensorflow-gpu-2.2.0</td><td style=text-align:left>3.5~3.8</td><td style=text-align:left>MSVC 2019</td><td style=text-align:left>Bazel 2.0.0</td><td style=text-align:left>7.6</td><td style=text-align:left>10.1</td></tr><tr><td style=text-align:left>tensorflow-gpu-2.1.0</td><td style=text-align:left>3.5~3.7</td><td style=text-align:left>MSVC 2019</td><td style=text-align:left>Bazel 0.29.1</td><td style=text-align:left>7.6</td><td style=text-align:left>10.1</td></tr><tr><td style=text-align:left>tensorflow-gpu-2.0.0</td><td style=text-align:left>3.5~3.7</td><td style=text-align:left>MSVC 2017</td><td style=text-align:left>Bazel 0.26.1</td><td style=text-align:left>7.4</td><td style=text-align:left>10</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.15.0</td><td style=text-align:left>3.5~3.7</td><td style=text-align:left>MSVC 2017</td><td style=text-align:left>Bazel 0.26.1</td><td style=text-align:left>7.4</td><td style=text-align:left>10</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.14.0</td><td style=text-align:left>3.5~3.7</td><td style=text-align:left>MSVC 2017</td><td style=text-align:left>Bazel 0.26.1</td><td style=text-align:left>7.4</td><td style=text-align:left>10</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.13.0</td><td style=text-align:left>3.5~3.7</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Bazel 0.21.0</td><td style=text-align:left>7.4</td><td style=text-align:left>10</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.12.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Bazel 0.15.0</td><td style=text-align:left>7.2</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.11.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Bazel 0.15.0</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.10.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.9.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.8.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.7.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.6.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.5.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>7</td><td style=text-align:left>9</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.4.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>6</td><td style=text-align:left>8</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.3.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>6</td><td style=text-align:left>8</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.2.0</td><td style=text-align:left>3.5~3.6</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>5.1</td><td style=text-align:left>8</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.1.0</td><td style=text-align:left>3.5</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>5.1</td><td style=text-align:left>8</td></tr><tr><td style=text-align:left>tensorflow-gpu-1.0.0</td><td style=text-align:left>3.5</td><td style=text-align:left>MSVC 2015</td><td style=text-align:left>Cmake v3.6.3</td><td style=text-align:left>5.1</td><td style=text-align:left>8</td></tr></tbody></table><h2 id=三查看版本>三、查看版本</h2><h3 id=1cuda版本查看>1、CUDA版本查看</h3><p>查看已安装CUDA版本<br></p><blockquote><ol><li>直接在NVIDIA的控制面板里查看NVCUDA.DLL的版本<br>注意：这个版本并不能绝对说明自己安装的CUDA工具包一定是这个版本</li><li>通过命令：nvcc -V 或者 nvcc &ndash;version</li><li>直接通过文件查看<br>Linux：进入安装目录，然后执行 cat version.txt<br>win：CUDA的安装目录中，比如：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.2 里面version.txt</li></ol></blockquote><h3 id=2cudnn版本查看>2、cuDNN版本查看</h3><p>cuDNN本质上就是一个C语言的H头文件。<br>cudnn.h的头文件，直接打开查看，在最开始的部分有如下定义：</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=color:#75715e># define CUDNN_MAJOR 7
</span><span style=color:#75715e># define CUDNN_MINOR 5
</span><span style=color:#75715e># define CUDNN_PATCHLEVEL 0
</span><span style=color:#75715e></span>
<span style=color:#75715e># define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 500 + CUDNN_PATCHLEVEL)
</span></code></pre></div><p>即：7500，也就是cudnn的版本为7.5.0</p><blockquote><ol><li>win：进入安装目录C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.2\include 里 cudnn.h 打开查看</li><li>Linux：进入安装目录 cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 </li></ol></blockquote></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0035_python%2f0010_build_env%2f0020_cuda_env%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0035_python%2f0010_build_env%2f0020_cuda_env%2f&text=cuda&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0035_python%2f0010_build_env%2f0020_cuda_env%2f&title=cuda" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0035_python%2f0010_build_env%2f0020_cuda_env%2f&title=cuda" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=cuda https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0035_python%2f0010_build_env%2f0020_cuda_env%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=cuda&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0035_python%2f0010_build_env%2f0020_cuda_env%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/ title=py-env class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>py-env</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/ title=字符编码 class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>字符编码</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一简介>一、简介</a><ul><li><a href=#1cuda>1、CUDA</a></li><li><a href=#2cuda编程模型>2、CUDA编程模型</a></li><li><a href=#3cudnn>3、cuDNN</a></li></ul></li><li><a href=#二cuda安装>二、CUDA安装</a><ul><li><a href=#1驱动安装>1、驱动安装</a></li><li><a href=#2cuda安装>2、CUDA安装</a></li><li><a href=#3cudnn安装>3、cuDNN安装</a></li><li><a href=#4cuda版本切换>4、CUDA版本切换</a></li><li><a href=#5tftorch版本--cuda版本--cudnn版本>5、TF/torch版本 & CUDA版本 & cuDNN版本</a></li></ul></li><li><a href=#三查看版本>三、查看版本</a><ul><li><a href=#1cuda版本查看>1、CUDA版本查看</a></li><li><a href=#2cudnn版本查看>2、cuDNN版本查看</a></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script><script src=/js/mermaid-8.14.0.min.js></script><script>mermaid.initialize({startOnLoad:true});</script></body></html>