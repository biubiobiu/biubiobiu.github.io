<!doctype html><html><head><title>数学计算</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="数学计算"><meta property="og:description" content="一、数学计算  torch.abs(input)。 数学&mdash;绝对值 torch.add(input, value)。数学&mdash;对张量的每个元素加value值 torch.div(input, value)。数学&mdash;逐元素除法，将input逐元素除以标量value torch.div(input, other)。数学&mdash;逐元素除法。
两个张量input和other逐元素相除.这两个维度可以不同，但元素数量一定要一致。输出: 与input维度一致 torch.mul(input, value)。数学&mdash;逐元素乘法 torch.mul(input, other)。数学&mdash;逐元素乘法 torch.fmod(inpur, divisor, out)。数学&mdash;取余 torch.remainder(input, divisor, out)。数学&mdash;取余 相当于 %。
divisor: 标量或者张量 逐元素 torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)。数学&mdash; 像素点相除后相加。
out = tensor .+ value*(tensor1./tensor2) torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)。数学&mdash; 像素点相乘后相加。
out = tensor .+ value*(tensor1 .* tensor2) torch.neg(input)。数学&mdash;取负。out = -1 * input。 torch.reciprocal(input)。数学&mdash;倒数。out = 1.0 / input。 torch.sign(input)。数学&mdash;取正负符号 torch.sin(Tensor)。数学&mdash;正弦 torch.cos(Tensor)。数学&mdash;余弦 torch.tan(Tensor)。数学&mdash;正切 torch.sinh(Tensor)。数学&mdash;双曲正弦 torch.cosh(Tensor)。数学&mdash;双曲余弦 torch.tanh(Tensor)。数学&mdash;双曲正切 torch.asin(Tensor)。数学&mdash;反正弦 torch.acos(input)。数学&mdash;反余弦 torch."><meta property="og:type" content="article"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/"><meta property="article:published_time" content="2022-04-08T06:00:20+06:00"><meta property="article:modified_time" content="2022-04-08T06:00:20+06:00"><meta name=description content="数学计算"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css><link rel=stylesheet href=/css/layouts/single.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/posts data-filter=all>博文</a></li><div class=subtree><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00020_toha-tutorial/>Toha教程</a><ul><li><a href=/zh-cn/posts/00020_toha-tutorial/0010_toha-config/ title=Toha的配置>Toha的配置</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/ title=撰写文章>撰写文章</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/ title=MarkDown入门>MarkDown入门</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/ title=Katex公式>Katex公式</a></li><li><a href=/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/ title=区域块-实例>区域块-实例</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/>数学知识</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/>概率论</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/ title=基本概念>基本概念</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/ title=随机变量及其分布>随机变量及其分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/ title=大数定律>大数定律</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/ title=样本及抽样分布>样本及抽样分布</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/ title=假设检验>假设检验</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/ title=方差分析及回归分析>方差分析及回归分析</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/ title=随机过程>随机过程</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/ title=马尔科夫链>马尔科夫链</a></li><li><a href=/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/ title=平稳随机过程>平稳随机过程</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/>凸优化</a><ul><li><a href=/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/ title=基本概念>基本概念</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00030_deeplearning_summary/>深度学习</a><ul><li><a href=/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/ title=深度学习开篇>深度学习开篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/ title=深度学习-结构>深度学习-结构</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/ title=神经网络画图篇>神经网络画图篇</a></li><li><a href=/zh-cn/posts/00030_deeplearning_summary/0200_cam/ title=CAM>CAM</a></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00035_programming_language/>编程语言</a><ul class=active><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/>Python</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/>env</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/ title=py-env>py-env</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/ title=cuda>cuda</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/>Internal</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/ title=字符编码>字符编码</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/ title=基础操作>基础操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ title=内置模块>内置模块</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/ title=进阶操作>进阶操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/ title=异常>异常</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/ title=文件读取>文件读取</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/>SDK</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/ title=并行操作>并行操作</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/ title=importlib>importlib</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/ title=ipdb>ipdb</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/ title=正则-re>正则-re</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/ title=堆-heapd>堆-heapd</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/ title=requests>requests</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/ title=logging>logging</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/ title=argparse>argparse</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/ title=PIL>PIL</a></li><li><a href=/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/ title=OpenCV>OpenCV</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/>TensorFlow</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/>兼容1.x</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/ title=静态图>静态图</a></li><li><a href=/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/ title=模型训练>模型训练</a></li></ul></li></ul></li><li><i class="fas fa-minus-circle"></i><a class=active href=/zh-cn/posts/00035_programming_language/0050_pytorch/>PyTorch</a><ul class=active><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/ title=基础操作>基础操作</a></li><li><a class=active href=/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/ title=数学计算>数学计算</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/ title=Tensor和变量>Tensor和变量</a></li><li><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/ title=模型训练>模型训练</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/>MxNet</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/>NdArray</a><ul><li><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ title=NdArray使用>NdArray使用</a></li></ul></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/>CV</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0010_backbone/>基础</a><ul><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/ title=CNN>CNN</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/ title=optimizer>optimizer</a></li><li><a href=/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/ title="backbone net">backbone net</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/>对比学习</a><ul><li><a href=/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/ title="contrastive learning">contrastive learning</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/>ViT</a><ul><li><a href=/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/ title="vision transformer">vision transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0050_detect_object/>目标检测</a><ul><li><a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/>语义分割</a><ul><li><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ title=简介>简介</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00100_cv/0060_image-matting/>抠图</a><ul><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ title=抠图综述>抠图综述</a></li><li><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/ title="animal matting">animal matting</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/>NLP</a><ul><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/>Word Embedding</a><ul><li><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ title="Word Embedding综述">Word Embedding综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0020_rnn/>RNN</a><ul><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ title=RNN综述>RNN综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/gru/ title=GRU网络>GRU网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ title=LSTM网络>LSTM网络</a></li><li><a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ title=编解码架构>编解码架构</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0030_transformer/>Transformer</a><ul><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/attention/ title=Attention>Attention</a></li><li><a href=/zh-cn/posts/00200_nlp/0030_transformer/transformer_summary/ title=Transformer>Transformer</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0080_gpt/>GPT</a><ul><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/ title=GPT综述>GPT综述</a></li><li><a href=/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/ title=GPT-1>GPT-1</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0100_bert/>Bert</a><ul><li><a href=/zh-cn/posts/00200_nlp/0100_bert/bert_summary/ title=Bert综述>Bert综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0150_bart/>BART</a><ul><li><a href=/zh-cn/posts/00200_nlp/0150_bart/bart_summary/ title=BART综述>BART综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/0200_electra/>ELECTRA</a><ul><li><a href=/zh-cn/posts/00200_nlp/0200_electra/electra_summary/ title=ELECTRA综述>ELECTRA综述</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00200_nlp/1000_code/>CODE</a><ul><li><a href=/zh-cn/posts/00200_nlp/1000_code/bart_summary/ title=code解析>code解析</a></li></ul></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00300_aigc/>AIGC</a><ul><li><a href=/zh-cn/posts/00300_aigc/0010_aigc_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00300_aigc/0012_generate_summary/ title=生成模型-简介>生成模型-简介</a></li><li><a href=/zh-cn/posts/00300_aigc/0015_llama_summary/ title=LLaMa>LLaMa</a></li><li><a href=/zh-cn/posts/00300_aigc/0100_diffusion_summary_/ title=模型介绍>模型介绍</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00400_vlp/>多模态</a><ul><li><a href=/zh-cn/posts/00400_vlp/vlp_summary/ title=简介>简介</a></li><li><a href=/zh-cn/posts/00400_vlp/clip/ title=CLIP>CLIP</a></li></ul></li><li><i class="fas fa-plus-circle"></i><a href=/zh-cn/posts/00500_video/>视频理解</a><ul><li><a href=/zh-cn/posts/00500_video/vidio_summary/ title=简介>简介</a></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/default-hero.jpg)></div><div class=page-content><div class="author-profile ml-auto align-self-lg-center"><img class=rounded-circle src=/images/author/john_hu7f9991f5b5d471ecdfc6cff3db1a9fe6_6397_120x120_fit_box_2.png alt="Author Image"><h5 class=author-name>biubiobiu</h5><p>April 8, 2022</p></div><div class=title><h1>数学计算</h1></div><div class=taxonomy-terms><ul><li class=rounded><a href=/zh-cn/tags/torch class="btn, btn-sm">torch</a></li><li class=rounded><a href=/zh-cn/tags/%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97 class="btn, btn-sm">数学计算</a></li></ul></div><div class=post-content id=post-content><h2 id=一数学计算>一、数学计算</h2><ol><li><input checked disabled type=checkbox> <font color=#a020f0>torch.abs(input)</font>。 数学&mdash;绝对值</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.add(input, value)</font>。数学&mdash;对张量的每个元素加value值</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.div(input, value)</font>。数学&mdash;逐元素除法，将input逐元素除以标量value</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.div(input, other)</font>。数学&mdash;逐元素除法。<br>两个张量input和other逐元素相除.这两个维度可以不同，但元素数量一定要一致。输出: 与input维度一致</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.mul(input, value)</font>。数学&mdash;逐元素乘法</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.mul(input, other)</font>。数学&mdash;逐元素乘法</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.fmod(inpur, divisor, out)</font>。数学&mdash;取余</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.remainder(input, divisor, out)</font>。数学&mdash;取余 相当于 %。<br>divisor: 标量或者张量 逐元素</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)</font>。数学&mdash; 像素点相除后相加。<br>out = tensor .+ value*(tensor1./tensor2)</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)</font>。数学&mdash; 像素点相乘后相加。<br>out = tensor .+ value*(tensor1 .* tensor2)</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.neg(input)</font>。数学&mdash;取负。out = -1 * input。</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.reciprocal(input)</font>。数学&mdash;倒数。out = 1.0 / input。</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sign(input)</font>。数学&mdash;取正负符号</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sin(Tensor)</font>。数学&mdash;正弦</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.cos(Tensor)</font>。数学&mdash;余弦</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.tan(Tensor)</font>。数学&mdash;正切</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sinh(Tensor)</font>。数学&mdash;双曲正弦</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.cosh(Tensor)</font>。数学&mdash;双曲余弦</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.tanh(Tensor)</font>。数学&mdash;双曲正切</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.asin(Tensor)</font>。数学&mdash;反正弦</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.acos(input)</font>。数学&mdash;反余弦</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.atan(Tensor)</font>。数学&mdash;反正切</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.atan2(input1, input2, out=None)</font>。数学&mdash;</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.ceil(input)</font>。数学&mdash;向上取整</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.floor(input)</font>。数学&mdash;向下取整</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.round(input, out)</font>。数学&mdash;四舍五入</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.clamp(input, min, max, out=None)</font>。数学&mdash;销掉最小最大。将input张量每个元素，夹在[min,max]之间</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.exp(tensor)</font>。数学&mdash;指数</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.pow(input, exponent, out)</font>。数学&mdash;逐元素求exponent次幂</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.rsqrt(tensor)</font>。数学&mdash;平方根倒数。out = 1.0 / input^0.5</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.frac(tensor)</font>。数学&mdash;返回逐元素的小数部分</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sqrt(tensor)</font>。数学&mdash;平方根。out = input^0.5</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.lerp(start, end, weight, out)</font>。数学&mdash;线性插值。out = start + weight(end-start)</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.log(tensor, out=None)</font>。数学&mdash;自然对数。out = log(input)</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.loglp(tensor, out=None)</font>。数学&mdash;input+1的自然对数。out = log(input+1)</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sigmoid(input)</font>。数学&mdash;sigmoid</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.cumsum(input, dim, out)</font>。数学&mdash;累加。沿指定维度的累加和</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.cumprod(input, dim, out)</font>。数学&mdash;累积。沿指定维度累积</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.dist(input, other, p=2, out)</font>。数学&mdash;两个Tensor之间的范数</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.norm(input, p=2, dim, out=None)</font>。数学&mdash;单个Tensor的范数。返回输入张量的p的范数</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.mean(input, dim, out=None)</font>。数学&mdash;均值</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.std(input, dim, out=None)</font>。数学&mdash;标准差。返回张量在指定维度上的标准差</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.var(input, dim, out=None)</font>。数学&mdash;方差</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sum(input, dim, out=None)</font>。数学&mdash;和</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.median(input, dim=-1, values=None, indices=None)</font>。数学&mdash;中位数</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.mode(input, dim=-1, values=None, indices=None)</font>。数学&mdash;众数</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.prod(input, dim, out=None)</font>。数学&mdash;所有元素的积。输出张量在指定维度上所有元素的积</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.cross(input, other, dim=-1, out=None)</font>。数学&mdash;叉积。输出两个张量的向量积,dim维上size必须为3</li></ol><h2 id=二逻辑计算>二、逻辑计算</h2><ol><li><input checked disabled type=checkbox> <font color=#a020f0>torch.eq(input, other, out=None)</font>。比较&mdash; 等于 像素级</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.equal(tensor1, tensor2)</font>。比较&mdash; Tensor，是否具有相同的形状和元素值</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.ge(input, other, out=None)</font>。比较&mdash; 大于等于 像素级</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.gt(input, other, out=None)</font>。比较&mdash; 大于 像素级</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.le(input, other, out=None)</font>。比较&mdash; 小于等于 像素级</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.lt(input, other, out=None)</font>。比较&mdash; 小于 像素级</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.ne(input, other, out=None)</font>。比较&mdash; 不等于 像素级</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.max(input, dim, max=None, max_indices=None)</font>。比较&mdash; 取最大值。在指定维度上取最大值</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.min(input, dim, min=None, min_indices=None)</font>。比较&mdash; 取最小值。在指定维度上取最小值</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.kthvalue(input, k, dim=None, out=None)</font>。比较&mdash; 取第k个最小值。取张量在指定维度上第k个最小值，默认最后一维</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.sort(input, dim=None, descending=False, out=None)</font>。比较&mdash; 排序</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.topk(input, k, dim=None, largest=True, sorted=True, out=None)</font>。比较&mdash; 取第k个最大值</li></ol><h2 id=三复数域>三、复数域</h2><ol><li><input checked disabled type=checkbox> <font color=#a020f0>torch.view_as_complex()</font>。将实数 [a, b] 转为复数域 [a, bj]。复数域</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.view_as_real()</font>。将复数 [a, bj] 转为实数域 [a, b]</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.flatten(input, start_dim=0, end_dim=1)</font>。默认将张量拉成一维的向量</li></ol><h2 id=四矩阵操作>四、矩阵操作</h2><ol><li><input checked disabled type=checkbox> <font color=#a020f0>torch.matmul(input, other, out)</font>。矩阵&mdash; 矩阵相乘</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.mm(input, other, out)</font>。矩阵&mdash; 矩阵相乘</li><li><input checked disabled type=checkbox> <font color=#a020f0>toch.mv(mat, vec, out=None)</font>。矩阵<em>向量。矩阵&mdash; 矩阵</em>向量</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.addbmm(beta=1, mat, alpha=1, batch1, batch2, out=None)</font>。矩阵&mdash; batch 相乘后相加。<br>batch1: $ b·n·m $ ; batch2: $b·m·p$。<br>mat: $n·p$; out: $n·p$;。<br>res = $beta·mat + alpha·sum(batch1_i·batch2_i),i\in[0~b]$。<br>out: batch个2维矩阵相乘后,再相加</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.addmm(beta=1, mat, alpha=1, mat1, mat2, out=None)</font>。矩阵&mdash; 单个矩阵 相乘后相加。<br>$ out=beta·mat + alpha·mat_1·mat_2 $</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.addmv(beta=1, tensor, alpha=1, mat, vec, out=None)</font>。矩阵&mdash; 单个矩阵 矩阵*向量后相加。<br>vec: 向量。mat: 矩阵。$out=beta·tensor + alpha·(mat·vec)$</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.addr(beta=1, mat, alpha=1, vec1, vec2, out)</font>。矩阵&mdash; 向量*向量后相加。<br>$out=beta·mat + alpha·(vec_1·vec_2)$</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.baddbmm(beta=1, mat, alpha=1, batch1, batch2, out=None)</font>。矩阵&mdash; batch 单个矩阵相乘后单个相加。<br>$out=beta·mat_i + alpha·(batch1_i·batch2_i)$</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.bmm(batch1, batch2, out=None)</font>。矩阵&mdash; batch 单个矩阵相乘。<br>$out=batch1_i·batch2_i$</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.ger(vec1, vec2, out=None)</font>。矩阵&mdash; 向量相乘生成矩阵</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.inverse(input, out=None)</font>。矩阵&mdash; 取逆</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.dot(tensor1, tensor2)</font>。矩阵&mdash; 内积。计算两个张量的内积, 两个张量都是一维向量</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.eig(a, eigenvectors=False, out=None)</font>。矩阵&mdash; 特征值+特征向量</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.symeig(input, eigenvectors=False, upper=True, out=None)</font>。矩阵&mdash; 实对称矩阵的特征值+特征向量</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.qr(input, out=None)</font>。矩阵&mdash; QR分解</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.svd(input, some=True, out=None)</font>。矩阵&mdash; 奇异值分解</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.gesv(B, A, out=None)</font>。矩阵&mdash; 线性方程组的解。<br>$X, Lu = torch.gesv(B, A)$, 返回线性方程$A·x=B$的解</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.btrifact(A, info=None)</font>。矩阵&mdash; 方程组求解 IntTensor。返回一个元组，包含LU分解和pivots</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.btrisolve(b, LU_data, LU_pivots)</font>。矩阵&mdash; 方程组求解r。返回线性方程组Ax=b的LU解</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.diag(input, diagonal=0, out)</font>。矩阵&mdash; 对角线</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.histc(input, bins=100, min=0, max=0, out=None)</font>。矩阵&mdash;直方图。bins(int):直方图分区个数</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.trace(input)</font>。矩阵&mdash; 对角线和。返回输入2维矩阵对角线元素的和</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.tril(input, k=0, out)</font>。矩阵&mdash; 下三角</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.triu(input, k=0, out)</font>。矩阵&mdash; 上三角</li><li><input checked disabled type=checkbox> <font color=#a020f0>torch.gels(B, A, out=None)</font>。矩阵&mdash; 最小二乘解。输出：元组，X: 最小二乘解 qr: QR分解的细节</li></ol></div><div class="row pl-3 pr-3"><div class="col-md-6 share-buttons"><strong>分享:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0050_pytorch%2f0030_mathematical%2f" target=_blank><i class="fab fa-facebook"></i></a><a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0050_pytorch%2f0030_mathematical%2f&text=%e6%95%b0%e5%ad%a6%e8%ae%a1%e7%ae%97&via=biubiobiu%27s%20Blog" target=_blank><i class="fab fa-twitter"></i></a><a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0050_pytorch%2f0030_mathematical%2f&title=%e6%95%b0%e5%ad%a6%e8%ae%a1%e7%ae%97" target=_blank><i class="fab fa-reddit"></i></a><a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0050_pytorch%2f0030_mathematical%2f&title=%e6%95%b0%e5%ad%a6%e8%ae%a1%e7%ae%97" target=_blank><i class="fab fa-linkedin"></i></a><a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=%e6%95%b0%e5%ad%a6%e8%ae%a1%e7%ae%97 https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0050_pytorch%2f0030_mathematical%2f" target=_blank><i class="fab fa-whatsapp"></i></a><a class="btn btn-sm email-btn" href="mailto:?subject=%e6%95%b0%e5%ad%a6%e8%ae%a1%e7%ae%97&body=https%3a%2f%2fbiubiobiu.github.io%2fzh-cn%2fposts%2f00035_programming_language%2f0050_pytorch%2f0030_mathematical%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/ title=基础操作 class="btn btn-outline-info"><div><i class="fas fa-chevron-circle-left"></i>上一篇</div><div class=next-prev-text>基础操作</div></a></div><div class="col-md-6 next-article"><a href=/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/ title=Tensor和变量 class="btn btn-outline-info"><div>下一篇 <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Tensor和变量</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center pl-3">目录</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#一数学计算>一、数学计算</a></li><li><a href=#二逻辑计算>二、逻辑计算</a></li><li><a href=#三复数域>三、复数域</a></li><li><a href=#四矩阵操作>四、矩阵操作</a></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script><script src=/js/single.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=stylesheet href=/katex/katex.min.css><script type=text/javascript defer src=/katex/katex.min.js></script><script type=text/javascript defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body);></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false},{left:'\\(',right:'\\)',display:false},{left:'\\[',right:'\\]',display:true}],throwOnError:false});});</script><script src=/js/mermaid-8.14.0.min.js></script><script>mermaid.initialize({startOnLoad:true});</script></body></html>