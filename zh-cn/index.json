[{"categories":null,"contents":"查阅文档 怎么查阅相关文档？ 官网\n1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random))  __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。  2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。\nhelp(nd.ones_like) 注意：\n jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。      内存开销   原始操作 首先来个例子：Y = Y + X \u0026ndash;\u0026gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：\n内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026lt;\u0026ndash; Y\n  Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026ndash;\u0026gt; 把内存id_x+y中数值复制到内存id_y中\n  使用运算符全名函数中的out参数 可以避免临时内存开销，使用运算符全名函数：nd.elemwise_add(X, Y, out=Y)。内存使用情况： 内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_y \u0026lt;\u0026ndash; 直接存放 X+Y 的计算结果\n      自动求梯度 MXNet提供的autograd模块，可以自动求梯度(gradient) from mxnet import autograd, nd # 1. 创建变量 x，并赋初值 x = nd.arrange(4).reshape((4, 1)) # 2. 为了求变量x的梯度，先调用attach_grad函数来申请存储梯度所需要的内存  x.attach_grad() # 3. 为了减少计算和内存开销，默认条件下MXNet是不会记录：求梯度的计算， # 需要调用record函数来要求MXNet记录与求梯度有关的计算。 print(autograd.is_training()) # False with autograd.record(): print(autograd.is_training()) # True y = 2*nd.dot(x.T, x) # 4. 调用backward函数自动求梯度。y必须是一个标量， # 如果y不是标量：MXNet会先对y中元素求和，然后对该和值求有关x的梯度 y.backward() 注意：\n 在调用record函数后，MXNet会记录并计算梯度； 默认情况下，autograd会改变运行模式：从预测模式转为训练模式。可以通过调用is_training函数来查看。      样例 from mxnet import nd     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/ndarray_summary/","summary":"查阅文档 怎么查阅相关文档？ 官网\n1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random))  __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。  2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。\nhelp(nd.ones_like) 注意：\n jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。      内存开销   原始操作 首先来个例子：Y = Y + X \u0026ndash;\u0026gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：\n内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026lt;\u0026ndash; Y\n  Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026ndash;\u0026gt; 把内存id_x+y中数值复制到内存id_y中","tags":null,"title":"NdArray使用"},{"categories":null,"contents":"sum/mean等操作 - 保留原维度数 keepdims: 保留原维度数。例如：\nfrom mxnet import nd def softmax(X): X_exp = X.exp() # shape = (n, m) # shape = (n, 1) 而并不是 (n,) partition = X_exp.sum(axis=1, keepdims=True) return X_exp / partition # 这里应用了广播机制 X = nd.random.normal(shape=(2, 5)) X_prob = softmax(X)     B的值作为A的索引 - 取值 from mxnet import nd y_hat = nd.array([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) y = nd.array([0, 2], dtype=\u0026#39;int32\u0026#39;) nd.pick(y_hat, y) # 结果: [0.1, 0.5] # 应用的实例：交叉熵的实现 def cross_entropy(y_hat, y): return -nd.pick(y_hat, y).log()     样例 from mxnet import nd     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/technic_gather/","summary":"sum/mean等操作 - 保留原维度数 keepdims: 保留原维度数。例如：\nfrom mxnet import nd def softmax(X): X_exp = X.exp() # shape = (n, m) # shape = (n, 1) 而并不是 (n,) partition = X_exp.sum(axis=1, keepdims=True) return X_exp / partition # 这里应用了广播机制 X = nd.random.normal(shape=(2, 5)) X_prob = softmax(X)     B的值作为A的索引 - 取值 from mxnet import nd y_hat = nd.array([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) y = nd.array([0, 2], dtype=\u0026#39;int32\u0026#39;) nd.pick(y_hat, y) # 结果: [0.","tags":null,"title":"NdArray技巧搜集"},{"categories":null,"contents":"模型基类-Block from mxnet.gluon import Block, nn from mxnet import ndarray as F class Model(Block): def __init__(self, **kwargs): super(Model, self).__init__(**kwargs) # use name_scope to give child Blocks appropriate names. with self.name_scope(): self.dense0 = nn.Dense(20) self.dense1 = nn.Dense(20) def forward(self, x): x = F.relu(self.dense0(x)) return F.relu(self.dense1(x)) model = Model() model.initialize(ctx=mx.cpu(0)) model(F.zeros((10, 10), ctx=mx.cpu(0))) class Block(builtins.object)\n网络的最基础的类，搭建网络时必须继承此Block类 —————————————————\nBlock的两个参数：\n prefix : str; 前缀的作用就像一个命名空间。在父模块的作用域下创建的子模块都有父模块的前缀(prefix). params : ParameterDict or None; 共享参数。\n例如：dense1共享dense0的参数。\ndense0 = nn.Dense(20)\ndense1 = nn.Dense(20, params=dense0.collect_params())  —————————————————\nBlock的方法：\n collect_params(self, select=None) 返回一个ParameterDict类。默认包含所有的参数；同时也可以正则匹配:\n例如：选出特定的参数 [\u0026lsquo;conv1_weight\u0026rsquo;, \u0026lsquo;conv1_bias\u0026rsquo;, \u0026lsquo;fc_weight\u0026rsquo;, \u0026lsquo;fc_bias\u0026rsquo;]\n即：model.collect_params(\u0026lsquo;conv1_weight|conv1_bias|fc_weight|fc_bias\u0026rsquo;)\nParameters：空 或者 正则表达式\nReturns: py:class:ParameterDict forward(self, *args) 完成前向计算，输入是NDArray列表\nParameters：*args : list of NDArray hybridize(self, active=True, **kwargs) 激活/不激活HybridBlock的递归\nParameters： bool, default True initialize(self, init=\u0026lt;mxnet.initializer.Uniform object\u0026gt;, ctx=None, verbose=False, force_reinit=False)\n对模型的参数初始化，默认是均匀分布。\n等价于：block.collect_params().initialize(\u0026hellip;)\nParameters：\ninit : Initializer 初始化方法\nctx : 设备 或者 设备列表。会把模型copy到所有指定的设备上\nverbose : bool, default False 是否在初始化时粗略地打印细节。\nforce_reinit : bool, default False 是否重新初始化，即使已经初始化 load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False, cast_dtype=False, dtype_source=\u0026lsquo;current\u0026rsquo;)\n加载模型参数从 用save_parameters保存的模型文件中。\nParameters：\nfilename : str 模型文件路径\nctx : 设备 或者设备列表。默认使用CPU\nallow_missing : bool, default False 是否默默跳过模型文件中不存\n在的模型参数。\nignore_extra : bool, default False 是否默默忽略模型中不存在的参\n数(模型文件中有，模型定义中没有)\ncast_dtype : bool, default False 从checkpointload模型时，是否根\n据传入转换NDArray的数据类型\ndtype_source : str, default \u0026lsquo;current\u0026rsquo; 枚举值：{\u0026lsquo;current\u0026rsquo;, \u0026lsquo;saved\u0026rsquo;}\n只有再cast_dtype=True时有效，指定模型参数的数据类型 name_scope(self) 返回一个命名空间，用来管理Block和参数names。\n必须在with语句中使用：\nwith self.name_scope():\nself.dense = nn.Dense(20) register_child(self, block, name=None) 将block注册为子节点，block的属\n性将自动注册。 save_parameters(self, filename) 保持模型参数到磁盘。该方法只保存模型\n参数的权重，不保存模型的结构。如果想要保存模型的结构，请使\n用:py:meth:HybridBlock.export.\nParameters：Path to file. summary(self, *inputs) 打印模型的输出和参数的摘要。模型必须被初始化  —————————————————\n数据描述：\n name :py:class:Block 的名字 params：返回一个参数字典（不包含子节点的参数） prefix：返回py:class:Block的前缀      模型参数-Parameter ctx = mx.gpu(0) x = mx.nd.zeros((16, 100), ctx=ctx) w = mx.gluon.Parameter(\u0026#39;fc_weight\u0026#39;, shape=(64, 100), init=mx.init.Xavier()) b = mx.gluon.Parameter(\u0026#39;fc_bias\u0026#39;, shape=(64,), init=mx.init.Zero()) w.initialize(ctx=ctx) b.initialize(ctx=ctx) out = mx.nd.FullyConnected(x, w.data(ctx), b.data(ctx), num_hidden=64) class:Parameter 一个存放Blocks的参数的权重的容器。初始化后Parameter.initialize(...)，会copy所有参数权重到每个设备上。如果grad_req不为null，在每个设备上，该容器会拥有一个梯度向量。\nParameter(name,\ngrad_req=\u0026lsquo;write\u0026rsquo;,\nshape=None,\ndtype=\u0026lt;class \u0026lsquo;numpy.float32\u0026rsquo;\u0026gt;,\nlr_mult=1.0,\nwd_mult=1.0,\ninit=None,\nallow_deferred_init=False,\ndifferentiable=True,\nstype=\u0026lsquo;default\u0026rsquo;,\ngrad_stype=\u0026lsquo;default\u0026rsquo;)\n形参：\n——————————\n name : str类型；参数的名字。 grad_req : 枚举值：{\u0026lsquo;write\u0026rsquo;, \u0026lsquo;add\u0026rsquo;, \u0026lsquo;null\u0026rsquo;}, 默认值：\u0026lsquo;write\u0026rsquo;。指定怎么更新梯度到梯度向量。\n'write':每次把梯度值写到 梯度向量中\n'add': 每次把计算的梯度值add到梯度向量中. 在每次迭代之前，\n你需要手动调用zero_grad()来清理梯度缓存。\n'null': 参数不需要计算梯度，不会分配梯度向量。 shape : int or tuple of int, default None. 参数的尺寸. dtype : numpy.dtype or str, default \u0026lsquo;float32\u0026rsquo;. 参数的数据类型 lr_mult : float, default 1.0, 学习率. wd_mult : float, default 1.0, 权重衰减率 L2 init : Initializer, default None. 参数的初始化，默认全局初始化 stype: 枚举值: {\u0026lsquo;default\u0026rsquo;, \u0026lsquo;row_sparse\u0026rsquo;, \u0026lsquo;csr\u0026rsquo;}, defaults to \u0026lsquo;default\u0026rsquo;. 参数的存储类型。 grad_stype: 枚举值: {\u0026lsquo;default\u0026rsquo;, \u0026lsquo;row_sparse\u0026rsquo;, \u0026lsquo;csr\u0026rsquo;}, defaults to \u0026lsquo;default\u0026rsquo;. 参数梯度的存储类型  属性:\n——————————\n grad_req : 枚举值:{\u0026lsquo;write\u0026rsquo;, \u0026lsquo;add\u0026rsquo;, \u0026lsquo;null\u0026rsquo;} 可以在初始化之前/之后设置。当不需要计算参数的梯度时，设置为null，以节省内存和计算量。 lr_mult : float 学习率 wd_mult : float 权重衰减率  定义的函数：\n——————————\n  cast(self, dtype) 转换参数的值/梯度的数据类型。\ndtype : str or numpy.dtype 新的数据类型\n  data(self, ctx=None) 获取这个参数在设备ctx上的值，参数必须已经初始化了。\nctx : 指定设备\nReturns：NDArray on ctx\n  grad(self, ctx=None) 获取这个参数在设备ctx上的梯度值。\nctx : 指定设备\n  initialize(self, init=None, ctx=None,\ndefault_init=\u0026lt;mxnet.initializer.Uniform\u0026gt;,\nforce_reinit=False) 初始化参数和梯度向量\ninit : Initializer 初始化参数的值\nctx : 设备/设备列表, 默认使用:py:meth:context.current_context().\ndefault_init : Initializer 当:py:func:init和:py:meth:Parameter.init都为none时，使用该默认的初始化.\nforce_reinit : bool, default False 当参数已经被初始化，是否再次初始化。\n  weight = mx.gluon.Parameter(\u0026#39;weight\u0026#39;, shape=(2, 2)) weight.initialize(ctx=mx.cpu(0)) weight.data() #　[[-0.01068833 0.01729892] #　[ 0.02042518 -0.01618656]] #　\u0026lt;NDArray 2x2 @cpu(0)\u0026gt; weight.grad() #　[[ 0. 0.] #　[ 0. 0.]] #　\u0026lt;NDArray 2x2 @cpu(0)\u0026gt; weight.initialize(ctx=[mx.gpu(0), mx.gpu(1)]) weight.data(mx.gpu(0)) #　[[-0.00873779 -0.02834515] #　[ 0.05484822 -0.06206018]] #　\u0026lt;NDArray 2x2 @gpu(0)\u0026gt; weight.data(mx.gpu(1)) #　[[-0.00873779 -0.02834515] #　[ 0.05484822 -0.06206018]] #　\u0026lt;NDArray 2x2 @gpu(1)\u0026gt;  list_ctx(self) 返回参数初始化在那些设备上 list_data(self) 按照顺序返回所有设备上的参数值 Returns: list of NDArrays list_grad(self) 按照顺序返回所有设备上的梯度值 list_row_sparse_data(self, row_id) 按照顺序返回所有设备上的 行稀疏的参数。\nrow_id: 指定看哪一行的数据\nReturns: list of NDArrays reset_ctx(self, ctx) 重新设定设备，把参数copy到该设备上\nctx : Context or list of Context, default context.current_context() row_sparse_data(self, row_id)\nrow_id: NDArray 指定看哪一行的数据\nReturns: NDArray on row_id\u0026rsquo;s context set_data(self, data) 在所有设备上，设置该参数的值。 var(self) 返回一个代表该参数的符号 zero_grad(self) 将所有设备上的梯度缓存清零  数据描述:\n——————————\n dtype 参数的数据类型 grad_req shape 参数的尺寸      模型参数-访问 ToTensor：将图像数据从uint8格式变换成32位浮点数格式，并除以255使得所有像素的数值均在0到1之间 transform_first函数：数据集的函数。将ToTensor的变换应用在每个数据样本（图像和标签）的第一个元素，即图像之上.\nfrom mxnet import nd from mxnet.gluon import nn     网络设计 from mxnet import nd from mxnet.gluon import nn     模型初始化 from mxnet import nd from mxnet.gluon import nn     模型初始化 from mxnet import nd from mxnet.gluon import nn     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/module_gluon_nn/","summary":"模型基类-Block from mxnet.gluon import Block, nn from mxnet import ndarray as F class Model(Block): def __init__(self, **kwargs): super(Model, self).__init__(**kwargs) # use name_scope to give child Blocks appropriate names. with self.name_scope(): self.dense0 = nn.Dense(20) self.dense1 = nn.Dense(20) def forward(self, x): x = F.relu(self.dense0(x)) return F.relu(self.dense1(x)) model = Model() model.initialize(ctx=mx.cpu(0)) model(F.zeros((10, 10), ctx=mx.cpu(0))) class Block(builtins.object)\n网络的最基础的类，搭建网络时必须继承此Block类 —————————————————\nBlock的两个参数：\n prefix : str; 前缀的作用就像一个命名空间。在父模块的作用域下创建的子模块都有父模块的前缀(prefix). params : ParameterDict or None; 共享参数。\n例如：dense1共享dense0的参数。\ndense0 = nn.","tags":null,"title":"Gluon-nn模块"},{"categories":null,"contents":"实例-单层感知机 模型：o = w1*x1 + w2*x2 + b 输出o作为线性回归的输出，输入层是2维特征；输入层不涉及计算，该神经网络只有输出层1层。\n神经元：输出层中负责计算o的单元。\n该神经元，依赖于输入层的全部特征，也就是说输出层中的神经元和输入层中各个输入完全连接，所以，这里的输出层又叫作全连接层(fully connected layer)或者稠密层(dense layer)\n    生成数据集 目标： o = 2x1 - 3.4x2 + 4.2 其中： 样本集：features: [w1, w2]， labels: [真实值+噪声]\nfrom IPython import display from matplotlib import pyplot as plt from mxnet import autograd, nd import random num_inputs = 2 num_examples = 1000 true_w = [2, -3.4] true_b = 4.2 features = nd.random.normal(scale=1, shape=(num_examples, num_inputs)) labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b labels += nd.random.normal(scale=0.01, shape=labels.shape)     读取数据集 - 从零实现 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) random.shuffle(indices) # 样本的读取顺序是随机的 for i in range(0, num_examples, batch_size): j = nd.array(indices[i: min(i + batch_size, num_examples)]) # take函数根据索引返回对应元素 yield features.take(j), labels.take(j)     读取数据集 - Gluon实现 DataLoader 返回一个迭代器，一次返回batch_size个样本\nfrom mxnet.gluon import data as gdata batch_size = 10 # 将训练数据的特征和标签组合 dataset = gdata.ArrayDataset(features, labels) # 随机读取小批量 data_iter = gdata.DataLoader(dataset, batch_size, shuffle=True)     模型定义 - 从零实现 手动定义模型参数，一定要开辟存储梯度的内存。\n# 将权重初始化为：均值为0、标准差为0.01的正太随机数 w = nd.random.normal(scale=0.01, shape=(num_inputs, 1)) b = nd.zeros(shape=(1,)) # 开辟存储梯度的内存 w.attach_grad() b.attach_grad() # 定义线性回归的模型 def linreg(X, w, b): return nd.dot(X, w) + b     模型定义 - Gluon实现 Gluon模块：提供了大量预定义的层。nn模块(neural networks)的缩写，所以里面定义了大量神经网络 的层。 Sequential：可以看作是一个 串联各个层的容器，在构建模型时，在该容器中一次添加层。当给定输入数据时， 容器中的每一层的输出作为下一层的输入。\ninit模块：initializer的缩写。该模块提供了模型参数初始化的各种方法。\nfrom mxnet.gluon import nn from mxnet import init # 定义模型 net = nn.Sequential() net.add(nn.Dense(1)) # 初始化模型参数 net.initialize(init.Normal(sigma=0.01))     定义损失函数 - 从零实现 def squared_loss(y_hat, y): return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 loss = squared_loss     定义损失函数 - Gluon实现 Gluon中的loss模块：定义了各种损失函数。\nfrom mxnet.gluon import loss as gloss loss = gloss.L2Loss() # 平方损失又称L2范数损失     定义优化算法 - 从零实现 param.grad自动求梯度模块计算得来的梯度是一个批量样本的梯度和。在迭代模型参数时，需要除以批量大小来得到平均值。\ndef sgd(params, lr, batch_size): for param in params: param[:] = param - lr * param.grad / batch_size     定义优化算法 - Gluon实现 Gluon模块中的Trainer类，用来迭代模型中的全部参数。这些参数可以通过collect_params函数获取。\nfrom mxnet.gluon import Trainer trainer = Trainer(net.collect_params(), \u0026#39;sgd\u0026#39;, {\u0026#39;learning_rate\u0026#39;: 0.03})     训练模型 - 从零实现 lr = 0.03 num_epochs = 3 net = linreg # 训练模型一共需要num_epochs个迭代周期 for epoch in range(num_epochs): # 在每一个迭代周期中，会使用训练数据集中所有样本一次（假设样本数能够被批量大小整除） # x和y分别是小批量样本的特征和标签 for X, y in data_iter(batch_size, features, labels): with autograd.record(): l = loss(net(X, w, b), y) # l是有关小批量X和y的损失 l.backward() # 小批量的损失对模型参数求梯度 sgd([w, b], lr, batch_size) # 使用小批量随机梯度下降迭代模型参数 train_l = loss(net(features, w, b), labels) print(\u0026#39;epoch %d, loss %f\u0026#39; % (epoch + 1, train_l.mean().asnumpy()))     训练模型 - Gluon实现 通过Trainer实例的step函数来迭代模型参数。由于loss是长度为batch_size的向量，在执行l.backward()时， 等价于执行l.sum().backward()。所以要用batch_size做平均。\nnum_epochs = 3 # 训练模型一共需要num_epochs个迭代周期 for epoch in range(1, num_epochs + 1): # 在每一个迭代周期中，会使用训练数据集中所有样本一次（假设样本数能够被批量大小整除） # x和y分别是小批量样本的特征和标签 for X, y in data_iter: with autograd.record(): l = loss(net(X), y) # l是有关小批量X和y的损失 l.backward() # 等价于l.sum().backward() trainer.step(batch_size) # 指定batch_size，从而对批量样本梯度求平均 l = loss(net(features), labels) print(\u0026#39;epoch %d, loss: %f\u0026#39; % (epoch, l.mean().asnumpy()))     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/gluon_summary/","summary":"实例-单层感知机 模型：o = w1*x1 + w2*x2 + b 输出o作为线性回归的输出，输入层是2维特征；输入层不涉及计算，该神经网络只有输出层1层。\n神经元：输出层中负责计算o的单元。\n该神经元，依赖于输入层的全部特征，也就是说输出层中的神经元和输入层中各个输入完全连接，所以，这里的输出层又叫作全连接层(fully connected layer)或者稠密层(dense layer)\n    生成数据集 目标： o = 2x1 - 3.4x2 + 4.2 其中： 样本集：features: [w1, w2]， labels: [真实值+噪声]\nfrom IPython import display from matplotlib import pyplot as plt from mxnet import autograd, nd import random num_inputs = 2 num_examples = 1000 true_w = [2, -3.4] true_b = 4.2 features = nd.random.normal(scale=1, shape=(num_examples, num_inputs)) labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b labels += nd.","tags":null,"title":"Gluon实例"},{"categories":null,"contents":"gluon模块-结构 路径.mxnet/gluon/下的树状结构:\n│　block.py 类：Block, HybridBlock\n│　loss.py 各种loss函数\n│　parameter.py 类：Parameter, Constant, ParameterDict\n│　trainer.py 类：Trainer\n│　utils.py 优化操作\n│　init.py\n│\n├─contrib\n│　│\n│　├─cnn\n│　│　└─ conv_layers.py\n│　├─data\n│　│　└─ sampler.py\n│　│\n│　├─estimator\n│　│　│　estimator.py\n│　│　└─ event_handler.py\n│　│\n│　├─nn\n│　│　└─ basic_layers.py\n│　│\n│　└─rnn\n│　│　conv_rnn_cell.py\n│　└─ rnn_cell.py\n│\n├─data 主要是数据处理操作\n│　│　dataloader.py 类：DataLoader\n│　│　dataset.py 常用类: ArrayDataset\n│　│　sampler.py\n│　│\n│　└─vision\n│　│　datasets.py 可用的数据集-各个类\n│　└─ transforms.py 数据预处理-各个类\n│\n├─model_zoo\n│　│　model_store.py\n│　│\n│　└─vision\n│　│　alexnet.py\n│　│　densenet.py\n│　│　inception.py\n│　│　mobilenet.py\n│　│　resnet.py\n│　│　squeezenet.py\n│　└─ vgg.py\n├─nn 网络结构\n│　│　activations.py 定义了各种激活层\n│　│　basic_layers.py 定义了网络的基础层,例如：BN,Dropout等\n│　└─ conv_layers.py 定义了各种卷积池化层等\n│\n└─rnn\n│　rnn_cell.py\n└─ rnn_layer.py    gluon模块-导入 # data from mxnet.gluon.data import ArrayDataset, DataLoader from mxnet.gluon.data.vision.transforms import ToTensor, Normalize # nn from mxnet.gluon.nn import Block, HybridBlock, Sequential, HybridSequential, Dropout, BatchNorm, Dense, PReLU, Conv2D # 模型参数 from mxnet.gluon.parameter import Parameter, Constant, ParameterDict # 训练 from mxnet.gluon.trainer import Trainer # 损失函数 from mxnet.gluon. import loss # 损失函数 [\u0026#39;Loss\u0026#39;, \u0026#39;L2Loss\u0026#39;, \u0026#39;L1Loss\u0026#39;, \u0026#39;SigmoidBinaryCrossEntropyLoss\u0026#39;, \u0026#39;SigmoidBCELoss\u0026#39;, \u0026#39;SoftmaxCrossEntropyLoss\u0026#39;, \u0026#39;SoftmaxCELoss\u0026#39;, \u0026#39;KLDivLoss\u0026#39;, \u0026#39;CTCLoss\u0026#39;, \u0026#39;HuberLoss\u0026#39;, \u0026#39;HingeLoss\u0026#39;, \u0026#39;SquaredHingeLoss\u0026#39;, \u0026#39;LogisticLoss\u0026#39;, \u0026#39;TripletLoss\u0026#39;, \u0026#39;PoissonNLLLoss\u0026#39;, \u0026#39;CosineEmbeddingLoss\u0026#39;]     数据集 - data ToTensor：将图像数据从uint8格式变换成32位浮点数格式，并除以255使得所有像素的数值均在0到1之间 transform_first函数：数据集的函数。将ToTensor的变换应用在每个数据样本（图像和标签）的第一个元素，即图像之上.\nfrom mxnet.gluon import data as gdata batch_size = 256 transformer = gdata.vision.transforms.ToTensor() if sys.platform.startswith(\u0026#39;win\u0026#39;): num_workers = 0 # 0表示不用额外的进程来加速读取数据 else: num_workers = 4 train_iter = gdata.DataLoader(mnist_train.transform_first(transformer), batch_size, shuffle=True, num_workers=num_workers) test_iter = gdata.DataLoader(mnist_test.transform_first(transformer), batch_size, shuffle=False, num_workers=num_workers)     模型初始化 - init from mxnet import init     损失函数 - loss from mxnet.gluon import loss as gloss # 平方损失又称L2范数损失 loss = gloss.L2Loss() # 包含了softmax运算和交叉熵损失运算 loss = gloss.SoftmaxCrossEntropyLoss()     优化算法 - Trainer from mxnet.gluon import Trainer     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/module_gather/","summary":"gluon模块-结构 路径.mxnet/gluon/下的树状结构:\n│　block.py 类：Block, HybridBlock\n│　loss.py 各种loss函数\n│　parameter.py 类：Parameter, Constant, ParameterDict\n│　trainer.py 类：Trainer\n│　utils.py 优化操作\n│　init.py\n│\n├─contrib\n│　│\n│　├─cnn\n│　│　└─ conv_layers.py\n│　├─data\n│　│　└─ sampler.py\n│　│\n│　├─estimator\n│　│　│　estimator.py\n│　│　└─ event_handler.py\n│　│\n│　├─nn\n│　│　└─ basic_layers.py\n│　│\n│　└─rnn\n│　│　conv_rnn_cell.py\n│　└─ rnn_cell.py\n│\n├─data 主要是数据处理操作","tags":null,"title":"Gluon模块简介"},{"categories":null,"contents":"Depth First Search(DFS)遍历 # -*- coding: utf-8 -*- class TreeNode: def __init__(self, value): self.value = value self.left = None self.right = None class Tree_Method: def DFS(self, root): \u0026#39;\u0026#39;\u0026#39; 深度优先遍历，即先访问根节点，然后遍历左子树接着遍历右子树。 主要利用栈的特点，先将右子树压栈，再将左子树压栈，这样左子树就位于栈顶， 可以结点的左子树先与右子树被遍历。 \u0026#39;\u0026#39;\u0026#39; if root == None: return None stack = [] \u0026#39;\u0026#39;\u0026#39;用列表模仿入栈\u0026#39;\u0026#39;\u0026#39; stack.append(root) while stack: \u0026#39;\u0026#39;\u0026#39;将栈顶元素出栈\u0026#39;\u0026#39;\u0026#39; current_node = stack.pop() print(current_node.value, end=\u0026#39; \u0026#39;) \u0026#39;\u0026#39;\u0026#39;判断该节点是否有右孩子，有就入栈\u0026#39;\u0026#39;\u0026#39; if current_node.right: stack.append(current_node.right) \u0026#39;\u0026#39;\u0026#39;判断该节点是否有左孩子，有就入栈\u0026#39;\u0026#39;\u0026#39; if current_node.left: def preOrder(self, root): \u0026#39;\u0026#39;\u0026#39;先序遍历\u0026#39;\u0026#39;\u0026#39; if root == None: return None print(root.value) self.preOrder(root.left) self.preOrder(root.right) # 先序打印二叉树（非递归） def preOrderTravese(node): stack = [node] while len(stack) \u0026gt; 0: print(node.val) if node.right is not None: stack.append(node.right) if node.left is not None: stack.append(node.left) node = stack.pop() def minOrder(self, root): \u0026#39;\u0026#39;\u0026#39;中序遍历\u0026#39;\u0026#39;\u0026#39; if root == None: return None self.minOrder(root.left) print(root.value) self.minOrder(root.right) # 中序打印二叉树（非递归） def inOrderTraverse(node): stack = [] pos = node while pos or stack: if pos: stack.append(pos) pos = pos.left else: pos = stack.pop() print(pos.val) pos = pos.right def postOrder(self, root): \u0026#39;\u0026#39;\u0026#39;后序遍历\u0026#39;\u0026#39;\u0026#39; if root == None: return None self.postOrder(root.left) self.postOrder(root.right) print(root.value) # 后序打印二叉树（非递归） # 使用两个栈结构 # 第一个栈进栈顺序：左节点-\u0026gt;右节点-\u0026gt;跟节点 # 第一个栈弹出顺序： 跟节点-\u0026gt;右节点-\u0026gt;左节点(先序遍历栈弹出顺序：跟-\u0026gt;左-\u0026gt;右) # 第二个栈存储为第一个栈的每个弹出依次进栈 # 最后第二个栈依次出栈 def postOrderTraverse(node): stack = [node] stack2 = [] while stack: node = stack.pop() stack2.append(node) if node.left: stack.append(node.left) if node.right: stack.append(node.right) while stack2: print(stack2.pop().val)     Breadth First Search(BFS)遍历 # -*- coding: utf-8 -*- class TreeNode: def __init__(self, value): self.value = value self.left = None self.right = None class Tree_Method: def create_tree(self, arr): \u0026#39;\u0026#39;\u0026#39; 利用二叉树的三个组成部分：根节点-左子树-右子树； 传入的arr是一个多维列表，每一维最大为3， 每一维中的内容依次表示根节点-左子树-右子树。然后递归的进行构建 \u0026#39;\u0026#39;\u0026#39; length = len(arr) #计算每一维的大小 root = TreeNode(arr[0]) #获取每一维的根节点 if length \u0026gt;= 2: #判断是否有左子树 root.left = self.create_tree(arr[1]) if length \u0026gt;= 3: #判断是否有右子树 root.right = self.create_tree(arr[2]) return root def BFS(self, root): \u0026#39;\u0026#39;\u0026#39; 广度优先遍历，即从上到下，从左到右遍历。 主要利用队列先进先出的特性，入队的时候，是按根左右的顺序，那么只要按照这个顺序出队就可以了 \u0026#39;\u0026#39;\u0026#39; if root == None: return None queue = [] \u0026#39;\u0026#39;\u0026#39;用列表模仿入队\u0026#39;\u0026#39;\u0026#39; queue.append(root) while queue: \u0026#39;\u0026#39;\u0026#39;将队首元素出栈\u0026#39;\u0026#39;\u0026#39; current_node = queue.pop(0) print(current_node.value, end=\u0026#39; \u0026#39;) \u0026#39;\u0026#39;\u0026#39;判断该节点是否有左孩子，有就入队\u0026#39;\u0026#39;\u0026#39; if current_node.left: queue.append(current_node.left) \u0026#39;\u0026#39;\u0026#39;判断该节点是否有右孩子，有就入队\u0026#39;\u0026#39;\u0026#39; if current_node.right: queue.append(current_node.right)     torch模块-样例 import torch     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/torch_summary/","summary":"Depth First Search(DFS)遍历 # -*- coding: utf-8 -*- class TreeNode: def __init__(self, value): self.value = value self.left = None self.right = None class Tree_Method: def DFS(self, root): \u0026#39;\u0026#39;\u0026#39; 深度优先遍历，即先访问根节点，然后遍历左子树接着遍历右子树。 主要利用栈的特点，先将右子树压栈，再将左子树压栈，这样左子树就位于栈顶， 可以结点的左子树先与右子树被遍历。 \u0026#39;\u0026#39;\u0026#39; if root == None: return None stack = [] \u0026#39;\u0026#39;\u0026#39;用列表模仿入栈\u0026#39;\u0026#39;\u0026#39; stack.append(root) while stack: \u0026#39;\u0026#39;\u0026#39;将栈顶元素出栈\u0026#39;\u0026#39;\u0026#39; current_node = stack.pop() print(current_node.value, end=\u0026#39; \u0026#39;) \u0026#39;\u0026#39;\u0026#39;判断该节点是否有右孩子，有就入栈\u0026#39;\u0026#39;\u0026#39; if current_node.right: stack.append(current_node.right) \u0026#39;\u0026#39;\u0026#39;判断该节点是否有左孩子，有就入栈\u0026#39;\u0026#39;\u0026#39; if current_node.left: def preOrder(self, root): \u0026#39;\u0026#39;\u0026#39;先序遍历\u0026#39;\u0026#39;\u0026#39; if root == None: return None print(root.value) self.","tags":null,"title":"二叉树"},{"categories":null,"contents":"分治法 分治法(divide and conquer)：\n 待解决复杂问题，能够简化为若干个小规模相同的问题，各个子问题独立存在，并且与原问题形式相同； 递归地解决各个子问题； 将各个子问题的解合并，得到原问题的解。  示例：\n归并排序\n    动态规划 与分治法的不同：\n动态规划与分治法相似，都是组合子问题的解来解决原问题，与分治法的不同在于：\n 分治法：将原问题划分为一个个不相交的子问题（比如：归并排序，将数组不断地划分为一个个的子数组进行排序，再将返回的两个有序数组进行合并排序） 动态规划：要解决的是子问题有重叠的问题，例如0-1背包问题。即：不同的子问题有公共的子子问题，这些重叠的子问题在动态规划中是不应该也不需要重新计算的，而是应该将其解以一定方式保存起来，提供给父问题使用。  设计步骤：\n动态规划通常用来求解最优解问题，这类问题会有很多个解，每个解都对应一个值，而我们则希望在这些解中找到最优解（最大值或者最小值）。 通常四个步骤设计一个动态规划算法：\n 刻画一个最优解的结构特征，就是那个递推公式 递归的定义最优解的值 计算最优解的值，通常采用自底向上的方法；有重叠的话，就先记录下来 利用计算出的信息构造一个最优解  实现方法：\n 自顶向下：此方法需要一个备忘录来辅助实现，备忘录主要用来保存每一个子问题的解，当每个子问题只求一次，如果后续需要子问题的解，只需要查找备忘录中保存的结果，不必重复计算。 自底向上：此方法最常用，必须明确每个子问题规模的概念，使得任何子问题的求解都依赖于子子问题的解来进行求解。  示例：\n0-1背包问题\n    贪心算法 贪心算法：在对问题求解时，总是做出在当前看来是做好的选择。即：当考虑做何种选择的时候，我们只考虑对当前问题最佳的选择而不考虑子问题的结果，这是贪心算法可行的第一个基本要素。不从整体最优上考虑，而是仅仅在某种意义上的局部最优解。贪心算法以迭代的方式作出相继的贪心选择，每做一次贪心选择就将问题简化为规模更小的子问题。\n何时采用贪心算法：对于一个具体问题，要确定它是否具有贪心选择性质，必须证明每一步所作的贪心选择最终导致问题的整体最优解。\n示例：\n完全背包问题、均分纸牌、最大整数\n实际上，贪心算法适用的情况很少。需要先证明：局部最优解会得出整体最优解，才可以使用。一旦证明能成立，它就是一种高效的算法。\n例如【0-1背包问题】：即：对于每个物品，要么装要么不装(0或1)\n有一个背包，背包容量是M=150。有7个物品，物品可以分割成任意大小。要求尽可能让装入背包中的物品总价值最大，但不能超过总容量。\n物品： A B C D E F G\n重量： 35 30 60 50 40 10 25\n价值： 10 40 30 50 35 40 30\n目标函数： ∑pi最大\n利用贪心算法，可以这样：\n 每次挑选价值最大的物品装入背包，（是否是最优解？） 每次选择重量最小的物品装入背包，（是否是最优解？） 每次选择单位重量价值最大的物品，（是否是最优解？）  上面的3中贪心策略，都无法成立，所以不能采用贪心算法。所以，贪心算法虽然简单高效，但是能证明可以使用该算法的场景比较少。\n    回溯法 回溯法： 是一种类似枚举的搜索尝试过程，在搜索尝试过程中寻找问题的解，当发现已不满足条件时，就回溯返回，尝试别的路径。\n回溯法是一种选优搜索法，通常是创建一棵树，从根节点出发，按照深度优先搜索的策略进行搜索，到达某一节点后，搜索该节点是否包含该问题的解：a. 如果包含，则进入下一个节点进行搜索；b. 如果不包含，则回溯到父节点选择其他支路进行搜索。\n何时采用回溯算法： 必须有标志性操作——搜索时不满足条件就剪枝 + 所有解\n设计步骤:\n 针对所给的原问题，定义问题的解空间； 确定易于搜索的解空间结构； 以深度优先搜索解空间，并在搜索过程中用剪枝函数除去无效搜索。  示例：\n全排列、旅行商问题、八皇后问题\n    分支限界法 分支限界法(branch and bound method)： 和回溯法类似，也是一种搜索算法，与回溯法不同的是：\n 回溯法：找出问题的许多解；通常用深度优先的方式搜索解空间树； 分支限界法：找出原问题的一个解，或者 在满足约束条件的解中找出使某一目标函数的极大解/极小解。通常以广度优先或最小耗费优先的方式搜索解空间树。  在当前节点(扩展节点)处，生成其所有的子节点(分支)，然后再从当前节点的子节点表中选择下一个扩展节点。为了有效地选择下一个扩展节点，加速搜索的进程，在每个节点处，计算一个限界，从其子节点表中选择一个最有利的节点作为扩展节点，使搜索朝着解空间上最优解的分支推进。\n何时采用分支界限法： 必须有标志性操作——搜索时不满足限界就剪枝 + 最优解\n示例：\n0-1背包问题：限界就是背包的大小，一个节点的子节点表中，如果有超过限界的就直接剪枝。如下图所示：\n    ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/dynamic_plan/","summary":"分治法 分治法(divide and conquer)：\n 待解决复杂问题，能够简化为若干个小规模相同的问题，各个子问题独立存在，并且与原问题形式相同； 递归地解决各个子问题； 将各个子问题的解合并，得到原问题的解。  示例：\n归并排序\n    动态规划 与分治法的不同：\n动态规划与分治法相似，都是组合子问题的解来解决原问题，与分治法的不同在于：\n 分治法：将原问题划分为一个个不相交的子问题（比如：归并排序，将数组不断地划分为一个个的子数组进行排序，再将返回的两个有序数组进行合并排序） 动态规划：要解决的是子问题有重叠的问题，例如0-1背包问题。即：不同的子问题有公共的子子问题，这些重叠的子问题在动态规划中是不应该也不需要重新计算的，而是应该将其解以一定方式保存起来，提供给父问题使用。  设计步骤：\n动态规划通常用来求解最优解问题，这类问题会有很多个解，每个解都对应一个值，而我们则希望在这些解中找到最优解（最大值或者最小值）。 通常四个步骤设计一个动态规划算法：\n 刻画一个最优解的结构特征，就是那个递推公式 递归的定义最优解的值 计算最优解的值，通常采用自底向上的方法；有重叠的话，就先记录下来 利用计算出的信息构造一个最优解  实现方法：\n 自顶向下：此方法需要一个备忘录来辅助实现，备忘录主要用来保存每一个子问题的解，当每个子问题只求一次，如果后续需要子问题的解，只需要查找备忘录中保存的结果，不必重复计算。 自底向上：此方法最常用，必须明确每个子问题规模的概念，使得任何子问题的求解都依赖于子子问题的解来进行求解。  示例：\n0-1背包问题\n    贪心算法 贪心算法：在对问题求解时，总是做出在当前看来是做好的选择。即：当考虑做何种选择的时候，我们只考虑对当前问题最佳的选择而不考虑子问题的结果，这是贪心算法可行的第一个基本要素。不从整体最优上考虑，而是仅仅在某种意义上的局部最优解。贪心算法以迭代的方式作出相继的贪心选择，每做一次贪心选择就将问题简化为规模更小的子问题。\n何时采用贪心算法：对于一个具体问题，要确定它是否具有贪心选择性质，必须证明每一步所作的贪心选择最终导致问题的整体最优解。\n示例：\n完全背包问题、均分纸牌、最大整数\n实际上，贪心算法适用的情况很少。需要先证明：局部最优解会得出整体最优解，才可以使用。一旦证明能成立，它就是一种高效的算法。\n例如【0-1背包问题】：即：对于每个物品，要么装要么不装(0或1)\n有一个背包，背包容量是M=150。有7个物品，物品可以分割成任意大小。要求尽可能让装入背包中的物品总价值最大，但不能超过总容量。\n物品： A B C D E F G\n重量： 35 30 60 50 40 10 25\n价值： 10 40 30 50 35 40 30","tags":null,"title":"五大常用算法"},{"categories":null,"contents":"滑动窗口算法 参考\n滑动窗口算法：是在给定特定窗口大小的数组或字符串上执行要求的操作，该技术可以将一部分问题中的嵌套循环转变为一个单循环，可以减少时间复杂度。即：在一个特定大小的字符串/数组上进行操作，而不是在整个字符串/数组上操作，这样就降低了问题的复杂度。\n滑动：说明这个窗口是移动的；\n窗口：窗口大小并不是固定的，可以不断扩容直到满足一定的条件；也可以不断缩小，直到找到一个满足条件的最小窗口；也可以是固定大小。\n滑动窗口算法的思路：\n 我们在字符串 S 中使用双指针中的左右指针技巧，初始化 left = right = 0，把索引闭区间 [left, right] 称为一个「窗口」。 我们先不断地增加 right 指针扩大窗口 [left, right]，直到窗口中的字符串符合要求（包含了 T 中的所有字符）。 此时，我们停止增加 right，转而不断增加 left 指针缩小窗口 [left, right]，直到窗口中的字符串不再符合要求（不包含 T 中的所有字符了）。同时，每次增加 left，我们都要更新一轮结果。 重复第 2 和第 3 步，直到 right 到达字符串 S 的尽头。  对于固定窗口大小，框架总结如下：\n# 固定窗口大小为k # 在s中 寻找窗口大小为k时的所包含最大元音字母个数 right = 0 while right\u0026lt;len(s): window.append(s[right]) right += 1 # 如果符合要求，说明窗口构造完成 if right\u0026gt;=k: # 这已经是一个窗口了，根据条件做一些事情 ... 可以计算窗口最大值 # 最后不要忘记把 【right-k】位置元素从窗口里移除 对于不固定窗口大小，框架总结如下：\n# 在s中寻找 t 的 最小覆盖子串 left, right = 0, 0 while right\u0026lt;len(s): right += 1 # 如果符合要求，说明窗口构造完成，移动left缩小窗口 while \u0026#39;符合要求\u0026#39;: # 如果这个窗口的子串更短，则更新res res = minLen(res, windown) window.remove(left) left += 1 return res     ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/sliding_window/","summary":"滑动窗口算法 参考\n滑动窗口算法：是在给定特定窗口大小的数组或字符串上执行要求的操作，该技术可以将一部分问题中的嵌套循环转变为一个单循环，可以减少时间复杂度。即：在一个特定大小的字符串/数组上进行操作，而不是在整个字符串/数组上操作，这样就降低了问题的复杂度。\n滑动：说明这个窗口是移动的；\n窗口：窗口大小并不是固定的，可以不断扩容直到满足一定的条件；也可以不断缩小，直到找到一个满足条件的最小窗口；也可以是固定大小。\n滑动窗口算法的思路：\n 我们在字符串 S 中使用双指针中的左右指针技巧，初始化 left = right = 0，把索引闭区间 [left, right] 称为一个「窗口」。 我们先不断地增加 right 指针扩大窗口 [left, right]，直到窗口中的字符串符合要求（包含了 T 中的所有字符）。 此时，我们停止增加 right，转而不断增加 left 指针缩小窗口 [left, right]，直到窗口中的字符串不再符合要求（不包含 T 中的所有字符了）。同时，每次增加 left，我们都要更新一轮结果。 重复第 2 和第 3 步，直到 right 到达字符串 S 的尽头。  对于固定窗口大小，框架总结如下：\n# 固定窗口大小为k # 在s中 寻找窗口大小为k时的所包含最大元音字母个数 right = 0 while right\u0026lt;len(s): window.append(s[right]) right += 1 # 如果符合要求，说明窗口构造完成 if right\u0026gt;=k: # 这已经是一个窗口了，根据条件做一些事情 ... 可以计算窗口最大值 # 最后不要忘记把 【right-k】位置元素从窗口里移除 对于不固定窗口大小，框架总结如下：","tags":null,"title":"滑动窗口"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":["Basic"],"contents":"一、 参考， 论文， Gitlab\n","date":"May 9, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/vlp/clip/","summary":"一、 参考， 论文， Gitlab","tags":["多模态","CLIP"],"title":"CLIP"},{"categories":["Basic"],"contents":"从2019年中~2020年中，对比学习火了一段时间，到ViT出来后，大量的研究这才投身于ViT。\n一、简介 什么是对比学习？\n简单来说就是，只要模型把相似的数据跟其他不相似的数据区分开就可以。比如：$A_1, A_2, \u0026hellip;$ 是狗，$B_1, B_2, \u0026hellip;$ 是猫，只要模型能把这两批数据区分开就行。\n所以，训练集中不需要明确的标签，只要能区分出那些数据之间是相似的，那些是与它们不相似的。\n所以，训练集中不必人为标注，只需要设计一些规则生产出这种类型的训练集就行。\n看下Hinton老爷子的《Self-organizing neural network that discovers surfaces in random-dot stereograms》 和 LeCun的《Dimensionality reduction by learning an invariant mapping》 对比学习为啥在cv领域被认为是无监督呢？：\n 通过设计一些巧妙的代理任务，就是pretext task：人为的定义一些规则，这些规则可以用来定义那些图片是相似的，那些图片是不相似的。\n例如：instance discrimination：如果有N张图片的数据集，随机一张图片$x_i$，对这个图片随机裁剪+数据增广，从同一张图片中通过裁剪+增广产生的数据，虽然有差异但是语义信息是一样的，所以是正样本(它们之间是相似的)，负样本就是除了图$x_i$之外的所有样本。  1、代理任务 代理任务(pretext task)的目的: 生成一个自监督的信号，从而充当ground truth这个标签信息\n有监督学习：训练时比较输出 $\\hat{Y}$ 和 groud truth $Y$；\n自监督学习：因为缺少groud truth，所以需要代理任务自己创建类似groud truth的信号。\n2、对比学习的loss 1)、InfoNCE loss noise contrastive estimation loss：其实就是一个交叉熵 $$ L_q = -log\\frac{exp(q\\cdot k_+ / \\tau)}{\\sum_{i=0}^{K} exp(q\\cdot k_i / \\tau)} $$ 分母：一个正样本，K个负样本；$\\tau$：温度超参数，值越大分布就越平缓，表示对每种的关注度越相似；值越小分布就越陡峭，表示比较关注比较困难的case，不容易收敛。\n3、数据 数据处理流程：\n 图片$x_1$经过不同的变换分别生成了不同的图片$x_1^1, x_1^2$，一般$x_1^1$为锚点作为基准；$x_1^2$是$x_1^1$的正样本；剩余的$x_2, x_3, \u0026hellip;, x_N$是$x_1^1$的负样本。 有了正负样本数据后，就是把这些数据丢进编码器提取特征；锚点的特征：$f_{11}$，正样本：$f_{12}$，负样本：$f_2, f_3, \u0026hellip;, f_N$ 对比学习的目的：在特征空间里，让锚点的特征$f_{11}$与正样本的特征$f_{12}$尽量靠近；与负样本的特征$f_2, f_3, \u0026hellip;, f_N$尽量远离。  二、初代对比网络 1、InstDisc 《Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination》2018 缺点是：字典特征不一致。\n 提出了个体判别这个代理任务。 把ImageNet的每张图片，表示层128维特征，提前算好存起来(memory bank) 对memory bank的特征进行动态更新 在计算loss时使用动量，来弥补字典特征的不一致性  2、InvaSpread 《Unsupervised Embedding Learning via Invariant and Spreading Instance Feature》2019：Invariant：对于相似的图片，特征尽量不变；Spreading：对于不相似的图片，特征尽量分散。 缺点：字典太小。\n 个体判别代理任务 在mni-batch内选择正样本和负样本：比如batch size = 256，正样本就是mini-batch内的每个样本，负样本就是除去该正样本后的所有样本和其数据增强后的样本。 目标函数为 NCE Loss的一个变体  3、CPC 《Representation Learning with Contrastive Predictive Coding》2018\n 预测未来的代理任务(生成式)：未来输入，通过已训的网络后的输出特征作为正样本；其他任意输入通过已训的网络后的输出特征作为负样本。  4、CMC 《Contrastive Multiview Coding》2019\n 多视角的代理任务：同一事物的不同视角的表征，是正样本；其他事物的表征，是负样本 不同视角会有不同的编码器 证明了多模态融合的可能性  三、二代目对比网络 1、MoCo MoCo(2020) 作为一个无监督的表征学习工作，不仅在分类领域逼近有监督的模型，还在检测、分割、人体关键点检测都超越了有监督的预训练模型，MoCo的出现证明了在视觉领域无监督训练是有前途的。\n问题：为什么无监督学习在NLP领域表现较好，在视觉领域效果不好呢？\n作者认为：NLP领域，每个token是一个独立的语义信息，其分布是一个离散的信号空间，由于token的独立性，在字典集合中，其就是一个分类任务，可以有类似标签的形式帮助训练；视觉是一个高维连续空间，不像token有很强的语义信息而且浓缩的比较好，导致视觉不能创建一个类似NLP的字典，没有这个字典就不容易建模，所以在视觉领域无监督学习还不如有监督学习。\n问题：作者设计动机？\n以往的工作，会受限于：a. 字典的大小；b. 字典内的一致性。\n 训练一个encoder，从图像数据里抽样出特征，由这些特征组成一个动态字典；  这个字典一定要大：字典越大，就可以表征更多的视觉信息。 在训练的时候，字典内要有一致性：各个key的尽量是通过相同的编码器产出的，不然query可能选择与自己的编码器相同的key，而不是真的和它含有相同语义信息的那个key。   对比学习使得正样本间距离尽量小，负样本距离尽量大    作者怎么设计的：\n 怎么构建大字典？所有数据集组成一个字典肯定不行，计算一次要花费很长时间，而且内存也不够。作者使用了队列这种数据结构，队列的大小就是字典的大小；队列可以很大(字典很大)，每次训练的mini-batch很小；队列中的元素不是每次都需要更新，每次更新mini-batch大小的数据。新的数据入队，最久的数据出队。字典大小(作者默认：65536)是一个超参数，可以是几千上万，训练时间都差不多。 怎么保持一致性呢？作者设计了动量编码器：例如：query的编码器为 $\\theta_q$，动量编码器为：$\\theta_k \\gets m \\theta_{k} + (1-m)\\theta_q$。设计一个较大的动量参数m(e.g., m=0.999)，使得动量编码器更新的比较缓慢，不会因为 $\\theta_q$引起太多的改变，所以近似保持一致性。只有 $\\theta_q$ 参与训练，$\\theta_k$ 是不参与训练的，是由0.999的上一个 $\\theta_k$+0.001的当前 $\\theta_q$组合而成。     # f_q, f_k: encoder networks for query and key # queue: dictionary as a queue of K keys (CxK) # m: momentum # t: temperature f_k.params = f_q.params # initialize for x in loader: # load a minibatch x with N samples x_q = aug(x) # a randomly augmented version x_k = aug(x) # another randomly augmented version q = f_q.forward(x_q) # queries: NxC k = f_k.forward(x_k) # keys: NxC k = k.detach() # no gradient to keys # positive logits: Nx1 l_pos = bmm(q.view(N,1,C), k.view(N,C,1)) # negative logits: NxK l_neg = mm(q.view(N,C), queue.view(C,K)) # logits: Nx(1+K) logits = cat([l_pos, l_neg], dim=1) # contrastive loss, Eqn.(1) labels = zeros(N) # positives are the 0-th loss = CrossEntropyLoss(logits/t, labels) # SGD update: query network loss.backward() update(f_q.params) # momentum update: key network f_k.params = m*f_k.params+(1-m)*f_q.params # update dictionary enqueue(queue, k) # enqueue the current minibatch dequeue(queue) # dequeue the earliest minibatch 2、SimCLR 《A simple framework for contrastive learning of visual representations》2020很简单。缺点就是 字典比较小。\n 在mni-batch内选择正样本和负样本：比如batch size = 256，正样本就是mini-batch内的每个样本，负样本就是除去该正样本后的所有样本和其数据增强后的样本。 训练时添加了一个mlp全连接层，就是那个 $g(\\sdot)$，这个简单的操作，在ImageNet数据集上提升了10个点。 更丰富的数据增强  3、MoCo v2 MoCo V2 基于初版MoCo和SimCLR的全连接层，做了一些优化，发现添加mlp全连接层真香\n 加了更丰富的数据增强 提升3个点 加了MLP 提升了6个点 加了cosine 的学习率 训练更多个epoch 提升4个点  4、SimCLR v2 《Big Self-Supervised Models are Strong Semi-Supervised Learners》\n 采用更大的模型，152-ResNet 添加了2层mlp 使用动量编码器  5、SwAV(swap assignment views) 《Unsupervised Learning of Visual Features by Contrasting Cluster Assignments》2020：给定同样一张图片，生成不同的视角；希望可以用一个视角得到的特征去预测另外一个视角得到的特征。\n multi crop 技术：全局和局部的特征都需要关注  四、三代目对比网络 不使用负样本\n1、BYOL 《Bootstrap your own latent: A new approach to self-supervised Learning》2020\n 对输入图片x，锚点通过一系列的变换，最后是 $q_{\\theta}(z_{\\theta})$；正样本通过一些列的变换，最后是 $sg(z'_{\\xi})$。这两个是输入图片的近似表示 让 $sg(z'_{\\xi})$ 做target，计算这两个的MSE-loss 模型最后就训练了编码器 $f_{\\theta}$，正样本的编码器 $f_{\\xi}$ 只是 $f_{\\theta}$ 的平均，也就是动量编码器。 模型没有使用负样本，只是用自己预测自己，为啥没有出现模型坍塌呢？  参考 这个 Blog 博主，通过一系列的实验，得出他的结论：BYOL能够学到东西，主要是因为Batch normalization。通过BN的操作，用整个batch的样本计算 均值、方差，然后用在batch内的各个样本上；这个操作相当于存在信息泄露，一个样本在计算是也能看到整个batch的信息，相当于一个平均的信息作为负样本；即使没有刻意提供负样本，但通过BN的操作也有了负样本的作用。 BYOL的作者听到后就不同意了，他也做了一些列的实验 《BYOL works even without batch statistics》，发现BN确实很香；不过，他认为是BN只是使得模型能够稳定训练，真正起作用的是一个很好的初始化。    2、SimSiam 《Exploring Simple Siamese Representation Learning》2020\n作者怎么设计的：\n 不需要负样本 不需要大的batch size 不需要动量编码器  # f: backbone + projection mlp # h: prediction mlp for x in loader: # load a minibatch x with n samples x1, x2 = aug(x), aug(x) # random augmentation z1, z2 = f(x1), f(x2) # projections, n-by-d p1, p2 = h(z1), h(z2) # predictions, n-by-d L = D(p1, z2)/2 + D(p2, z1)/2 # loss L.backward() # back-propagate update(f, h) # SGD update def D(p, z): # negative cosine similarity z = z.detach() # stop gradient p = normalize(p, dim=1) # l2-normalize z = normalize(z, dim=1) # l2-normalize return -(p*z).sum(dim=1).mean()      结论：类似于EM(Expectation-Maximization)算法。\n五、四代目对比网络 Transformer在对比学习上的应用\n1、MoCo V3 《An Empirical Study of Training Self-Supervised Vision Transformers》2021 相当于 MoCo V2 和SimSiam的合体\n 不训练 patch projection层。 把backbone有ResNet换成ViT；在训练时作者发现，准确度会时不时的塌陷。这个原因是什么呢？  作者通过观察回传梯度，在第一层梯度波动较大，说明这一层梯度不正常。作者设想：梯度既然不正常还不如直接不用梯度更新第一层，作者在第一层初始化后就直接冻住，不再更新第一层，实验后发现问题解决了。 所以，在ViT的第一层patch projection 还是有问题的，后续会被继续研究     # f_q: encoder: backbone + proj mlp + pred mlp # f_k: momentum encoder: backbone + proj mlp # m: momentum coefficient # tau: temperature for x in loader: # load a minibatch x with N samples x1, x2 = aug(x), aug(x) # augmentation q1, q2 = f_q(x1), f_q(x2) # queries: [N, C] each k1, k2 = f_k(x1), f_k(x2) # keys: [N, C] each loss = ctr(q1, k2) + ctr(q2, k1) # symmetrized loss.backward() update(f_q) # optimizer update: f_q f_k = m*f_k + (1-m)*f_q # momentum update: f_k # contrastive loss def ctr(q, k): logits = mm(q, k.t()) # [N, N] pairs labels = range(N) # positives are in diagonal loss = CrossEntropyLoss(logits/tau, labels) return 2 * tau * loss    2、DINO 《Emerging Properties in Self-Supervised Vision Transformers》2021 跟BYOL、SimSiam类似，也是预测型。\n跟MoCo V3 非常类似\n总结一下：\n # gs, gt: student and teacher networks # C: center (K) # tps, tpt: student and teacher temperatures # l, m: network and center momentum rates gt.params = gs.params for x in loader: # load a minibatch x with n samples x1, x2 = augment(x), augment(x) # random views s1, s2 = gs(x1), gs(x2) # student output n-by-K t1, t2 = gt(x1), gt(x2) # teacher output n-by-K loss = H(t1, s2)/2 + H(t2, s1)/2 loss.backward() # back-propagate # student, teacher and center updates update(gs) # SGD gt.params = l*gt.params + (1-l)*gs.params C = m*C + (1-m)*cat([t1, t2]).mean(dim=0) def H(t, s): t = t.detach() # stop gradient s = softmax(s / tps, dim=1) t = softmax((t - C) / tpt, dim=1) # center + sharpen return - (t * log(s)).sum(dim=1).mean()    ","date":"May 9, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/contrastive_learning/contrastive_learning/","summary":"从2019年中~2020年中，对比学习火了一段时间，到ViT出来后，大量的研究这才投身于ViT。\n一、简介 什么是对比学习？\n简单来说就是，只要模型把相似的数据跟其他不相似的数据区分开就可以。比如：$A_1, A_2, \u0026hellip;$ 是狗，$B_1, B_2, \u0026hellip;$ 是猫，只要模型能把这两批数据区分开就行。\n所以，训练集中不需要明确的标签，只要能区分出那些数据之间是相似的，那些是与它们不相似的。\n所以，训练集中不必人为标注，只需要设计一些规则生产出这种类型的训练集就行。\n看下Hinton老爷子的《Self-organizing neural network that discovers surfaces in random-dot stereograms》 和 LeCun的《Dimensionality reduction by learning an invariant mapping》 对比学习为啥在cv领域被认为是无监督呢？：\n 通过设计一些巧妙的代理任务，就是pretext task：人为的定义一些规则，这些规则可以用来定义那些图片是相似的，那些图片是不相似的。\n例如：instance discrimination：如果有N张图片的数据集，随机一张图片$x_i$，对这个图片随机裁剪+数据增广，从同一张图片中通过裁剪+增广产生的数据，虽然有差异但是语义信息是一样的，所以是正样本(它们之间是相似的)，负样本就是除了图$x_i$之外的所有样本。  1、代理任务 代理任务(pretext task)的目的: 生成一个自监督的信号，从而充当ground truth这个标签信息\n有监督学习：训练时比较输出 $\\hat{Y}$ 和 groud truth $Y$；\n自监督学习：因为缺少groud truth，所以需要代理任务自己创建类似groud truth的信号。\n2、对比学习的loss 1)、InfoNCE loss noise contrastive estimation loss：其实就是一个交叉熵 $$ L_q = -log\\frac{exp(q\\cdot k_+ / \\tau)}{\\sum_{i=0}^{K} exp(q\\cdot k_i / \\tau)} $$ 分母：一个正样本，K个负样本；$\\tau$：温度超参数，值越大分布就越平缓，表示对每种的关注度越相似；值越小分布就越陡峭，表示比较关注比较困难的case，不容易收敛。","tags":["backbone","contrastive learning"],"title":"contrastive learning"},{"categories":["Basic"],"contents":"一、简介 1、Transformer用在CV领域 在NLP中，Transformer的输入是一个时间步长为T的序列，比如：basic版bert，T=512，每个token embeding为768维特征。如何把二维图片转化为一维呢？\n $\\bf \\color{red} \\times$ 如果把每个像素点看做是一个样本，铺平后是一维序列。但是，图片大小 224*224=50176，远远大于Transformer的最大序列长度。 $\\bf \\color{red} \\times$ 卷积和Transformer一起用：《Non-local Neural Networks》(2018)、《End-to-End Object Detection with Transformers》(2020) 为了减小序列的长度，不直接使用输入图片，而是使用feature map 转换为序列。比如：ResNet50在最后的阶段的输出尺寸为 14x14，拉平后序列长度只有196。 $\\bf \\color{red} \\times$ 抛弃卷积使用定制化的自注意力机制：《Stand-Alone Self-Attention in Vision Models》(2019) 采用的是 孤立自注意力。用一个局部的小窗口做自注意力； 《Stand-alone axial-attention for panoptic segmentation》(2020) 采用的是轴注意力。在高度的方向上做自注意力、在宽度方向做自注意力。由于这些自注意力机制比较定制化，还没有在硬件上大规模加速计算，所以网络做不大。 $\\color{green} \\checkmark$ 对图片做些预处理，直接使用Transformer：将图片切分成一个个patch，然后每个patch作为一个token输入到Transformer中。  $224 \\times 224$ 的图片，切分成一个个 $16 \\times 16$ 的patch，最终切分出196个patch；每个patch的大小是：$16 \\times 16 \\times 3=768$，刚好是basic版bert每个token的维度。 多头注意力机制，12个头，每个头的k、q、v对应的维度是64维    二、网络 1、ViT ViT(2021) 直接把Transformer应用到图像处理，尽量改动最少，所以只对图像做预处理，让其符合NLP的输入形式， 思路：\n 图片尺寸 224x224，将图片切分成一个个patch，patch的大小16x16，每个patch作为一个token，即：14x14=196个patch，每个patch长16x16x3=768 学习一个线性矩阵$E$，尺寸为768x768，对每个patch做线性变换。多头注意力的话，basic版本12个头，所以12个196x64拼接起来，还是196x768。 位置编码：可学习的位置向量，尺寸为196x768 cls的输出作为提取的图片特征，用于后续的分类操作  实验结论：\n 额外使用cls做分类，为啥不用GAP呢？作者对比了这两种方式，发现如果参数调整好的话效果是一样的。所以为了在使用Transformer时改动最少，所以继续使用cls作为分类。 位置编码信息，每个位置编码信息是一个768维度的向量。图像是二维的，所以是否需要在位置编码里体现二维特征呢？作者实验发现，即使是一维的768维度的向量，其中也会学习到二维特征，所以没有必要故意设计二维特征。 归纳偏置(inductive bias)，在cnn中位置信息是贯穿在所有卷积操作中的，卷积是线性操作，具有偏移不变性。在ViT中除了添加了位置编码信息，是没有其他的空间信息的。所以作者认为是这个原因导致ViT在小规模的数据集上效果不好，在中/大规模的数据集上效果较好。 Transformer有处理长文本的能力，所以ViT能够捕获图片的全局信息，而并不是像cnn只用到感受野区域。 作者还提出是否可以类比BERT，mask掉一些patch，然后自监督训练，修复出mask掉的区域。这就是后来何大神的MAE。 ViT可以说是打通了CV和NLP的鸿沟，对多模态具有重要的意义。  可视化显示模型能学习的信息： 可学习的线性矩阵$\\bf E$，具体学习的信息：跟CNN很像，可以学习到颜色、纹理、等底层信息。  位置信息：发现可以学习到位置信息，同时也可以学习到行、列的信息；这就是为啥没有必要设计2维的位置信息。   图中，每列都有16个点，就是16个头的输出；纵轴：平均注意力的距离；横轴：网络的层数。图展示了ViT能不能注意到全局信息: a. 在前几层有相近的、距离远的，这说明，在刚开始模型就能注意到较远的像素，而不像CNN前几层因为感受野较小只能注意到相近的像素点；b. 在后几层距离都比较远，说明网络学习到的特征越来越具有语义信息。  作者用网络的最后一层的输出，映射回输入图片上，发现模型是可以获取图像的高阶语义信息，是可以关注到用于分类的图像区域。   2、BEiT 《BEiT: BERT Pre-Training of Image Transformers》(2021)\n3、PVT 《Pyramid Vision Transformer》(2021)\n4、Swin Swin Transformer(2021) 微软亚研究院发表在ICCV上的一篇文章，获取2021 best paper。 github \n把Transformer从NLP应用到vision领域，有两个挑战：\n 图中物体尺寸不一，比如一个行人、一辆骑车，在图中尺寸不同；就算是两个行人，也有大有小。NLP的同一个词，在图片中尺寸可能差别很大。 图像分辨率太大，如果以像素点为基本单位的话，则序列就非常大。为了减少序列长度，一些方法：使用feature  作者为了解决这两个问题，提出了Swin：\n 通过移动窗口学习出 序列特征作为Transformer的输入； 移动窗口(shifted window)能够使得相邻的两个窗口有了交互，变相的达到全局建模的能力。 层级结构(hierarchical architecture)，非常灵活，不仅可以提供不同尺度的特征信息；而且计算复杂度跟图片大小成线性关系    ViT：每个token代表的尺寸都是一样的，每一层看到的token的尺寸都是一样的；虽说通过多注意力机制能够把握全局信息，但是在多尺寸特征上的把握是不够的。而在vision中多尺寸的的特征是很重要的。 ViT：多注意力机制是在全图上计算，所以它的计算复杂度跟图片尺寸成平方的关系； Swin：在小窗口内计算多注意力，因为在视觉里有这样的先验：相邻的区域大概率是相似物体。对于视觉直接做全局注意力是浪费的 Swin：在卷积操作中，由于pooling操作提供了不同尺寸的特征；类比pooling，作者提出了patch merging：把相邻的小patch合并成一个大patch   怎么计算多注意力？滑动窗口的设计？\n图中灰框：是 $4\\times4$ 的小块；rgb三通道拉直后就是 $1\\times48$ 图中红框：是一个包含 $7\\times7$ 个小块的窗口，即：$7\\times7\\times48$。多注意力机制就是在这些窗口中计算的。\n滑动窗口：\n 在窗口里做多头注意力计算，只能关注到这个窗口的信息；只这样操作，就违背了Transformer的初衷(把握上下文)，所以作者采用滑动窗口，下一层的窗口与上一层的多个窗口相交，这样多个窗口之间就有了联系。作者提出的patch merging 合并到Transformer最后几层时，就会看到大部分图片的信息了。 为了统一的标准化计算，采用循环移位；  向右下移动两个位置；上面多出的部分循环移动到下面、左边多出的部分循环移动到右边、左上角多出的部分循环移动到右下角 在窗口内，循环移动的这些块之间 在图片中是不相邻的，所以不应该计算它们之间的联系(比如：上面是天空下面是地面)。作者就采用masked MSA 在计算完注意力后，把移动的块复原到原来的位置；保证信息的一致性       网络架构\n  输入图片：$224\\times224\\times3$，通过patch partition操作，把 $4\\times4$ 的小patch拉直后，变成：$56\\times56\\times48$\n  通过4个Swin Transformer块，生成不同尺度的特征。\n 第一个Swin Tranformer块 没有使用patch merging，尺寸信息为 $56\\times56\\times96$，其中 $C=96$；剩余的模块，都经过patch merging：让H、W减半，在channel上扩大2倍。即：$56\\times56\\times96 \\rArr 28\\times28\\times192 \\rArr 14\\times14\\times384 \\rArr 7\\times7\\times768$ (768怎么这么熟悉^_^) 每个Swin Transformer块，都含有两个Transformer块，第一个采用W-MSA（窗口-多头自注意力），第二个相匹配的采用SW-MSA（滑动窗口-多头自注意力）。    不同变体：\n Swin-T：$C=96, layer numbers = {2, 2, 6, 2}$ ，计算复杂度与ResNet50差不多 Swin-S：$C=96, layer numbers = {2, 2, 18, 2}$ ，计算复杂度与ResNet101差不多 Swin-B：$C=128, layer numbers = {2, 2, 18, 2}$ Swin-L：$C=192, layer numbers = {2, 2, 18, 2}$    patch merging\n其中，patch merging 的操作如下图所示：\n 把相邻 $2*2$ 的patch块，拉伸到channel维度；使得H、W方向降维，C方向升维 拉伸后变成 $4C$，如果希望是 $2C$的话，后续接一个全连接层   masked MSA\n 只要不是自己区域的向量相乘，就需要被mask掉 掩码矩阵：需要mask的区域为：-100，不需要mask掉的区域为：0。 softmax(计算好的自注意力矩阵（就是那个权重） + 掩码矩阵)，-100经过softmax后近似为0了。     W-MSA\n 在每个窗口中做多头自注意力计算，各个窗口之间是没有联系的 计算复杂度大概：$4hwC^2+2hwM^2C$，相比于全图片做自注意力计算($4hwC^2+2(hw)^2C$)，计算效率提升不少   SW-MSA\n 如果只在窗口内各自计算注意力，那么就没有整个图片上下文；通过移动窗口来使得相邻的窗口之间有联系 窗口的大小固定为 $7\\times7$，由于patch merging类似于pooling操作，所以随着层数的加深，窗口看到的感受野越来越大    5、MAE MAE(2021) 主要思想：随机mask掉一些patch，然后重构这些patch里的所有像素。\n 设计非对称的encoder-decoder架构\nencoder：作用在非mask的patch；将这些观察到的信息，映射到一个潜表示（在语义空间上的表示）\ndecoder：是一个轻量级的解码器，从这个潜表示中重构原始信号； 模型架构就是ViT，不一样的是输入是非mask的patchs  高比例的mask是比较有效的，因为低比例的mask可以通过简单的插值就能重组，使得模型学不到什么东西；高比例的mask迫使模型学习更有效的表征； 由于参与计算的是非mask的patch，高比例的mask使得计算速度加快好几倍。   图片patch与文本token的区别：图像只是被记录下来的光，没有语义分解成视觉上的词。后续的工作可以是：mask掉 不能构建语义段的patchs，就是这些patchs没有主体，只是包含主体的一小部分。  由于patch不是一个word，不是独立的语义，可能跟其他patch构成一个独立的语义word，这就说明图片相对于文本冗余信息太多，即使mask掉好多信息也可以重构出图片 模型学习到图片的全局信息，可以通过一些局部信息重构图片     6、 微软研究院提出的Focal Transformer在分类/检测/分割任务上表现SOTA！在ADE20K 语义分割上高达55.4 mIoU\n中科大、微软亚洲研究院提出的CSWin在ImageNet上高达87.5%准确率，在ADE20K上高达55.2mIoU github 北大提出的CBNetV2 github 三、CV各领域 1、目标检测 1). DETR(Detection Transformer) 《End-to-End Object Detection with Transformers》(2020)，是Transformer在目标检测领域的开山之作。\n2、图像分割 ","date":"May 9, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/vision_transformer/vision_transformer/","summary":"一、简介 1、Transformer用在CV领域 在NLP中，Transformer的输入是一个时间步长为T的序列，比如：basic版bert，T=512，每个token embeding为768维特征。如何把二维图片转化为一维呢？\n $\\bf \\color{red} \\times$ 如果把每个像素点看做是一个样本，铺平后是一维序列。但是，图片大小 224*224=50176，远远大于Transformer的最大序列长度。 $\\bf \\color{red} \\times$ 卷积和Transformer一起用：《Non-local Neural Networks》(2018)、《End-to-End Object Detection with Transformers》(2020) 为了减小序列的长度，不直接使用输入图片，而是使用feature map 转换为序列。比如：ResNet50在最后的阶段的输出尺寸为 14x14，拉平后序列长度只有196。 $\\bf \\color{red} \\times$ 抛弃卷积使用定制化的自注意力机制：《Stand-Alone Self-Attention in Vision Models》(2019) 采用的是 孤立自注意力。用一个局部的小窗口做自注意力； 《Stand-alone axial-attention for panoptic segmentation》(2020) 采用的是轴注意力。在高度的方向上做自注意力、在宽度方向做自注意力。由于这些自注意力机制比较定制化，还没有在硬件上大规模加速计算，所以网络做不大。 $\\color{green} \\checkmark$ 对图片做些预处理，直接使用Transformer：将图片切分成一个个patch，然后每个patch作为一个token输入到Transformer中。  $224 \\times 224$ 的图片，切分成一个个 $16 \\times 16$ 的patch，最终切分出196个patch；每个patch的大小是：$16 \\times 16 \\times 3=768$，刚好是basic版bert每个token的维度。 多头注意力机制，12个头，每个头的k、q、v对应的维度是64维    二、网络 1、ViT ViT(2021) 直接把Transformer应用到图像处理，尽量改动最少，所以只对图像做预处理，让其符合NLP的输入形式， 思路：\n 图片尺寸 224x224，将图片切分成一个个patch，patch的大小16x16，每个patch作为一个token，即：14x14=196个patch，每个patch长16x16x3=768 学习一个线性矩阵$E$，尺寸为768x768，对每个patch做线性变换。多头注意力的话，basic版本12个头，所以12个196x64拼接起来，还是196x768。 位置编码：可学习的位置向量，尺寸为196x768 cls的输出作为提取的图片特征，用于后续的分类操作  实验结论：","tags":["backbone","vision transformer"],"title":"vision transformer"},{"categories":["Basic"],"contents":"一、简介 It is coming soon.\n二、网络 1、 2、 3、 4、 ","date":"May 9, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/video/vidio_summary/","summary":"一、简介 It is coming soon.\n二、网络 1、 2、 3、 4、 ","tags":["video","summary"],"title":"简介"},{"categories":["Basic"],"contents":"一、简介 多模态学习，英文全程MultiModal Machine Learning(MMML)，从1970年 起步，已经经历了多个发展阶段，在2010年后，全面进入深度学习的阶段。多模态机器学习，以机器学习实现处理和理解多源模态信息的能力。图像、视频、音频、语义之间的多模态学习比较热门。比如互联网大型视频平台，都会将多模态技术用于视频理解业务，可以加视频封面、视频抽帧、文本信息融合。当计算机能够看懂视频，就可以做很多事儿了，比如：视频分类、审核、推荐、搜索、特效。\n多模态学习有5个研究方向：\n 多模态表示学习（Multimodal Representation） 模态转化（Translation） 对齐（Alignment） 多模态融合（Multimodal Fusion） 协同学习（Co-learning）  实际应用，比如：\n 视频网站上进度条，会显示那个时间段是高光时刻 自动驾驶领域，雷达、视觉与多传感器信息融合 视频的分类、审核、推荐、搜索、特效等等  1、VLP 微软发表的一篇文章《An Empirical Study of Training End-to-End Vision-and-Language Transformers》进行了大量的实验，对不同VLP模型、各个模块不同配置的效果。\nVLP通常都会遵循同一个框架，包含5大模块：\n Vision Encoder：主要有3中类型  使用object detection模型，比如：Faster R-CNN，识别图像中的目标区域，并生成每个目标区域的特征表示，输入到后续模型中 利用CNN模型提取grid feature作为图像输入 ViT采用的将图像分解成patch，每个patch生成embeding输入到模型。 随着Vision Transformer的发展，ViT的方式逐渐成为主流方式。   Text Encoder：包括BERT、RoBERTa、ELECTRA、ALBERT、DeBERTa等经典预训练语言模型结构。 Multimodel Fusion：主要指如何融合图像、文本，主要有2中：  co-attention：图像、文本分别使用Transformer编码，在每个Transformer模块中加入图像、文本的cross attention merged attention model，图像、文本在开始就拼接在一起，输入到Transformer   模型结构：主要有2中：  Encoder-only：这种比较常见 Encoder-Decoder   预训练任务：主要有3中：  Masked Language Modeling（MLM）类似BERT，随机mask掉部分token，用剩余的预测出被mask掉的token Masked Image Modeling，对输入的部分图像patch进行mask，然后预测被mask的patchs Image-Text Matching（ITM），预测image和text的pair对是否匹配，对比学习的预训练方法可以属于这类。    二、网络 Open AI 在2021年1月份发布的DALL-E和CLIP，属于结合图像和文本的多模态模型，其中DALL-E是基于文本来生成模型的模型；CLIP是用文本作为监督信号来训练可迁移的视觉模型，这两个工作带动了一波新的研究高潮。\n1、CLIP 参考\nCLIP\n2、DALL-E DALL-E：通过文本生成图片\n3、 ","date":"May 9, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/vlp/vlp_summary/","summary":"一、简介 多模态学习，英文全程MultiModal Machine Learning(MMML)，从1970年 起步，已经经历了多个发展阶段，在2010年后，全面进入深度学习的阶段。多模态机器学习，以机器学习实现处理和理解多源模态信息的能力。图像、视频、音频、语义之间的多模态学习比较热门。比如互联网大型视频平台，都会将多模态技术用于视频理解业务，可以加视频封面、视频抽帧、文本信息融合。当计算机能够看懂视频，就可以做很多事儿了，比如：视频分类、审核、推荐、搜索、特效。\n多模态学习有5个研究方向：\n 多模态表示学习（Multimodal Representation） 模态转化（Translation） 对齐（Alignment） 多模态融合（Multimodal Fusion） 协同学习（Co-learning）  实际应用，比如：\n 视频网站上进度条，会显示那个时间段是高光时刻 自动驾驶领域，雷达、视觉与多传感器信息融合 视频的分类、审核、推荐、搜索、特效等等  1、VLP 微软发表的一篇文章《An Empirical Study of Training End-to-End Vision-and-Language Transformers》进行了大量的实验，对不同VLP模型、各个模块不同配置的效果。\nVLP通常都会遵循同一个框架，包含5大模块：\n Vision Encoder：主要有3中类型  使用object detection模型，比如：Faster R-CNN，识别图像中的目标区域，并生成每个目标区域的特征表示，输入到后续模型中 利用CNN模型提取grid feature作为图像输入 ViT采用的将图像分解成patch，每个patch生成embeding输入到模型。 随着Vision Transformer的发展，ViT的方式逐渐成为主流方式。   Text Encoder：包括BERT、RoBERTa、ELECTRA、ALBERT、DeBERTa等经典预训练语言模型结构。 Multimodel Fusion：主要指如何融合图像、文本，主要有2中：  co-attention：图像、文本分别使用Transformer编码，在每个Transformer模块中加入图像、文本的cross attention merged attention model，图像、文本在开始就拼接在一起，输入到Transformer   模型结构：主要有2中：  Encoder-only：这种比较常见 Encoder-Decoder   预训练任务：主要有3中：  Masked Language Modeling（MLM）类似BERT，随机mask掉部分token，用剩余的预测出被mask掉的token Masked Image Modeling，对输入的部分图像patch进行mask，然后预测被mask的patchs Image-Text Matching（ITM），预测image和text的pair对是否匹配，对比学习的预训练方法可以属于这类。    二、网络 Open AI 在2021年1月份发布的DALL-E和CLIP，属于结合图像和文本的多模态模型，其中DALL-E是基于文本来生成模型的模型；CLIP是用文本作为监督信号来训练可迁移的视觉模型，这两个工作带动了一波新的研究高潮。","tags":["vlp","summary"],"title":"简介"},{"categories":["Basic"],"contents":"一、 ","date":"April 8, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/pytorch/tensor/","summary":"一、 ","tags":["torch","Tensor"],"title":"Tensor"},{"categories":["Basic"],"contents":"一、 ","date":"April 8, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/pytorch/basic/","summary":"一、 ","tags":["torch","基础操作"],"title":"基础操作"},{"categories":["Basic"],"contents":"一、 ","date":"April 8, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/pytorch/mathematical/","summary":"一、 ","tags":["torch","数学计算"],"title":"数学计算"},{"categories":["Basic"],"contents":"一、 ","date":"April 8, 2022","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/pytorch/train_model/","summary":"一、 ","tags":["torch","训练","模型"],"title":"模型训练"},{"categories":["Basic"],"contents":"import_module()函数 背景：一个函数运行，需要根据不同项目的配置，动态导入对应的配置文件。 例如：如下路径，向a模块中导入c.py中的对象 a\n├── a.py\n├── __init__.py\nb\n├── b.py\n├── c │　├── c.py　# 该文件中，有变量args=[]，class C\n│　├── __init__.py\n方案：\nimport importlib # 导入 params = importlib.import_module(\u0026#34;b.c.c\u0026#34;) # 对象中取出需要的对象 params.args # 取出变量 params.C # 取出类C ","date":"December 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/python/sdk_lib/importlib/","summary":"import_module()函数 背景：一个函数运行，需要根据不同项目的配置，动态导入对应的配置文件。 例如：如下路径，向a模块中导入c.py中的对象 a\n├── a.py\n├── __init__.py\nb\n├── b.py\n├── c │　├── c.py　# 该文件中，有变量args=[]，class C\n│　├── __init__.py\n方案：\nimport importlib # 导入 params = importlib.import_module(\u0026#34;b.c.c\u0026#34;) # 对象中取出需要的对象 params.args # 取出变量 params.C # 取出类C ","tags":["vlp","summary"],"title":"importlib包"},{"categories":["Basic"],"contents":"It\u0026rsquo;s coming soon. ","date":"September 9, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/image-matting/image-matting-animal/","summary":"It\u0026rsquo;s coming soon. ","tags":["matting","CV"],"title":"animal matting"},{"categories":["Basic"],"contents":"卷积神经网络的发展历程：\n一、Backbone 1. LeNet 论文\nLeNet：名字来源于第一作者Yann LeCun。是一个奠基性的网络，第一次将卷积神经网络推上舞台。\n 卷积层+最大池化：卷积层用来识别图像里的空间模式；最大池化用来降低卷积层对位置的敏感度。卷积层块由两个这样的基本单位重复堆叠构成。 LeNet可以在早起的小数据集上取得较好的效果，但是在更大的真实数据集上表现并不如人意。一方面：神经网络计算复杂，在GPU没有大量普及的20世纪90年代，训练一个多通道、多层、含有大量参数的卷积神经网络是很难完成的；另一方面：当年并没有深入研究参数初始化和非凸优化算法，导致复杂的神经网络的训练通常比较困难。 特征本身是由学习得来的，为了表征足够复杂的输入，特征本身应该分级表示。想要学习到复杂的多级特征，需要大量的带有标签的数据，这样才能表现得比其他经典方法要好。早期研究只基于小的公开数据集，自2009年ImageNet数据集创建以来，传统方法不再有优势。  输入：32*32  C1-卷积层：卷积层尺寸：6 * 28 * 28；卷积核尺寸：6 * 1 * 5 * 5；可训练参数：(5 * 5 + 1) * 6 S2-池化层：池化尺寸：2 * 2；步幅：2；方式：4个输入相加，然后乘以个可训练参数，加上个可训练参数，最后通过sigmoid；输出尺寸：6 * 14 * 14；可训练 参数：2 * 6 C3-卷积层：输出尺寸：16 * 10 * 10；卷积核尺寸: 16 * 6 * 5 * 5;\n组合方式：前6个map - 以S2中3个相邻的feature map\n再6个map - 以S2中4个相邻的feature map\n再3个map - 以S2中不相邻的4个feature map\n再1个map - 以S2中所有feature map   S4-池化层：输出尺寸：16 * 5 * 5；池化尺寸：2 * 2；步幅：2\n采样方式：4个输入相加，然后乘个可训参数，加上个可训参数，最后通过sigmoid C5-卷积层：输出尺寸：120*1；卷积核：120 * 16 * 5 * 5；可训参数：120 * (16 * 5 * 5 + 1) F6-全连接层：输出尺寸：84；对应一个 7 * 12的比特图；可训参数：84 * (120+1) Output层-全连接层：输出尺寸：10；分别代表数字0~9  2. AlexNet 论文\n2012年AlexNet横空出世，这个名字来源于一作的姓名(Alex Krizhevsky)，是Hinton实验室提出的，是卷积神经网络在大规模数据集上的开篇巨作。它赢得了2012年ImageNet图像识别挑战赛，首次证明了学习到的特征可以超越手工设计的特征，使视觉从业者从人工提取特征的特征工程中解脱出来，转向 从数据中自动提取需要的特征，做数据驱动。\n卷积层：卷积核11 * 11；步幅4；输出：96 * 54 *54\npool层：pool尺寸3 * 3；步幅2；输出：96 * 26 * 26\n卷积层：卷积核5 * 5；填充2；输出：256 * 26 * 26\npool层：pool尺寸3 * 3；步幅2；输出：265 * 12 * 12\n卷积层：卷积核3 * 3；填充1；输出：384 * 12 * 12\n卷积层：卷积核3 * 3；填充1；输出：384 * 12 * 12\n卷积层：卷积核3 * 3；填充1；输出：256 * 12 * 12\npool层：pool尺寸3 * 3；步幅2；输出：256 * 5 * 5\n全连接层：4096；DropOut(0.5)\n全连接层：4096；DropOut(0.5)\n输出层：1000\n创新点：\n 加深了网络深度 激活函数由sigmoid转换为Relu，作用：加快收敛速度；引入非线性，增强非线性的映射能力 使用DropOut，控制模型复杂度 数据增广：翻转、裁剪、颜色变化，进一步扩大数据集来缓解过拟合。 使用GPU计算 局部相应归一化(LRN)：N 表示通道数，在通道维度做局部归一化。比如在第i通道(x,y)像素点做归一化：前后n/2个通道上做局部归一化。  3. VGG 论文\nAlexNet：指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则，没有指导后来者如何设计新的网络。\nVGG(牛津Visual Geometry Group 实验室)：提供了可以通过重复使用简单的基础块来构建深度模型的思路。证明了网络深度对性能的影响。在 LSVRC2014比赛分类项目的第二名。\n创新点：\n 使用3*3的卷积核替换大尺寸卷积核。增加了网络深度，证明了网络深度对精度的影响 使用基础块 搭建网络的 思路  4. NiN 论文\nNiN(network in network)：提出了一个新思路。串联多个(卷积层+全连接层构成的小网络) 来构建一个深层网络。使用1*1的卷积层来替代全连接层，从而使得空间信息能够传递到后面层。 NiN基础块如下：\n模块堆叠：\n   NiN基础块 池化层 NiN基础块 池化层 NiN基础块 池化层 NiN基础块 全局平均池化层 Flatten    创新点：\n 使用1*1的卷积层 来替换全连接层，对准确率提升有效果。 串联多个小网络，搭建一个深层网络  5. GoogLeNet 论文 ImageNet分类Top5错误率：6.67% GoogLeNet 在ImageNet LSVRC2014比赛分类项目的第一名，名字上向LeNet致敬。GoogLeNet吸收了NiN网络串联的思想，并在此基础上做了很大改进。GoogLeNet采用了模块化的结构(Inception结构，名字与电影《盗梦空间》Inception同名)，方便添加和修改。\n模块堆叠：\n   Conv2D MaxPool2D Conv2D Conv2D MaxPool2D Inception Inception MaxPool2D Inception Inception Inception Inception Inception MaxPool2D Inception Inception 全局平均池化层    创新点：\n Inception模块里有4条并行的线路：1 * 1、3 * 3、5 * 5 的卷积层是用来抽取不同空间尺寸下的特征信息，其中中间两条线路会对输入先做1*1的卷积，是为了减少输入通道数，减低复杂度；第四条线路则使用3 * 3最大池化层，后接1 * 1卷积层来改变通道数。4条线路使用了合适的填充来保障输入与输出的尺寸一致。 采用4条线路并行，是想提取不同空间尺寸的特征信息，那种信息更有用，在模型训练时让数据自己选择。 GoogLeNet跟VGG一样，在主体卷积部分使用5个模块(block)，每个模块之间使用步幅为2的3 * 3最大池化层来减小输出宽高。  6. ResNet 论文 ImageNet分类Top5错误率：3.57% 随着网络逐渐加深，模型的误差不降反曾。ResNet针对这个问题，在2015年的ImageNet LSVRC-2015比赛中夺魁。以前的网络，网络层拟合的是映射f(x)，而ResNet的网络层拟合的是残差：f(x)-x。残差映射更易于捕捉恒等映射的细微波动。\n7. ResNeXt ResNeXt是ResNet和Inception的结合体，是2016年的ImageNet LSVRC-2016比赛的亚军。\n8. SENet SENet(2017)是ImageNet 2017（ImageNet收官赛）的冠军模型，ImageNet分类Top5错误率：2.25% 主要思想：\n Squeeze部分。即为压缩部分，原始feature map的维度为 H x W x C，Squeeze做的事情是把H x W x C压缩为1 x 1 x C，相当于把H x W压缩成一维了，实际中一般是用global average pooling实现的。H x W压缩成一维后，相当于这一维参数获得了之前H x W全局的视野，感受区域更广。 Excitation部分。得到Squeeze的1 x 1 x C的表示后，加入一个FC全连接层（Fully Connected），对每个通道的重要性进行预测，得到不同channel的重要性大小后再作用（激励）到之前的feature map的对应channel上，再进行后续操作  提升很大，并且代价很小，通过对通道进行加权，强调有效信息，抑制无效信息，注意力机制，并且是一个通用方法。\n9. DenseNet 论文(2017)\n受ResNet影响，DenseNet将输入和输出拼接在一起；ResNet是：输入+输出。DenseNet的主要构建模块：稠密快(dense block)和过渡层(transition layer)\n稠密块：主要定义输入和输出是如何连接的\n过渡层：用来调控通道数，h/w 尺寸。由于输入和输出拼接在一起，通道数增加，需要过渡层来调控。\n主要结论：\n 一些较早层提取出的特征仍然可能被较深层直接使用 过渡层 输出大量冗余特征 最后的分类层，虽然使用了之前的多层信息，但更偏向于使用最后几个feature map，说明在网络的最后几层，某些high-level的特征可能被产生  10. SKNet SKNet(2019) 是对SENet的改进。 SENet 在channel维度上做attention，而SKNet在SENet的基础上又引入了kernel维度上的attention，除此之外，还利用诸如分组卷积和多路卷积的trike来平衡计算量。\n11. CSPNet CSPNet(2019) 作者想提出一个计算量小效果还好的网络结构。具体来说作者希望：\n 增强CNN的学习能力 减少计算量 降低内存占用  作者把 CSPNet 应用到分类和检测任务中，发现性能都有所提升，特别是在检测任务中提升更为明显。这也是为什么后续的 YOLOv4 和 YOLOv5 的 backbone 都是基于 CSPNet 修改的\n12. EfficientNet EfficientNet(2019)\n12. VoVNet VoVNet(2019) 基于DenseNet，实现实时目标检测。 VoVNet2(2020)\n13. RepVGG RepVGG(2021)\n14. ViT ViT(2021)\n二、各领域的Backbone 1、 提升速度的Backbone 1. SqueezeNet SqueezeNet(2016) 的主要思想：\n 多用 1x1 的卷积核，而少用 3x3 的卷积核 在用 3x3 卷积的时候尽量减少 channel 的数量，从而减少参数量 延后用 pooling，因为 pooling 会减小 feature map size，延后用 pooling， 这样可以使 size 到后面才减小，而前面的层可以保持一个较大的 size，从而起到提高精度的作用。  2. MobileNet MobileNet (2017) 是通过优化卷积操作来达到轻量化的目的的，具体来说，文中通过 Deepwise Conv（其实是Deepwise Conv + Pointwise Conv）代替原始的卷积操作实现，从而达到减少计算的目的（通常所使用的是 3×3 的卷积核，计算量会下降到原来的九分之一到八分之一）\n3. ShuffleNet ShuffleNet(2017) 的核心思想是对卷积进行分组，从而减少计算量，但是由于分组相当于将卷积操作局限在某些固定的输入上，为了解决这个问题采用 shuffle 操作将输入打乱，从而解决这个问题。\n2、 目标检测的Backbone 1. 2. Darknet YOLO作者自己写的一个深度学习框架叫Darknet\n3.DetNet 旷视2018年提出的DetNet，是一个目标检测的backbone\n3、 姿态识别的Backbone 《Stacked Hourglass Networks for Human Pose Estimation》(2016)\n","date":"September 9, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/backbone/backbone_net/","summary":"卷积神经网络的发展历程：\n一、Backbone 1. LeNet 论文\nLeNet：名字来源于第一作者Yann LeCun。是一个奠基性的网络，第一次将卷积神经网络推上舞台。\n 卷积层+最大池化：卷积层用来识别图像里的空间模式；最大池化用来降低卷积层对位置的敏感度。卷积层块由两个这样的基本单位重复堆叠构成。 LeNet可以在早起的小数据集上取得较好的效果，但是在更大的真实数据集上表现并不如人意。一方面：神经网络计算复杂，在GPU没有大量普及的20世纪90年代，训练一个多通道、多层、含有大量参数的卷积神经网络是很难完成的；另一方面：当年并没有深入研究参数初始化和非凸优化算法，导致复杂的神经网络的训练通常比较困难。 特征本身是由学习得来的，为了表征足够复杂的输入，特征本身应该分级表示。想要学习到复杂的多级特征，需要大量的带有标签的数据，这样才能表现得比其他经典方法要好。早期研究只基于小的公开数据集，自2009年ImageNet数据集创建以来，传统方法不再有优势。  输入：32*32  C1-卷积层：卷积层尺寸：6 * 28 * 28；卷积核尺寸：6 * 1 * 5 * 5；可训练参数：(5 * 5 + 1) * 6 S2-池化层：池化尺寸：2 * 2；步幅：2；方式：4个输入相加，然后乘以个可训练参数，加上个可训练参数，最后通过sigmoid；输出尺寸：6 * 14 * 14；可训练 参数：2 * 6 C3-卷积层：输出尺寸：16 * 10 * 10；卷积核尺寸: 16 * 6 * 5 * 5;\n组合方式：前6个map - 以S2中3个相邻的feature map\n再6个map - 以S2中4个相邻的feature map\n再3个map - 以S2中不相邻的4个feature map\n再1个map - 以S2中所有feature map   S4-池化层：输出尺寸：16 * 5 * 5；池化尺寸：2 * 2；步幅：2","tags":["backbone","卷积神经网络"],"title":"backbone net"},{"categories":["Basic"],"contents":"一、卷积 实际上，卷积操作需要对卷积核进行上下/左右翻转，然后用卷积核对输入进行滑动计算。由于网络学习目的是要\u0026quot;学习\u0026quot;出一个近最优解的权重，即：近最优解情况下卷积核的值，所以在卷积操作时，也就没必要在做翻转操作，反正卷积核的值是要被\u0026quot;调教\u0026quot;的，最终的卷积核的状态：可以看成是已经被上下/左右翻转过了。卷积操作也就变成互相关运算。\n卷积层解决的问题：\n 卷积层保留输入图片的形状，使图像的像素在高/宽两个方向上的相关性均可能被有效识别。 卷积层通过滑动窗口，将同一卷积核与不同位置的输入重复计算，参数共享，避免参数尺寸过大。  在卷积操作时，会有两个超参数：填充(padding)和步幅(stride)，根据输入尺寸和卷积核改变输出形状：\n假设：输入尺寸：nh * nw，卷积核尺寸：kh * kw\n 填充(padding)：在输入高和宽的两侧填充元素(通常是0)，一般来说：在高的两侧一共填充ph行；在宽的两侧一同填充pw列，一般填充的是偶数，即：nn.Conv2D(padding=(ph/2, pw/2)) 步幅(stride)：在滑动计算时，每次滑动的步长，假设：在高上步幅为sh，在宽上步幅为sw  则：输出尺寸： $$ \\tag{公式1} o_h = \\frac{n_h-k_h+p_h+s_h} {s_h }, o_w = \\frac{n_w-k_w+p_w+s_w} {s_w } $$\n1. 1*1卷积层 1*1卷积层：被看作是卷积操作的全连接层。这是为什么呢？\n1*1卷积的计算发生在通道维度上：输出的每个元素，来自输入中相同位置的元素在不同通道之间按权重叠加。假设我们将通道维度当作特征维度，将宽高维度上的元素看作数据样本，那么1*1卷积层的作用与全连接等价。 二、池化层 池化层(pooling)：缓解卷积层对位置的过渡敏感性。\n 浅层网络获取的是图像的细节信息，比如：纹理特征、边缘；高层网络获取的是图像的整体特征。池化层把感受野扩大，把图像的整体特征传递下去，网络越深感受野越大 池化层一般是最大池化或者平均池化，类比生物学的神经细胞：只有电解质信号超过一定阈值，才能激活下一个神经元，才能把信号传递下去。  三、批量归一化 batch normalization：在一个batch内，算出平均值a, 方差：b^2；然后对每个样本做归一化：c*(x-a)/b+d。其中c、d是需要训练的。\n$$ x_{i+1} = \\gamma \\frac{x_i - \\mu}{\\sigma} + \\beta $$ 由于数据的差异性，在卷积后可能会存在较大的波动。$\\frac{x_i - \\mu}{\\sigma}$ 的作用就是把数据统一拉回N(0,1)的标准正态分布；但是每个特征的分布不一定是标准正态分布，所以添加了可学习的参数：$\\gamma, \\beta$。 通过训练来调节实际的均值 $\\beta$ 和标准差 $\\gamma$ ，不过 $\\beta$ 和 $\\gamma$ 是在一定的范围内，不能波动太大。\n作用：\n 避免梯度的消失/爆炸，这是因为通过归一化(a的作用是偏移，b的作用是拉伸)，把原来可能波动比较大的数据，限制在一定的范围内，从而减弱了梯度 消失/爆炸 的问题。 批量归一化为啥会有效，有的说：通过 a,b的偏移和拉伸，相当于添加了一个随机噪声，因为a,b是在当前样本上算出来的，包含了随机性。由于c,d是可以学习的，所以这两个值是比较稳定的。 批量归一化，可以加速收敛，可以调大学习率。  ","date":"September 9, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/backbone/backbone_cnn/","summary":"一、卷积 实际上，卷积操作需要对卷积核进行上下/左右翻转，然后用卷积核对输入进行滑动计算。由于网络学习目的是要\u0026quot;学习\u0026quot;出一个近最优解的权重，即：近最优解情况下卷积核的值，所以在卷积操作时，也就没必要在做翻转操作，反正卷积核的值是要被\u0026quot;调教\u0026quot;的，最终的卷积核的状态：可以看成是已经被上下/左右翻转过了。卷积操作也就变成互相关运算。\n卷积层解决的问题：\n 卷积层保留输入图片的形状，使图像的像素在高/宽两个方向上的相关性均可能被有效识别。 卷积层通过滑动窗口，将同一卷积核与不同位置的输入重复计算，参数共享，避免参数尺寸过大。  在卷积操作时，会有两个超参数：填充(padding)和步幅(stride)，根据输入尺寸和卷积核改变输出形状：\n假设：输入尺寸：nh * nw，卷积核尺寸：kh * kw\n 填充(padding)：在输入高和宽的两侧填充元素(通常是0)，一般来说：在高的两侧一共填充ph行；在宽的两侧一同填充pw列，一般填充的是偶数，即：nn.Conv2D(padding=(ph/2, pw/2)) 步幅(stride)：在滑动计算时，每次滑动的步长，假设：在高上步幅为sh，在宽上步幅为sw  则：输出尺寸： $$ \\tag{公式1} o_h = \\frac{n_h-k_h+p_h+s_h} {s_h }, o_w = \\frac{n_w-k_w+p_w+s_w} {s_w } $$\n1. 1*1卷积层 1*1卷积层：被看作是卷积操作的全连接层。这是为什么呢？\n1*1卷积的计算发生在通道维度上：输出的每个元素，来自输入中相同位置的元素在不同通道之间按权重叠加。假设我们将通道维度当作特征维度，将宽高维度上的元素看作数据样本，那么1*1卷积层的作用与全连接等价。 二、池化层 池化层(pooling)：缓解卷积层对位置的过渡敏感性。\n 浅层网络获取的是图像的细节信息，比如：纹理特征、边缘；高层网络获取的是图像的整体特征。池化层把感受野扩大，把图像的整体特征传递下去，网络越深感受野越大 池化层一般是最大池化或者平均池化，类比生物学的神经细胞：只有电解质信号超过一定阈值，才能激活下一个神经元，才能把信号传递下去。  三、批量归一化 batch normalization：在一个batch内，算出平均值a, 方差：b^2；然后对每个样本做归一化：c*(x-a)/b+d。其中c、d是需要训练的。\n$$ x_{i+1} = \\gamma \\frac{x_i - \\mu}{\\sigma} + \\beta $$ 由于数据的差异性，在卷积后可能会存在较大的波动。$\\frac{x_i - \\mu}{\\sigma}$ 的作用就是把数据统一拉回N(0,1)的标准正态分布；但是每个特征的分布不一定是标准正态分布，所以添加了可学习的参数：$\\gamma, \\beta$。 通过训练来调节实际的均值 $\\beta$ 和标准差 $\\gamma$ ，不过 $\\beta$ 和 $\\gamma$ 是在一定的范围内，不能波动太大。","tags":["卷积","cnn"],"title":"CNN"},{"categories":["Basic"],"contents":"在深度学习中，通过最小化损失函数使得训练误差最小化，由于损失函数一般都会比较复杂，很难直接求解析解，而是需要基于数值方法的优化算法找到近似解，即：数值解。在局域数值方法的优化算法中，损失函数就是目标函数(Objective Function)，\n1. 梯度下降法 梯度下降(gradient descent)的工作原理，以一维为例： 假设连续可导的函数 $f:\\Reals \\to \\Reals$ 的输入和输出都是标量，给定绝对值足够小的数 $\\epsilon$ ，根据泰勒展开式，近似： $$ f(x+\\epsilon) \\approx f(x) + \\epsilon f'(x) $$ 其中 $f'(x)$ 表示函数在x处的梯度。找到一个常数 $\\eta \u0026gt; 0$，使得 $\\lvert \\eta f'(x) \\rvert$ 足够小，那么可以将 $\\epsilon$ 提换为 $-\\eta f'(x)$，得到： $$ f(x-\\eta f'(x)) \\approx f(x) - \\eta f'(x)^{2} $$ 所以 $$ f(x-\\eta f'(x)) \\lesssim f(x) $$ 这就意味着，可以通过 $x \\gets x-\\eta f'(x)$ 来迭代x，函数 $f(x)$ 的值可能会降低。在梯度下降中，先取一个初始值 $x_0$ 和学习率 $\\eta\u0026gt;0$，然后不断通过上式迭代x，直到停止条件。学习率 $\\eta$ 是一个超参数，需要人工设定，如果学习率过小：会导致x更新缓慢从而需要更多的迭代次数；如果学习率过大，泰勒展开式不再成立，可能会出现振荡，无法保证会迭代出近似最优解。\n在每次迭代中，由于训练集较大，不可能把所有样本都加载到内存中，通常是随机均匀采样多个样本组成一个小批量，然后使用这个小批量来计算梯度，完成一次迭代，即：小批量随机梯度下降(batch gradient descent)。\n设：目标函数 $f(x): \\Reals^{d} \\to \\Reals$ 小批量数据集 $\\text{\\ss}$ 梯度计算： $$ g_t \\gets \\nabla f_{\\text{\\ss}_{t}}=\\frac {1} {\\lvert \\text{\\ss} \\rvert} \\displaystyle\\sum_{i \\in \\text{\\ss}_{t}} \\nabla f_i(x_{t-1}) $$\n$$ x_t \\gets x_{t-1} - \\eta_t g_t $$\n其中，$ \\lvert \\text{\\ss} \\rvert $ 表示批量大小，$\\eta_t$ 表示学习率，这两个都是超参数。\n2. 动量法 问题：自变量的梯度代表了目标函数在当前位置下降最快的方向，沿着该方向更新自变量，可能还是会有一些问题。例如：类似峡谷的函数，在有些方向上的梯度比较缓慢，在有些方向上梯度比较陡峭，在相同的学习率下，容易导致在梯度缓慢的方向收敛太慢；如果调大学习率，容易导致在梯度陡峭的方向上振荡。如下图，梯度在水平方向上为正，而在竖直方向上时上时下：\n动量法：动量法在迭代自变量时，不仅仅是利用当前的梯度值，而是利用过去一段时间的梯度值的平均。新的梯度更迭方向，不再是指下降最陡峭的方向，而是指向过去梯度的加权平均值的方向，越靠近当前时刻权重越重。\n$$ \\upsilon_t \\gets \\gamma \\upsilon_{t-1} + \\eta_t g_t $$\n$$ x_t \\gets x_{t-1} - \\upsilon_t $$\n其中，$0 \\leqslant \\gamma \u0026lt; 1$，当$\\gamma = 0$时，动量法等价于小批量随机梯度下降法。\n证明：\n我们先解释指数加权移动平均(exponentially weighted moving average)，然后在类比到动量法。\n$$ y_t = \\gamma y_{t-1} + (1-\\gamma)x_t $$ 其中，$0 \\leqslant \\gamma \u0026lt; 1$，在当前时间步$t$的变量$y_t$可以展开（类似信号系统中的激励与响应）：\n$$ \\begin{array}{cc} y_t \u0026amp; = (1-\\gamma)x_t + \\gamma y_{t-1} \\\\ \u0026amp; = (1-\\gamma)x_t + (1-\\gamma)\\gamma x_{t-1} + \\gamma^2 y_{t-2} \\\\ \u0026amp; = (1-\\gamma)x_t + (1-\\gamma)\\gamma x_{t-1} + \\dots + (1-\\gamma)\\gamma^{t-1} x_{1} + \\gamma^t y_{0} \\end{array} $$\n令$n=\\frac {1} {1-\\gamma}$，那么$(1-\\frac {1} {n})^n = \\gamma^{\\frac {1} {1-\\gamma}}$。\n有极限：$\\lim\\limits_{n \\to \\infty} (1-\\frac {1} {n})^n =\\lim\\limits_{\\gamma \\to 1} \\gamma^{\\frac {1} {1-\\gamma}}= exp(-1) \\approx 0.3679$\n对于$y_t$，可以看做是对最近$\\frac {1} {1-\\gamma}$个时间步的加权平均；忽略含有$\\gamma^{\\frac {1} {1-\\gamma}}$和比$\\gamma^{\\frac {1} {1-\\gamma}}$更高阶系数的项，即：当$\\gamma=0.95$时，可以看成对最近20时间步的$x_i$值的加权平均\n$$ y_t \\approx 0.05\\displaystyle\\sum_{i=0}^{19} 0.95^i x_{t-i} $$\n类比向量法\n$$ \\upsilon_t \\gets \\gamma \\upsilon_{t-1} + (1-\\gamma)\\frac {\\eta_t} {1-\\gamma} g_t $$\n$$ x_t \\gets x_{t-1} - \\upsilon_t $$\n 所以：向量$\\upsilon_t$实际上是对序列$\\frac {\\eta_{t-i}} {1-\\gamma} g_{t-i}$做指数加权移动平均；也就是说：动量法在每个时间步的自变量更新量近似于将最近的$\\frac {1} {1-\\gamma}$个时间步的更新量做指数加权移动平均。动量法中，自变量在各个方向上的移动幅度，不仅取决于当前梯度，还取决于历史各个梯度在各个方向上是否一致。如果在某个方向上时正时负，说明在该方向上有振荡，通过动量的向量相加，对于该情况会降低每次的更新量，使得梯度在该方向上不发散。\n 3. AdaGrad算法 问题：在统一学习率的情况下，梯度值较大的维度可能会振荡，梯度值较小的维度收敛可能会过慢。\nAdaGrad算法：根据自变量在每个维度的梯度值大小来调整各个维度上的学习率，从而避免统一的学习率难以适应所有维度的问题。\n$$ s_t \\gets s_{t-1} + g_t \\odot g_t $$\n$$ x_t \\gets x_{t-1} - \\frac {\\eta} {\\sqrt{s_t + \\epsilon}} \\odot g_t $$\n其中，$\\odot$表示按元素相乘，$\\eta$表示学习率。目标函数自变量中每个元素的学习率通过按元素运算重新调整一下，每个元素都分别拥有自己的学习率。由于$s_t$一直在累加，所以每个元素的学习率在迭代过程中一直在降低，当学习率在迭代早期降得比较快且当前解依然不佳时，AdaGrad算法在迭代后期由于学习率过小，可能较难找到一个有用的解。\n4. RMSProp算法 问题：AdaGrad算法在迭代后期由于学习率过小，可能较难找到一个有用的解。为了解决这一问题，RMSProp算法对AdaGrad算法做了一些修改。\nRMSProp算法：只是在AdaGrad算法中添加了 指数加权移动平均。\n$$ s_t \\gets \\gamma s_{t-1} + (1-\\gamma)g_t \\odot g_t $$\n$$ x_t \\gets x_{t-1} - \\frac {\\eta} {\\sqrt{s_t + \\epsilon}} \\odot g_t $$\n其中，$\\eta$是学习率，RMSProp算法的状态变量是对平方项$g_t \\odot g_t$的指数加权移动平均，所以可以看作最近$\\frac {1} {1-\\gamma}$个时间步的加权平均。如此一来，自变量每个元素的学习率在迭代过程中就不再一直降低。\n5. AdaDelta算法 AdaDelta算法：是另一个针对AdaGrad算法优化的算法，不过没有学习率这个超参数。\n$$ s_t \\gets \\gamma s_{t-1} + (1-\\gamma)g_t \\odot g_t $$\n$$ g_t' \\gets \\sqrt{\\frac {\\Delta x_{t-1} + \\epsilon} {s_t + \\epsilon}} \\odot g_t $$\n$$ \\Delta x_t \\gets \\gamma \\Delta x_{t-1} + (1-\\gamma)g_t' \\odot g_t' $$\nRMSProp算法，还维护一个额外的状态变量$\\Delta x_t$，用来记录自变量变化量$g_t'$按元素平方的指数加权移动平均。\n$$ x_t \\gets x_{t-1} - g_t' $$\n6. Adam算法 Adam算法：结合了动量变量$\\upsilon_t$ 和 RMSProp算法的梯度按元素平方和的指数加权移动平均。\n$$ \\upsilon_t \\gets \\beta_1 \\upsilon_{t-1} + (1-\\beta_1) g_t $$\n其中，$0 \\leqslant \\beta_1 \u0026lt; 1$（建议0.9），$\\upsilon_0$初始化为0，则：$\\upsilon_t = (1-\\beta_1)\\displaystyle\\sum_{i=1}^t \\beta_1^{t-i} g_i$\n将过去各时间步小批量随机梯度的权值相加：$(1-\\beta_1)\\displaystyle\\sum_{i=1}^t \\beta_1^{t-i}=1-\\beta_1^t$，当t较小时，过去各时间步梯度权值之和会较小，为了消除这样的影响，对任意时间步t，可以将向量$\\upsilon_t$再除以$1-\\beta_1^t$ ：\n$$ \\hat{\\upsilon}_t \\gets \\frac {\\upsilon_t} {1-\\beta_1^t} $$\n$$ s_t \\gets \\beta_2 s_{t-1} + (1-\\beta_2)g_t \\odot g_t $$\n$$ \\hat{s}_t \\gets \\frac {s_t} {1-\\beta_2^t} $$\n其中，$0 \\leqslant \\beta_2 \u0026lt; 1$（建议0.999），$s_0$初始化为0\nAdam算法使用修正后的变量$\\hat{\\upsilon}_t, \\hat{s}_t$，将模型参数中每个元素的学习率通过按元素运算重新调整。\n$$ g_t' \\gets \\frac {\\eta \\hat{\\upsilon}_t} {\\sqrt{\\hat{s}_t + \\epsilon}} $$ 其中，$\\eta$是学习率，$\\epsilon$是为了维持数值稳定性而添加的常数，例如$10^{-8}$。分子：是动量，可以在方向上消除发散；分母：在幅度上修改每个元素的学习率。\n$$ x_t \\gets x_{t-1} - g_t' $$\n","date":"September 9, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/backbone/optimizer/","summary":"在深度学习中，通过最小化损失函数使得训练误差最小化，由于损失函数一般都会比较复杂，很难直接求解析解，而是需要基于数值方法的优化算法找到近似解，即：数值解。在局域数值方法的优化算法中，损失函数就是目标函数(Objective Function)，\n1. 梯度下降法 梯度下降(gradient descent)的工作原理，以一维为例： 假设连续可导的函数 $f:\\Reals \\to \\Reals$ 的输入和输出都是标量，给定绝对值足够小的数 $\\epsilon$ ，根据泰勒展开式，近似： $$ f(x+\\epsilon) \\approx f(x) + \\epsilon f'(x) $$ 其中 $f'(x)$ 表示函数在x处的梯度。找到一个常数 $\\eta \u0026gt; 0$，使得 $\\lvert \\eta f'(x) \\rvert$ 足够小，那么可以将 $\\epsilon$ 提换为 $-\\eta f'(x)$，得到： $$ f(x-\\eta f'(x)) \\approx f(x) - \\eta f'(x)^{2} $$ 所以 $$ f(x-\\eta f'(x)) \\lesssim f(x) $$ 这就意味着，可以通过 $x \\gets x-\\eta f'(x)$ 来迭代x，函数 $f(x)$ 的值可能会降低。在梯度下降中，先取一个初始值 $x_0$ 和学习率 $\\eta\u0026gt;0$，然后不断通过上式迭代x，直到停止条件。学习率 $\\eta$ 是一个超参数，需要人工设定，如果学习率过小：会导致x更新缓慢从而需要更多的迭代次数；如果学习率过大，泰勒展开式不再成立，可能会出现振荡，无法保证会迭代出近似最优解。\n在每次迭代中，由于训练集较大，不可能把所有样本都加载到内存中，通常是随机均匀采样多个样本组成一个小批量，然后使用这个小批量来计算梯度，完成一次迭代，即：小批量随机梯度下降(batch gradient descent)。\n设：目标函数 $f(x): \\Reals^{d} \\to \\Reals$ 小批量数据集 $\\text{\\ss}$ 梯度计算： $$ g_t \\gets \\nabla f_{\\text{\\ss}_{t}}=\\frac {1} {\\lvert \\text{\\ss} \\rvert} \\displaystyle\\sum_{i \\in \\text{\\ss}_{t}} \\nabla f_i(x_{t-1}) $$","tags":["optimizer"],"title":"optimizer"},{"categories":["Basic"],"contents":"一、简介 一图抵万言！本篇介绍神经网络的可视化工具和绘图软件。\n二、示意图 1、NN SVG 提供三种典型的神经网络绘图风格，个性化参数多；交互式绘图。 NN-SVG是由麻省理工学院弗兰克尔生物工程实验室开发的。可以绘制的图包括以节点形式展示的FCNN style，这个特别适合传统的全连接神经网络的绘制。\nGithub\nDemo\n2、PlotNeuralNet 底层基于latex的宏指令绘制，上层提供基于python的描述框架，绘制脚本简单。可以绘制复杂的网络结构。\nPlotNeuralNet 是由萨尔大学计算机科学专业的一个学生开发的，目前主要支持的是卷积神经网络，其中卷积层、池化层、bottleneck、skip-connection、up-conv、Softmax等常规的层在代码中都有定义，但缺少RNN相关的可视化层展示。\nGithub\n三、计算图 1、Netron Netron是一个神经网络可视化包，支持绝大多数神经网络操作。该功能包可以为不同节点显示不同的颜色，卷积层用蓝色显示，池化层和归一化层用绿色显示，数学操作用黑色显示。在使用方面，可以直接访问网页端，上传模型文件，就可以看到网络结构图，并可以进一步利用pip安装并引入到程序中通过浏览器查看模型的变化。\nGithub\nDemo\n","date":"September 9, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/deeplearning_summary/draw_map_for_dl/","summary":"一、简介 一图抵万言！本篇介绍神经网络的可视化工具和绘图软件。\n二、示意图 1、NN SVG 提供三种典型的神经网络绘图风格，个性化参数多；交互式绘图。 NN-SVG是由麻省理工学院弗兰克尔生物工程实验室开发的。可以绘制的图包括以节点形式展示的FCNN style，这个特别适合传统的全连接神经网络的绘制。\nGithub\nDemo\n2、PlotNeuralNet 底层基于latex的宏指令绘制，上层提供基于python的描述框架，绘制脚本简单。可以绘制复杂的网络结构。\nPlotNeuralNet 是由萨尔大学计算机科学专业的一个学生开发的，目前主要支持的是卷积神经网络，其中卷积层、池化层、bottleneck、skip-connection、up-conv、Softmax等常规的层在代码中都有定义，但缺少RNN相关的可视化层展示。\nGithub\n三、计算图 1、Netron Netron是一个神经网络可视化包，支持绝大多数神经网络操作。该功能包可以为不同节点显示不同的颜色，卷积层用蓝色显示，池化层和归一化层用绿色显示，数学操作用黑色显示。在使用方面，可以直接访问网页端，上传模型文件，就可以看到网络结构图，并可以进一步利用pip安装并引入到程序中通过浏览器查看模型的变化。\nGithub\nDemo","tags":null,"title":"神经网络画图篇"},{"categories":["Basic"],"contents":"一、Attention机制 如何有选择地引导注意力：\n非自主性提示： 基于环境中物体的突出性和易见性。比如 《辛德勒的名单》中的镜头：黑白镜头中的穿红衣服的小女孩。\n自主性提示： 选择受到 认知、意识的控制。\n在不受自我意识控制的情况下，与环境差别最大的事物，就越显眼、易见。\n在受到自我意识控制的情况下，意识偏向那个，就选择那个\n 查询(query)：自主性提示，类似于自我意识。\n键(key)：非自主提示，类似于事物的突出性、易见性。\n值(value)：感官输入，类似于具体的事物-值。\n   attention机制可以认为是一个这样的函数：\n$$ f(\\bold{q_j}) = \\sum_{i=1}^m \\alpha(\\bold{q}_j, \\bold{k}_i) \\bold{v}_i$$ 由$ \\bold{V}$ 的各个向量的加权平均，组成一个新的向量 $f(q_j)$。其中，权重的计算是通过 query向量和每个key向量 计算出来的，这个计算方式可以有多种，比如：加性注意力、缩放点积注意力\n$\\bold{Q} \\in \\R^{n \\times q}$: 查询矩阵，是由N个向量组成，每个向量有q个元素\nK-V: M个键值对集合。\n$\\bold{K} \\in \\R^{m \\times k}$: M个键向量组成的矩阵，每个键向量(k维)：就是每个字的标签信息\n$\\bold{V} \\in \\R^{m \\times v}$: M个值向量组成的矩阵，每个值向量(v维)：就是每个字的embeding\n1、加性注意力 $$\\alpha(\\bold{q}_j, \\bold{k}_i) = \\bold{w}_v^T tanh(\\bold{W}_q \\bold{q}_j + \\bold{W}_k \\bold{k}_i)$$ 其中，$\\bold{w}_v^T \\in \\R^h, \\bold{W}_q \\in \\R^{h \\times q}, \\bold{W}_k \\in \\R^{h \\times k}$ 是需要训练的。\n2、缩放点积注意力(SDPA) attention机制的SDPA(缩放点积注意力Scaled Dot-Product Attention)实现方式，计算效率更高，但是点积操作要求 $\\bold{q}$ 和 $\\bold{k}$ 具有相同的长度。\n假设：$\\bold{q}$ 和 $\\bold{k}$ 的所有元素都是独立的随机变量，并且满足标准正态分布 $N(0,1)$\n那么：两个向量的点积，服从正态分布 $N(0, d)$，其中 $d$ 就是$\\bold{q}$(或者$\\bold{k}$)的长度。\n所以：点积后，除以 $\\sqrt{d}$，即： $$\\alpha(\\bold{q}_j, \\bold{k}_i) = \\frac{\\bold{q}_j^T \\bold{k}_i}{\\sqrt{d}}$$ 基于n个查询、m个键值对，计算注意力，其中： $\\bold{Q} \\in \\R^{n \\times d}$、$\\bold{K} \\in \\R^{m \\times d}$、$\\bold{V} \\in \\R^{m \\times v}$ 的缩放点积注意力： $$softmax(\\frac{\\bold{Q} \\bold{K}^T}{\\sqrt{d}}) \\bold{V} \\in \\R^{n \\times v}$$\n具体操作：\n $\\bold{Q}$的每个向量 $\\bold{q}_i$ 做如下操作:  计算第i个向量 $q_i$ 与M个键向量的相似度(内积)，生成一个1*M的向量 对该向量做softmax操作(概率化) 用概率化后的值做M个值向量权重系数，做加权求和，生成一个加权后的embeding   $\\bold{Q}$的向量个数：表示需要多少个加权后的embeding，即：$\\tilde{V}$  3、多头注意力(MHA) 在实践中，当给定 query、key、value时，我们希望模型可以基于相同的注意力机制，学习到不同的行为，然后将不同的行为作为知识组合起来，以捕获序列内各种范围的依赖关系。因此，允许注意力机制组合使用 query、key、value的不同子空间表示，可能是有益的。所以，对给定的query、key、value，经过不同的线性变换获取其子空间表示，然后并行地送入注意力机制，最后把各个子空间的输出拼接起来，再通过一个可以学习的线性变换产生最终输出。\nMHA(多头注意力Multi-Head Attention) 实现方式：多路融合的SDPA，具体操作：\n 对Q、K、V矩阵做多次线性变换，例如：第i次变换的生成结果 $Q'_i, K'_i, V'_i$ 利用第i次线性变换后的 $Q'_i, K'_i, V'_i$，做SDPA操作，得到 $\\tilde{V_i}$ 对所有的 $\\tilde{V_i}$，在列方向上concat拼接起来  4、实际模式    QKV的关系      $Q \\neq K \\neq V$ QKV模式   $Q \\neq K=V$ QVV模式   $Q=K=V$ VVV模式，即：自注意力，自己即是查询向量，也是key向量；表示句子内部与自己相似的权重比较大    5、在seq2seq的应用 在seq2seq架构中，编码器生成各个时间步的上下文变量state，最后一时间步的state作为解码器的state。然而，有个问题：在解码器 解码某个词元时，并非所有输入词元都需要，或者说并非所有输入词元的贡献都一样，肯定是有的输入词元的贡献大一些。所以，在解码时能不能让贡献大的输入词元的state权重大一些呢？\nBahdanau等人提出了一个没有严格单向对齐限制的可微注意力模型。在预测词元时，如果不是跟所有输入词元都相关，模型使用仅跟当前预测相关的部分输入序列。\n$$c_{t'} = \\sum_{t=1}^T \\alpha(s_{t'-1}, h_t) h_t$$ 在解码时，需要 上一时间步的隐状态 $s_{t'-1}$ 和 上一时间步的真实值。添加attention的话，就要修改 $s_{t'-1}$，让其是 编码器各个隐状态的加权和，这就是attention的操作，即：\n 用解码器上一时间步的隐状态 $s_{t'-1}$ 作为查询 编码器各个隐状态 $h_t$ 其中 $t \\in [1, n]$ $\\alpha()$ 函数，采用加性注意力  ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/transformer/attention/","summary":"一、Attention机制 如何有选择地引导注意力：\n非自主性提示： 基于环境中物体的突出性和易见性。比如 《辛德勒的名单》中的镜头：黑白镜头中的穿红衣服的小女孩。\n自主性提示： 选择受到 认知、意识的控制。\n在不受自我意识控制的情况下，与环境差别最大的事物，就越显眼、易见。\n在受到自我意识控制的情况下，意识偏向那个，就选择那个\n 查询(query)：自主性提示，类似于自我意识。\n键(key)：非自主提示，类似于事物的突出性、易见性。\n值(value)：感官输入，类似于具体的事物-值。\n   attention机制可以认为是一个这样的函数：\n$$ f(\\bold{q_j}) = \\sum_{i=1}^m \\alpha(\\bold{q}_j, \\bold{k}_i) \\bold{v}_i$$ 由$ \\bold{V}$ 的各个向量的加权平均，组成一个新的向量 $f(q_j)$。其中，权重的计算是通过 query向量和每个key向量 计算出来的，这个计算方式可以有多种，比如：加性注意力、缩放点积注意力\n$\\bold{Q} \\in \\R^{n \\times q}$: 查询矩阵，是由N个向量组成，每个向量有q个元素\nK-V: M个键值对集合。\n$\\bold{K} \\in \\R^{m \\times k}$: M个键向量组成的矩阵，每个键向量(k维)：就是每个字的标签信息\n$\\bold{V} \\in \\R^{m \\times v}$: M个值向量组成的矩阵，每个值向量(v维)：就是每个字的embeding\n1、加性注意力 $$\\alpha(\\bold{q}_j, \\bold{k}_i) = \\bold{w}_v^T tanh(\\bold{W}_q \\bold{q}_j + \\bold{W}_k \\bold{k}_i)$$ 其中，$\\bold{w}_v^T \\in \\R^h, \\bold{W}_q \\in \\R^{h \\times q}, \\bold{W}_k \\in \\R^{h \\times k}$ 是需要训练的。","tags":["NLP","attention"],"title":"Attention"},{"categories":null,"contents":"一、背景 在使用预训练模型，处理下游任务时，有两类策略：基于特征(feature-based)、基于微调(fine-tuning)\n 基于特征：比如：ELMo，在使用时，对每个下游任务，创建一个跟这个任务相关的神经网络；预训练作为额外的特征跟输入一起输入到模型，预训练的额外特征可能会对要训练的模型有指导作用。 基于微调：比如：GPT，预训练模型在下游使用时，不需要改动太多，类似于视觉模型的fine-tuning，预训练完成特征提取，预训练模型后面添加个简单的网络用于实现具体任务。  1、上下文敏感 在自然语言中，有丰富的多义现象，一个词到底是什么意思，需要参考上下文才能判断。流行的上下文敏感表示：\n TagLM(language-model-augmented sequence tagger 语言模型增强的序列标记器) CoVe(Context Vectors 上下文向量) ELMo(Embeddings from Language Models 来自语言模型的嵌入)  ELMo 将来自预训练LSTM的所有中间层表示组合为输出表示 ELMo的表示，将作为添加特征添加到下游任务的有监督模型中    2、从特定任务到通用任务 ELMo显著改进了自然语言任务，但每个解决方案仍然依赖于一个特定的任务架构。怎么设计一个模型，让各个自然语言任务通用呢？\nGPT(Generative Pre Training 生成式预训练)：在Transformer的基础上，为上下文敏感设计了通用的模型。\n 预训练一个用于表示文本序列的语言模型 当将GPT应用于下游任务时，语言模型的后面接一个线性输出层，以预测任务的标签。GPT的下游任务的监督学习过程，只对预训练Transformer解码器中的所有参数做微调。 GPT只能从左到右  二、BERT BERT的全称是Bidirectional Encoder Representation from Transformers, 即双向Transformer的Encoder。Bert结合了ELMo和GPT的有点，其主要贡献：\n 双向的重要性 基于微调的掩码语言模型(Masked Language Modeling)：BERT随机遮掩词元，并使用来自双向上下文的词元以自监督的方式预测该遮掩词元。  1、构造输入 token embedding: 格式：\u0026lt;CLS\u0026gt;第一个文本序列\u0026lt;SEP\u0026gt;第二个文本序列\u0026lt;SEP\u0026gt;\nsegment embedding: 用来区分句子\nposition embedding: 在bert中 位置嵌入 是可学习的\ndef get_tokens_and_segments(tokens_a, tokens_b=None): \u0026#34;\u0026#34;\u0026#34;获取输入序列的词元及其片段索引\u0026#34;\u0026#34;\u0026#34; tokens = [\u0026#39;\u0026lt;cls\u0026gt;\u0026#39;] + tokens_a + [\u0026#39;\u0026lt;sep\u0026gt;\u0026#39;] # 0和1分别标记片段A和B segments = [0] * (len(tokens_a) + 2) if tokens_b is not None: tokens += tokens_b + [\u0026#39;\u0026lt;sep\u0026gt;\u0026#39;] segments += [1] * (len(tokens_b) + 1) return tokens, segments 2、MLM 词元维度\n在预训练任务中，随机选择15%的词元作为预测的遮掩词元。\n 80%的概率 替换为特殊词元 \u0026lt;mask\u0026gt; （填词） 10%的概率 替换为 随机词元 （纠错） 10%的概率 不做任何处理 （作弊）  class MaskLM(nn.Module): \u0026#34;\u0026#34;\u0026#34;BERT的掩蔽语言模型任务\u0026#34;\u0026#34;\u0026#34; def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs): super(MaskLM, self).__init__(**kwargs) self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens), nn.ReLU(), nn.LayerNorm(num_hiddens), nn.Linear(num_hiddens, vocab_size)) def forward(self, X, pred_positions): num_pred_positions = pred_positions.shape[1] pred_positions = pred_positions.reshape(-1) batch_size = X.shape[0] batch_idx = torch.arange(0, batch_size) # 假设batch_size=2，num_pred_positions=3 # 那么batch_idx是np.array（[0,0,0,1,1,1]） # batch_idx: batch * 序列大小 batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions) masked_X = X[batch_idx, pred_positions] # masked_x的形状：（batch, 每个序列中被mask词的个数, 词元特征维度） masked_X = masked_X.reshape((batch_size, num_pred_positions, -1)) mlm_Y_hat = self.mlp(masked_X) # 输出mlm_Y_hat形状：（batch, 每个序列中被mask词的个数, vocab_size） return mlm_Y_hat 3、预测下一句 句子维度\n尽管MLM能够使用上下文来表示词元，但它不能显式地建模文本对之间的逻辑关系，为了帮助理解两个文本序列之间的关系，BERT在预训练中考虑了一个二元分类：预测下一句。\n 在为预训练构建句子对儿时，50%的概率 句子对儿是连续句子；50%的概率 句子对儿不是连续句子。  class NextSentencePred(nn.Module): \u0026#34;\u0026#34;\u0026#34;BERT的下一句预测任务\u0026#34;\u0026#34;\u0026#34; def __init__(self, num_inputs, **kwargs): super(NextSentencePred, self).__init__(**kwargs) self.output = nn.Linear(num_inputs, 2) def forward(self, X): # X的形状：(batchsize,num_hiddens) return self.output(X) 4、bert模型 class BERTEncoder(nn.Module): \u0026#34;\u0026#34;\u0026#34;BERT编码器\u0026#34;\u0026#34;\u0026#34; def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, max_len=1000, key_size=768, query_size=768, value_size=768, **kwargs): super(BERTEncoder, self).__init__(**kwargs) self.token_embedding = nn.Embedding(vocab_size, num_hiddens) self.segment_embedding = nn.Embedding(2, num_hiddens) self.blks = nn.Sequential() for i in range(num_layers): self.blks.add_module(f\u0026#34;{i}\u0026#34;, d2l.EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, True)) # 在BERT中，位置嵌入是可学习的，因此我们创建一个足够长的位置嵌入参数 self.pos_embedding = nn.Parameter(torch.randn(1, max_len, num_hiddens)) def forward(self, tokens, segments, valid_lens): # 在以下代码段中，X的形状保持不变：（批量大小，最大序列长度，num_hiddens） X = self.token_embedding(tokens) + self.segment_embedding(segments) X = X + self.pos_embedding.data[:, :X.shape[1], :] for blk in self.blks: X = blk(X, valid_lens) return X class BERTModel(nn.Module): \u0026#34;\u0026#34;\u0026#34;BERT模型\u0026#34;\u0026#34;\u0026#34; def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, max_len=1000, key_size=768, query_size=768, value_size=768, hid_in_features=768, mlm_in_features=768, nsp_in_features=768): super(BERTModel, self).__init__() self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, max_len=max_len, key_size=key_size, query_size=query_size, value_size=value_size) self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens), nn.Tanh()) self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features) self.nsp = NextSentencePred(nsp_in_features) def forward(self, tokens, segments, valid_lens=None, pred_positions=None): encoded_X = self.encoder(tokens, segments, valid_lens) # encoded_X 的形状：（批量大小，最大序列长度，num_hiddens） if pred_positions is not None: mlm_Y_hat = self.mlm(encoded_X, pred_positions) else: mlm_Y_hat = None # 用于下一句预测的多层感知机分类器的隐藏层，0是“\u0026lt;cls\u0026gt;”标记的索引 nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :])) return encoded_X, mlm_Y_hat, nsp_Y_hat ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/bert/bert_summary/","summary":"一、背景 在使用预训练模型，处理下游任务时，有两类策略：基于特征(feature-based)、基于微调(fine-tuning)\n 基于特征：比如：ELMo，在使用时，对每个下游任务，创建一个跟这个任务相关的神经网络；预训练作为额外的特征跟输入一起输入到模型，预训练的额外特征可能会对要训练的模型有指导作用。 基于微调：比如：GPT，预训练模型在下游使用时，不需要改动太多，类似于视觉模型的fine-tuning，预训练完成特征提取，预训练模型后面添加个简单的网络用于实现具体任务。  1、上下文敏感 在自然语言中，有丰富的多义现象，一个词到底是什么意思，需要参考上下文才能判断。流行的上下文敏感表示：\n TagLM(language-model-augmented sequence tagger 语言模型增强的序列标记器) CoVe(Context Vectors 上下文向量) ELMo(Embeddings from Language Models 来自语言模型的嵌入)  ELMo 将来自预训练LSTM的所有中间层表示组合为输出表示 ELMo的表示，将作为添加特征添加到下游任务的有监督模型中    2、从特定任务到通用任务 ELMo显著改进了自然语言任务，但每个解决方案仍然依赖于一个特定的任务架构。怎么设计一个模型，让各个自然语言任务通用呢？\nGPT(Generative Pre Training 生成式预训练)：在Transformer的基础上，为上下文敏感设计了通用的模型。\n 预训练一个用于表示文本序列的语言模型 当将GPT应用于下游任务时，语言模型的后面接一个线性输出层，以预测任务的标签。GPT的下游任务的监督学习过程，只对预训练Transformer解码器中的所有参数做微调。 GPT只能从左到右  二、BERT BERT的全称是Bidirectional Encoder Representation from Transformers, 即双向Transformer的Encoder。Bert结合了ELMo和GPT的有点，其主要贡献：\n 双向的重要性 基于微调的掩码语言模型(Masked Language Modeling)：BERT随机遮掩词元，并使用来自双向上下文的词元以自监督的方式预测该遮掩词元。  1、构造输入 token embedding: 格式：\u0026lt;CLS\u0026gt;第一个文本序列\u0026lt;SEP\u0026gt;第二个文本序列\u0026lt;SEP\u0026gt;\nsegment embedding: 用来区分句子\nposition embedding: 在bert中 位置嵌入 是可学习的\ndef get_tokens_and_segments(tokens_a, tokens_b=None): \u0026#34;\u0026#34;\u0026#34;获取输入序列的词元及其片段索引\u0026#34;\u0026#34;\u0026#34; tokens = [\u0026#39;\u0026lt;cls\u0026gt;\u0026#39;] + tokens_a + [\u0026#39;\u0026lt;sep\u0026gt;\u0026#39;] # 0和1分别标记片段A和B segments = [0] * (len(tokens_a) + 2) if tokens_b is not None: tokens += tokens_b + [\u0026#39;\u0026lt;sep\u0026gt;\u0026#39;] segments += [1] * (len(tokens_b) + 1) return tokens, segments 2、MLM 词元维度","tags":null,"title":"Bert综述"},{"categories":null,"contents":"一、简介 二、GPT GPT(2018-06)\n三、GPT-2 GPT-2(2019-02)\n四、GPT-4 GPT-3(2020-05)\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/gpt/gpt_summary/","summary":"一、简介 二、GPT GPT(2018-06)\n三、GPT-2 GPT-2(2019-02)\n四、GPT-4 GPT-3(2020-05)","tags":null,"title":"GPT综述"},{"categories":["Basic"],"contents":"一、简介 RNNs中，需要的信息都放在隐藏层，当序列太长时，隐藏层累积了太多的信息，对前面太久的信息，就不容易获取到了。\n另外，有些信息不太重要，有些词比较重要，所以，设计了：\n更新门： $Z_t$ 有助于捕获序列中的长期依赖关系。当$Z_t = 0$时，并不是就没有$H_{t-1}$的信息了，而是$H_{t-1}$的信息通过正常的计算$H_t$的途径进来；而当$Z_t \u0026gt; 0$时，$H_{t-1}$的信息可以绕过正常的计算途径，直接添加到$H_t$中。\n重置门： $R_t$ 有助于捕获序列中的短期依赖关系。$\\tilde{H_t}$ 的计算跟RNNs计算相似，就是加了 $R_t$ 来限制 $H_{t-1}$，本来RNNs对太久的信息就不容易获取，所以 $R_t$ 的作用：是否忘掉历史没用的信息。\n$$R_t = sigmoid(X_tW_{xr}+H_{t-1}W_{hr}+b_r)$$ $$Z_t = sigmoid(X_tW_{xz}+H_{t-1}W_{hz}+b_z)$$ $$\\tilde{H_t} = tanh(X_tW_{xh} + (R_t \\odot H_{t-1})W_{hh} + b_h)$$ $$H_t = Z_t \\odot H_{t-1} + (1-Z_t)\\odot \\tilde{H_t}$$\n其中，$R_t$ ：表示在更新候选隐状态时，需要多少历史隐状态信息，$Z_t$ ：表示在算真正的隐状态时，需要多少新输入的$X_t$的信息，这两个的维度与隐状态是一致的。\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/rnn/gru/","summary":"一、简介 RNNs中，需要的信息都放在隐藏层，当序列太长时，隐藏层累积了太多的信息，对前面太久的信息，就不容易获取到了。\n另外，有些信息不太重要，有些词比较重要，所以，设计了：\n更新门： $Z_t$ 有助于捕获序列中的长期依赖关系。当$Z_t = 0$时，并不是就没有$H_{t-1}$的信息了，而是$H_{t-1}$的信息通过正常的计算$H_t$的途径进来；而当$Z_t \u0026gt; 0$时，$H_{t-1}$的信息可以绕过正常的计算途径，直接添加到$H_t$中。\n重置门： $R_t$ 有助于捕获序列中的短期依赖关系。$\\tilde{H_t}$ 的计算跟RNNs计算相似，就是加了 $R_t$ 来限制 $H_{t-1}$，本来RNNs对太久的信息就不容易获取，所以 $R_t$ 的作用：是否忘掉历史没用的信息。\n$$R_t = sigmoid(X_tW_{xr}+H_{t-1}W_{hr}+b_r)$$ $$Z_t = sigmoid(X_tW_{xz}+H_{t-1}W_{hz}+b_z)$$ $$\\tilde{H_t} = tanh(X_tW_{xh} + (R_t \\odot H_{t-1})W_{hh} + b_h)$$ $$H_t = Z_t \\odot H_{t-1} + (1-Z_t)\\odot \\tilde{H_t}$$\n其中，$R_t$ ：表示在更新候选隐状态时，需要多少历史隐状态信息，$Z_t$ ：表示在算真正的隐状态时，需要多少新输入的$X_t$的信息，这两个的维度与隐状态是一致的。","tags":["循环神经网络","GRU"],"title":"GRU网络"},{"categories":["Basic"],"contents":"一、简介 长短期记忆网络(LSTM)\n忘记门：$F_t = sigmoid(X_tW_{xf}+H_{t-1}W_{hf}+b_f)$ 输入门：$I_t = sigmoid(X_tW_{xi}+H_{t-1}W_{hi}+b_i)$ 输出门：$O_t = sigmoid(X_tW_{xo}+H_{t-1}W_{ho}+b_o)$ 候选记忆单元：$\\tilde{C_t} = tanh(X_tW_{xc} + (R_t \\odot H_{t-1})W_{hc} + b_c)$ 记忆单元：$C_t = F_t \\odot C_{t-1} + I_t\\odot \\tilde{C_t}$ 隐状态：$H_t = O_t \\odot tanh(C_t)$ 其中，$F_t, I_t, O_t, C_t, H_t, \\in \\R^{n \\times d}$\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/rnn/lstm/","summary":"一、简介 长短期记忆网络(LSTM)\n忘记门：$F_t = sigmoid(X_tW_{xf}+H_{t-1}W_{hf}+b_f)$ 输入门：$I_t = sigmoid(X_tW_{xi}+H_{t-1}W_{hi}+b_i)$ 输出门：$O_t = sigmoid(X_tW_{xo}+H_{t-1}W_{ho}+b_o)$ 候选记忆单元：$\\tilde{C_t} = tanh(X_tW_{xc} + (R_t \\odot H_{t-1})W_{hc} + b_c)$ 记忆单元：$C_t = F_t \\odot C_{t-1} + I_t\\odot \\tilde{C_t}$ 隐状态：$H_t = O_t \\odot tanh(C_t)$ 其中，$F_t, I_t, O_t, C_t, H_t, \\in \\R^{n \\times d}$","tags":["循环神经网络","LSTM"],"title":"LSTM网络"},{"categories":null,"contents":"一、查阅文档 怎么查阅相关文档？ 官网\n1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random))  __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。  2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。\nhelp(nd.ones_like) 注意：\n jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。  二、内存开销   原始操作 首先来个例子：Y = Y + X \u0026ndash;\u0026gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：\n内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026lt;\u0026ndash; Y\n  Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026ndash;\u0026gt; 把内存id_x+y中数值复制到内存id_y中\n  使用运算符全名函数中的out参数 可以避免临时内存开销，使用运算符全名函数：nd.elemwise_add(X, Y, out=Y)。内存使用情况： 内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_y \u0026lt;\u0026ndash; 直接存放 X+Y 的计算结果\n  三、自动求梯度 MXNet提供的autograd模块，可以自动求梯度(gradient) from mxnet import autograd, nd # 1. 创建变量 x，并赋初值 x = nd.arrange(4).reshape((4, 1)) # 2. 为了求变量x的梯度，先调用attach_grad函数来申请存储梯度所需要的内存  x.attach_grad() # 3. 为了减少计算和内存开销，默认条件下MXNet是不会记录：求梯度的计算， # 需要调用record函数来要求MXNet记录与求梯度有关的计算。 print(autograd.is_training()) # False with autograd.record(): print(autograd.is_training()) # True y = 2*nd.dot(x.T, x) # 4. 调用backward函数自动求梯度。y必须是一个标量， # 如果y不是标量：MXNet会先对y中元素求和，然后对该和值求有关x的梯度 y.backward() 注意：\n 在调用record函数后，MXNet会记录并计算梯度； 默认情况下，autograd会改变运行模式：从预测模式转为训练模式。可以通过调用is_training函数来查看。  ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/mxnet/ndarray/ndarray_summary/","summary":"一、查阅文档 怎么查阅相关文档？ 官网\n1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random))  __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。  2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。\nhelp(nd.ones_like) 注意：\n jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。  二、内存开销   原始操作 首先来个例子：Y = Y + X \u0026ndash;\u0026gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：\n内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026lt;\u0026ndash; Y\n  Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x \u0026lt;\u0026ndash; X 内存id_y \u0026lt;\u0026ndash; Y 内存id_x+y \u0026ndash;\u0026gt; 把内存id_x+y中数值复制到内存id_y中","tags":null,"title":"NdArray使用"},{"categories":["Basic"],"contents":"一、文本预处理 1、词元-token 英文：在训练文本模型时，模型输入最小单元：可以是词元维度，也可以是字符维度(这样的话，模型还得学习怎么用字符组合成单词)\n中文：一般是字符维度；如果是词元维度，在模型之前需要进行分词，如果要使用词元维度，需要先分词，用空格间隔开。\n特殊词元：未知词元 \u0026lt;unk\u0026gt;，填充词元\u0026lt;pad\u0026gt;，序列开始词元 \u0026lt;bos\u0026gt;，序列结束词元 \u0026lt;eos\u0026gt;\n2、词表-vocabulary 把token映射到：一个从0开始的数字索引，也就是：\ntoken \u0026ndash;\u0026gt; idx：token_to_idx {0:then, 1:token, \u0026hellip;.}\nidx \u0026ndash;\u0026gt; token：idx_to_token: [the, token, \u0026hellip;.] 例如：\ntokens: 例如：一篇文章\n例如：[[一句话按照空格split后], [], [], ....]\nvocab：词表，代码里可以写成一个类，其元素有：\nself.idx_to_token ：['\u0026lt;unk\u0026gt;', \u0026lsquo;the\u0026rsquo;, \u0026hellip;] token的列表，按照token的个数降序排列\nself.token_to_idx ：{'\u0026lt;unk\u0026gt;': 0, \u0026lsquo;the\u0026rsquo;: 1, \u0026hellip;.} token\u0026ndash;\u0026gt;idx 的映射\ncorpus：语料库，先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为语料\n例如：[('\u0026lt;unk\u0026gt;', 1000), ('the', 900), ....]\n  二、深度循环神经网络 循环神经网络(Recurrent Netural Networks)：是具有隐状态的神经网络。\n类似于MLP多层感知机，RNNs只是添加了时间轴信息。比如，MLP的表示如下：\n$$ H = \\phi(XW_{xh} + b_h) $$ $$O = HW_{hq} + b_q $$\nRNNs的表示如下，需要$H_{t}$ 这个隐状态 记录历史： $$ H_{t} = \\phi(X_{t}W_{xh} + H_{t-1}W_{hh} + b_h)$$ $$ O_{t} = H_{t}W_{hq} + b_{q}$$\n假设语料库的大小为N，那么RNNs的每次预测，其实就是一个N分类。所以，评估一个语言模型的好坏，用的是交叉熵： $$\\frac{1}{n}\\sum_{t=1}^n-log P(x_t|x_{t-1},\\dots,x_1)$$ 由于历史原因，喜欢用困惑度perplexity来表示： $$exp(\\frac{1}{n}\\sum_{t=1}^n-log P(x_t|x_{t-1},\\dots,x_1))$$\nRNNs的应用： 文本生成、文本分类、问答/机器翻译、Tag生成；其输入/输出形式如下：\n三、双向循环神经网络 场景：填空题，”下文“传达了重要信息，这些重要信息关乎到选择那些词来填空。\n我__ 我__饿了 我__写作中 设计方案：概率图模型，设计一个隐马尔科夫模型：\n 在任意时间步t，存在某个隐变量 $h_t$，通过概率 $P(x_t|h_t)$ 控制观测到的 $x_t$。 任何 $h_t \\rarr h_{t+1}$ 转移，都是由一些状态转移概率 $P(h_{t+1}|h_t)$ 给出。  前向递归(forward recursion)：$\\pi_{t+1} = f(\\pi_t, x_t)$ 其中 $f$ 表示一些可被学习的函数。看起来就像循环神经网络中，隐变量的更新过程。这是前向计算 后向递归(backward recursion)：$\\rho_{t-1} = g(\\rho_t, x_t)$ 其中 $g$ 表示一些可被学习的函数。这是后向计算，知道未来数据何时可用，对隐马尔科夫模型是有益的。  双向循环神经网络(bidirectional RNNs)：添加了反向传递信息的隐藏层。\n 在训练阶段，能够利用过去、未来的数据来估计现在空缺的词；在测试阶段，只有过去的数据，因此精度将会很差 双向循环神经网络的计算速度非常慢  所以双向循环神经网络并不常用。\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/rnn/rnn_summary/","summary":"一、文本预处理 1、词元-token 英文：在训练文本模型时，模型输入最小单元：可以是词元维度，也可以是字符维度(这样的话，模型还得学习怎么用字符组合成单词)\n中文：一般是字符维度；如果是词元维度，在模型之前需要进行分词，如果要使用词元维度，需要先分词，用空格间隔开。\n特殊词元：未知词元 \u0026lt;unk\u0026gt;，填充词元\u0026lt;pad\u0026gt;，序列开始词元 \u0026lt;bos\u0026gt;，序列结束词元 \u0026lt;eos\u0026gt;\n2、词表-vocabulary 把token映射到：一个从0开始的数字索引，也就是：\ntoken \u0026ndash;\u0026gt; idx：token_to_idx {0:then, 1:token, \u0026hellip;.}\nidx \u0026ndash;\u0026gt; token：idx_to_token: [the, token, \u0026hellip;.] 例如：\ntokens: 例如：一篇文章\n例如：[[一句话按照空格split后], [], [], ....]\nvocab：词表，代码里可以写成一个类，其元素有：\nself.idx_to_token ：['\u0026lt;unk\u0026gt;', \u0026lsquo;the\u0026rsquo;, \u0026hellip;] token的列表，按照token的个数降序排列\nself.token_to_idx ：{'\u0026lt;unk\u0026gt;': 0, \u0026lsquo;the\u0026rsquo;: 1, \u0026hellip;.} token\u0026ndash;\u0026gt;idx 的映射\ncorpus：语料库，先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为语料\n例如：[('\u0026lt;unk\u0026gt;', 1000), ('the', 900), ....]\n  二、深度循环神经网络 循环神经网络(Recurrent Netural Networks)：是具有隐状态的神经网络。\n类似于MLP多层感知机，RNNs只是添加了时间轴信息。比如，MLP的表示如下：\n$$ H = \\phi(XW_{xh} + b_h) $$ $$O = HW_{hq} + b_q $$","tags":["循环神经网络"],"title":"RNN综述"},{"categories":["Basic"],"contents":"一、简介 谷歌大脑、谷歌研究院等团队于2017年联合发表文章《Attention Is All You Need》，提出了一种新的注意力 Seq2Deq 模型，以取代之前以RNN作为编/解码器实现的 Seq2Seq 模型。模型采用的也是编码器-解码器架构，但是在该模型中，编码器和解码器不再是 RNN结构，取而代之的是编码器栈（encoder stack）和解码器栈（decoder stack）（注：所谓的“栈”就是将同一结构重复多次，“stack”翻译为“堆叠”更为合适）。编码器栈和解码器栈中分别为连续N个具有相同结构的编码器和解码器。\n 编码器：由两部分组成（自注意力模块 + 前馈神经网络）\n自注意力模块：具体来说是“Multi-Head Attention”，即“多头注意力”模块\n全连接前馈网络 每个子网络都具有残差连接，其输出形式为 $LayerNorm(Sublayer(x)+x)$ ，其中 $Sublayer(x)$ 表示子网络对输入特征x进行的具体映射操作；$LayerNorm()$ 表示归一化操作。\n  解码器：由三部分组成（自注意力模块 + 编码-解码注意力模块 + 前馈神经网络）\n解码器中多了一个编码-解码注意力模块，用来利用当前已有的输出，来匹配输入特征（即：attention操作），然后拿计算出的新特征来计算当前时间步的输出。解码器中的自注意力模块与编码器不同是：这里只能看到当前时间步之前的输入，而不是全部的输入，所以需要有mask的操作。\n 论文中图：    二、Transformer 输入：序列的embeding表示 + 位置编码\n编码器：\n 多头注意力 + 残差连接(residual connection) \u0026ndash;\u0026gt; 层归一化(layer normalization) 基于位置的前馈网络(positionwise feed-forward network) + 残差连接(residual connection) \u0026ndash;\u0026gt; 层归一化(layer normalization)  class PositionWiseFFN(nn.Module): \u0026#34;\u0026#34;\u0026#34;基于位置的前馈网络\u0026#34;\u0026#34;\u0026#34; def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs): super(PositionWiseFFN, self).__init__(**kwargs) self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens) self.relu = nn.ReLU() self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs) def forward(self, X): return self.dense2(self.relu(self.dense1(X))) 解码器：\n 解码器自注意力：解码器中每个位置只能考虑该位置之前的所有位置，所以添加掩码 编码器-解码器注意力：query：前一个解码器层的输出；k和v：整个编码器的输出。目的是捕获与当前解码最相关的编码状态，而不是所有的编码状态都是同等重要。 基于位置的前馈网络(positionwise feed-forward network) + 残差连接(residual connection) \u0026ndash;\u0026gt; 层归一化(layer normalization)  1、位置编码 与CNN/RNN不同，自注意力是没有记录位置信息的。可以回顾自注意力的计算过程，在$q_j$ 跟 $\\bold{K}$、$\\bold{V}$ 计算后，生成一个把$\\bold{V}$各个向量加权后的向量，这里面是没有位置信息的，也就是说不管输入的 $\\bold{V}$ 的向量顺序如何变化，自注意力的输出是不会改变的。\n所以：需要位置编码将位置信息注入到输入里。\n输入：$\\bold{X} \\in \\R^{n \\times d}$ 包含一个序列中n个词元的d维嵌入表示。\n位置编码：$\\bold{P} \\in \\R^{n \\times d}$, 矩阵第i行 偶数列、奇数列：用不同的频率、偏移来记录位置信息。 $$p_{i,2j} = sin(\\frac{i}{10000^{\\frac{2j}{d}}})$$ $$p_{i,2j+1} = cos(\\frac{i}{10000^{\\frac{2j}{d}}})$$\n在 $\\bold{X} + \\bold{P}$ 时，当$\\bold{X}$的幅度值比$\\bold{P}$小或者差不多时，可以增大$\\bold{X}$的幅度值，以保证$\\bold{X}$的主导性。 $$ \\bold{X} \\times M + \\bold{P} $$\n2、层归一化 层归一化：《Layer Normalization》，在一个输入序列中，做归一化。\n 由于输入序列的长度是不确定的  批归一化：《Batch normalization》，在一个batch中，在通道维度 做归一化。\n 避免梯度消失/爆炸：这是因为通过归一化(偏移、拉伸)，把原来可能波动较大的数据，限制在一定的范围内 为啥有效：有的解释是：通过(偏移、拉伸)，相当于添加了一个随机噪声，因为 均值、方差是在当前小批量样本上算出来的，包含了随机性。 批归一化，限制波动的范围，所以可以调大学习率，可以加速收敛。  # 批归一化 mean = X.mean(dim=(0, 2, 3), keepdim=True) var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True) X_hat = (X - mean) / torch.sqrt(var + eps) 图像与文本\n 图像: (batch, c, h, w) ： (h, w: 图像的高和宽)、(c: 通道数) 文本: (batch, T, d) ：(T：序列长度)、(d: 每个词元embeding表示的维度)  类比一下：\n 每个图像中包含 $h \\times w$ 个像素点，这个数目 类似 文本的长度。 每个像素点在channel方向是一个向量，这个向量 类似 词元的embeding  也就是说：图像的每个像素点表示一个样本点，channel方向 表示该样本点的特征表示。这也就是为什么说 $1 \\times 1$ 的卷积核的作用相当于全连接层。\n  class AddNorm(nn.Module): \u0026#34;\u0026#34;\u0026#34;残差连接后进行层规范化\u0026#34;\u0026#34;\u0026#34; def __init__(self, normalized_shape, dropout, **kwargs): super(AddNorm, self).__init__(**kwargs) self.dropout = nn.Dropout(dropout) self.ln = nn.LayerNorm(normalized_shape) def forward(self, X, Y): return self.ln(self.dropout(Y) + X) 3、基于位置的前馈网络 输入：(batch, 序列长度, embeding维度)\n输出：(batch, 序列长度, 新特征维度)\n作用：类似于卷积中的 $1 \\times 1$ 卷积核，就是转换一下特征的维度，样本个数不变。\nclass PositionWiseFFN(nn.Module): \u0026#34;\u0026#34;\u0026#34;基于位置的前馈网络\u0026#34;\u0026#34;\u0026#34; def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs): super(PositionWiseFFN, self).__init__(**kwargs) self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens) self.relu = nn.ReLU() self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs) def forward(self, X): return self.dense2(self.relu(self.dense1(X))) 4、编码器中的attention 在编码器中使用VVV模式，该自注意力模块为 MHA 结构，其中V为上一个编码器对输入句子中的每个词的编码（这里的编码可以理解为 RNN 中的隐变量向量，即输入句子中每个词的内部表示。如果是第一个编码器这里的编码即每个词的嵌入向量）。编码器自注意力模块用来捕捉输入句子中词与词之间的关系。例如翻译句子“The dog is barking at the bird because it is angry”，这里的“it”到底说的是狗还是鸟？编码器自注意力模块就是为了在对“it”进行编码时，尽量使得 “dog”对其具有更高的影响力——即注意力权重。 下图为针对上述翻译问题的一个自注意力模块示意，其中 $x_1, \\dotsb, x_{11}$ 分别代表句子中每个词的编码（为简化起见不考虑结束符等辅助符号），$y_1, \\dotsb, y_{11}$ 分别为自注意力模块对每个词的输出， $e_{ij}$ 即为自注意力模型输出 时在输入 $x_i$ 上投射的注意力权重。下图以 $y_9$（即针对“it”一词）为例，示意了各个输入编码上的注意力权重分配。\nclass EncoderBlock(nn.Module): \u0026#34;\u0026#34;\u0026#34;transformer编码器块\u0026#34;\u0026#34;\u0026#34; def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias=False, **kwargs): super(EncoderBlock, self).__init__(**kwargs) self.attention = d2l.MultiHeadAttention( key_size, query_size, value_size, num_hiddens, num_heads, dropout, use_bias) self.addnorm1 = AddNorm(norm_shape, dropout) self.ffn = PositionWiseFFN( ffn_num_input, ffn_num_hiddens, num_hiddens) self.addnorm2 = AddNorm(norm_shape, dropout) def forward(self, X, valid_lens): Y = self.addnorm1(X, self.attention(X, X, X, valid_lens)) return self.addnorm2(Y, self.ffn(Y)) class TransformerEncoder(d2l.Encoder): \u0026#34;\u0026#34;\u0026#34;transformer编码器\u0026#34;\u0026#34;\u0026#34; def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False, **kwargs): super(TransformerEncoder, self).__init__(**kwargs) self.num_hiddens = num_hiddens self.embedding = nn.Embedding(vocab_size, num_hiddens) self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout) self.blks = nn.Sequential() for i in range(num_layers): self.blks.add_module(\u0026#34;block\u0026#34;+str(i), EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias)) def forward(self, X, valid_lens, *args): # 因为位置编码值在-1和1之间， # 因此嵌入值乘以嵌入维度的平方根进行缩放， # 然后再与位置编码相加。 X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens)) self.attention_weights = [None] * len(self.blks) for i, blk in enumerate(self.blks): X = blk(X, valid_lens) self.attention_weights[ i] = blk.attention.attention.attention_weights return X 5、解码器中的attention 在解码器中先使用VVV模式，该自注意力模块与编码器自注意力模块的结构非常类似，唯一不同的是添加了掩膜机制，这是由于在解码器中，自注意力模块只被允许处理当前项之前的那些项，这一点与编码器需要“看到”所有项是不同的。上述目标的实现方式非常简单，只要在softmax 注意力权重概率化之前，用掩膜将当前处理项之后的所有项隐去即可，即将注意力的计算改为如下具有掩膜的形式\n解码器自注意力模块之后是编码-解码注意力模块：该模块也被构造为MHA结构、QVV模式。其中Q来自于上一个解码器的输出，而V来自于最后一个编码器输出（即也是编码器栈的最终输出）。该注意力模块能够使得解码器中的每个项都能够有重点的“看一遍”输入序列中的每一个词，这一点与基于 RNN结构的 Seq2Seq 结构类似。\nclass DecoderBlock(nn.Module): \u0026#34;\u0026#34;\u0026#34;解码器中第i个块\u0026#34;\u0026#34;\u0026#34; def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, i, **kwargs): super(DecoderBlock, self).__init__(**kwargs) self.i = i self.attention1 = d2l.MultiHeadAttention( key_size, query_size, value_size, num_hiddens, num_heads, dropout) self.addnorm1 = AddNorm(norm_shape, dropout) self.attention2 = d2l.MultiHeadAttention( key_size, query_size, value_size, num_hiddens, num_heads, dropout) self.addnorm2 = AddNorm(norm_shape, dropout) self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens) self.addnorm3 = AddNorm(norm_shape, dropout) def forward(self, X, state): enc_outputs, enc_valid_lens = state[0], state[1] # 训练阶段，输出序列的所有词元都在同一时间处理， # 因此state[2][self.i]初始化为None。 # 预测阶段，输出序列是通过词元一个接着一个解码的， # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示 if state[2][self.i] is None: key_values = X else: key_values = torch.cat((state[2][self.i], X), axis=1) state[2][self.i] = key_values if self.training: batch_size, num_steps, _ = X.shape # dec_valid_lens的开头:(batch_size,num_steps), # 其中每一行是[1,2,...,num_steps] dec_valid_lens = torch.arange( 1, num_steps + 1, device=X.device).repeat(batch_size, 1) else: dec_valid_lens = None # 自注意力 X2 = self.attention1(X, key_values, key_values, dec_valid_lens) Y = self.addnorm1(X, X2) # 编码器－解码器注意力。 # enc_outputs的开头:(batch_size,num_steps,num_hiddens) Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens) Z = self.addnorm2(Y, Y2) return self.addnorm3(Z, self.ffn(Z)), state class TransformerDecoder(d2l.AttentionDecoder): def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, **kwargs): super(TransformerDecoder, self).__init__(**kwargs) self.num_hiddens = num_hiddens self.num_layers = num_layers self.embedding = nn.Embedding(vocab_size, num_hiddens) self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout) self.blks = nn.Sequential() for i in range(num_layers): self.blks.add_module(\u0026#34;block\u0026#34;+str(i), DecoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, i)) self.dense = nn.Linear(num_hiddens, vocab_size) def init_state(self, enc_outputs, enc_valid_lens, *args): return [enc_outputs, enc_valid_lens, [None] * self.num_layers] def forward(self, X, state): X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens)) self._attention_weights = [[None] * len(self.blks) for _ in range (2)] for i, blk in enumerate(self.blks): X, state = blk(X, state) # 解码器自注意力权重 self._attention_weights[0][ i] = blk.attention1.attention.attention_weights # “编码器－解码器”自注意力权重 self._attention_weights[1][ i] = blk.attention2.attention.attention_weights return self.dense(X), state @property def attention_weights(self): return self._attention_weights ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/transformer/transformer_summary/","summary":"一、简介 谷歌大脑、谷歌研究院等团队于2017年联合发表文章《Attention Is All You Need》，提出了一种新的注意力 Seq2Deq 模型，以取代之前以RNN作为编/解码器实现的 Seq2Seq 模型。模型采用的也是编码器-解码器架构，但是在该模型中，编码器和解码器不再是 RNN结构，取而代之的是编码器栈（encoder stack）和解码器栈（decoder stack）（注：所谓的“栈”就是将同一结构重复多次，“stack”翻译为“堆叠”更为合适）。编码器栈和解码器栈中分别为连续N个具有相同结构的编码器和解码器。\n 编码器：由两部分组成（自注意力模块 + 前馈神经网络）\n自注意力模块：具体来说是“Multi-Head Attention”，即“多头注意力”模块\n全连接前馈网络 每个子网络都具有残差连接，其输出形式为 $LayerNorm(Sublayer(x)+x)$ ，其中 $Sublayer(x)$ 表示子网络对输入特征x进行的具体映射操作；$LayerNorm()$ 表示归一化操作。\n  解码器：由三部分组成（自注意力模块 + 编码-解码注意力模块 + 前馈神经网络）\n解码器中多了一个编码-解码注意力模块，用来利用当前已有的输出，来匹配输入特征（即：attention操作），然后拿计算出的新特征来计算当前时间步的输出。解码器中的自注意力模块与编码器不同是：这里只能看到当前时间步之前的输入，而不是全部的输入，所以需要有mask的操作。\n 论文中图：    二、Transformer 输入：序列的embeding表示 + 位置编码\n编码器：\n 多头注意力 + 残差连接(residual connection) \u0026ndash;\u0026gt; 层归一化(layer normalization) 基于位置的前馈网络(positionwise feed-forward network) + 残差连接(residual connection) \u0026ndash;\u0026gt; 层归一化(layer normalization)  class PositionWiseFFN(nn.Module): \u0026#34;\u0026#34;\u0026#34;基于位置的前馈网络\u0026#34;\u0026#34;\u0026#34; def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs): super(PositionWiseFFN, self).","tags":["NLP","Transformer"],"title":"Transformer"},{"categories":["Basic"],"contents":"一、简介 Word Embedding is coming soon.\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/word_embedding/word_embedding_summary/","summary":"一、简介 Word Embedding is coming soon.","tags":["word embedding"],"title":"Word Embedding综述"},{"categories":null,"contents":"一、数据类型与操作    操作 说明      del A[i] 删除列表A中下标为i的元素，其后的每个元素都前移一个位置 列表-删除   A.pop() 弹出列表尾部元素，相当于出栈 列表-删除   A.pop(i) 弹出列表中任何位置出的元素 列表-删除   A.remove('a') 有时候不知道索引号，只知道要删除的值；remove只删除第一个指定的值 列表-删除   A.sort(reverse=True) 对列表A从大到小排序，列表A被永久改变 列表-排序   B=sorted(A) 排序后，A没有被改变 列表-排序   A.reverse() A列表被永久的翻转了一下 列表-翻转              二、*和**的作用   * 在函数定义/调用时的应用\n 在函数定义时：*让python创建一个名为topping的空元组，并将收到的所有值封装在这个元组中。  def make_pizza(size, *topping): # 定义 ...  在调用时：*操作符自动把参数列表拆开  toppings = [\u0026#39;nushroom\u0026#39;, \u0026#39;green peppers\u0026#39;, \u0026#39;extra cheese\u0026#39;] make_pizza(size, *toppings) # 调用   ** 在函数定义/调用时的应用\n 在函数定义时：** 让python创建一个名为user_info的空字典，并将收到的所有键值对都封装到这个字典中。  def build_profile(first, last, **user_info): # 定义 ...  在调用时：** 操作符自动把参数字典拆开  user_infos = {} build_profile(first, last, **user_infos) # 调用   三、 ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/python/internal_lib/basic_operator/","summary":"一、数据类型与操作    操作 说明      del A[i] 删除列表A中下标为i的元素，其后的每个元素都前移一个位置 列表-删除   A.pop() 弹出列表尾部元素，相当于出栈 列表-删除   A.pop(i) 弹出列表中任何位置出的元素 列表-删除   A.remove('a') 有时候不知道索引号，只知道要删除的值；remove只删除第一个指定的值 列表-删除   A.sort(reverse=True) 对列表A从大到小排序，列表A被永久改变 列表-排序   B=sorted(A) 排序后，A没有被改变 列表-排序   A.reverse() A列表被永久的翻转了一下 列表-翻转              二、*和**的作用   * 在函数定义/调用时的应用\n 在函数定义时：*让python创建一个名为topping的空元组，并将收到的所有值封装在这个元组中。  def make_pizza(size, *topping): # 定义 .","tags":null,"title":"基础操作"},{"categories":null,"contents":"一、字符编码  ASCII：计算机是美国人发明的，所以最早只考虑了简单的26个字母和一些控制字符，所以只用7-bit组合出128个组合，编号0~127，存储的时候凑成了一个byte。这个组合没有考虑其他国家，比如汉字就不只128个，于是中国为汉字编码发明了GB2312编码，其他国家也有自己的各种编码，互不兼容。\n为了统一，提出了unicode编码，包含了各个国家的文字，对每个字符都用2个byte来表示，英文的话就在前面加0。\nunicode对于英文就会有些浪费，为了解决这个问题，为了节约硬盘空间/ 网络带宽，又发明了utf-8编码，1个字符可能会被编码成1~6个字节，英文还是1个字节，汉字变成了3个字节，只有在生僻字才会在4个字节。\n    字符 ASCII unicode utf-8     A 01000001 00000000 01000001 01000001   中  01001110 00101101 11100100 10111000 10101101   字符应用层的形式  字符在内存的形式 字符在硬盘/网络中的形式    二、解析/转换 图片在网络中获取下来是二进制的格式(bytes)；或者通过 open('***.jpg', \u0026lsquo;rb\u0026rsquo;) 读取的图片也是二进制的格式\n  bytes格式 \u0026lt;-\u0026gt; str\n bytes: 是(二进制)数字序列，是utf-8的编码形式。该格式的变量是不可修改的。  str \u0026ndash;\u0026gt; bytes : 使用str.encode()方法 bytes \u0026ndash;\u0026gt; str : 使用bytes.decode()方法   bytearray(): 该格式的变量是可以修改的  a = \u0026#39;人生苦短\u0026#39; # 此时b的格式是bytes，是不能修改的，即不能操作：b[:6] = \u0026#39;生命\u0026#39;.encode()  b = a.encode() # \\xe4\\xba\\xba\\xe7\\x94\\x9f\\xe8\\x8b\\xa6\\xe7\\x9f\\xad c = bytearray(b) # 转变为bytearray格式，就可以修改了 c[:6] = bytearray(\u0026#39;生命\u0026#39;.encode())   bytes格式 \u0026lt;-\u0026gt; numpy  bytes \u0026ndash;\u0026gt; numpy :  img_np = np.asarray(bytearray(content), dtype=\u0026#39;uint8\u0026#39;) # 或者 img_np = np.frombuffer(content, dtype=\u0026#39;uint8\u0026#39;)  numpy \u0026ndash;\u0026gt; bytes : img_content = img_np.tobytes()    bytes格式 \u0026lt;-\u0026gt; PIL\n bytes \u0026ndash;\u0026gt; PIL :  content = b\u0026#39;\\x...\u0026#39; # 二进制序列 utf-8编码格式 img_pil = PIL.Image.open(BytesIO(content))  PIL \u0026ndash;\u0026gt; bytes :  from PIL import Image from io import BytesIO # BytesIO: 在内存中读写bytes.  # 例如：f = BytesIO() f.write(\u0026#39;中文\u0026#39;.encode()) f.getvalue() img_pil = Image.open(\u0026#39;***.png\u0026#39;) f = BytesIO() img_pil.save(f, format=\u0026#39;PNG\u0026#39;) # PNG参数：四通道；JPEG参数：三通道 img_bytes = f.getvalue() # 转二进制    bytes格式 \u0026lt;-\u0026gt; opencv\n bytes -\u0026gt; cv2  img_np = np.asarray(bytearray(content), dtype=\u0026#39;uint8\u0026#39;) img_cv = cv2.imdecode(img_np, cv2.IMREAD_UNCHANGED)  cv2 -\u0026gt; bytes  success, encode_img = cv2.imencode(\u0026#39;.jpg\u0026#39;, img_cv) img_bytes = encode_img.tostring()   PIL \u0026lt;-\u0026gt; np\n PIL -\u0026gt; np  img_np = np.array(img_pil)  np -\u0026gt; PIL  img_pil = Image.fromarray(img_np)   PIL \u0026lt;-\u0026gt; cv2 PIL的图片是RGB模式，cv2的图片是BGR格式\n PIL -\u0026gt; cv2  img_cv = cv2.cvtColor(numpy.asarray(img_pil), cv2.COLOR_RGB2BGR)  cv2 -\u0026gt; PIL  img_pil = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))   ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/python/internal_lib/encode_mode/","summary":"一、字符编码  ASCII：计算机是美国人发明的，所以最早只考虑了简单的26个字母和一些控制字符，所以只用7-bit组合出128个组合，编号0~127，存储的时候凑成了一个byte。这个组合没有考虑其他国家，比如汉字就不只128个，于是中国为汉字编码发明了GB2312编码，其他国家也有自己的各种编码，互不兼容。\n为了统一，提出了unicode编码，包含了各个国家的文字，对每个字符都用2个byte来表示，英文的话就在前面加0。\nunicode对于英文就会有些浪费，为了解决这个问题，为了节约硬盘空间/ 网络带宽，又发明了utf-8编码，1个字符可能会被编码成1~6个字节，英文还是1个字节，汉字变成了3个字节，只有在生僻字才会在4个字节。\n    字符 ASCII unicode utf-8     A 01000001 00000000 01000001 01000001   中  01001110 00101101 11100100 10111000 10101101   字符应用层的形式  字符在内存的形式 字符在硬盘/网络中的形式    二、解析/转换 图片在网络中获取下来是二进制的格式(bytes)；或者通过 open('***.jpg', \u0026lsquo;rb\u0026rsquo;) 读取的图片也是二进制的格式\n  bytes格式 \u0026lt;-\u0026gt; str\n bytes: 是(二进制)数字序列，是utf-8的编码形式。该格式的变量是不可修改的。  str \u0026ndash;\u0026gt; bytes : 使用str.encode()方法 bytes \u0026ndash;\u0026gt; str : 使用bytes.decode()方法   bytearray(): 该格式的变量是可以修改的  a = \u0026#39;人生苦短\u0026#39; # 此时b的格式是bytes，是不能修改的，即不能操作：b[:6] = \u0026#39;生命\u0026#39;.","tags":null,"title":"字符编码"},{"categories":null,"contents":"一、线程与进程     进程 线程      进程：是一个应用程序在处理机上的一次执行过程，是具有一定独立功能的程序在某数据集上的一次运行，是一个动态的概念。进程是系统进行资源分配和调度的独立单位。 线程：是进程中的一个实体，是CPU调度和分派的基本单位，线程自己基本上不拥有系统资源，它与同属于一个进程内的其他线程共享进程的全部资源。   地址空间 进程有自己独立的地址空间 进程中至少有一个线程，它们共享进程的地址空间   资源 进程是资源分配和拥有的单位 进程内的多个线程共享进程的资源   调度  线程是进程内的一个执行单元，也是进程内的可调度实体，也是处理器调度的基本单位    二、多线程 1、threading模块 python主要是通过thread和threading这两个模块来实现多线程，thread模块是比较底层的模块，threading模块是对thread做了一些封装，使用更方便。但是由于GIL的存在，无法使用threading充分利用CPU资源，如果想充分发挥多核CPU的计算能力，需要使用multiprocessing模块\npython 3.x 已经摒弃了python 2.x中采用函数式thread模块来产生线程的方式。而是通过threading模块创建新的线程：\n  通过threading.Thread(Target=可执行方法)\nimport threading pro_list = [] mult_image_label_list = [] for index, img_list in enumerate(mult_image_label_list): # 创建线程 t1 = threading.Thread(target=函数名, args=(index, img_list)) pro_list.append(t1) for thread in pro_list: # 将线程设置为保护线程，否则会被无限挂起。 thread.setDaemon(True) thread.start() # 该位置---子线程与父线程同时执行，父线程执行完后，同时结束子线程的执行。 # 如果不添加join()语句，父线程结束后，子线程就会结束。 # 如果需要在子线程执行完后，父线程才结束，需要添加join()，让父进程一直处于阻塞状态，直到所有子线程执行完毕。 for thread in pro_list: # 在子线程结束前，父线程一直处于阻塞状态。让子线程执行完，才执行父线程，添加join()。 thread.join()   继承threading.Thread定义子类，并重写run()方法和init()\n实例化后调用start()方法启动新线程，即：它调用了线程的run()方法。\nimport threading import time class myThread(threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print(\u0026#34;Starting \u0026#34; + self.name) print_time(self.name, self.counter, 5) print(\u0026#34;Exiting \u0026#34; + self.name) def print_time(threadName, delay, counter): while counter: time.sleep(delay) print(\u0026#34;%sprocess at: %s\u0026#34; % (threadName, time.ctime(time.time()))) counter -= 1 # 创建新线程 thread1 = myThread(1, \u0026#34;Thread-1\u0026#34;, 1) thread2 = myThread(2, \u0026#34;Thread-2\u0026#34;, 2) # 开启线程 thread1.start() thread2.start() # 等待线程结束 thread1.join() thread2.join() print(\u0026#34;Exiting Main Thread\u0026#34;) 上例中thread1和thread2执行顺序是乱序的，如果要使其有序，需要进行线程同步。\n如果多个线程共同对某个数据操作，可能会出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。threading.Lock()有acquire方法(进行加锁)和release方法(进行解锁)，对于需要每次只允许一个线程操作的数据，可以将其操作放在acquire和release方法之间。线程同步的方式：锁机制、同步队列\n 锁机制  class myThread(threading.Thread): def __init__(self, threadID, name, counter, lock): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter self.lock = lock def run(self): print(\u0026#34;Starting \u0026#34; + self.name) # 加锁 self.lock.acquire() print_time(self.name, self.counter, 5) # 解锁 self.lock.release() print(\u0026#34;Exiting \u0026#34; + self.name) def print_time(threadName, delay, counter): while counter: time.sleep(delay) print(\u0026#34;%sprocess at: %s\u0026#34; % (threadName, time.ctime(time.time()))) counter -= 1 lock = threading.Lock() # 创建新线程 thread1 = myThread(1, \u0026#34;Thread-1\u0026#34;, 1, lock) thread2 = myThread(2, \u0026#34;Thread-2\u0026#34;, 2, lock) # 开启线程 thread1.start() thread2.start() # 等待线程结束 thread1.join() thread2.join() print(\u0026#34;Exiting Main Thread\u0026#34;) 线程同步队列queue\npython 2.x 提供的Queue，python3.x中提供的是queue。其中queue模块找那个提供了同步的、线程安全队列类，包括：FIFO(先入先出队列)、LIFO(后入先出队列)、PriorityQueue(优先级别队列)。这些队列都实现了锁原语，能够在多线程中直接使用。\n可以使用队列来实现线程间的同步。    queue常用方法      queue.qsize() 返回队列的大小   queue.empty() 如果队列为空，返回True，否则返回False   queue.full() 如果队列满了，返回True，否则返回False   queue.get() 获取队列   queue.get_nowait() 相当于Queue.get(False)   queue.put() 写入队列   queue.put_nowait(item) 相当于Queue.put(item, False)   queue.task_done() 在完成一项工作之后，向任务已经完成的队列发送一个信号   queue.join() 实际上意味着等到队列为空，再执行别的操作      #!/usr/bin/python3 import queue import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print (\u0026#34;开启线程：\u0026#34; + self.name) process_data(self.name, self.q) print (\u0026#34;退出线程：\u0026#34; + self.name) def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print (\u0026#34;%sprocessing %s\u0026#34; % (threadName, data)) else: queueLock.release() time.sleep(1) threadList = [\u0026#34;Thread-1\u0026#34;, \u0026#34;Thread-2\u0026#34;, \u0026#34;Thread-3\u0026#34;] nameList = [\u0026#34;One\u0026#34;, \u0026#34;Two\u0026#34;, \u0026#34;Three\u0026#34;, \u0026#34;Four\u0026#34;, \u0026#34;Five\u0026#34;] queueLock = threading.Lock() workQueue = queue.Queue(10) threads = [] threadID = 1 # 创建新线程 for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1 # 填充队列 queueLock.acquire() for word in nameList: workQueue.put(word) queueLock.release() # 等待队列清空 while not workQueue.empty(): pass # 通知线程是时候退出 exitFlag = 1 # 等待所有线程完成 for t in threads: t.join() print (\u0026#34;退出主线程\u0026#34;)   2、ThreadPoolExecutor线程池  传统多线程问题：一个线程的运行时间可以分为3部分：线程的启动时间、线程体的运行时间、线程的销毁时间。如果线程不能被重用，这就意味着每次创建都需要经过启动、运行、销毁这3个过程。这必然会增加系统响应的时间，降低效率。另外一种高效的解决方法——线程池。\n线程池：把任务放进队列中，然后开N个线程，每个线程都取队列中取一个任务，执行完了之后告诉系统我执行完了，然后接着从队列中取下一个任务，直至队列中所有任务取空，退出线程。由于线程预先被穿件并放入线程池中，同时处理完当前任务之后并不销毁而是被安排处理下一个任务，因此能够避免多次穿件线程，从而节省线程创建和销毁的开销，能带来更好的性能和系统稳定性。\n线程池设置：服务器CPU核数有限，能够同时并发的线程数有限，并不是开得越多越好。线程切换是有开销的，如果线程切换过于频繁，反而会使性能降低。假设N核服务器，通过执行业务的单线程分析出本地计算时间x，等待时间为y，则工作线程数设置为 N*(x+y)/x，能让CPU的利用率最大化。\n 从python3.2开始，标准库提供了concurrent.futures模块，它提供了ThreadPoolExecutor和ProcessPoolExecutor两个类，实现了对threading和multiprocessing的进一步抽象。\nfrom concurrent.futures import ThreadPoolExecutor, as_completed import time # 参数times用来模拟网络请求的时间 def get_html(times): time.sleep(times) print(\u0026#34;get page {}s finished\u0026#34;.format(times)) return times executor = ThreadPoolExecutor(max_workers=2) urls = [3, 2, 4] # 并不是真的url # 方法：as_completed all_task = [executor.submit(get_html, url) for url in urls] for future in as_completed(all_task): data = future.result() print(\u0026#34;in main: get page {}s success\u0026#34;.format(data)) # 执行结果 # get page 2s finished # in main: get page 2s success # get page 3s finished # in main: get page 3s success # get page 4s finished # in main: get page 4s success # 方法：map for data in executor.map(get_html, urls): print(\u0026#34;in main: get page {}s success\u0026#34;.format(data)) # 执行结果 # get page 2s finished # get page 3s finished # in main: get page 3s success # in main: get page 2s success # get page 4s finished # in main: get page 4s success ThreadPoolExecutor构造实例的时候，传入max_workers参数：来设置线程池中最多能同时运行的线程数目。\n   常用方法      submit() 用来提交线程池需要执行的任务到线程池中，并返回该任务的句柄，注意：submit不是阻塞的，而是立即返回。\n任务句柄能够使用done()方法来判断该任务是否结束。   cancel() 可以取消提交的任务。如果任务已经在线程池中运行了，就取消不了了。   result() 获取任务的返回值，这个方法内部是阻塞的。   as_completed() 判断线程池中那些任务结束了。as_completed方法是一个生成器，在没有任务完成的时候，会阻塞；在有任务完成时，会yield该任务，然后继续阻塞   map()    wait()     三、多进程 1、multiprocessing模块 multiprocessing模块是python中的多进程管理包，与thread.Thread类似，可以利用multiprocessing.Process对象来创建一个进程。该Process对象与Thread对象的用法相同，也有start()，run()，join()方法。\n  在unix平台上，在某个进程结束之后，该进程需要被其父进程调用wait，否则进程成为僵尸进程(zombie)，所以，有必要对每个Process对象调用join方法(等同于wait)。 multiprocessing模块提供了threading包没有的IPC(比如Pipe和Queue)，效率更高，应该优先考虑Pipe和Queue，避免使用Lock/Event/Semaphore/Condition等同步方式。 多进程应该避免共享资源。多线程本来就共享资源，可以方便的使用全局变量。各进程有自己的独立空间，共享资源会降低程序的效率。对于多进程，可以通过Manager方法来共享资源。   多进程： import multiprocessing q_input = multiprocessing.Queue(100) q_output = multiprocessing.Queue(100) all_task = [] for i in range(10): all_task.append(multiprocessing.Process(target=函数名, args=(形参))) for p in all_task: p.daemon = True p.start() for p in all_task: p.join() 进程池(Process Pool) 进程池可以创建多个进程，这些进程就像随时待命的士兵，准备执行任务，一个进程池中可以容纳多个待命的进程。如下：Pool创建了一个容许5个进程的进程池，每个进程都执行f函数，利用map方法将f()函数作用到表的每个元素上。\nimport multiprocessing def f(x): return x**2 pool = multiprocessing.Pool(processes=5) #-------map-------# result = pool.map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9]) print(result) #------apply_async--------# all_task = [] for i in range(1, 10): # 进程池中维持processes=5个进程 all_task.append(pool.apply_async(f, (i,))) pool.close() pool.join() # 结果 result = [] for res in all_task: result.append(res.get())    方法 说明     apply_async(func, args=()) 从进程池中取出一个进程执行func函数，args为该函数的参数，它将返回一个AsyncResult对象，可以用该对象的get()方法来获取结果。非阻塞   close() 进程池不能再创建新的进程   join() wait进程池中的全部进程，必须对Pool先调用close()方法才能join    共享内存 可以使用Value或Array将数据存储在共享内存映射中\nfrom multiprocessing import Process, Value, Array def f(n, a): n.value = 3.1415927 for i in range(len(a)): a[i] = -a[i] if __name__ == \u0026#39;__main__\u0026#39;: # d: 表示双精度浮点数据 # i: 表示有符号整数 num = Value(\u0026#39;d\u0026#39;, 0.0) arr = Array(\u0026#39;i\u0026#39;, range(10)) p = Process(target=f, args=(num, arr)) p.start() p.join() print(num.value) print(arr[:]) # 结果 # 3.1415927 # [0, -1, -2, -3, -4, -5, -6, -7, -8, -9] 服务进程 Manager() 返回的管理器对象控制一个服务进程：用来保存Python对象并允许其他进程使用代理操作他们。利用Manager()可以通过共享进程的方法共享数据。\n管理器支持的数据类型有：list、dict、Namespace、Lock、RLock、Semaphore、BoundedSemaphore、Condition、Event、Barrier、Queue、Value 和 Array\nfrom multiprocessing import Process,Manager def func1(shareList,shareValue,shareDict,lock): with lock: shareValue.value+=1 shareDict[1]=\u0026#39;1\u0026#39; shareDict[2]=\u0026#39;2\u0026#39; for i in xrange(len(shareList)): shareList[i]+=1 if __name__ == \u0026#39;__main__\u0026#39;: manager=Manager() list1=manager.list([1,2,3,4,5]) dict1=manager.dict() array1=manager.Array(\u0026#39;i\u0026#39;,range(10)) value1=manager.Value(\u0026#39;i\u0026#39;,1) lock=manager.Lock() proc=[Process(target=func1,args=(list1,value1,dict1,lock)) for i in xrange(20)] for p in proc: p.start() for p in proc: p.join() print list1 print dict1 print array1 print value1 # 结果 # [21, 22, 23, 24, 25] # {1: \u0026#39;1\u0026#39;, 2: \u0026#39;2\u0026#39;} # array(\u0026#39;i\u0026#39;, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) # Value(\u0026#39;i\u0026#39;, 21) 2、ProcessPoolExecutor模块 ProcessPoolExecutor在使用上和ThreadPoolExecutor大致一样，在futures中的方法也是相同的，但对于map()方法，ProcessPoolExecutor会对一个参数chunksize，将迭代对象切成块，将其作为分开的任务提交给pool，对于很大的iterables，设置较大的chunksize可以提高性能。\nfrom concurrent.futures import ProcessPoolExecutor, as_completed import time # 参数times用来模拟网络请求的时间 def get_html(times): time.sleep(times) print(\u0026#34;get page {}s finished\u0026#34;.format(times)) return times executor = ProcessPoolExecutor(max_workers=2) urls = [3, 2, 4] # 并不是真的url # 方法：as_completed all_task = [executor.submit(get_html, url) for url in urls] for future in as_completed(all_task): data = future.result() print(\u0026#34;in main: get page {}s success\u0026#34;.format(data)) # 执行结果 # get page 2s finished # in main: get page 2s success # get page 3s finished # in main: get page 3s success # get page 4s finished # in main: get page 4s success # 方法：map for data in executor.map(get_html, urls): print(\u0026#34;in main: get page {}s success\u0026#34;.format(data)) ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/python/sdk_lib/multiprocessing/","summary":"一、线程与进程     进程 线程      进程：是一个应用程序在处理机上的一次执行过程，是具有一定独立功能的程序在某数据集上的一次运行，是一个动态的概念。进程是系统进行资源分配和调度的独立单位。 线程：是进程中的一个实体，是CPU调度和分派的基本单位，线程自己基本上不拥有系统资源，它与同属于一个进程内的其他线程共享进程的全部资源。   地址空间 进程有自己独立的地址空间 进程中至少有一个线程，它们共享进程的地址空间   资源 进程是资源分配和拥有的单位 进程内的多个线程共享进程的资源   调度  线程是进程内的一个执行单元，也是进程内的可调度实体，也是处理器调度的基本单位    二、多线程 1、threading模块 python主要是通过thread和threading这两个模块来实现多线程，thread模块是比较底层的模块，threading模块是对thread做了一些封装，使用更方便。但是由于GIL的存在，无法使用threading充分利用CPU资源，如果想充分发挥多核CPU的计算能力，需要使用multiprocessing模块\npython 3.x 已经摒弃了python 2.x中采用函数式thread模块来产生线程的方式。而是通过threading模块创建新的线程：\n  通过threading.Thread(Target=可执行方法)\nimport threading pro_list = [] mult_image_label_list = [] for index, img_list in enumerate(mult_image_label_list): # 创建线程 t1 = threading.Thread(target=函数名, args=(index, img_list)) pro_list.append(t1) for thread in pro_list: # 将线程设置为保护线程，否则会被无限挂起。 thread.setDaemon(True) thread.","tags":null,"title":"并行操作"},{"categories":["Basic"],"contents":"It\u0026rsquo;s coming soon. ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/image-matting/image-matting-summary/","summary":"It\u0026rsquo;s coming soon. ","tags":["matting","CV"],"title":"抠图综述"},{"categories":null,"contents":"一、tf.layers tf.layers模块在TensorFlow2.0中已经被完全移除了，用tf.keras.layers定义层是新的标准。\n二、tf.losses tf.losses模块包含了经常使用的、能够实现独热编码的损失函数。\n三、tf.train 1. Optimizer TensorFlow提供的优化器\n   优化器 功能     tf.train.Optimizer    tf.train.GradientDescentOptimizer    tf.train.AdadeltaOptimizer    tf.train.AdagtadOptimizer    tf.train.AdagradDAOptimizer    tf.train.MomentumOptimizer    tf.train.AdamOptimizer    tf.train.FtrlOptimizer    tf.train.ProximalGradientDescentOptimizer    tf.train.ProximalAdagradOptimizer    tf.train.RMSProOptimizer     Optimizer类与其子类的继承关系：\n def minimize(self, loss, # 损失值， tensor # 全局训练步数，随着模型迭代优化自增， variable global_step=None, # 待训练模型参数的列表， list var_list=None, # 计算梯度和更新参数模型时的并行化程度，可选值GATE_OP,GATE_NONE,GATE_GRAPH # GATE_NONE 无同步，最大化并行执行效率，将梯度计算和模型参数更新完全并行化。 # GATE_OP，操作级同步，对于每个操作，分别确保所有梯度在使用前都计算完成。 # GATE_GRAPH，图级同步，最小化并行执行效率，确保所有模型参数的梯度计算完成。 gate_gradients=GATE_OP, # 聚集梯度值的方法， Enum aggregation_methed=None, # 是否将梯度计算放置到对应操作所在同一个设备，默认否，Boolean colocate_gradients_with_ops=False, # 优化器在数据流图中的名称，string nmae=None, # 损失值的梯度  grad_loss=None)       属性 功能介绍     _name 表示优化器的名称   _use_locking 表示是否在并发更新模型参数时加锁   minimize 最小化损失函数，该方法会依次调用compute_gradients和apply_gradients   compute_gradients 计算模型所有参数的梯度值,返回\u0026lt;梯度，响应参数\u0026gt;的键值对列表   apply_gradients 将梯度值更新到对应的模型参数，优化器的apply_gradients成员方法内部会调用tf.assign，tf.assign_add,tf.assign_sub方法完成模型参数的更新。    自定义优化器\n 分为三步骤：\n 计算梯度：调用compute_gradients方法，依据指定的策略求得梯度值。 处理梯度：用户按照自己的需求处理梯度值，例如：进行梯度裁剪和梯度加权 应用梯度：调用apply_gradients方法，将处理后的梯度值应用到模型参数，实现模型更新。   def define_optimizer(learning_rate,loss): # 定义优化器 optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate,beta1=0.5) # 计算梯度 grads_and_vars=optimizer.compute_gradients(loss=loss) # 处理梯度 for i,(g,v) in enumerate(grads_and_vars): if g is not None: grads_and_vars[i]=(tf.clip_by_norm(g,5),v) # 应用梯度 return optimizer.apply_gradients(grads_and_vars) 2. Saver 保存模型参数很重要，训练中断后，可以根据保存的参数继续迭代。Saver 是TensorFlow Python API提供的、能够保存当前模型变量的对象，Saver对象：只能保存变量，不能保存图结构，所以更常用于训练迭代过程，防止中断重启。 SavedModel对象：可以同时保存图结构和变量，所以Saved Model对象与(将训练好的模型用在生产中)的行为联系更紧密。\ntf.train.Saver()\n四、tf.summary 可以记录数据流图、直方图、标量值、分布、日志图和其他多种数据类型。\n   操作 解释 功能     tf.summary.scalar() 例如：tf.summary.scalar(\u0026lsquo;loss\u0026rsquo;, loss) 记录标量值   tf.summary.Filewirter() 可以关联不同的路径，这样可以可视化不同阶段的数据情况     ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/tf/compat/tf_compat_train/","summary":"一、tf.layers tf.layers模块在TensorFlow2.0中已经被完全移除了，用tf.keras.layers定义层是新的标准。\n二、tf.losses tf.losses模块包含了经常使用的、能够实现独热编码的损失函数。\n三、tf.train 1. Optimizer TensorFlow提供的优化器\n   优化器 功能     tf.train.Optimizer    tf.train.GradientDescentOptimizer    tf.train.AdadeltaOptimizer    tf.train.AdagtadOptimizer    tf.train.AdagradDAOptimizer    tf.train.MomentumOptimizer    tf.train.AdamOptimizer    tf.train.FtrlOptimizer    tf.train.ProximalGradientDescentOptimizer    tf.train.ProximalAdagradOptimizer    tf.train.RMSProOptimizer     Optimizer类与其子类的继承关系：\n def minimize(self, loss, # 损失值， tensor # 全局训练步数，随着模型迭代优化自增， variable global_step=None, # 待训练模型参数的列表， list var_list=None, # 计算梯度和更新参数模型时的并行化程度，可选值GATE_OP,GATE_NONE,GATE_GRAPH # GATE_NONE 无同步，最大化并行执行效率，将梯度计算和模型参数更新完全并行化。 # GATE_OP，操作级同步，对于每个操作，分别确保所有梯度在使用前都计算完成。 # GATE_GRAPH，图级同步，最小化并行执行效率，确保所有模型参数的梯度计算完成。 gate_gradients=GATE_OP, # 聚集梯度值的方法， Enum aggregation_methed=None, # 是否将梯度计算放置到对应操作所在同一个设备，默认否，Boolean colocate_gradients_with_ops=False, # 优化器在数据流图中的名称，string nmae=None, # 损失值的梯度  grad_loss=None)       属性 功能介绍     _name 表示优化器的名称   _use_locking 表示是否在并发更新模型参数时加锁   minimize 最小化损失函数，该方法会依次调用compute_gradients和apply_gradients   compute_gradients 计算模型所有参数的梯度值,返回\u0026lt;梯度，响应参数\u0026gt;的键值对列表   apply_gradients 将梯度值更新到对应的模型参数，优化器的apply_gradients成员方法内部会调用tf.","tags":null,"title":"模型训练"},{"categories":["Basic"],"contents":"一、简介 It\u0026rsquo;s coming soon.\n二、网络 1、R-CNN 《Rich feature hierarchies for accurate object detection and semantic segmentation》(2013)\n2、SPPNet 《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》(2014)\n3、Fast R-CNN 《Fast R-CNN》(2015)\n4、Faster R-CNN 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》(2016)\n5、FPN 《Feature Pyramid Networks for Object Detection》(2017)\n4、YOLO 《You Only Look Once: Unified, Real-Time Object Detection》(2016)\n5、YOLO V2 《YOLO9000: Better, Faster, Stronger》(2016)\n6、YOLO V3 《YOLOv3: An Incremental Improvement》(2018)\n7、Mask R-CNN 《Mask R-CNN》(2017) 是何恺明团队提出的一个基于Faster R-CNN模型的一种新型的分割模型，此论文斩获ICCV 2017的最佳论文。\n8、RetinaNet RetinaNet 原始论文为发表于 2017 ICCV 《Focal Loss for Dense Object Detection》(2017) one-stage 网络首次超越 two-stage 网络，拿下了 best student paper。\n9、Cascade 《Cascade R-CNN》(2017)\n10、ATSS 《Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection》(2019)\n11、RepPoints V2 《RepPoints V2: Verification Meets Regression for Object Detection》(2020)\n12、YOLO V4 《YOLOv4: Optimal Speed and Accuracy of Object Detection》(2020)\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/detect_object/object_detection_summary/","summary":"一、简介 It\u0026rsquo;s coming soon.\n二、网络 1、R-CNN 《Rich feature hierarchies for accurate object detection and semantic segmentation》(2013)\n2、SPPNet 《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》(2014)\n3、Fast R-CNN 《Fast R-CNN》(2015)\n4、Faster R-CNN 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》(2016)\n5、FPN 《Feature Pyramid Networks for Object Detection》(2017)\n4、YOLO 《You Only Look Once: Unified, Real-Time Object Detection》(2016)\n5、YOLO V2 《YOLO9000: Better, Faster, Stronger》(2016)\n6、YOLO V3 《YOLOv3: An Incremental Improvement》(2018)","tags":["目标检测","CV"],"title":"简介"},{"categories":["Basic"],"contents":"一、简介 It\u0026rsquo;s coming soon.\n二、网络-基于编码器-解码器 1、FCN 《Fully Convolutional Networks for Semantic Segmentation》(2015) 要说语义分割整体实现精度大的跨越还是在FCN（全卷积神经网络）提出之后。它完全改变了之前需要一个窗口来将语义分割任务转变为图片分类任务的观念，FCN完全丢弃了图片分类任务中全连接层，从头到尾都只使用到了卷积层。从FCN后，基于编码器解码器结构的经典网络结构如同雨后春笋般冒了出来\n2、U-Net 《U-Net: Convolutional Networks for Biomedical Image Segmentation》(2015) Unet网络是在医学影像分割中最常用的模型。它的典型特点是，它是U型对称结构，左侧是卷积层，右侧是上采样层（典型的编码器解码器结构）。\n另一个特点是，Unet网络的每个卷积层得到的特征图都会concatenate到对应的上采样层，从而实现对每层特征图都有效使用到后续计算中。也就是文中所说的skip-connection。这样，同其他的一些网络结构比如FCN比较，Unet避免了直接在高级feature map中进行监督和loss计算，而是结合了低级feature map中的特征，从而可以使得最终所得到的feature map中既包含了high-level 的feature，也包含很多的low-level的feature，实现了不同scale下feature的融合，提高模型的结果精确度。\n3、SegNet 《SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation》(2015) 是一个由剑桥大学团队开发的图像分割的开源项目，该项目可以对图像中的物体所在区域进行分割，例如车，马路，行人等，并且精确到像素级别\n4、Deeplab V1 《Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs》(2015) 2015 年的ICLR上提出DeepLab V1是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。它将DenseCRFs作为网络的后处理方法。采用DenseCRFs作为后处理的方法，简单来说，就是对一个像素进行分类的时候，不仅考虑DCNN的输出，而且考虑该像素点周围像素点的值，这样语义分割结果边界清楚。\n5、Deeplab V2 《DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs》(2017) 在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是重复的池化和下采样降低了分辨率。但是另一方面，重复的池化和下采样扩大了感受野，而感受野的扩大对语义分割任务来说也是至关重要的。针对这一问题，DeepLab v2采用的空洞卷积算法扩展感受野，与此同时不会降低特征图的分辨率。此外，deeplab v2基于空洞卷积，设计了ASPP模块。它组合了不同dilation rate的空洞卷积所产生的特征图。这样，不同空洞卷积产生的不同感受野的特征图被组合在了一起，从而获取了更加丰富的上下文信息。\n6、PSPnet 《Pyramid Scene Parsing Network》(2017)\n7、Deeplab V3 《Rethinking Atrous Convolution for Semantic Image Segmentation》(2017) deeplab v3的创新点一是改进了ASPP模块。其实也就是与原来的ASPP相比，新的ASPP模块能够聚集到全局的上下文信息，而之前的只能聚集局部的上下文。\n8、Deeplab V3+ 《Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation》(2018)\ndeeplab v3+的创新点：\n 是设计基于v3的decode module，使得结果变得更加精细； 是用modify xception作为backbone。  三、网络-基于注意力 1、DANet 《Dual Attention Network for Scene Segmentation》(2019)\n2、CCNet 《CCNet: Criss-Cross Attention for Semantic Segmentation》(2019)\n3、DANet 《Context Prior for Scene Segmentation》(2020)\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/cv/semantic_segmentation/object_detection_summary/","summary":"一、简介 It\u0026rsquo;s coming soon.\n二、网络-基于编码器-解码器 1、FCN 《Fully Convolutional Networks for Semantic Segmentation》(2015) 要说语义分割整体实现精度大的跨越还是在FCN（全卷积神经网络）提出之后。它完全改变了之前需要一个窗口来将语义分割任务转变为图片分类任务的观念，FCN完全丢弃了图片分类任务中全连接层，从头到尾都只使用到了卷积层。从FCN后，基于编码器解码器结构的经典网络结构如同雨后春笋般冒了出来\n2、U-Net 《U-Net: Convolutional Networks for Biomedical Image Segmentation》(2015) Unet网络是在医学影像分割中最常用的模型。它的典型特点是，它是U型对称结构，左侧是卷积层，右侧是上采样层（典型的编码器解码器结构）。\n另一个特点是，Unet网络的每个卷积层得到的特征图都会concatenate到对应的上采样层，从而实现对每层特征图都有效使用到后续计算中。也就是文中所说的skip-connection。这样，同其他的一些网络结构比如FCN比较，Unet避免了直接在高级feature map中进行监督和loss计算，而是结合了低级feature map中的特征，从而可以使得最终所得到的feature map中既包含了high-level 的feature，也包含很多的low-level的feature，实现了不同scale下feature的融合，提高模型的结果精确度。\n3、SegNet 《SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation》(2015) 是一个由剑桥大学团队开发的图像分割的开源项目，该项目可以对图像中的物体所在区域进行分割，例如车，马路，行人等，并且精确到像素级别\n4、Deeplab V1 《Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs》(2015) 2015 年的ICLR上提出DeepLab V1是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。它将DenseCRFs作为网络的后处理方法。采用DenseCRFs作为后处理的方法，简单来说，就是对一个像素进行分类的时候，不仅考虑DCNN的输出，而且考虑该像素点周围像素点的值，这样语义分割结果边界清楚。\n5、Deeplab V2 《DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs》(2017) 在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是重复的池化和下采样降低了分辨率。但是另一方面，重复的池化和下采样扩大了感受野，而感受野的扩大对语义分割任务来说也是至关重要的。针对这一问题，DeepLab v2采用的空洞卷积算法扩展感受野，与此同时不会降低特征图的分辨率。此外，deeplab v2基于空洞卷积，设计了ASPP模块。它组合了不同dilation rate的空洞卷积所产生的特征图。这样，不同空洞卷积产生的不同感受野的特征图被组合在了一起，从而获取了更加丰富的上下文信息。","tags":["语义分割","CV"],"title":"简介"},{"categories":null,"contents":"官方文档\ntorch目录下，树状图:\n├── quasirandom.py\n├── random.py random模块\n├── serialization.py\n├── storage.py\n├── tensor.py Tensor模块\n├── functional.py\n│\n├── cuda\n│　├── comm.py\n│　├── error.py\n│　├── memory.py\n│　├── nccl.py\n│　├── nvtx.py\n│　├── profiler.py\n│　├── random.py\n│　├── sparse.py\n│　└── streams.py\n│\n├── nn\n│　├── backends\n│　├── cpp.py\n│　├── functional.py\n│　├── grad.py\n│　├── init.py\n│　├── intrinsic\n│　│　├── modules\n│　│　│　└── fused.py\n│　│　├── qat\n│　│　│　└── modules\n│　│　│　├── conv_fused.py\n│　│　│　└── linear_relu.py\n│　│　└── quantized\n│　│　└── modules\n│　│　├── conv_relu.py\n│　│　└── linear_relu.py\n│　├── modules\n│　│　├── activation.py\n│　│　├── adaptive.py\n│　│　├── container.py\n│　│　├── conv.py\n│　│　├── distance.py\n│　│　├── dropout.py\n│　│　├── flatten.py\n│　│　├── fold.py\n│　│　├── instancenorm.py\n│　│　├── linear.py\n│　│　├── loss.py\n│　│　├── module.py\n│　│　├── normalization.py\n│　│　├── padding.py\n│　│　├── pooling.py\n│　│　├── rnn.py\n│　│　├── sparse.py\n│　│　├── transformer.py\n│　│　├── upsampling.py\n│　│　└── utils.py\n│　├── parallel\n│　│　├── data_parallel.py\n│　│　├── distributed.py\n│　│　├── parallel_apply.py\n│　│　├── replicate.py\n│　├── parameter.py\n│　├── qat\n│　│　└── modules\n│　│　├── conv.py\n│　│　└── linear.py\n│　├── quantized\n│　│　├── dynamic\n│　│　│　└── modules\n│　│　│　├── linear.py\n│　│　│　└── rnn.py\n│　│　├── functional.py\n│　│　└── modules\n│　│　├── activation.py\n│　│　├── conv.py\n│　│　├── functional_modules.py\n│　│　├── linear.py\n│　│　└── utils.py\n│　└── utils\n│　├── clip_grad.py\n│　├── convert_parameters.py\n│　├── fusion.py\n│　├── prune.py\n│　├── rnn.py\n│　└── spectral_norm.py\n│\n├── optim\n│　├── adadelta.py\n│　├── adagrad.py\n│　├── adam.py\n│　├── adamax.py\n│　├── adamw.py\n│　├── asgd.py\n│　├── lbfgs.py\n│　├── optimizer.py\n│　├── rmsprop.py\n│　├── rprop.py\n│　├── sgd.py\n│　└── sparse_adam.py\n│\n├── autograd\n│　├── anomaly_mode.py\n│　├── function.py\n│　├── grad_mode.py\n│　├── profiler.py\n│　└── variable.py\n│\n├── distributed\n│　├── autograd\n│　├── distributed_c10d.py\n│　├── optim\n│　│　└── optimizer.py\n│　├── rendezvous.py\n│　└── rpc\n│　├── api.py\n│　├── backend_registry.py\n│　├── constants.py\n│　└── internal.py\n│\n├── distributions\n│　├── bernoulli.py\n│　├── beta.py\n│　├── binomial.py\n│　├── categorical.py\n│　├── constraint_registry.py\n│　├── constraints.py\n│　├── distribution.py\n│　├── exp_family.py\n│　├── exponential.py\n│　├── gamma.py\n│　├── geometric.py\n│　├── gumbel.py\n│　├── independent.py\n│　├── kl.py\n│　├── laplace.py\n│　├── log_normal.py\n│　├── logistic_normal.py\n│　├── lowrank_multivariate_normal.py\n│　├── multinomial.py\n│　├── multivariate_normal.py\n│　├── negative_binomial.py\n│　├── normal.py\n│　├── pareto.py\n│　├── poisson.py\n│　├── relaxed_bernoulli.py\n│　├── relaxed_categorical.py\n│　├── studentT.py\n│　├── transformed_distribution.py\n│　├── transforms.py\n│　├── uniform.py\n│　├── utils.py\n│　└── weibull.py\n│\n├── jit\n│　├── annotations.py\n│　├── frontend.py\n│　├── quantized.py\n│　└── supported_ops.py\n│\n├── multiprocessing\n│　├── pool.py\n│　├── queue.py\n│　├── reductions.py\n│　└── spawn.py\n│\n├── quantization\n│　├── default_mappings.py\n│　├── fake_quantize.py\n│　├── fuse_modules.py\n│　├── observer.py\n│　├── qconfig.py\n│　├── quantize.py\n│　└── stubs.py\n│\n├── onnx\n│　├── operators.py\n│　├── symbolic_caffe2.py\n│　├── symbolic_opset10.py\n│　├── symbolic_opset11.py\n│　├── symbolic_opset7.py\n│　├── symbolic_opset8.py\n│　├── symbolic_opset9.py\n│　├── symbolic_registry.py\n│　└── utils.py\n│\n├── utils: 辅助模块\n│　├── backcompat\n│　├── bottleneck\n│　├── collect_env.py\n│　├── cpp_extension.py\n│　├── data\n│　│　│　├── collate.py\n│　│　│　├── pin_memory.py\n│　│　│　└── worker.py\n│　│　├── dataloader.py\n│　│　├── dataset.py\n│　│　├── distributed.py\n│　│　├── sampler.py\n│　├── dlpack.py\n│　├── file_baton.py\n│　│　└── constants.py\n│　├── mkldnn.py\n│　├── model_zoo.py\n│　├── tensorboard\n│　│　├── summary.py\n│　│　└── writer.py\n│\n└── version.py  PyTorch主要包括一下16个模块：\n  torch模块\n torch本身包含了PyTorch经常使用的激活函数：torch.sigmoid, torch.relu, torch.tanh 一些张量操作：torch.mm()(矩阵的乘法), torch.select()(张量元素的选择)等操作 生成张量：torch.zeros(), torch.randn()等操作。    torch.Tensor模块\ntorch.Tensor模块：定义了torch中的张量类型。张量：一定维度的矩阵。\n 张量类中包含着一些列的方法，返回新的张量或者更改当前的张量：根据PyTorch的命名规则，如果张量方法后缀带有下划线，该方法会修改张量本身的数据；反之则会返回新的张量。例如：Torch.add方法：返回新的张量；Torch.add_方法：修改当前张量的值。 torch.Storage负债torch.Tensor底层的数据存储，即：为一个张量分配连续的一维内存地址。    torch.sparse模块\ntorch.sparse模块：定义了稀疏张量，其中构造的稀疏张量采用的是COO格式(Coordinate)，用一个长整形定义非零元素的位置，用浮点数张量定义对应非零元素的值。稀疏张量之间可以做元素的算术运算和矩阵运算。\n  torch.cuda模块\ntorch.cuda模块：定义了与CUDA运算相关的一些列函数，包括：检测系统的CUDA是否可用、当前进程对应的GPU序号、清除GPU上的缓存、设置GPU的计算流、同步GPU上执行的所有核函数等。\n  torch.nn模块\ntorch.nn模块：是神经网络模块化的核心模块，该模块定义了一些神经网络的计算模块：nn.ConvNd(卷积层，其中N=1,2,3)、nn.Linear(全连接层)等。构建深度学习模型的时候，可以通过继承nn.Module类并重写forward方法来实现一个新的神经网络。\n torch.nn.functional模块：定义一些和神经网络相关的函数，包括卷积函数和池化函数等，这些函数也是深度学习网络构建的基础。需要指出的是：torch.nn中定义的模块一般会调用torch.nn.functional里的函数，比如：nn.ConvNd模块会调用torch.nn.functional.convNd函数。另外，torch.nn.functional里面还定义了一些不常用的激活函数：torch.nn.functional.relu6、torch.nn.functional.elu等。 torch.nn.init模块：定义了神经网络权重的初始化。    torch.optim模块\n 定义了一系列的优化器。比如：torch.optim.SGD(随机梯度下降法)、torch.optim.Adagrad、torch.optim.RMSprop、torch.optim.Adam等。 定义了一些学习率衰减的算法的子模块：torch.optim.lr_scheduler，这个子模块中包含了：torch.optim.lr_scheduler.StepLR(学习率阶梯下降算法)、torch.optim.lr_scheduler.CosineAnnealingLR(余弦退火算法)等学习率衰减算法。    torch.autograd模块\ntorch.autograd模块：是PyTorch的自动微分模块，定义了一系列的自动微分函数，包括torch.autograd.backward函数，主要用于：在求得损失函数之后进行反向梯度传播。torch.autograd.grad函数：用于一个标量张量对一个另一个张量求导(在代码中设置不参与求导的部分参数)。另外，这个模块还内置了数值梯度功能和检查自动微分引擎是否输出正确结果的功能。\n  torch.distribute模块\ntorch.distributed模块：是PyTorch的分布式计算模块，主要功能是提供PyTorch并行运行环境，其主要支持的后端有MPI、Gloo、NCCL三种。PyTorch分布式工作原理：启动多个并行的进程，每个进程(都拥有一个模型的备份，然后输入不同的训练数据)，计算损失函数，每个进程独立地做反向 传播，最后对所有进行权重张量的梯度做归约(Reduce)。用到后端的部分主要是：数据的广播(Broadcast)和数据的收集(Gather)\n Broadcast：把数据从一个节点(进程)传播到另一个节点(进程)，比如：归约后梯度张量的传播 Gather：把数据从其他节点(进程)转移到当前节点(进程)，比如：把梯度张量从其他节点转移到某个特定的节点，然后求梯度平均。\nPyTorch的分布式计算模块不但踢动了后端的一个包装，还提供了一些启动方式来启动多个进程，包括：通过网络(TCP)方式、通过环境变量方法、通过共享文件方式等。    torch.distributions模块\ntorch.distributions模块：提供了一系列类，使得PyTorch能够对不同的分布进行采样，并生成概率采样过程的计算图。在一些应用过程中，比如强化学习(Reinforcement Learning)，经常会使用一个深度学习模型来模拟在不同环境条件下采取的策略，其最后的输出是不同动作的概率。当深度学习模型输出概率之后，需要根据概率对策略进行采样来模拟当前的策略概率分布，最后用梯度下降法来让最优策略的概率最大(策略梯度算法PolicyGradient)。实际上，因为采样的输出结果是离散的，无法直接求导，所以不能使用反向传播的方法来优化网络。torch.distributions模块的存在就是为了解决这个问题。可以结合torch.distributions.Categorical进行采样，然后使用对数求导来规避这个问题。当然，除了服从多项式分布的torch.distributions.Categorical类，PyTorch还支持其他的分布(包括连续分布和离散分布)，比如torch.distributions.Normal类支持连续的正态分布的采样，可以用于连续的强化学习的策略。\n  torch.hub模块\ntorch.hub模块：提供了一系列预训练的模型，比如：torch.hub.list函数可以获取某个模型镜像站点的模型信息。通过torch.hub.load来加载预训练模型，载入后的模型可以保存到本地，并可以看到这些模型对应类支持的方法。\n  torch.jit模块\ntorch.jit模块：是PyTorch的即时编译器，这个模块存在的意义是把PyTorch的动态图换成可以优化和序列化的静态图，工作原理：通过输入预先定义好的张量，追踪整个动态图的构建过程，得到最终构建出来的动态图，然后转换为静态图(通过中间表示：IntermediateRepresentation，来描述最后得到的图)。通过JIT得到的静态图可以被保存，并且被PyTorch其他的前端支持。另外，JIT可以用来生成其他格式的神经网络描述文件，比如ONNX。torch.jit支持两种模式，即：脚本模式(ScriptModule)和追踪模式(Tracing)，这两个都能构建静态图，区别在于脚本模式支持控制流，追踪模式不支持，不过前者支持的神经网络模块比后者少。\n  torch.multiprocessing模块\ntorch.multiprocessing模块：定义PyTorch中的多进程API。通过这个模块可以启动不同的进程，每个进程运行不同的深度学习模型，并且能够在进程间共享张量，共享的张量可以在CPU上，也可在GPU上。多进程API还提供了与Python原生的多进程API相同的一系列函数，包括锁(Lock)和队列(Queue)等。\n  torch.random模块\ntorch.random模块：提供了一系列的方法来保存和设置随机数生成器的状态。因为神经网络的训练是一个随机过程，包括数据的输入、权重的初始化都具有一定的随机性。设置一个统一的随机种子可以有效地帮助我们测试不同结构神经网络的表现，有助于调试神经网络的结构。\n get_rng_state函数获取当前随机数生成器状态 set_rng_state函数：设置当前随机数生成器状态 manual_seed函数：设置随机种子 initial_seed函数：得到程序初始的随机种子。    torch.onnx模块\ntorch.onnx模块：定义了PyTorch导出和载入ONNX格式的深度学习模型描述文件。ONNX格式的存在：为了方便不同深度学习框架之间交换模型。引入这个模块可以方便PyTorch导出模型给其他深度学习架构使用，或者让PyTorch可以载入其他深度学习框架构建的深度学习模型。\n  PyTorch的辅助模块\n torch.utils.bottleneck模块：可以用来检测深度学习模型中模块的运行时间，从而可以找到导致性能瓶颈的那些模块，通过优化这些模块的运行时间，优化整个深度学习模型的性能。 torch.utils.checkpoint模块：可以用来节约深度学习使用的内存。因为梯度反向传播，在构建计算图的时候需要保存中间数据，而这些数据大大增加了深度学习的内存消耗。为了减少内存消耗，让迷你批次的大小得到提高，从而提升深度学习模型的性能和优化时的稳定性，可以通过这个模块记录中间数据的计算过程，然后丢掉这些中间数据，等需要用到的时候再从新计算这些数据，这个模块设计的核心思想是以计算时间换存储空间。 torch.utils.cpp_extension模块：定义了PyTorch的C++扩展。 torch.utils.data模块：引入了数据集和数据载入器的概念，前者代表包含了所有数据的数据集，通过索引能够得到某条特定的数据，后者通过对数据集的包装，可以对数据集进行随机排列和采样，得到一些列打乱顺序的批次。 torch.utils.dlpacl模块：定义了PyTorch张量和DLPack张量存储格式之间的转换，用于不同框架之间张量数据的交换。 torch.utils.tensorboard模块：是PyTorch对TensorBoard数据可视化工具的支持。TensorBoard原来是TF自带的数据可视化工具，能够显示深度学习模型在训练过程中损失函数、张量权重的直方图，以及模型训练过程中输出的文本、图像、视频等。TensorBoard的功能非常强大，而且是基于可交互的动态网页设计的，使用者可以通过预先提供的一系列功能来输出特定的训练过程细节。PyTorch支持TensorBoard可视化后，在训练过程中，可以方便地观察中间输出的张量，可以方便地调试深度学习模型。      ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/pytorch/torch_summary/","summary":"官方文档\ntorch目录下，树状图:\n├── quasirandom.py\n├── random.py random模块\n├── serialization.py\n├── storage.py\n├── tensor.py Tensor模块\n├── functional.py\n│\n├── cuda\n│　├── comm.py\n│　├── error.py\n│　├── memory.py\n│　├── nccl.py\n│　├── nvtx.py\n│　├── profiler.py\n│　├── random.py\n│　├── sparse.py\n│　└── streams.py\n│\n├── nn\n│　├── backends\n│　├── cpp.py\n│　├── functional.py\n│　├── grad.py\n│　├── init.py\n│　├── intrinsic\n│　│　├── modules","tags":null,"title":"简介"},{"categories":["Basic"],"contents":"一、编码器-解码器 架构 机器翻译：是把一个序列转换为另一个序列。为处理这种类型的输入和输出，设计这样的架构：\n 编码器：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。\n 解码器：将固定形状的编码状态映射到长度可变的序列。\n  二、seq2seq Ilya Sutskever 等人设计的seq2seq：将编码器最后一时间步的state，作为解码器第一时间步的state使用。\nKyunghyun Cho 等人设计的seq2seq，将编码器最后一时间步的state，作为解码器每一个时间步的输入序列的一部分。\n","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/nlp/rnn/encode_decode/","summary":"一、编码器-解码器 架构 机器翻译：是把一个序列转换为另一个序列。为处理这种类型的输入和输出，设计这样的架构：\n 编码器：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。\n 解码器：将固定形状的编码状态映射到长度可变的序列。\n  二、seq2seq Ilya Sutskever 等人设计的seq2seq：将编码器最后一时间步的state，作为解码器第一时间步的state使用。\nKyunghyun Cho 等人设计的seq2seq，将编码器最后一时间步的state，作为解码器每一个时间步的输入序列的一部分。","tags":["循环神经网络","编码器-解码器 架构"],"title":"编解码架构"},{"categories":null,"contents":"一、环境变量 1、临时环境变量    操作 说明 功能     os.environ['WORKON_HOME']=\u0026quot;变量\u0026quot; 设置环境变量    os.environ.get('WORKON_HOME') 获取环境变量-方法1    os.getenv('path') 获取环境变量-方法2-推荐    del os.environ['WORKON_HOME'] 删除环境变量         os.environ['HOMEPATH'] 当前用户主目录    os.environ['TEMP'] 临时目录路径    os.environ['PATHEXT'] 可以执行文件    os.environ['SYSTEMROOT'] 系统主目录    os.environ['LOGONSERVER'] 机器名    os.environ['PROMPT'] 设置提示符     2、永久环境变量    操作 说明 功能     path = r\u0026quot;路径\u0026quot;\ncommand = r\u0026quot;setx WORK1 %s /m\u0026quot;%path\nos.system() /m 表示系统变量，不加/m表示用户变量     3、内部变量    操作 说明 功能     __doc__ 获取文件的注释    __file__ 获取当前文件的路径    __name__ 获取导入文件的路径加文件名称。当前文件，其值为__main__    __package__ 获取导入文件的路径。当前文件，其值为 None    __cached__     __builtins__ 内置函数在这里     实例：获取该执行文件的绝对路径：os.path.dirname(os.path.abspath(__file__))\n二、yield 带有yield函数在python中被称为generator。以菲波那切数列为例，介绍一下，yield的功能：\n 输出菲波那切数列list\n缺点：返回list，运行时占用的内存随着参数max的增大而增大，如果要控制内存，最好不要用list来存储中间结果，而是通过iterable对象来迭代。  def fab(max): n, a, b = 0, 0, 1 L = [] while n \u0026lt; max: L.append(b) a, b = b, a+b n = n + 1 return L iterable 的方法实现：通过next()函数不断返回数列的下一个数，内存占用始终未常数。\n缺点：不够简洁  class Fab(object): def __init__(self, max): self.max = max self.n, self.a, self.b = 0, 0, 1 def __iter__(self): return self def next(self): if self.n \u0026lt; self.max: r = self.b self.a, self.b = self.b, self.a+self.b self.n = self.n+1 return r raise StopIteration() # 调用 for n in Fab(5): print(n) 使用yield：yield把一个函数变成一个generator，调用fab()函数时不会执行该函数，而是返回一个iterable对象。在for循环执行时，每次循环都会执行fab函数内部的代码。  def fab(max): n, a, b = 0, 0, 1 while n \u0026lt; max: yield b a, b = b, a+b n = n+1 # 调用 for n in fab(5): print(n) 三、闭包 # 定义 def line_conf(a, b): def line(x): return a*x+b return line # 定义两条直线 line_a = line_conf(2,1) # y=2x+1 line_b = line_conf(3,2) # y=3x+2 print(line_conf().__closure__) # 闭包函数的属性   闭包函数的必要条件\n 闭包函数(例如：line_conf())，必须返回一个函数对象 闭包函数返回的函数对象(例如：line())，必须引用外部变量(一般不能是全局变量)，而返回的那个函数对象(例如：line())内部不一定要return    作用域分析\n 函数的作用域是由def关键词界定的，函数内的代码访问变量的方式是：从其所在层级由内向外寻找 函数属性：闭包函数将函数的唯一实例保存在它内部的__closure__属性中，在再次创建函数实例时，闭包检查函数实例已存在自己的属性中，不会再让它创建新的实例，而是将现有的实例返回。    四、装饰器  实例  # 定义 def a_new_decorator(a_func): def wrapTheFunction(): print(\u0026#39;I am doing some boring work before executing a_func()\u0026#39;) a_func() print(\u0026#39;I am doing some boring work after executing a_func()\u0026#39;) return wrapTheFunction def a_function_requiring_decoration(): print(\u0026#39;I am the function which needs some decoration to remove my foul smell.\u0026#39;) # 调用 a_function_requiring_decoration() # 结果：I am the function which needs some decoration to remove my foul smell. a_function_requiring_decoration = a_new_decorator(a_function_requiring_decoration) a_function_requiring_decoration() # 结果： # I am doing some boring work before executing a_func() # I am the function which needs some decoration to remove my foul smell. # I am doing some boring work after executing a_func() 用@简化代码\n缺点：print(a_function_requiring_decoration.name) 返回的是装饰器: wrapTheFunction  # 定义 def a_new_decorator(a_func): def wrapTheFunction(): print(\u0026#39;I am doing some boring work before executing a_func()\u0026#39;) a_func() print(\u0026#39;I am doing some boring work after executing a_func()\u0026#39;) return wrapTheFunction @a_new_decorator def a_function_requiring_decoration(): print(\u0026#39;I am the function which needs some decoration to remove my foul smell.\u0026#39;) # 调用 a_function_requiring_decoration() # 结果： # I am doing some boring work before executing a_func() # I am the function which needs some decoration to remove my foul smell. # I am doing some boring work after executing a_func() @蓝本 可以利用@wraps接受一个函数进行装饰，并加入复制函数名称、注释文档、参数列表等功能。  # 定义 from functools import wraps def a_new_decorator(a_func): @wraps(a_func) def wrapTheFunction(): print(\u0026#39;I am doing some boring work before executing a_func()\u0026#39;) a_func() print(\u0026#39;I am doing some boring work after executing a_func()\u0026#39;) return wrapTheFunction @a_new_decorator def a_function_requiring_decoration(): print(\u0026#39;I am the function which needs some decoration to remove my foul smell.\u0026#39;) # 调用 a_function_requiring_decoration() # 结果： # I am doing some boring work before executing a_func() # I am the function which needs some decoration to remove my foul smell. # I am doing some boring work after executing a_func() print(a_function_requiring_decoration.__name__) # 结果：a_function_requiring_decoration 五、内置函数   eval('字符串')：把字符串作为语句执行 作用：解析并执行字符串，并将返回结果输出。eval()函数将去掉字符串的两个引号，将其解释为一个变量。\n 1）单引号，双引号，eval()函数都将其解释为int类型；eval(\u0026lsquo;100\u0026rsquo;)，输出的是int类型。 2）三引号则解释为str类型。eval('\u0026ldquo;hello\u0026rdquo;')，输出的是字符串    input() : 键盘输入 作用：接收键盘的输入，返回的是字符串类型。 input和eval函数结合使用：\n 1）从键盘输入，接收一个字符串类型： a = input(\u0026lsquo;请输入一个字符串：') 2）从键盘输入，接收一个整型： a = eval(input(\u0026lsquo;请输入一个数字：'))    lambda 匿名函数\n格式：lambda[arg1[,arg2,\u0026hellip;,argN]] : 表达式 例如：test = lambda x, y: x+y\n  sorted 排序 b=sorted(a.items(), key=lambda item:item[0], reverse = True)\n a.items() 表示可迭代的tuple列表 key=lambda item:item[0]：按照key值排序; lambda x:x[0] reverse = True：降序排序    六、内置模块-os    操作 解释     os.path.basename()    os.path.dirname()    os.path.join()    os.path.exists() 判断该路径是否存在   os.path.isfile() 判断是不是文件   os.path.isdir() 判断是不是目录   os.path.abspath() 获取绝对路径\n例如：os.path.abspath(file)获取当前文件的绝对路径   os.listdir() 遍历该目录下的文件，返回文件名列表   os.walk() 遍历目录，返回一个三元组(root,dirs,files)\nroot: 指的是当前正在遍历的文件夹本身的目录\ndirs: 是一个list，内容是该文件夹中所有的目录的名字(不包含子目录)\nfiles: 是一个list，内容是该文件夹中所有的文件(不包括子目录)   os.makedirs 创建一个目录   os.remove 删除一个目录   os.environ 环境变量\n例如：获取环境变量：os.environ.get(\u0026lsquo;环境变量名\u0026rsquo;, \u0026lsquo;默认值\u0026rsquo;)    ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/python/internal_lib/advance_operator/","summary":"一、环境变量 1、临时环境变量    操作 说明 功能     os.environ['WORKON_HOME']=\u0026quot;变量\u0026quot; 设置环境变量    os.environ.get('WORKON_HOME') 获取环境变量-方法1    os.getenv('path') 获取环境变量-方法2-推荐    del os.environ['WORKON_HOME'] 删除环境变量         os.environ['HOMEPATH'] 当前用户主目录    os.environ['TEMP'] 临时目录路径    os.environ['PATHEXT'] 可以执行文件    os.environ['SYSTEMROOT'] 系统主目录    os.environ['LOGONSERVER'] 机器名    os.environ['PROMPT'] 设置提示符     2、永久环境变量    操作 说明 功能     path = r\u0026quot;路径\u0026quot;","tags":null,"title":"进阶操作"},{"categories":null,"contents":"在TensorFlow 2中使用兼容性模块，必须使用tf.compat.v1替换tf，并且在导入TensorFlow软件包后添加一行tf.compat.v1.disable_eager_execution()函数来关闭eager执行模式。\nimport tensorflow as tf tf.compat.v1.disable_eager_execution() 简介 数据流是一种编程模型，被广泛地应用于并行计算中。TF使用数据流图来表示计算中各个运算之间的关系，在数据流图中，节点：表示计算单元(即：操作tf.Operation)；边：表示被计算单元消费/生产的数据(即：tf.Tensor)。 数据流图，可以被导出成一个可移植的、编程语言不相关的表示(ProtoBuf)，这种表示可以被其他语言使用，来创建一个图并在会话中使用它。\ndef graph_demo(): a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[10, 0, 0], [0, 0.5, 0], [0, 0, 2]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) y = tf.add(tf.matmul(a, b), c, name=\u0026#39;result\u0026#39;) writer = tf.summary.FileWriter(os.path.join(root_dir, \u0026#39;log/matmul\u0026#39;), tf.get_default_graph()) writer.close() return y # 在终端启动TensorBoard对图进行可视化 tensorboard --logdir log/matmul  上例中创建一个数据流图，然后用TensorBoard对这个图进行可视化。\n tf.summary.FileWriter 创建了一个tf.summary.SummaryWriter来保存一个图像化表示，这个writer对象创建时，初始化参数包括：a.该图像化表示的存储路径；b.一个tf.Graph对象，可以使用tf.get_default_graph函数返回默认图 tf.get_default_graph 函数，返回默认图。   在执行时，调用TF API创建数据流图，这个阶段并没有进行计算。\n1、图-tf.Graph TF是一个C++库，我们只是用python来用简单的方式来构造数据流图，python简化了数据流图的描述阶段，因为它无须特意显示定义一个图，而是会默认一个tf.Graph。\n图的定义:\n 隐式定义：在我们用tf.*搭建一个图时，TensorFlow总是会定义一个默认的tf.Graph，可以通过tf.get_default_graph访问。隐式定义限制了TF的表示能力，因为它被限制只能使用一个图。 显式定义：可以显式地定义一个计算图，因此每个应用可以有多个图。这种方式的表现能力更强，但并不常用，因为需要多个图的应用不常见。 TF通过tf.Graph()创建一个tf.Graph对象，并通过as_default方法创建一个上下文管理器，每个上下文中定义的运算都被放进相应的图中。实际上，tf.Graph()对象定义了一个它所包含的tf.Operation对象的命名空间。 import tensorflow as tf def graph_define(): g1 = tf.Graph() g2 = tf.Graph() with g1.as_default(): a = tf.constant([[1, 2, 3], [3, 4, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[9, 0, 0], [0, 1, 0], [0, 0, 0.5]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) y = tf.add(tf.matmul(a, b), c, name=\u0026#39;result\u0026#39;) with g2.as_default(): with tf.name_scope(\u0026#39;scope_2\u0026#39;): x = tf.constant(1, name=\u0026#39;x\u0026#39;) print(x) # Tensor(\u0026#34;scope_2/x:0\u0026#34;, shape=(), dtype=int32) with tf.name_scope(\u0026#39;scope_3\u0026#39;): x = tf.constant(10, name=\u0026#39;x\u0026#39;) print(x) # Tensor(\u0026#34;scope_3/x:0\u0026#34;, shape=(), dtype=int32) y = tf.constant(12) z = x*y writer = tf.summary.FileWriter(os.path.join(root_dir, \u0026#39;log/two_graphs/g1\u0026#39;), g1) writer = tf.summary.FileWriter(os.path.join(root_dir, \u0026#39;log/two_graphs/g2\u0026#39;), g2) writer.close()   图的集合：\n每个tf.Graph，用集合机制 来存储与图结构相关的元数据，一个集合由一个键值唯一标识，其内容是一个对象/运算的列表。使用者通常不需要关注集合是否存在，因为它们是TF为了正确定义一个图所使用的。\n图中节点名：\n 后缀：图中每个节点的名字都是唯一的，如果有重复，为了避免重复，TF会添加:id形式的后缀。 在定义时如果没有指定节点的name，TF就会用Operation（操作）的名字来命名，输出的tf.Tensor和其相关的tf.Operation名字相同，只是可能会加上后缀。 前缀：可以通过tf.name_scope函数定义一个上下文，为该上下文中所有的运算添加命名范围前缀。  图中的计算：\n 作为一个C++库，TF数据类型是严格的静态类型，这意味着在图定义阶段必须知道每个运算/张量的类型，且参与运算的数据类型必须相同。 可以使用运算符重载，来简化一些常用的数学运算。运算符重载使得图定义更便捷，并且与tf.*的API调用完全等价，只是有一点：不能给运算指定名字。 y = tf.add(tf.matmul(A, x), b, name=\u0026#39;result\u0026#39;) # 等价 y = A @ x + b    运算符 操作名 运算符 操作名 运算符 操作名 运算符 操作名     __neg__ unary - __abs__ abs() __invert__ unary ~ __add__ binary +   __sub__ binary - __mul__ binary 元素* __floordiv__ binary // __truediv__ binary /   __mod__ binary % __pow__ binary ** __and__ binary \u0026amp; __or__ binary |   __xor__ binary ^ __le__ binary \u0026lt; __lt__ binary \u0026lt;= __gt__ binary \u0026gt;   __ge__ binary \u0026gt;= __matmul__ binary @            2、图放置-tf.device tf.device创建一个和设备相符的上下文管理器，这个函数运行使用者将同一个上下文下的所有运算放置在相同的设备上。tf.device指定的设备不仅仅是物理设备，它能指定远程服务器、远程设备、远程工作者、不同种类的物理设备(GPU、CPU、TPU)。\n 格式：/job:\u0026lt;JOB_NAME\u0026gt;/task:\u0026lt;TASK_INDEX\u0026gt;/device:\u0026lt;DEVICE_TYPE\u0026gt;:\u0026lt;DEVICE_INDEX\u0026gt;\n \u0026lt;JOB_NAME\u0026gt;：是一个由字母和数字构成的字符串，首个字符不能是数字 \u0026lt;TASK_INDEX\u0026gt;：是一个非负整数，代表在名为\u0026lt;JOB_NAME\u0026gt;的工作中的任务编号 \u0026lt;DEVICE_TYPE\u0026gt;：是一个已经注册过的设备类型(CPU或者GPU) \u0026lt;DEVICE_INDEX\u0026gt;：是一个非负整数，代表设备的索引号   def device_demo(): with tf.device(\u0026#39;/CPU:0\u0026#39;): a = tf.constant([[1, 2, 3], [3, 4, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[9, 0, 0], [0, 1, 0], [0, 0, 0.5]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) with tf.device(\u0026#39;/GPU:0\u0026#39;): mul = tf.matmul(a, b, name=\u0026#39;mul_result\u0026#39;) y = tf.add(mul, c, name=\u0026#39;add_result\u0026#39;) writer = tf.summary.FileWriter(os.path.join(root_dir, \u0026#39;log/device\u0026#39;), tf.get_default_graph()) writer.close() 3、图执行-tf.Session 静态图，图的定义与执行完全分离，在eager执行模式中不是这样。tf.Session：是一个TF提供的类，用来表示Python程序与C++运算库之间的联系，是唯一能直接与硬件通信、将运算放置到指定的设备上、使用本地和分布式TF运行库的类。它的主要目的：根据定义的图，具体地实现各个计算。 tf.Session对象是高度优化过的，一旦被正确构建，它会将tf.Graph缓存起来以加速其执行，tf.Session作为物理资源的拥有者，必须以一个文件描述符的方式来做下面的工作：\n 通过创建tf.Session来获取资源（等价于open操作系统调用） 使用这些资源（等价于在文件描述符上使用 读/写 操作） 使用tf.Session.close释放资源（通常会使用一个上下文管理器，不需要手动销毁释放资源）  1). tf.Session的三个参数 Session(target='', graph=None, config=None)\n  target：配置执行引擎 常见的场景：\n  使用当前的本地的硬件来执行图\nwith tf.Session() as sess: # 使用session去执行 某些操作 sess.run(...)   一些更复杂的场景：使用一个远程TensorFlow服务器，可以通过使用服务器的url(grpc://)来指定tf.Session的target参数\n# TensorFlow服务器的 ip和port ip = \u0026#39;192.168.1.90\u0026#39; port = \u0026#39;9877\u0026#39; with tf.Session(target=f\u0026#39;grpc://{ip}:{port}\u0026#39;) as sess: sess.run(...)     graph: 指定需要使用的图。tf.Session会使用默认的图对象，在需要运算多个图时，可以指定需要使用的图。tf.Session对象每次只能处理一个图。\n  config: 硬件/网络配置，这个配置通过tf.ConfigProto对象来指定，用来控制Session的行为。tf.ConfigProto比较复杂，选项也比较多，最常用的选项有下面两个：\n allow_soft_placement：当为True时：启动软设备安排，即：不是所有运算都会按照图定义的那样，被安排在指定的设备上。这是为了防止这种情况：比如GPU不存在，或者原来存在现在出了些问题，TensorFlow没有检测到该设备，就可以把指定给这个设备的运算，安排到其他正确的设备上。 gpu_options.allow_growth：当为True时：会改变GPU显存分配器的工作方式。分配器默认的工作方式：tf.Session被创建时就会分配所有可用的GPU显存。当allow_growth=True时，分配器会以逐步递增的方式分配显存。这是为了适应这种情况：在研究环境下，GPU资源是共享的，当一个tf.Session执行时，不能占用所有资源，其他人也还在使用。 per_process_gpu_memory_fraction：手动限定显存的使用量 log_device_placement：当为True时，会获取Operations和Tensor被指派到的设备号，在终端会打印出各个操作是在那些设备上运行的。  config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True) config.gpu_options.allow_growth=True config.gpu_options.per_process_gpu_memory_fraction = 0.4 #占用40%显存 with tf.Session(config=config) as sess: # 使用session去执行 某些操作 sess.run(...)   2). sess.run() sess.run(y)的工作方式如下：\n y是一个运算的输出节点，回溯y的输入 递归的回溯所有节点，直到无法找到父节点 评估输入 跟踪依赖图：分析各个节点的关系 执行计算  feed_dict：可以把外部的数据，注入计算图中，相当于重写计算图里的某个值。跟tf.placeholder配合使用，完成外部的数据流入计算图。 tf.placeholder：重写运算符。其创建的目的就是：当外面的值没有注入图中时，就会抛出一个错误。\ndef session_demo(): a = tf.constant([[1, 2, 3], [3, 4, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[9, 0, 0], [0, 1, 0], [0, 0, 0.5]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) y = tf.add(tf.matmul(a, b), c, name=\u0026#39;result\u0026#39;) with tf.Session() as sess: a_value, b_value, c_value = sess.run([a, b, c]) y_value = sess.run(y) # 重写 y_new = sess.run(y, feed_dict={c: np.zeros((1, 3))}) print(f\u0026#39;a: {a_value}\\nb: {b_value}\\nc: {c_value}\\ny: {y_value}\u0026#39;) print(f\u0026#39;y_new: {y_new}\u0026#39;) 4、图中的变量 一个变量是一个tf.Variable对象，用于维护图的状态，作为图中其他节点的输入。tf.Tensor和tf.Variable对象可以用相同的方式使用，不过tf.Variable拥有更多的属性：\n 一个变量必须要被初始化 一个变量默认被加到全局变量和可训练变量集合中  1. 变量声明 声明变量的两种方式：需要(type, shape)\n  tf.Variable：是一个类，创建一个变量，同时它需要指定一个初始值。\n变量的赋值，可以使用assign函数：比如：w.assign(w+0.1)等价于w.assign_add(0.1)。其实，变量的初始化操作，就是把初始值assign给每个变量。\n tf.Variable是一个类\n__init__( initial_value=None,\ntrainable=True, # 是否可训练\ncollections=None,\nvalidate_shape=True,\ncaching_device=None,\nname=None,\nvariable_def=None,\ndtype=None,\nexpected_shape=None,\nimport_scope=None,\nconstraint=None)\n size_in = 100 size_out = 100 # w的初始值是有tf.truncated_normal运算产生，服从正太分布N(0, 0.1) w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\u0026#39;w\u0026#39;) # b的初始值是有tf.constant运算产生的常量来初始化 b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\u0026#39;b\u0026#39;) with tf.Session() as sess: # 变量的初始化 sess.run(w.initializer)   tf.get_variable：更复杂，但拥有更强的表现能力。例如：如果我们需要变量共享，就不能使用tf.Variable定义，只能使用tf.get_variable。tf.get_variable和tf.variable_scope一起使用，通过它的reuse参数，实现tf.get_variable的变量共享能力。其中，tf.get_variable不受tf.name_scope的影响。 TensorFlow提供的tf.layers模块，包含了几乎所有常用的层，这些层内部都是用tf.get_variable来定义的，因此，这些层可以和tf.variable_scope一起使用来共享它们的变量。\n tf.get_variable是一个函数：\n(\nname,\nshape=None,\ndtype=None,\ninitializer=None,\nregularizer=None,\ntrainable=True,\ncollections=None,\ncaching_device=None,\npartitioner=None,\nvalidate_shape=None,\nuse_resource=None,\ncustom_getter=None,\nconstraint=None\n)\n with tf.variable_scope(\u0026#39;scope\u0026#39;): a = tf.get_variable(\u0026#39;v\u0026#39;, [1]) with tf.variable_scope(\u0026#39;scope\u0026#39;, reuse=True): b = tf.get_variable(\u0026#39;v\u0026#39;, [1]) print(a.name, b.name) # scope/v:0 scope/v:0   2. 变量初始化 TensorFlow变量随机初始化，例如：w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name='w') 常见的随机函数：\n   操作 功能     tf.random_normal() 正态分布，参数:(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)   tf.truncated_normal 正态分布，但如果随机出来的值偏离平均值超过了2个标准差，那么这个数将会被重新随机, 参数如上   tf.random_uniform 平均分布，参数：([m, n], 最小值, 最大值, 取值类型)   tf.random.gamma Gamma分布，参数：([m, n], 形状参数 $\\alpha$，尺度参数 $\\beta$, 取数类型)   常数函数    tf.zeros() 参数：(shape, dtype=tf.float32, name=None)， shape的格式: [m, n]   tf.ones() 参数：(shape, dtype=tf.float32, name=None), shape的格式: [m, n]   tf.fill() 参数：(shape, value, name=None), shape的格式: [m, n]   tf.constant() 参数：(value, dtype=None, shape=None, name=\u0026lsquo;Const\u0026rsquo;, verify_shape=False)例如：tf.constant([1, 2, 3, 4, 5, 6, 7]) =\u0026gt; [1 2 3 4 5 6 7]tensor = tf.constant(-1.0, shape=[2, 3]) =\u0026gt; [[-1. -1. -1.],[-1. -1. -1.]]   tf.range() 参数：tf.range(start, limit, delta)   tf.linspace() 参数：(start, stop, num) 功能： (stop - start)/(num - 1)      传入初始值\n 在session中执行时，变量必须要初始化：\na. 全部变量初始化： tf.global_variables_initializers():其实内部实现：=tf.variabels_initializer(tf.global_variables())\nb. 部分变量初始化：tf.variables_initializer([变量])\nc. 检查变量是否初始化成功：tf.is_variable_initialized：检查变量是否初始化；tf.report_uninitialized_variables：获取未初始化的变量集合；tf.assert_variables_initialized：断言变量已经初始化。\n with tf.Session() as sess: sess.run(tf.global_variable_initializer()) # 初始化所有变量   从checkpoint文件中恢复变量的值\n当我们创建Saver实例时，它的构造方法会向当前的数据流图中添加一对操作：SaveOp和RestoreOp\n  SaveOp负责向checkpoint文件中写入变量\nsaver = tf.train.Saver() saver.save(sess, \u0026#39;/tmp/summary/test.ckpt\u0026#39;)   RestoreOp负责从checkpoint文件中恢复变量\nsaver = tf.train.Saver() saver.restore(sess, \u0026#39;/tmp/summary/test.ckpt\u0026#39;)     3. 变量的访问  通过在tf.global_variable()变量表中，根据变量名进行匹配查找  x = tf.Variable(1,name=\u0026#39;x\u0026#39;) y = tf.get_variable(name=\u0026#39;y\u0026#39;,shape=[1,2]) for var in tf.global_variables(): #返回全部变量列表 if var.name == \u0026#39;x:0\u0026#39;: print(var) 利用tf.get_tensor_by_name，在图中根据name查找  import tensorflow as tf x = tf.Variable(1,name=\u0026#39;x\u0026#39;) y = tf.get_variable(name=\u0026#39;y\u0026#39;,shape=[1,2]) graph = tf.get_default_graph() x1 = graph.get_tensor_by_name(\u0026#34;x:0\u0026#34;) y1 = graph.get_tensor_by_name(\u0026#34;y:0\u0026#34;) ","date":"September 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/programming_language/tf/compat/tf_compat_summary/","summary":"在TensorFlow 2中使用兼容性模块，必须使用tf.compat.v1替换tf，并且在导入TensorFlow软件包后添加一行tf.compat.v1.disable_eager_execution()函数来关闭eager执行模式。\nimport tensorflow as tf tf.compat.v1.disable_eager_execution() 简介 数据流是一种编程模型，被广泛地应用于并行计算中。TF使用数据流图来表示计算中各个运算之间的关系，在数据流图中，节点：表示计算单元(即：操作tf.Operation)；边：表示被计算单元消费/生产的数据(即：tf.Tensor)。 数据流图，可以被导出成一个可移植的、编程语言不相关的表示(ProtoBuf)，这种表示可以被其他语言使用，来创建一个图并在会话中使用它。\ndef graph_demo(): a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[10, 0, 0], [0, 0.5, 0], [0, 0, 2]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) y = tf.add(tf.matmul(a, b), c, name=\u0026#39;result\u0026#39;) writer = tf.summary.FileWriter(os.path.join(root_dir, \u0026#39;log/matmul\u0026#39;), tf.get_default_graph()) writer.close() return y # 在终端启动TensorBoard对图进行可视化 tensorboard --logdir log/matmul  上例中创建一个数据流图，然后用TensorBoard对这个图进行可视化。\n tf.summary.FileWriter 创建了一个tf.summary.SummaryWriter来保存一个图像化表示，这个writer对象创建时，初始化参数包括：a.该图像化表示的存储路径；b.一个tf.Graph对象，可以使用tf.get_default_graph函数返回默认图 tf.get_default_graph 函数，返回默认图。   在执行时，调用TF API创建数据流图，这个阶段并没有进行计算。","tags":null,"title":"静态图"},{"categories":["Basic"],"contents":"官方文档\n线上工具\n一、基础篇 1. 输入公式   行内公式： 格式：$数学公式$ 例如：$x^2=1$ :  $x^2=1$\n  行间公式：\n$$\n数学公式\n$$\n例如: $$f(x)=\\int_{-\\infty}^\\infty\\widehat f\\xi\\ e^{2\\pi i\\xi x}\\ d\\xi$$ $$f(x)=\\int_{-\\infty}^\\infty\\widehat f\\xi\\ e^{2\\pi i\\xi x}\\ d\\xi$$\n  二、进阶篇 1. 声调/变音符号 \\dot{a}, \\ddot{a}, \\acute{a}, \\grave{a}\n$\\dot{a}, \\ddot{a}, \\acute{a}, \\grave{a}$\n\\check{a}, \\breve{a}, \\tilde{a}, \\bar{a}\n$\\check{a}, \\breve{a}, \\tilde{a}, \\bar{a}$\n\\hat{a}, \\widehat{a}, \\vec{a}, \\tilde{a}, \\widetilde{a}\n$\\hat{a}, \\widehat{a}, \\vec{a}, \\tilde{a}, \\widetilde{a}$\na', a'' \n$a', a''$\n2. 标准函数   指数/上下标\n 指数：\\exp_a b = a^b, \\exp b = e^b, 10^m\n$\\exp_a b = a^b, \\exp b = e^b, 10^m$ 前置上下标：{}_1^2\\!X_3^4\n${}_1^2!X_3^4$ 导数：x', \\dot{x}, \\ddot{y}\n$x', \\dot{x}, \\ddot{y}$    对数\n\\ln c, \\lg d = \\log e, \\log_{10} f\n$\\ln c, \\lg d = \\log e, \\log_{10} f$\n  三角函数\n \\sin a, \\cos b, \\tan c, \\cot d, \\sec e, \\csc f\n$\\sin{a}, \\cos b, \\tan c, \\cot d, \\sec e, \\csc f$ \\arcsin a, \\arccos b, \\arctan c\n$\\arcsin a, \\arccos b, \\arctan c$    绝对值\n \\left\\vert s \\right\\vert\n$\\left\\vert s \\right\\vert$ \\lVert z \\rVert\n$\\lVert z \\rVert$    最大值/最小值\n\\min(x,y), \\max(x,y)\n$\\min(x,y), \\max(x,y)$\n  3. 界限/极限 \\min x, \\max y, \\inf s, \\sup t, \n$\\min x, \\max y, \\inf s, \\sup t$\n\\lim_{x \\to \\infty} \\frac{1}{n(n+1)}\n$\\lim_{x \\to \\infty} \\frac{1}{n(n+1)}$\n4. 微分/导数 dt, \\mathrm{d}t, \\partial t, \\nabla\\psi\n$dt, \\mathrm{d}t, \\partial t, \\nabla\\psi$\ndy/dx, \\mathrm{d}y/\\mathrm{d}x\n$dy/dx, \\mathrm{d}y/\\mathrm{d}x$\n\\frac{dy}{dx}, \\frac{\\mathrm{d}y}{\\mathrm{d}x}, \\frac{\\partial^2}{\\partial x_1\\partial x_2}y\n$\\frac{dy}{dx}, \\frac{\\mathrm{d}y}{\\mathrm{d}x}, \\frac{\\partial^2}{\\partial x_1\\partial x_2}y$\n\\prime, \\backprime, f^\\prime, f', f'', f^{(3)}, \\dot y, \\ddot y\n$\\prime, \\backprime, f^\\prime, f', f'', f^{(3)}, \\dot y, \\ddot y$\n5. 根号/分数 \\surd, \\sqrt{2}, \\sqrt[n]{}, \\sqrt[3]{\\frac{x^3+y^3}{2}}\n$\\surd, \\sqrt{2}, \\sqrt[n]{}, \\sqrt[3]{\\frac{x^3+y^3}{2}}$\n6. 运算符            $\\sum$ \\sum $\\prod$ \\prod $\\bigotimes$ \\bigotimes $\\bigvee$ \\bigvee   $\\int$ \\int $\\coprod$ \\coprod $\\bigoplus$ \\bigoplus $\\bigwedge$ \\bigwedge   $\\iint$ \\iint $\\intop$ \\intop $\\bigodot$ \\bigodot $\\bigcap$ \\bigcap   $\\iiint$ \\iiint $\\smallint$ \\smallint $\\biguplus$ \\biguplus $\\bigcup$ \\bigcup   $\\oint$ \\oint $\\oiint$ \\oiint $\\oiiint$ \\oiiint $\\bigsqcup$ \\bigsqcup         $+$ + $\\cdot$ \\cdot $\\gtrdot$ \\gtrdot $x \\pmod a$ x \\pmod a   $-$ - $\\cdotp$ \\cdotp $\\intercal$ \\intercal $x \\pod a$ x \\pod a   $/$ / $\\centerdot$ \\centerdot $\\land$ \\land $\\rhd$ \\rhd   $*$ * $\\circ$ \\circ $\\leftthreetimes$ \\leftthreetimes $\\rightthreetimes$ \\rightthreetimes   $\\amalg$ \\amalg $\\circledast$ \\circledast $\\ldotp$ \\ldotp $\\rtimes$ \\rtimes   $\\And$ \\And $\\circledcirc$ \\circledcirc $\\lor$ \\lor $\\setminus$ \\setminus   $\\ast$ \\ast $\\circleddash$ \\circleddash $\\lessdot$ \\lessdot $\\smallsetminus$ \\smallsetminus   $\\barwedge$ \\barwedge $\\Cup$ \\Cup $\\lhd$ \\lhd $\\sqcap$ \\sqcap   $\\bigcirc$ \\bigcirc $\\cup$ \\cup $\\ltimes$ \\ltimes $\\sqcup$ \\sqcup   $\\bmod$ \\bmod $\\curlyvee$ \\curlyvee $x \\mod a$ x\\mod a $\\times$ \\times   $\\boxdot$ \\boxdot $\\curlywedge$ \\curlywedge $\\mp$ \\mp $\\unlhd$ \\unlhd   $\\boxminus$ \\boxminus $\\div$ \\div $\\odot$ \\odot $\\unrhd$ \\unrhd   $\\boxplus$ \\boxplus $\\divideontimes$ \\divideontimes $\\ominus$ \\ominus $\\uplus$ \\uplus   $\\boxtimes$ \\boxtimes $\\dotplus$ \\dotplus $\\oplus$ \\oplus $\\vee$ \\vee   $\\bullet$ \\bullet $\\doublebarwedge$ \\doublebarwedge $\\otimes$ \\otimes $\\veebar$ \\veebar   $\\Cap$ \\Cap $\\doublecap$ \\doublecap $\\oslash$ \\oslash $\\wedge$ \\wedge   $\\cap$ \\cap $\\doublecup$ \\doublecup $\\pm$ \\pm or \\plusmn $\\wr$ \\wr    直接输入: $∫ ∬ ∭ ∮ ∏ ∐ ∑ ⋀ ⋁ ⋂ ⋃ ⨀ ⨁ ⨂ ⨄ ⨆$ ∯ ∰\n$+ - / * ⋅ ± × ÷ ∓ ∔ ∧ ∨ ∩ ∪ ≀ ⊎ ⊓ ⊔ ⊕ ⊖ ⊗ ⊘ ⊙ ⊚ ⊛ ⊝ ◯$\n7. 关系符号 =, \\ne, \\neq, \\equiv, \\not\\equiv\n$=, \\ne, \\neq, \\equiv, \\not\\equiv$\n\\doteq, \\doteqdot, \\overset{\\underset{\\mathrm{def}}{}}{=}\n$\\doteq, \\doteqdot, \\overset{\\underset{\\mathrm{def}}{}}{=}$\n\\sim, \\nsim, \\backsim, \\thicksim, \\simeq, \\backsimeq, \\eqsim, \\cong, \\ncong\n$\\sim, \\nsim, \\backsim, \\thicksim, \\simeq, \\backsimeq, \\eqsim, \\cong, \\ncong$\n\\approx, \\thickapprox, \\approxeq, \\asymp, \\propto, \\varpropto\n$\\approx, \\thickapprox, \\approxeq, \\asymp, \\propto, \\varpropto$\n\u0026lt;, \\nless, \\ll, \\not\\ll, \\lll, \\not\\lll, \\lessdot\n$\u0026lt;, \\nless, \\ll, \\not\\ll, \\lll, \\not\\lll, \\lessdot$\n\u0026gt;, \\ngtr, \\gg, \\not\\gg, \\ggg, \\not\\ggg, \\gtrdot\n$\u0026gt;, \\ngtr, \\gg, \\not\\gg, \\ggg, \\not\\ggg, \\gtrdot$\n\\le, \\leq, \\lneq, \\leqq, \\nleq, \\nleqq, \\lneqq, \\lvertneqq\n$\\le, \\leq, \\lneq, \\leqq, \\nleq, \\nleqq, \\lneqq, \\lvertneqq$\n\\ge, \\geq, \\gneq, \\geqq, \\ngeq, \\ngeqq, \\gneqq, \\gvertneqq\n$\\ge, \\geq, \\gneq, \\geqq, \\ngeq, \\ngeqq, \\gneqq, \\gvertneqq$\n\\leqslant, \\nleqslant, \\eqslantless\n$\\leqslant, \\nleqslant, \\eqslantless$\n\\geqslant, \\ngeqslant, \\eqslantgtr\n$\\geqslant, \\ngeqslant, \\eqslantgtr$\n\\lesssim, \\lnsim, \\lessapprox, \\lnapprox\n$\\lesssim, \\lnsim, \\lessapprox, \\lnapprox$\n\\gtrsim, \\gnsim, \\gtrapprox, \\gnapprox\n$\\gtrsim, \\gnsim, \\gtrapprox, \\gnapprox$\n8. 集合 \\empty \\emptyset, \\varnothing\n$\\empty, \\emptyset, \\varnothing$\n\\in, \\notin \\not\\in, \\ni, \\not\\ni\n$\\in, \\notin \\not\\in, \\ni, \\not\\ni$\n\\cap, \\Cap, \\sqcap, \\bigcap\n$\\cap, \\Cap, \\sqcap, \\bigcap$\n\\cup, \\Cup, \\sqcup, \\bigcup, \\bigsqcup, \\uplus, \\biguplus\n$\\cup, \\Cup, \\sqcup, \\bigcup, \\bigsqcup, \\uplus, \\biguplus$\n\\subset, \\Subset, \\sqsubset\n$\\subset, \\Subset, \\sqsubset$\n\\supset, \\Supset, \\sqsupset\n$\\supset, \\Supset, \\sqsupset$\n\\subseteq, \\nsubseteq, \\subsetneq, \\varsubsetneq, \\sqsubseteq\n$\\subseteq, \\nsubseteq, \\subsetneq, \\varsubsetneq, \\sqsubseteq$\n\\supseteq, \\nsupseteq, \\supsetneq, \\varsupsetneq, \\sqsupseteq\n$\\supseteq, \\nsupseteq, \\supsetneq, \\varsupsetneq, \\sqsupseteq$\n\\subseteqq, \\nsubseteqq, \\subsetneqq, \\varsubsetneqq\n$\\subseteqq, \\nsubseteqq, \\subsetneqq, \\varsubsetneqq$\n\\supseteqq, \\nsupseteqq, \\supsetneqq, \\varsupsetneqq\n$\\supseteqq, \\nsupseteqq, \\supsetneqq, \\varsupsetneqq$\n9. 几何符号           % comment $\\dots$ \\dots $\\KaTeX$ \\KaTeX   $\\%$ \\\\% $\\cdots$ \\cdots $\\LaTeX$ \\LaTeX   $\\#$ \\\\# $\\ddots$ \\ddots $\\TeX$ \\TeX   $\\\u0026amp;$ \\\\\u0026amp; $\\ldots$ \\ldots $\\nabla$ \\nabla   $\\_$ \\\\_ $\\vdots$ \\vdots $\\infty$ \\infty   $\\text{\\textunderscore}$ \\text{\\textunderscore} $\\dotsb$ \\dotsb $\\infin$ \\infin   $\\text{\u0026ndash;}$ \\text{--} $\\dotsc$ \\dotsc $\\checkmark$ \\checkmark   $\\text{\\textendash}$ \\text{\\textendash} $\\dotsi$ \\dotsi $\\dag$ \\dag   $\\text{\u0026mdash;}$ \\text{---} $\\dotsm$ \\dotsm $\\dagger$ \\dagger   $\\text{\\textemdash}$ \\text{\\textemdash} $\\dotso$ \\dotso $\\text{\\textdagger}$ \\text{\\textdagger}   $\\text{\\textasciitilde}$ \\text{\\textasciitilde} $\\sdot$ \\sdot $\\ddag$ \\ddag   $\\text{\\textasciicircum}$ \\text{\\textasciicircum} $\\mathellipsis$ \\mathellipsis $\\ddagger$ \\ddagger    $\\text{\\textellipsis}$ \\text{\\textellipsis} $\\text{\\textdaggerdbl}$ \\text{\\textdaggerdbl}   $\\text{\\textquoteleft}$ text{\\textquoteleft} $\\Box$ \\Box $\\Dagger$ \\Dagger   $\\lq$ \\lq $\\square$ \\square $\\angle$ \\angle   $\\text{\\textquoteright}$ \\text{\\textquoteright} $\\blacksquare$ \\blacksquare $\\measuredangle$ \\measuredangle   $\\rq$ \\rq $\\triangle$ \\triangle $\\sphericalangle$ \\sphericalangle   $\\text{\\textquotedblleft}$ \\text{\\textquotedblleft} $\\triangledown$ \\triangledown $\\top$ \\top   $\u0026quot;$ \u0026quot; $\\triangleleft$ \\triangleleft $\\bot$ \\bot   $\\text{\\textquotedblright}$ \\text{\\textquotedblright} $\\triangleright$ \\triangleright $$$ \\$   $\\colon$ \\colon $\\bigtriangledown$ \\bigtriangledown $\\text{\\textdollar}$ \\text{\\textdollar}   $\\backprime$ \\backprime $\\bigtriangleup$ \\bigtriangleup $\\pounds$ \\pounds   $\\prime$ \\prime $\\blacktriangle$ \\blacktriangle $\\mathsterling$ \\mathsterling   $\\text{\\textless}$ \\text{\\textless} $\\blacktriangledown$ \\blacktriangledown $\\text{\\textsterling}$ \\text{\\textsterling}   $\\text{\\textgreater}$ \\text{\\textgreater} $\\blacktriangleleft$ \\blacktriangleleft $\\yen$ \\yen   $\\text{\\textbar}$ \\text{\\textbar} $\\blacktriangleright$ \\blacktriangleright $\\surd$ \\surd   $\\text{\\textbardbl}$ \\text{\\textbardbl} $\\diamond$ \\diamond $\\degree$ \\degree   $\\text{\\textbraceleft}$ \\text{\\textbraceleft} $\\Diamond$ \\Diamond $\\text{\\textdegree}$ \\text{\\textdegree}   $\\text{\\textbraceright}$ \\text{\\textbraceright} $\\lozenge$ \\lozenge $\\mho$ \\mho   $\\text{\\textbackslash}$ \\text{\\textbackslash} $\\blacklozenge$ \\blacklozenge $\\diagdown$ \\diagdown   $\\text{\\P}$ \\text{\\P} or \\P $\\star$ \\star $\\diagup$ \\diagup   $\\text{\\S}$ \\text{\\S} or \\S $\\bigstar$ \\bigstar $\\flat$ \\flat   $\\text{\\sect}$ \\text{\\sect} $\\clubsuit$ \\clubsuit $\\natural$ \\natural   $\\copyright$ \\copyright $\\clubs$ \\clubs $\\sharp$ \\sharp   $\\circledR$ \\circledR $\\diamondsuit$ \\diamondsuit $\\heartsuit$ \\heartsuit   $\\text{\\textregistered}$ \\text{\\textregistered} $\\diamonds$ \\diamonds $\\hearts$ \\hearts   $\\circledS$ \\circledS $\\spadesuit$ \\spadesuit $\\spades$ \\spades   $\\text{\\textcircled a}$ \\text{\\textcircled a} $\\maltese$ \\maltese     Direct Input: § ¶ $ £ ¥ ∇ ∞ · ∠ ∡ ∢ ♠ ♡ ♢ ♣ ♭ ♮ ♯ ✓ … ⋮ ⋯ ⋱ !$ ‼ ⦵\n10. 逻辑符号 \\forall, \\exists, \\nexists\n$\\forall, \\exists, \\nexists$\n\\therefore, \\because, \\And\n$\\therefore, \\because, \\And$\n\\lor, \\vee, \\curlyvee, \\bigvee\n$\\lor, \\vee, \\curlyvee, \\bigvee$\n\\land, \\wedge, \\curlywedge, \\bigwedge\n$\\land, \\wedge, \\curlywedge, \\bigwedge$\n\\bar{q}, \\bar{abc}, \\overline{q}, \\overline{abc}, \\lnot \\neg, \\not\\operatorname{R}, \\bot, \\top\n$\\bar{q}, \\bar{abc}, \\overline{q}, \\overline{abc}, \\lnot \\neg, \\not\\operatorname{R}, \\bot, \\top$\n11. 箭头           $\\circlearrowleft$ \\circlearrowleft $\\leftharpoonup$ \\leftharpoonup $\\rArr$ \\rArr   $\\circlearrowright$ \\circlearrowright $\\leftleftarrows$ \\leftleftarrows $\\rarr$ \\rarr   $\\curvearrowleft$ \\curvearrowleft $\\leftrightarrow$ \\leftrightarrow $\\restriction$ \\restriction   $\\curvearrowright$ \\curvearrowright $\\Leftrightarrow$ \\Leftrightarrow $\\rightarrow$ \\rightarrow   $\\Darr$ \\Darr $\\leftrightarrows$ \\leftrightarrows $\\Rightarrow$ \\Rightarrow   $\\dArr$ \\dArr $\\leftrightharpoons$ \\leftrightharpoons $\\rightarrowtail$ \\rightarrowtail   $\\darr$ \\darr $\\leftrightsquigarrow$ \\leftrightsquigarrow $\\rightharpoondown$ \\rightharpoondown   $\\dashleftarrow$ \\dashleftarrow $\\Lleftarrow$ \\Lleftarrow $\\rightharpoonup$ \\rightharpoonup   $\\dashrightarrow$ \\dashrightarrow $\\longleftarrow$ \\longleftarrow $\\rightleftarrows$ \\rightleftarrows   $\\downarrow$ \\downarrow $\\Longleftarrow$ \\Longleftarrow $\\rightleftharpoons$ \\rightleftharpoons   $\\Downarrow$ \\Downarrow $\\longleftrightarrow$ \\longleftrightarrow $\\rightrightarrows$ \\rightrightarrows   $\\downdownarrows$ \\downdownarrows $\\Longleftrightarrow$ \\Longleftrightarrow $\\rightsquigarrow$ \\rightsquigarrow   $\\downharpoonleft$ \\downharpoonleft $\\longmapsto$ \\longmapsto $\\Rrightarrow$ \\Rrightarrow   $\\downharpoonright$ \\downharpoonright $\\longrightarrow$ \\longrightarrow $\\Rsh$ \\Rsh   $\\gets$ \\gets $\\Longrightarrow$ \\Longrightarrow $\\searrow$ \\searrow   $\\Harr$ \\Harr $\\looparrowleft$ \\looparrowleft $\\swarrow$ \\swarrow   $\\hArr$ \\hArr $\\looparrowright$ \\looparrowright $\\to$ \\to   $\\harr$ \\harr $\\Lrarr$ \\Lrarr $\\twoheadleftarrow$ \\twoheadleftarrow   $\\hookleftarrow$ \\hookleftarrow $\\lrArr$ \\lrArr $\\twoheadrightarrow$ \\twoheadrightarrow   $\\hookrightarrow$ \\hookrightarrow $\\lrarr$ \\lrarr $\\Uarr$ \\Uarr   $\\iff$ \\iff $\\Lsh$ \\Lsh $\\uArr$ \\uArr   $\\impliedby$ \\impliedby $\\mapsto$ \\mapsto $\\uarr$ \\uarr   $\\implies$ \\implies $\\nearrow$ \\nearrow $\\uparrow$ \\uparrow   $\\Larr$ \\Larr $\\nleftarrow$ \\nleftarrow $\\Uparrow$ \\Uparrow   $\\lArr$ \\lArr $\\nLeftarrow$ \\nLeftarrow $\\updownarrow$ \\updownarrow   $\\larr$ \\larr $\\nleftrightarrow$ \\nleftrightarrow $\\Updownarrow$ \\Updownarrow   $\\leadsto$ \\leadsto $\\nLeftrightarrow$ \\nLeftrightarrow $\\upharpoonleft$ \\upharpoonleft   $\\leftarrow$ \\leftarrow $\\nrightarrow$ \\nrightarrow $\\upharpoonright$ \\upharpoonright   $\\Leftarrow$ \\Leftarrow $\\nRightarrow$ \\nRightarrow $\\upuparrows$ \\upuparrows   $\\leftarrowtail$ \\leftarrowtail $\\nwarrow$ \\nwarrow    $\\leftharpoondown$ \\leftharpoondown $\\Rarr$ \\Rarr    $\\xleftarrow{abc}$ \\xleftarrow{abc} $\\xrightarrow[under]{over}$ \\xrightarrow[under]{over}    $\\xLeftarrow{abc}$ \\xLeftarrow{abc} $\\xRightarrow{abc}$ \\xRightarrow{abc}    $\\xleftrightarrow{abc}$ \\xleftrightarrow{abc} $\\xLeftrightarrow{abc}$ \\xLeftrightarrow{abc}    $\\xhookleftarrow{abc}$ \\xhookleftarrow{abc} $\\xhookrightarrow{abc}$ \\xhookrightarrow{abc}    $\\xtwoheadleftarrow{abc}$ \\xtwoheadleftarrow{abc} $\\xtwoheadrightarrow{abc}$ \\xtwoheadrightarrow{abc}    $\\xleftharpoonup{abc}$ \\xleftharpoonup{abc} $\\xrightharpoonup{abc}$ \\xrightharpoonup{abc}    $\\xleftharpoondown{abc}$ \\xleftharpoondown{abc} $\\xrightharpoondown{abc}$ \\xrightharpoondown{abc}    $\\xleftrightharpoons{abc}$ \\xleftrightharpoons{abc} $\\xrightleftharpoons{abc}$ \\xrightleftharpoons{abc}    $\\xtofrom{abc}$ \\xtofrom{abc} $\\xmapsto{abc}$ \\xmapsto{abc}    $\\xlongequal{abc}$ \\xlongequal{abc}      Direct Input: $← ↑ → ↓ ↔ ↕ ↖ ↗ ↘ ↙ ↚ ↛ ↞ ↠ ↢ ↣ ↦ ↩ ↪ ↫ ↬ ↭ ↮ ↰ ↱↶ ↷ ↺ ↻ ↼ ↽ ↾ ↾ ↿ ⇀ ⇁ ⇂ ⇃ ⇄ ⇆ ⇇ ⇈ ⇉ ⇊ ⇋ ⇌⇍ ⇎ ⇏ ⇐ ⇑ ⇒ ⇓ ⇔ ⇕ ⇚ ⇛ ⇝ ⇠ ⇢ ⟵ ⟶ ⟷ ⟸ ⟹ ⟺ ⟼$ ↽\n12. 上下标    功能 语法 效果     上标 a^2 $a^2$   下标 a_2 $a_2$   组合 a^{2+2} $a^{2+2}$   结合上下标 x_2^3 $x_2^3$   前置上下标 {}_1^2\\!X_3^4 ${}_1^2!X_3^4$   导数 x', \\dot{x}, \\ddot{x} $x', \\dot{x}, \\ddot{x}$   向量 \\vec{c}, \\overleftarrow{a b}, \\overrightarrow{c d}, \\overleftrightarrow{a b} $\\vec{c}, \\overleftarrow{a b}, \\overrightarrow{c d}, \\overleftrightarrow{a b}$   弧线 \\widehat{e f g}, \\overset{\\frown} {AB} $\\widehat{e f g}, \\overset{\\frown} {AB}$   上/下划线 \\overline{h i j}, \\underline{k l m} $\\overline{h i j}, \\underline{k l m}$   上括号 \\overbrace{1+2+\\cdots+100}\n\\begin{matrix} 5050 \\\\ \\overbrace{ 1+2+\\cdots+100 } \\end{matrix} $\\overbrace{1+2+\\cdots+100}$\n$\\begin{matrix} 5050 \\ \\overbrace{ 1+2+\\cdots+100 } \\end{matrix}$   下括号 \\underbrace{a+b+\\cdots+z}\n\\begin{matrix} \\underbrace{ a+b+\\cdots+z } \\\\ 26 \\end{matrix} $\\underbrace{a+b+\\cdots+z}$\n$\\begin{matrix} \\underbrace{ a+b+\\cdots+z } \\ 26 \\end{matrix}$   累加 \\sum_{k=1}^N k^2\n\\begin{matrix} \\sum_{k=1}^N k^2 \\end{matrix} $\\sum_{k=1}^N k^2$\n$\\begin{matrix} \\sum_{k=1}^N k^2 \\end{matrix}$   累加-格式 \\displaystyle\\sum_{\\substack{0\u0026lt;i\u0026lt;m\\\\\\\\0\u0026lt;j\u0026lt;n}}\\textstyle\\sum_{\\substack{0\u0026lt;i\u0026lt;m\\\\\\\\0\u0026lt;j\u0026lt;n}} $\\displaystyle\\sum_{\\substack{0\u0026lt;i\u0026lt;m\\\\0\u0026lt;j\u0026lt;n}}$$\\textstyle\\sum_{\\substack{0\u0026lt;i\u0026lt;m\\\\0\u0026lt;j\u0026lt;n}}$   累乘 \\prod_{i=1}^N x_i $\\prod_{i=1}^N x_i$   上积 \\coprod_{i=1}^N x_i $\\coprod_{i=1}^N x_i$   极限 \\lim_{n \\to \\infty}x_n $\\lim_{n \\to \\infty}x_n$   极限-格式 \\lim\\limits_{n \\to \\infty}x_n\\lim\\nolimits_{n \\to \\infty}x_n $\\lim\\limits_{n \\to \\infty}x_n$\n$\\lim\\nolimits_{n \\to \\infty}x_n$   积分 \\int_{-N}^{N} e^x\\, {\\rm d}x $\\int_{-N}^{N} e^x, {\\rm d}x$   双重积分 \\iint_{D}^{W} \\, \\mathrm{d}x\\,\\mathrm{d}y $\\iint_{D}^{W} , \\mathrm{d}x,\\mathrm{d}y$   三重积分 \\iiint_{E}^{V} \\, \\mathrm{d}x\\,\\mathrm{d}y\\,\\mathrm{d}z $\\iiint_{E}^{V} , \\mathrm{d}x,\\mathrm{d}y,\\mathrm{d}z$   闭合 \\oint_{C} x^3\\, \\mathrm{d}x + 4y^2\\, \\mathrm{d}y $\\oint_{C} x^3, \\mathrm{d}x + 4y^2, \\mathrm{d}y$   交集 \\bigcap_1^{n} p $\\bigcap_1^{n} p$   并集 \\bigcup_1^{k} p $\\bigcup_1^{k} p$    13. 分式 通常使用\\frac {分子} {分母} 来生成一个分数。如果分式比较复杂，也可以使用 分子 \\over 分母\n   功能 语法 效果     分数 \\frac{2}{4}=0.5 $\\frac{2}{4}=0.5$   小型分数 \\tfrac{2}{4} = 0.5 $\\tfrac{2}{4} = 0.5$   连分式 \\cfrac{2}{c + \\cfrac{2}{d + \\cfrac{2}{4}}} = a $\\cfrac{2}{c + \\cfrac{2}{d + \\cfrac{2}{4}}} = a$    \\binom{n}{k}, \\dbinom{n}{k}, \\tbinom{n}{k} $\\binom{n}{k}, \\dbinom{n}{k}, \\tbinom{n}{k}$    {n \\choose k}, {n\\brace k}, {n\\brack k} ${n \\choose k}, {n\\brace k}, {n\\brack k}$   二项式系数 \\dbinom{n}{r}=\\binom{n}{n-r}=\\mathrm{C}_n^r=\\mathrm{C}_n^{n-r} $\\dbinom{n}{r}=\\binom{n}{n-r}=\\mathrm{C}_n^r=\\mathrm{C}_n^{n-r}$   小型二项式系数 \\tbinom{n}{r}=\\tbinom{n}{n-r}=\\mathrm{C}_n^r=\\mathrm{C}_n^{n-r} $\\tbinom{n}{r}=\\tbinom{n}{n-r}=\\mathrm{C}_n^r=\\mathrm{C}_n^{n-r}$   大型二项式系数 \\binom{n}{r}=\\dbinom{n}{n-r}=\\mathrm{C}_n^r=\\mathrm{C}_n^{n-r} $\\binom{n}{r}=\\dbinom{n}{n-r}=\\mathrm{C}_n^r=\\mathrm{C}_n^{n-r}$    14. 矩阵    效果 语法 效果 语法     $\\begin{matrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{matrix}$ \\begin{matrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{matrix} $\\begin{array}{cc}a \u0026amp; b\\\\c \u0026amp; d\\end{array}$ \\begin{array}{cc}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{array}   $\\begin{pmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{pmatrix}$ \\begin{pmatrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{pmatrix} $\\begin{bmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{bmatrix}$ \\begin{bmatrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{bmatrix}   $\\begin{vmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{vmatrix}$ \\begin{vmatrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{vmatrix} $\\begin{Vmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{Vmatrix}$ \\begin{Vmatrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{Vmatrix}   $\\begin{Bmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{Bmatrix}$ \\begin{Bmatrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{Bmatrix} $\\def\\arraystretch{1.5}\\begin{array}{c:c:c} a \u0026amp; b \u0026amp; c \\\\ \\hline d \u0026amp; e \u0026amp; f \\\\ \\hdashline g \u0026amp; h \u0026amp; i \\end{array}$ \\def\\arraystretch{1.5}\n\\begin{array}{c:c:c}\na \u0026amp; b \u0026amp; c \\\\\\ \\hline\nd \u0026amp; e \u0026amp; f \\\\\\\n\\hdashline\ng \u0026amp; h \u0026amp; i\n\\end{array}   $x = \\begin{cases} a \u0026amp;\\text{if } b \\\\ c \u0026amp;\\text{if } d \\end{cases}$ x = \\begin{cases}\na \u0026amp;\\text{if } b \\\\\\\nc \u0026amp;\\text{if } d\n\\end{cases} 无效呢？ \\begin{rcases}\na \u0026amp;\\text{if } b \\\\\\\nc \u0026amp;\\text{if } d\n\\end{rcases}⇒…   $\\begin{smallmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{smallmatrix}$ \\begin{smallmatrix}\na \u0026amp; b \\\\\\\nc \u0026amp; d\n\\end{smallmatrix} $$\\sum_{\\begin{subarray}{l} i\\in\\Lambda\\\\ 0\u0026lt;j\u0026lt;n\\end{subarray}}$$ \\sum_{\n\\begin{subarray}{l}\ni\\in\\Lambda\\\\\\\n0\u0026lt;j\u0026lt;n\n\\end{subarray}}    15. 希腊字母 直接输入: $Α Β Γ Δ Ε Ζ Η Θ Ι \\allowbreak Κ Λ Μ Ν Ξ Ο Π Ρ Σ Τ Υ Φ Χ Ψ Ω$ $\\allowbreak α β γ δ ϵ ζ η θ ι κ λ μ ν ξ o π \\allowbreak ρ σ τ υ ϕ χ ψ ω ε ϑ ϖ ϱ ς φ ϝ$\n           $\\Alpha$ \\Alpha $\\Beta$ \\Beta $\\Gamma$ \\Gamma $\\Delta$ \\Delta   $\\Epsilon$ \\Epsilon $\\Zeta$ \\Zeta $\\Eta$ \\Eta $\\Theta$ \\Theta   $\\Iota$ \\Iota $\\Kappa$ \\Kappa $\\Lambda$ \\Lambda $\\Mu$ \\Mu   $\\Nu$ \\Nu $\\Xi$ \\Xi $\\Omicron$ \\Omicron $\\Pi$ \\Pi   $\\Rho$ \\Rho $\\Sigma$ \\Sigma $\\Tau$ \\Tau $\\Upsilon$ \\Upsilon   $\\Phi$ \\Phi $\\Chi$ \\Chi $\\Psi$ \\Psi $\\Omega$ \\Omega   $\\varGamma$ \\varGamma $\\varDelta$ \\varDelta $\\varTheta$ \\varTheta $\\varLambda$ \\varLambda   $\\varXi$ \\varXi $\\varPi$ \\varPi $\\varSigma$ \\varSigma $\\varUpsilon$ \\varUpsilon   $\\varPhi$ \\varPhi $\\varPsi$ \\varPsi $\\varOmega$ \\varOmega    $\\alpha$ \\alpha $\\beta$ \\beta $\\gamma$ \\gamma $\\delta$ \\delta   $\\epsilon$ \\epsilon $\\zeta$ \\zeta $\\eta$ \\eta $\\theta$ \\theta   $\\iota$ \\iota $\\kappa$ \\kappa $\\lambda$ \\lambda $\\mu$ \\mu   $\\nu$ \\nu $\\xi$ \\xi $\\omicron$ \\omicron $\\pi$ \\pi   $\\rho$ \\rho $\\sigma$ \\sigma $\\tau$ \\tau $\\upsilon$ \\upsilon   $\\phi$ \\phi $\\chi$ \\chi $\\psi$ \\psi $\\omega$ \\omega   $\\varepsilon$ \\varepsilon $\\varkappa$ \\varkappa $\\vartheta$ \\vartheta $\\thetasym$ \\thetasym   $\\varpi$ \\varpi $\\varrho$ \\varrho $\\varsigma$ \\varsigma $\\varphi$ \\varphi   $\\digamma $ \\digamma       Other Letters\n            $\\imath$ \\imath $\\nabla$ \\nabla $\\Im$ \\Im $\\Reals$ \\Reals $\\text{\\OE}$ \\text{\\OE}   $\\jmath$ \\jmath $\\partial$ \\partial $\\image$ \\image $\\wp$ \\wp $\\text{\\o}$ \\text{\\o}   $\\aleph$ \\aleph $\\Game$ \\Game $\\Bbbk$ \\Bbbk $\\weierp$ \\weierp $\\text{\\O}$ \\text{\\O}   $\\alef$ \\alef $\\Finv$ \\Finv $\\N$ \\N $\\Z$ \\Z $\\text{\\ss}$ \\text{\\ss}   $\\alefsym$ \\alefsym $\\cnums$ \\cnums $\\natnums$ \\natnums $\\text{\\aa}$ \\text{\\aa} $\\text{\\i}$ \\text{\\i}   $\\beth$ \\beth $\\Complex$ \\Complex $\\R$ \\R $\\text{\\AA}$ \\text{\\AA} $\\text{\\j}$ \\text{\\j}   $\\gimel$ \\gimel $\\ell$ \\ell $\\Re$ \\Re $\\text{\\ae}$ \\text{\\ae}    $\\daleth$ \\daleth $\\hbar$ \\hbar $\\real$ \\real $\\text{\\AE}$ \\text{\\AE}    $\\eth$ \\eth $\\hslash$ \\hslash $\\reals$ \\reals $\\text{\\oe}$ \\text{\\oe}     直接输入: $∂ ∇ ℑ Ⅎ ℵ ℶ ℷ ℸ ⅁ ℏ ð − ∗$ ÀÁÂÃÄÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖÙÚÛÜÝÞßàáâãäåçèéêëìíîïðñòóôöùúûüýþÿ\n16. 字体大小          $\\Huge AB$ \\Huge AB $\\normalsize AB$ \\normalsize AB   $\\huge AB$ \\huge AB $\\small AB$ \\small AB   $\\LARGE AB$ \\LARGE AB $\\footnotesize AB$ \\footnotesize AB   $\\Large AB$ \\Large AB $\\scriptsize AB$ \\scriptsize AB   $\\large AB$ \\large AB $\\tiny AB$ \\tiny AB    17. 颜色    语法 效果     \\color{blue} F=ma $\\color{blue} F=ma$   \\textcolor{blue}{F=ma} $\\textcolor{blue}{F=ma}$   \\textcolor{#228B22}{F=ma} $\\textcolor{#228B22}{F=ma}$   \\colorbox{aqua}{$F=ma$} $\\colorbox{aqua}{$F=ma$}$   \\fcolorbox{red}{aqua}{$F=ma$} $\\fcolorbox{red}{aqua}{$F=ma$}$    18. 字体           $\\mathrm{Ab0}$ \\mathrm{Ab0} $\\mathbf{Ab0}$ \\mathbf{Ab0} $\\mathit{Ab0}$ \\mathit{Ab0}   $\\mathnormal{Ab0}$ \\mathnormal{Ab0} $\\textbf{Ab0}$ \\textbf{Ab0} $\\textit{Ab0}$ \\textit{Ab0}   $\\textrm{Ab0}$ \\textrm{Ab0} $\\bf Ab0$ \\bf Ab0 $\\it Ab0$ \\it Ab0   $\\rm Ab0$ \\rm Ab0 $\\bold{Ab0}$ \\bold{Ab0} $\\textup{Ab0}$ \\textup{Ab0}   $\\textnormal{Ab0}$ \\textnormal{Ab0} $\\boldsymbol{Ab0}$ \\boldsymbol{Ab} $\\Bbb{AB}$ \\Bbb{AB}   $\\text{Ab0}$ \\text{Ab0} $\\bm{Ab0}$ \\bm{Ab0} $\\mathbb{AB}$ \\mathbb{AB}   $\\mathsf{Ab0}$ \\mathsf{Ab0} $\\textmd{Ab0}$ \\textmd{Ab0} $\\frak{Ab0}$ \\frak{Ab0}   $\\textsf{Ab0}$ \\textsf{Ab0} $\\mathtt{Ab0}$ \\mathtt{Ab0} $\\mathfrak{Ab0}$ \\mathfrak{Ab0}   $\\sf Ab0$ \\sf Ab0 $\\texttt{Ab0}$ \\texttt{Ab0} $\\mathcal{AB0}$ \\mathcal{AB0}    $\\tt Ab0$ \\tt Ab0 $\\cal AB0$ \\cal AB0     $\\mathscr{AB}$ \\mathscr{AB}    19. 括号             $(~)$ ( ) $\\lparen~\\rparen$ \\lparen\n$~~~~$\\rparen $⌈~⌉$ ⌈ ⌉ $\\lceil~\\rceil$ \\lceil\n$~~~~~$\\rceil $\\uparrow$ \\uparrow   $[~]$ [ ] $\\lbrack~\\rbrack$ \\lbrack\n$~~~~$\\rbrack $⌊~⌋$ ⌊ ⌋ $\\lfloor~\\rfloor$ \\lfloor\n$~~~~~$\\rfloor $\\downarrow$ \\downarrow   ${ }$ \\{ \\} $\\lbrace \\rbrace$ \\lbrace\n$~~~~$\\rbrace $⎰⎱$ ⎰⎱ $\\lmoustache \\rmoustache$ \\lmoustache\n$~~~~$\\rmoustache $\\updownarrow$ \\updownarrow   $⟨~⟩$ ⟨ ⟩ $\\langle~\\rangle$ \\langle\n$~~~~$\\rangle $⟮~⟯$ ⟮ ⟯ $\\lgroup~\\rgroup$ \\lgroup\n$~~~~~$\\rgroup $\\Uparrow$ \\Uparrow   $\\vert$ | $\\vert$ \\vert $┌ ┐$ ┌ ┐ $\\ulcorner \\urcorner$ \\ulcorner\n$~~~~$\\urcorner $\\Downarrow$ \\Downarrow   $\\Vert$ \\| $\\Vert$ \\Vert $└ ┘$ └ ┘ $\\llcorner \\lrcorner$ \\llcorner\n$~~~~$\\lrcorner $\\Updownarrow$ \\Updownarrow   $\\lvert~\\rvert$ \\lvert\n$~~~~$\\rvert $\\lVert~\\rVert$ \\lVert\n$~~~~~$\\rVert \\left. \\right. $\\backslash$ \\backslash   $\\lang~\\rang$ \\lang\n$~~~~$\\rang $\\lt~\\gt$ \\lt \\gt $⟦~⟧$ ⟦ ⟧ $\\llbracket~\\rrbracket$ \\llbracket\n$~~~~$\\rrbracket $\\lBrace~\\rBrace$ \\lBrace \\rBrace    调整尺寸\n$\\left(\\LARGE{AB}\\right)$ \\left(\\LARGE{AB}\\right)\n$( \\big( \\Big( \\bigg( \\Bigg($ ( \\big( \\Big( \\bigg( \\Bigg(\n            \\left \\big \\bigl \\bigm \\bigr   \\middle \\Big \\Bigl \\Bigm \\Bigr   \\right \\bigg \\biggl \\biggm \\biggr    \\Bigg \\Biggl \\Biggm \\Biggr    ","date":"June 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/toha-tutorial/latax_formula/","summary":"官方文档\n线上工具\n一、基础篇 1. 输入公式   行内公式： 格式：$数学公式$ 例如：$x^2=1$ :  $x^2=1$\n  行间公式：\n$$\n数学公式\n$$\n例如: $$f(x)=\\int_{-\\infty}^\\infty\\widehat f\\xi\\ e^{2\\pi i\\xi x}\\ d\\xi$$ $$f(x)=\\int_{-\\infty}^\\infty\\widehat f\\xi\\ e^{2\\pi i\\xi x}\\ d\\xi$$\n  二、进阶篇 1. 声调/变音符号 \\dot{a}, \\ddot{a}, \\acute{a}, \\grave{a}\n$\\dot{a}, \\ddot{a}, \\acute{a}, \\grave{a}$\n\\check{a}, \\breve{a}, \\tilde{a}, \\bar{a}\n$\\check{a}, \\breve{a}, \\tilde{a}, \\bar{a}$\n\\hat{a}, \\widehat{a}, \\vec{a}, \\tilde{a}, \\widetilde{a}\n$\\hat{a}, \\widehat{a}, \\vec{a}, \\tilde{a}, \\widetilde{a}$\na', a'' \n$a', a''$\n2. 标准函数   指数/上下标","tags":["Latex","公式"],"title":"Katex公式"},{"categories":["Basic"],"contents":"一、小技巧 可以使用html的标签\nmarkdown中常用的html标签：    操作 标签     换行 测试\u0026lt;br\u0026gt;一下   标记 \u0026lt;mark\u0026gt;测试一下\u0026lt;/mark\u0026gt;   引用 \u0026lt;cite\u0026gt;引用[^1]\u0026lt;/cite\u0026gt;   空格 \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;测试一下   删除线 \u0026lt;s\u0026gt;测试一下\u0026lt;/s\u0026gt;   下划线 \u0026lt;u\u0026gt;测试一下\u0026lt;/u\u0026gt;   字体增大 \u0026lt;big\u0026gt;测试一下\u0026lt;/big\u0026gt;   字体减小 \u0026lt;small\u0026gt;测试一下\u0026lt;/small\u0026gt;   文字上标 测试\u0026lt;sup\u0026gt;一下\u0026lt;/sup\u0026gt;   文字下标 测试\u0026lt;sub\u0026gt;一下\u0026lt;/sub\u0026gt;   右对齐 \u0026lt;p align=right\u0026gt;测试一下\u0026lt;/p\u0026gt;   文字居中 \u0026lt;center\u0026gt;测试一下\u0026lt;/center\u0026gt;   图片居中 \u0026lt;p align=\u0026quot;center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;***.jpg\u0026quot; width=\u0026quot;60%\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;   超链接 \u0026lt;a href=\u0026quot;center\u0026quot; target=\u0026quot;blank\u0026quot;\u0026gt;文本\u0026lt;/a\u0026gt; href指定跳转的目标路径；\ntarget属性指定超链接打开的位置，\n值blank: 表示在一个新的页面中打开；\n默认值self: 在当前页面中打开超链接   图片 \u0026lt;img src=\u0026quot;***.jpg\u0026quot; width=\u0026quot;60%\u0026quot; height=\u0026quot;图片高度(单位是像素级)\u0026quot; alt=\u0026quot;图片描述，当图片加载失败时显示\u0026quot;\u0026gt;   音频 \u0026lt;audio src=\u0026quot;音频的url\u0026quot; controls=\u0026quot;是否允许用户控制播放\u0026quot; autoplay=\u0026quot;音频文件是否自动播放\u0026quot; \nloop=\u0026quot;音频是否循环播放\u0026quot; preload=\u0026quot;音频在页面加载时进行加载-如果设置了autoplay则忽略该属性\u0026quot;\u0026gt;   视频 跟音频一样，只是多了width和height       操作 需求     Markdown只能识别一个空格(在半角输入状态下)。有两种方法插入更多空格\n方法一：手动输入空格(半个空格\u0026amp;nbsp;)(半角相当于1个空格\u0026amp;ensp;)(全角相当于2个空格\u0026amp;emsp;) 方法二：使用权角空格即：在全角状态下直接使用空格键就ok了 添加空格   如果行与行之间没有空行，则会被视为同一段落。\n方法一：段内换行，在上一行的结尾插入两个以上的空格然后回车; 或者直接用 \u0026lt;br\u0026gt; 方法二：新起一段，在上一行的结尾插入两个以上的空格然后回车+空行；或者直接用\u0026lt;/p\u0026gt; 换行    二、基本语法 教程\n1. 代码块 ​```语言名称``` 2. 标题 # 一阶标题  ## 二阶标题  ### 三阶标题  #### 四阶标题  ##### 五阶标题 ###### 六阶标题 3. 字体  斜体： 格式：*文本*  示例： *斜体*： 斜体 加粗： 格式：**文本**  示例： **加粗**： 加粗 斜体+加粗： 格式：***文本***  示例：***斜体加粗***：斜体加粗 删除线： 格式：~~文本~~或者\u0026lt;s\u0026gt;文本\u0026lt;/s\u0026gt;  示例：\u0026lt;s\u0026gt;删除线\u0026lt;/s\u0026gt;： 删除线 背景高亮：格式：\u0026lt;mark\u0026gt;文本\u0026lt;/mark\u0026gt;  示例：\u0026lt;mark\u0026gt;高亮\u0026lt;/mark\u0026gt;：高亮 背景按钮形式：格式：\u0026lt;kbd\u0026gt;文本\u0026lt;/kbd\u0026gt;  示例：\u0026lt;kbd\u0026gt;按钮\u0026lt;/kbd\u0026gt;：按钮 上标：格式：\u0026lt;sup\u0026gt;文本\u0026lt;/sup\u0026gt;  示例：x\u0026lt;sup\u0026gt;20\u0026lt;/sup\u0026gt;y：x20y 下标：格式：\u0026lt;sub\u0026gt;文本\u0026lt;/sub\u0026gt;  示例：H\u0026lt;sub\u0026gt;2\u0026lt;/sub\u0026gt;O：H2O  4. 引用 语法：\u0026gt;在引用的文字前加\u0026gt;即可。引用也可嵌套，比如加两个\u0026gt;\u0026gt; 三个\u0026gt;\u0026gt;\u0026gt; 引用文献 语法： \u0026lt;cite\u0026gt;论文名[^1]\u0026lt;/cite\u0026gt; [^1]: 详细的内容  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating. — Rob Pike1  引用第二篇论文 Matting2\n 5. 分割线 语法：两种表达方式 --- *** 下面是分割线： ---\n 下面是分割线： ***\n 6. 插入图片  markdown语法：![图片名称](图片地址)  []: 里面的内容表示图片未加载时的提示文字  (): 表示图片地址 \n  html语法： 插入图片：\u0026lt;img src=\u0026quot;***.jpg\u0026quot; width=\u0026quot;60%\u0026quot; height=\u0026quot;图片高度(单位是像素级)\u0026quot; alt=\u0026quot;图片描述，当图片加载失败时显示\u0026quot;\u0026gt;  居中：\u0026lt;p align=\u0026quot;center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;***.jpg\u0026quot; width=\u0026quot;60%\u0026quot;\u0026gt;\u0026lt;/p\u0026gt; \n  本项目中，图片统一放在根目录下的 /static/ 路径下：例如：图片路径: /static/datasets/moon.jpg \u0026lt;p align=\u0026quot;center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;/datasets/moon.jpg\u0026quot; width=\u0026quot;30%\u0026quot; height=\u0026quot;30%\u0026quot; title=\u0026quot;moon\u0026quot; alt=\u0026quot;moon\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;   如果图片与本文放在同一个路径下，例如：图片路径: /content/posts/***/moon.jpg  \u0026lt;p align=\u0026quot;center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;/zh-cn/posts/***/moon.jpg\u0026quot; width=\u0026quot;30%\u0026quot; height=\u0026quot;30%\u0026quot; title=\u0026quot;moon\u0026quot; alt=\u0026quot;moon\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;   7. 超链接  markdown语法：[名称](url地址/本地地址)\n  html语法：\u0026lt;a href=\u0026quot;目标路径\u0026quot; target=\u0026quot;blank\u0026quot;\u0026gt;文本\u0026lt;/a\u0026gt;\n   本项目的地址，例如本地地址: /content/posts/***/latax_formula.zh-cn.md 例如：\u0026lt;a href=\u0026quot;/zh-cn/posts/***/latax_formula\u0026quot; target=\u0026quot;bland\u0026quot;\u0026gt;katex\u0026lt;/a\u0026gt;  本地路径：katex\n  外网地址，例如：\u0026lt;a href=\u0026quot;https://www.baidu.com/\u0026quot; target=\u0026quot;blank\u0026quot;\u0026gt;百度一下\u0026lt;/a\u0026gt; 百度一下\n  8. 表格 语法： |表头|表头|表头| |:--|:--:|--:| |内容|内容|内容| |内容|内容|内容|    表头 表头 表头     内容 内容 内容   内容 内容 内容    9. 列表 1.无序列表 - 列表内容 + 列表内容 * 列表内容   效果一样\n  二级\n  三级\n 四级        2. 有序列表 数字加点 例如：1. 有序列表内容  一级有序列表内容  二级有序列表  三级有序列表  四级有序列表       一级有序列表内容  10. 流程图 st=\u0026gt;start: 开始 11. 注释 语法: \u0026lt;!-- this is a comment --\u0026gt; 12. 公式 markdown的公式: 可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染，例如：\n公式katex文档\n   希腊 转义 希腊 转义 希腊 转义 希腊 转义     $$\\alpha$$ \\alpha $$\\kappa$$ \\kappa $$\\psi$$ \\psi $$\\digamma$$ \\digamma   $$\\beta$$ \\beta $$\\lambda$$ \\lambda $$\\rho$$ \\rho $$\\varepsilon$$ \\varepsilon   $$\\chi$$ \\chi $$\\mu$$ \\mu $$\\sigma$$ \\sigma $$\\varkappa$$ \\varkappa   $$\\delta$$ \\delta $$\\nu$$ \\nu $$\\tau$$ \\tau $$\\varphi$$ \\varphi   $$\\epsilon$$ \\epsilon $$\\omicron$$ \\omicron $$\\theta$$ \\theta $$\\varpi$$ \\varpi   $$\\eta$$ \\eta $$\\omega$$ \\omega $$\\upsilon$$ \\upsilon $$\\varrho$$ \\varrho   $$\\gamma$$ \\gamma $$\\phi$$ \\phi $$\\xi$$ \\xi $$\\varsigma$$ \\varsigma   $$\\iota$$ \\iota $$\\pi$$ \\pi $$\\zeta$$ \\zeta $$\\vartheta$$ \\vartheta   $$\\Delta$$ \\Delta $$\\Theta$$ \\Theta $$\\Lambda$$ \\Lambda $$\\Xi$$ \\Xi   $$\\Gamma$$ \\Gamma $$\\Upsilon$$ \\Upsilon $$\\Omega$$ \\Omega $$\\Phi$$ \\Phi   $$\\Pi$$ \\Pi $$\\Psi$$ \\Psi $$\\Sigma$$ \\Sigma $$\\aleph$$ \\aleph   $$\\beth$$ \\beth $$\\gimel$$ \\gimel $$\\daleth$$ \\daleth      我是一个公式 $$\\Gamma(n) = (n-1)!$$：$$\\Gamma(n) = (n-1)!$$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n$$\\alpha = \\frac a b$$\n13. 切割成列 这个主题支持将页面分割成尽可能多的列。\n{\u0026lt; split 6 6\u0026gt;}   The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015. \u0026#x21a9;\u0026#xfe0e;\n 这是第二个引用的详细内容 \u0026#x21a9;\u0026#xfe0e;\n   ","date":"June 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/toha-tutorial/markdown-tutorial/","summary":"一、小技巧 可以使用html的标签\nmarkdown中常用的html标签：    操作 标签     换行 测试\u0026lt;br\u0026gt;一下   标记 \u0026lt;mark\u0026gt;测试一下\u0026lt;/mark\u0026gt;   引用 \u0026lt;cite\u0026gt;引用[^1]\u0026lt;/cite\u0026gt;   空格 \u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp;测试一下   删除线 \u0026lt;s\u0026gt;测试一下\u0026lt;/s\u0026gt;   下划线 \u0026lt;u\u0026gt;测试一下\u0026lt;/u\u0026gt;   字体增大 \u0026lt;big\u0026gt;测试一下\u0026lt;/big\u0026gt;   字体减小 \u0026lt;small\u0026gt;测试一下\u0026lt;/small\u0026gt;   文字上标 测试\u0026lt;sup\u0026gt;一下\u0026lt;/sup\u0026gt;   文字下标 测试\u0026lt;sub\u0026gt;一下\u0026lt;/sub\u0026gt;   右对齐 \u0026lt;p align=right\u0026gt;测试一下\u0026lt;/p\u0026gt;   文字居中 \u0026lt;center\u0026gt;测试一下\u0026lt;/center\u0026gt;   图片居中 \u0026lt;p align=\u0026quot;center\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;***.jpg\u0026quot; width=\u0026quot;60%\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;   超链接 \u0026lt;a href=\u0026quot;center\u0026quot; target=\u0026quot;blank\u0026quot;\u0026gt;文本\u0026lt;/a\u0026gt; href指定跳转的目标路径；","tags":["MarkDown","教程"],"title":"MarkDown入门"},{"categories":["Basic"],"contents":"🤑\nThis is a sample post intended to test the followings:\n Default hero image. Different shortcodes.  一、报警(Alert) The following alerts are available in this theme.\n这是 type=\u0026quot;success\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;success\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;danger\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;danger\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;warning\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;warning\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;info\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;info\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;dark\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;dark\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;primary\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;primary\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;secondary\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;secondary\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  二、插入图片(Image) 语法格式:\n {{\u0026lt; img src=\u0026quot;/zh-cn/posts/toha-tutorial/datasets/toha/moon.jpg\u0026quot; title=\u0026ldquo;鼠标停在图片上显示的\u0026rdquo; height=\u0026ldquo;尺寸\u0026rdquo; width=\u0026ldquo;尺寸\u0026rdquo; align=\u0026ldquo;center\u0026rdquo; float=\u0026ldquo;right\u0026rdquo;\u0026gt;}}\n 属性设置：\n float: 图片与文本内容之间的关系，值: right：表示图片在文本的右边(文本中插入图片，图片放在右边)\nalign: 图片排版方式，值：center：表示居中放置\n 例如：{{\u0026lt; img src=\u0026quot;/zh-cn/posts/toha-tutorial/datasets/toha/moon.jpg\u0026quot; height=\u0026ldquo;200\u0026rdquo; width=\u0026ldquo;300\u0026rdquo; float=\u0026ldquo;left\u0026rdquo; title=\u0026ldquo;A boat at the sea\u0026rdquo; \u0026gt;}}\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Cras egestas lectus sed leo ultricies ultricies. Praesent tellus risus, eleifend vel efficitur ac, venenatis sit amet sem. Ut ut egestas erat. Fusce ut leo turpis. Morbi consectetur sed lacus vitae vehicula. Cras gravida turpis id eleifend volutpat. Suspendisse nec ipsum eu erat finibus dictum. Morbi volutpat nulla purus, vel maximus ex molestie id. Nullam posuere est urna, at fringilla eros venenatis quis.\nFusce vulputate dolor augue, ut porta sapien fringilla nec. Vivamus commodo erat felis, a sodales lectus finibus nec. In a pulvinar orci. Maecenas suscipit eget lorem non pretium. Nulla aliquam a augue nec blandit. Curabitur ac urna iaculis, ornare ligula nec, placerat nulla. Maecenas aliquam nisi vitae tempus vulputate.\n三、页面分割(split) 这个主题支持将页面分割成你想要的任意多列。\n1. 分割成两列 语法格式：\n {{\u0026lt; split 6 6\u0026gt;}}\n---\n{{\u0026lt; /split \u0026gt;}}\n 例如：\n {{\u0026lt; split 6 6\u0026gt;}}\n这是左边列\n---\n这是右边列\n{{\u0026lt; /split \u0026gt;}}\n 结果样式：\n这是左边列  这是右边列   2. 分割3列 语法格式：\n {{\u0026lt; split 4 4 4 \u0026gt;}}\n---\n---\n{{\u0026lt; /split \u0026gt;}}\n 例如：\n {{\u0026lt; split 4 4 4 \u0026gt;}}\n这是左边列\n---\n这是中间列\n---\n这是右边列\n{{\u0026lt; /split \u0026gt;}}\n 结果样式：\n这是左边列  这是中间列  这是右边列   四、垂直方向-空行 在两行之间加入空行\n语法格式:\n {{\u0026lt; vs 4\u0026gt;}} ： 表示加入4个空行\n 五、视频 语法格式：\n {{\u0026lt; video src=\u0026quot;/videos/sample.mp4\u0026quot; \u0026gt;}}\n 例如：\n Video by Rahul Sharma from Pexels.\n六、hero 要显示自己的hero图：\n例如： 在一个块(CV)下创建子块(cv_sub)，路径如下：\n├── _index.en.md\n├── _index.zh-cn.md identifier: cv\n├── cv_sub\n│　├── _index.zh-cn.md identifier: cv_sub; parent: cv\n│　└── rich_content\n│　├── images hero图片位置\n│　│　├── forest.jpg\n│　│　└── hero.svg\n│　└── index.md 真正的博文内容，必须命名为index.md。identifier: rich-content; parent: cv_sub\n七、流程图 1、设置 要是用流程图时，需要添加：mermaid: true\ntitle: \u0026#34;Mermaid Support\u0026#34; date: 2022-03-14T06:15:35+06:00 menu: sidebar: name: Mermaid identifier: writing-post-mermaid parent: writing-post weight: 60 mermaid: true 2、语法 {{\u0026lt; mermaid align=\u0026ldquo;left\u0026rdquo; \u0026gt;}}\n內容\n{{\u0026lt; /mermaid \u0026gt;}}\n参数：\n align：让您将图表对齐到左边、右边或中间(left, right, center)。默认对齐方式为居中。 background：让您更改图表的背景颜色。    3、实例 1）Graph []：表示矩形框 ()：表示圆角矩形框\n{}：表示菱形框\n`{`{\u0026lt; mermaid align=\u0026quot;left\u0026quot; \u0026gt;}} graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] `{`{\u0026lt; /mermaid \u0026gt;}}  graph LR; A[Hard edge] --|Link text| B(Round edge) B -- C{Decision} C --|One| D[Result one] C --|Two| E[Result two]  b）序列图(Sequence Diagram) `{`{\u0026lt; mermaid \u0026gt;}} sequenceDiagram participant Alice participant Bob Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts \u0026lt;br/\u0026gt;prevail! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! `{`{\u0026lt; /mermaid \u0026gt;}}  sequenceDiagram participant Alice participant Bob Alice-John: Hello John, how are you? loop Healthcheck John-John: Fight against hypochondria end Note right of John: Rational thoughts prevail! John--Alice: Great! John-Bob: How about you? Bob--John: Jolly good!  c）甘特图 (Gantt diagram) `{`{\u0026lt; mermaid \u0026gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d `{`{\u0026lt; /mermaid \u0026gt;}}  gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d  4）类图(class diagram) `{`{\u0026lt; mermaid \u0026gt;}} classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 \u0026lt;--\u0026gt; C2: Cool label `{`{\u0026lt; /mermaid \u0026gt;}}  classDiagram Class01 C2 : Where am i? Class09 --* C3 Class09 --| Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08  C2: Cool label  5）git图(git graph) `{`{\u0026lt; mermaid background=\u0026quot;black\u0026quot; align=\u0026quot;right\u0026quot; \u0026gt;}} gitGraph: options { \u0026quot;nodeSpacing\u0026quot;: 150, \u0026quot;nodeRadius\u0026quot;: 10 } end commit branch newbranch checkout newbranch commit commit checkout master commit commit merge newbranch `{`{\u0026lt; /mermaid \u0026gt;}}  gitGraph: options { \"nodeSpacing\": 150, \"nodeRadius\": 10 } end commit branch newbranch checkout newbranch commit commit checkout master commit commit merge newbranch  6）ER图(ER Diagram) `{`{\u0026lt; mermaid \u0026gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses `{`{\u0026lt; /mermaid \u0026gt;}}  erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses  ","date":"June 8, 2021","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/toha-tutorial/shortcodes_samples/","summary":"🤑\nThis is a sample post intended to test the followings:\n Default hero image. Different shortcodes.  一、报警(Alert) The following alerts are available in this theme.\n这是 type=\u0026quot;success\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;success\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;danger\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;danger\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;warning\u0026quot;的报警样例.\n格式:\n {{\u0026lt; alert type=\u0026ldquo;warning\u0026rdquo; \u0026gt; }}\n内容\n {{\u0026lt; /alert \u0026gt; }}  这是 type=\u0026quot;info\u0026quot;的报警样例.","tags":["shortcodes"],"title":"区域块-实例"},{"categories":["Basic"],"contents":"论文入口\n一、开篇 在描述深度学习之前，先回顾下机器学习和深度学习的关系。\n机器学习：研究如何使用计算机系统利用经验改善性能。在机器学习的众多研究方向中，表征学习关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出。\n深度学习：是具有多级表示的表征学习方法。在每一级，深度学习通过简单的函数将该级的表示变换为更高级的表示。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合函数足够多时，就可以表达非常复杂的变换。 作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。 逐级表示越来越抽象的概念或模式。以图像为例，它的输入是一堆原始像素值，模型中逐级表示为：特定位置和角度的边缘 \u0026mdash;\u0026gt; 由边缘组合得出的花纹 \u0026mdash;\u0026gt; 由多种花纹进一步汇合得到的特定部位 \u0026mdash;\u0026gt; 由特定部位组合得到的整个目标。\n二、简介 It\u0026rsquo;s coming soon.\n三、欠/过拟合 1. 误差 训练误差(training error): 训练模型在训练数据集(training set)上表现出的误差。 泛化误差(generalization error)：模型在任意一个测试数据集(test set)上表现出的误差的期望。\n训练集(training set)：用来产出模型参数。\n验证集(validation set)：由于无法从训练误差评估泛化误差，因此从训练集中预留一部分数据作为验证集，主要用来选择模型。 测试集(test set)：在模型参数选定后，实际使用。\n2. 欠/过拟合 欠拟合(underfitting)：模型的表现能力不足。\n 训练样本足够，模型参数不足  过拟合(overfitting)：模型的表现能力过剩。\n 训练样本不足，模型参数足够：样本不足导致特征较少，相当于模型足够表征数据的特征，产生过拟合现象。  3. 优化过拟合 增大训练集可能会减轻过拟合，但是获取训练数据往往代价很高。可以在模型方面优化一下，减轻过拟合现象。\n  权重衰减(weight decay)： 对模型参数计算L2范数正则化。即：在原Loss中添加对模型参数的惩罚。使得模型学到的权重参数较接近于0。权重衰减通过惩罚绝对值较大的模型参数，为需要学习的模型增加了限制。这可能对过拟合有效。\n  丢弃法(dropout)：针对隐藏层中的各个神经元，以概率p随机丢弃，有可能该成神经元被全部清零。这样，下一层的计算无法过渡依赖该层的任意一个神经元，从而在训练中可以用来对付过拟合。在测试中，就不需要丢弃了。\n例如：对隐藏层使用丢弃法，丢弃概率: p，那么hi 有p的概率被清零；不丢弃概率: 1-p，为了保证隐藏层的期望值不变E(p')=E(p)，需要对不丢弃的神经元做拉伸，即：$$h'_i = \\frac{\\xi_i} {1-p} h_i$$ 其中：随机变量ξi 为0和1的概率分别为p和1-p   ","date":"January 1, 2021","hero":"/zh-cn/posts/deeplearning_summary/deeplearning_start/hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/deeplearning_summary/deeplearning_start/","summary":"论文入口\n一、开篇 在描述深度学习之前，先回顾下机器学习和深度学习的关系。\n机器学习：研究如何使用计算机系统利用经验改善性能。在机器学习的众多研究方向中，表征学习关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出。\n深度学习：是具有多级表示的表征学习方法。在每一级，深度学习通过简单的函数将该级的表示变换为更高级的表示。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合函数足够多时，就可以表达非常复杂的变换。 作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。 逐级表示越来越抽象的概念或模式。以图像为例，它的输入是一堆原始像素值，模型中逐级表示为：特定位置和角度的边缘 \u0026mdash;\u0026gt; 由边缘组合得出的花纹 \u0026mdash;\u0026gt; 由多种花纹进一步汇合得到的特定部位 \u0026mdash;\u0026gt; 由特定部位组合得到的整个目标。\n二、简介 It\u0026rsquo;s coming soon.\n三、欠/过拟合 1. 误差 训练误差(training error): 训练模型在训练数据集(training set)上表现出的误差。 泛化误差(generalization error)：模型在任意一个测试数据集(test set)上表现出的误差的期望。\n训练集(training set)：用来产出模型参数。\n验证集(validation set)：由于无法从训练误差评估泛化误差，因此从训练集中预留一部分数据作为验证集，主要用来选择模型。 测试集(test set)：在模型参数选定后，实际使用。\n2. 欠/过拟合 欠拟合(underfitting)：模型的表现能力不足。\n 训练样本足够，模型参数不足  过拟合(overfitting)：模型的表现能力过剩。\n 训练样本不足，模型参数足够：样本不足导致特征较少，相当于模型足够表征数据的特征，产生过拟合现象。  3. 优化过拟合 增大训练集可能会减轻过拟合，但是获取训练数据往往代价很高。可以在模型方面优化一下，减轻过拟合现象。\n  权重衰减(weight decay)： 对模型参数计算L2范数正则化。即：在原Loss中添加对模型参数的惩罚。使得模型学到的权重参数较接近于0。权重衰减通过惩罚绝对值较大的模型参数，为需要学习的模型增加了限制。这可能对过拟合有效。\n  丢弃法(dropout)：针对隐藏层中的各个神经元，以概率p随机丢弃，有可能该成神经元被全部清零。这样，下一层的计算无法过渡依赖该层的任意一个神经元，从而在训练中可以用来对付过拟合。在测试中，就不需要丢弃了。\n例如：对隐藏层使用丢弃法，丢弃概率: p，那么hi 有p的概率被清零；不丢弃概率: 1-p，为了保证隐藏层的期望值不变E(p')=E(p)，需要对不丢弃的神经元做拉伸，即：$$h'_i = \\frac{\\xi_i} {1-p} h_i$$ 其中：随机变量ξi 为0和1的概率分别为p和1-p   ","tags":["机器学习","深度学习","简介"],"title":"深度学习开篇"},{"categories":["Basic"],"contents":"一、启动 模板项目: github\n# --force 即使本文件夹不为空，也会强制创建站点 hugo new site myblog -f=yaml --force # 初始化本地仓库，因为部署时要把该文件的内容push到远端仓库 git init # 添加toha主题 git submodule add https://github.com/hugo-toha/toha.git themes/toha # 在本地启动站点，浏览器中打开: http://localhost:1313 hugo server -t toha -w Demo样例\nHugo文档\nGithub项目\n二、配置 config.yaml: 配置样例\n这个主题的大部分内容是由data目录中的一些 YAML 文件驱动的。 在本节中，我们将添加一些示例数据。 由于我们正在构建一个多语言站点，因此我们会将每种语言的数据保存在各自的语言环境文件夹中。首先，在data目录中创建 en 文件夹(英语环境)/zh-cn(汉语环境)。 我们将在这里添加英语语境数据。\n1、主页配置 在目的环境文件夹中创建site.yaml\n英语环境：/data/en/site.yaml 汉语环境：/data/zh-cn/site.yaml\n# Copyright Notice copyright: © 2021 Copyright. # A disclaimer notice for the footer. Make sure you have set \u0026#34;params.footer.disclaimer.enable: true\u0026#34; in your `config.yaml` file. disclaimer: \u0026#34;这个主题是MIT许可的\u0026#34; # Meta description for your site. This will help the search engines to find your site. description: 机器学习、深度学习 探索者. # 指定要在顶部导航栏中显示的自定义菜单列表。它们将通过分隔线与主菜单分开。 customMenus: - name: 文档 url: https://toha-guides.netlify.app/posts/ # Specify OpenGraph Headers openGraph: title: biubiobiu\u0026#39;s Blog type: website description: biubiobiu的简历和私人博客. image: images/author/john.png url: https://***.github.io 2、作者信息配置 在目的语言环境路径中创建：author.yaml文件\n英语环境: /data/en/author.yaml\n汉语环境: /data/zh-cn/author.yaml\n3、区域块设置 在目的语言环境路径中创建：sections文件夹\n英语环境：data/en/sections/\n汉语环境：data/zh-cn/sections/\n三、部署 It\u0026rsquo;s coming soon \u0026hellip;\n","date":"June 8, 2020","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/toha-tutorial/toha-config/","summary":"一、启动 模板项目: github\n# --force 即使本文件夹不为空，也会强制创建站点 hugo new site myblog -f=yaml --force # 初始化本地仓库，因为部署时要把该文件的内容push到远端仓库 git init # 添加toha主题 git submodule add https://github.com/hugo-toha/toha.git themes/toha # 在本地启动站点，浏览器中打开: http://localhost:1313 hugo server -t toha -w Demo样例\nHugo文档\nGithub项目\n二、配置 config.yaml: 配置样例\n这个主题的大部分内容是由data目录中的一些 YAML 文件驱动的。 在本节中，我们将添加一些示例数据。 由于我们正在构建一个多语言站点，因此我们会将每种语言的数据保存在各自的语言环境文件夹中。首先，在data目录中创建 en 文件夹(英语环境)/zh-cn(汉语环境)。 我们将在这里添加英语语境数据。\n1、主页配置 在目的环境文件夹中创建site.yaml\n英语环境：/data/en/site.yaml 汉语环境：/data/zh-cn/site.yaml\n# Copyright Notice copyright: © 2021 Copyright. # A disclaimer notice for the footer. Make sure you have set \u0026#34;params.footer.disclaimer.enable: true\u0026#34; in your `config.","tags":["Toha","配置"],"title":"Toha的配置"},{"categories":["Basic"],"contents":"一、创建类别 1、创建文章 在content文件夹中创建posts文件夹，在该文件夹中创建一个_index.zh-cn.md文件(中文环境)/_index.en.md(英文环境)。在里面添加如下内容：\n--- title: Posts --- 现在，假设你想写一篇文章。首先，创建一个文件，在末尾用markdown扩展名命名它。例如:我们创建了一个名为analytics-and-comments.en.md，并添加以下几行内容。如果在中文环境下创建，名字应该是analytics-and-comments.zh-cn.md:\n--- title: \u0026#34;Analytics and Comments\u0026#34; date: 2020-06-08T06:00:23+06:00 hero: /images/posts/writing-posts/analytics.svg description: Adding analytics and disquss comment in hugo theme Toha menu: sidebar: name: Analytics \u0026amp; Comments identifier: analytics-and-comments weight: 500 --- ### Complete Post Coming Soon... 在文件的头部以3个-开始和结束，称为前置内容。我们写得每一篇博客文章都需要有前置内容，在前置内容之后，可以开始写文章内容了，前置内容的参数有：\n   参数 解释     title 贴子的标题   date 显示博客发布时间，第一部分 year-month-date format   hero 文章封面图的位置路径。创建路径static/images/posts/writingposts/ 在其中放置图片文件   description 添加任意你喜欢的描述   menu 这个部分包含了另一个sidebar参数，该参数定义了侧边栏中文件结构的样子。该参数的子参数有：name,identifier,weight    name: 定义了侧边栏文件层次结构中，文档的名称    identifier: 标识符。有助于将文件与其他文件区分开来，有助于分类    weight: 权重值，对于多个文件，文档将基于该权重值以升序出现在文件层次结构中。    parent:        2、创建子类 刚刚我们创建了一个_index.zh-cn.md文件和一个博客文章的markdown文件，现在我们创建一个子类。创建一个文件夹 getting-started/_index.zh-cn.md，该文件中包含下面的前置内容:\n--- title: Deploy Site menu: sidebar: name: Deploy Site identifier: getting-started weight: 300 --- 上述代码块中各个参数的含义前面已经讨论过了。 只是，暂时请记住，我们将创建类别名称作为getting-started，这就是我们将其作为标识符包含在此 _index.md 中的原因。 接下来，我们将创建一个名为 github-pages.md 的 Markdown 文件。这将是我们此文件夹的博客文章文件。 github -pages.md 包括以下几行：\n--- title: \u0026#34;Deploy site in Github Pages\u0026#34; date: 2020-06-08T06:00:20+06:00 hero: /images/posts/writing-posts/git.svg menu: sidebar: name: Github Pages identifier: getting-started-github parent: getting-started weight: 10 --- 目录关系如下： getting-started |__ _index.md_ |__ github-pages.md 一个新参数：parent：该参数的值一定要与上一级的 标签(identifier)相匹配。\n3、作者信息 在默认情况下，文章的作者信息用的是 config.yaml文件中的相关信息。如果想修改作者信息，可以在前置内容中添加 author 块：\nauthor: name: Md.Habibur image: /images/authors/habib.jpg 二、创建子类 It\u0026rsquo;s coming soon \u0026hellip;\n","date":"June 8, 2020","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/posts/toha-tutorial/write-blogs/","summary":"一、创建类别 1、创建文章 在content文件夹中创建posts文件夹，在该文件夹中创建一个_index.zh-cn.md文件(中文环境)/_index.en.md(英文环境)。在里面添加如下内容：\n--- title: Posts --- 现在，假设你想写一篇文章。首先，创建一个文件，在末尾用markdown扩展名命名它。例如:我们创建了一个名为analytics-and-comments.en.md，并添加以下几行内容。如果在中文环境下创建，名字应该是analytics-and-comments.zh-cn.md:\n--- title: \u0026#34;Analytics and Comments\u0026#34; date: 2020-06-08T06:00:23+06:00 hero: /images/posts/writing-posts/analytics.svg description: Adding analytics and disquss comment in hugo theme Toha menu: sidebar: name: Analytics \u0026amp; Comments identifier: analytics-and-comments weight: 500 --- ### Complete Post Coming Soon... 在文件的头部以3个-开始和结束，称为前置内容。我们写得每一篇博客文章都需要有前置内容，在前置内容之后，可以开始写文章内容了，前置内容的参数有：\n   参数 解释     title 贴子的标题   date 显示博客发布时间，第一部分 year-month-date format   hero 文章封面图的位置路径。创建路径static/images/posts/writingposts/ 在其中放置图片文件   description 添加任意你喜欢的描述   menu 这个部分包含了另一个sidebar参数，该参数定义了侧边栏中文件结构的样子。该参数的子参数有：name,identifier,weight    name: 定义了侧边栏文件层次结构中，文档的名称    identifier: 标识符。有助于将文件与其他文件区分开来，有助于分类    weight: 权重值，对于多个文件，文档将基于该权重值以升序出现在文件层次结构中。    parent:        2、创建子类 刚刚我们创建了一个_index.","tags":["博文路径"],"title":"撰写文章"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://biubiobiu.github.io/zh-cn/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]