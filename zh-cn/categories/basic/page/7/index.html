<!doctype html><html><head><title>Basic</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="Basic"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/categories/basic/"><meta property="og:updated_time" content="2023-08-08T06:00:20+08:00"><link rel=stylesheet href=/css/layouts/list.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/categories data-filter=all>类别</a></li><div class="subtree taxonomy-terms"><li><a class="taxonomy-term active" href=https://biubiobiu.github.io/zh-cn/categories/basic/ data-taxonomy-term=basic><span class=taxonomy-label>Basic</span></a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>LSTM网络</h5><p class="card-text post-summary">一、简介 长短期记忆网络(LSTM)
忘记门：$F_t = sigmoid(X_tW_{xf}+H_{t-1}W_{hf}+b_f)$ 输入门：$I_t = sigmoid(X_tW_{xi}+H_{t-1}W_{hi}+b_i)$ 输出门：$O_t = sigmoid(X_tW_{xo}+H_{t-1}W_{ho}+b_o)$ 候选记忆单元：$\tilde{C_t} = tanh(X_tW_{xc} + (R_t \odot H_{t-1})W_{hc} + b_c)$ 记忆单元：$C_t = F_t \odot C_{t-1} + I_t\odot \tilde{C_t}$ 隐状态：$H_t = O_t \odot tanh(C_t)$ 其中，$F_t, I_t, O_t, C_t, H_t, \in \R^{n \times d}$</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0020_rnn/lstm/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>RNN综述</h5><p class="card-text post-summary">一、文本预处理 1、词元-token 英文：在训练文本模型时，模型输入最小单元：可以是词元维度，也可以是字符维度(这样的话，模型还得学习怎么用字符组合成单词)
中文：一般是字符维度；如果是词元维度，在模型之前需要进行分词，如果要使用词元维度，需要先分词，用空格间隔开。
特殊词元：未知词元 &lt;unk>，填充词元&lt;pad>，序列开始词元 &lt;bos>，序列结束词元 &lt;eos>
2、词表-vocabulary 把token映射到：一个从0开始的数字索引，也就是：
token &ndash;> idx：token_to_idx {0:then, 1:token, &mldr;.}
idx &ndash;> token：idx_to_token: [the, token, &mldr;.] 例如：
tokens: 例如：一篇文章
例如：[[一句话按照空格split后], [], [], ....]
vocab：词表，代码里可以写成一个类，其元素有：
self.idx_to_token ：['&lt;unk>', &lsquo;the&rsquo;, &mldr;] token的列表，按照token的个数降序排列
self.token_to_idx ：{'&lt;unk>': 0, &lsquo;the&rsquo;: 1, &mldr;.} token&ndash;>idx 的映射
corpus：语料库，先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为语料
例如：[('&lt;unk>', 1000), ('the', 900), ....]
二、深度循环神经网络 循环神经网络(Recurrent Netural Networks)：是具有隐状态的神经网络。
类似于MLP多层感知机，RNNs只是添加了时间轴信息。比如，MLP的表示如下：
$$ H = \phi(XW_{xh} + b_h) $$ $$O = HW_{hq} + b_q $$</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Transformer</h5><p class="card-text post-summary">一、简介 谷歌大脑、谷歌研究院等团队于2017年联合发表文章《Attention Is All You Need》，提出了一种新的注意力 Seq2Deq 模型，以取代之前以RNN作为编/解码器实现的 Seq2Seq 模型。模型采用的也是编码器-解码器架构，但是在该模型中，编码器和解码器不再是 RNN结构，取而代之的是编码器栈（encoder stack）和解码器栈（decoder stack）（注：所谓的“栈”就是将同一结构重复多次，“stack”翻译为“堆叠”更为合适）。编码器栈和解码器栈中分别为连续N个具有相同结构的编码器和解码器。
编码器：由两部分组成（自注意力模块 + 前馈神经网络）
自注意力模块：具体来说是“Multi-Head Attention”，即“多头注意力”模块
全连接前馈网络 每个子网络都具有残差连接，其输出形式为 $LayerNorm(Sublayer(x)+x)$ ，其中 $Sublayer(x)$ 表示子网络对输入特征x进行的具体映射操作；$LayerNorm()$ 表示归一化操作。
解码器：由三部分组成（自注意力模块 + 编码-解码注意力模块 + 前馈神经网络）
解码器中多了一个编码-解码注意力模块，用来利用当前已有的输出，来匹配输入特征（即：attention操作），然后拿计算出的新特征来计算当前时间步的输出。解码器中的自注意力模块与编码器不同是：这里只能看到当前时间步之前的输入，而不是全部的输入，所以需要有mask的操作。
论文中图： 二、Transformer 输入：序列的embeding表示 + 位置编码
编码器：
多头注意力 + 残差连接(residual connection) &ndash;> 层归一化(layer normalization) 基于位置的前馈网络(positionwise feed-forward network) + 残差连接(residual connection) &ndash;> 层归一化(layer normalization) class PositionWiseFFN(nn.Module): """基于位置的前馈网络""" def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs): super(PositionWiseFFN, self).</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Word Embedding综述</h5><p class="card-text post-summary">一、word embedding 词向量：是用来表示词的向量或者表征，也可被认为是词的特征向量。把词映射为实数域向量的技术 &ndash; 词嵌入(word embedding)
最简单的方式：one-hot向量。
词库里假设有N个词，对所有词排序，用0~N-1作为每个词的索引。 每个词的one-hot向量：长度为N，在该次索引的位置为1，其他位置都是0 缺点：one-hot向量，不能表征两个词的相似度。比如我们常用余弦相似度，one-hot的向量都是相互垂直的。
词嵌入是一种无监督学习。机器通过阅读大量的文章来学习的单词的意思，通过上下文信息来理解一个单词。怎么挖掘上下文信息：
Count-based method。认为如果两个单词一起出现的频率很高，那么它们的word embedding feature应该很接近彼此，二者的内积就越接近这两个的单词在同一篇文章中出现的次数。GloVe 就是一种count-based的算法。 prediction-based method. ski-gram 和 CBOW 就是这种算法。 二、Count-based method 1、GloVe 《GloVe: Global Vectors for Word Representation》 上下文窗口内的词共现可以携带丰富的语义信息。例如，在一个大型语料库中，“固体”比“气体”更有可能与“冰”共现，但“气体”一词与“蒸汽”的共现频率可能比与“冰”的共现频率更高。此外，可以预先计算此类共现的全局语料库统计数据：这可以提高训练效率。
GloVe模型基于平方损失 (Pennington et al., 2014)对跳元模型做了三个修改：
使用变量 $p_{ij} = x_{ij}$ 和 $q_{ij} = e^{(u^T_j v_i)}$ 而非概率分布，并取两者的对数。所以平方损失项是 $(log p_{ij} - log q_{ij})^2 = (u^T_j v_i - log x_{ij})^2$ 为每个词 $w_i$ 添加两个标量模型参数：中心词偏置 $b_i$ 和上下文词偏置 $c_i$。 用权重函数 $h(x_{ij})$ 替换每个损失项的权重，其中 $h(x)$ 在 $[0, 1]$ 的间隔内递增。 整合代码，训练GloVe是为了尽量降低以下损失函数： $$ \sum_{i \in V} \sum_{j \in V} h(x_{ij})(u^T_j v_i + b_i + c_j - log x_{ij})^2 $$</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>抠图综述</h5><p class="card-text post-summary">It&rsquo;s coming soon.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>简介</h5><p class="card-text post-summary">一、简介 It&rsquo;s coming soon.
二、网络 1、R-CNN 《Rich feature hierarchies for accurate object detection and semantic segmentation》(2013)
2、SPPNet 《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》(2014)
3、Fast R-CNN 《Fast R-CNN》(2015)
4、Faster R-CNN 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》(2016)
5、FPN 《Feature Pyramid Networks for Object Detection》(2017)
4、YOLO 《You Only Look Once: Unified, Real-Time Object Detection》(2016)
5、YOLO V2 《YOLO9000: Better, Faster, Stronger》(2016)
6、YOLO V3 《YOLOv3: An Incremental Improvement》(2018)</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>简介</h5><p class="card-text post-summary">一、简介 It&rsquo;s coming soon.
二、网络-基于编码器-解码器 1、FCN 《Fully Convolutional Networks for Semantic Segmentation》(2015) 要说语义分割整体实现精度大的跨越还是在FCN（全卷积神经网络）提出之后。它完全改变了之前需要一个窗口来将语义分割任务转变为图片分类任务的观念，FCN完全丢弃了图片分类任务中全连接层，从头到尾都只使用到了卷积层。从FCN后，基于编码器解码器结构的经典网络结构如同雨后春笋般冒了出来
2、U-Net 《U-Net: Convolutional Networks for Biomedical Image Segmentation》(2015) Unet网络是在医学影像分割中最常用的模型。它的典型特点是，它是U型对称结构，左侧是卷积层，右侧是上采样层（典型的编码器解码器结构）。
另一个特点是，Unet网络的每个卷积层得到的特征图都会concatenate到对应的上采样层，从而实现对每层特征图都有效使用到后续计算中。也就是文中所说的skip-connection。这样，同其他的一些网络结构比如FCN比较，Unet避免了直接在高级feature map中进行监督和loss计算，而是结合了低级feature map中的特征，从而可以使得最终所得到的feature map中既包含了high-level 的feature，也包含很多的low-level的feature，实现了不同scale下feature的融合，提高模型的结果精确度。
3、SegNet 《SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation》(2015) 是一个由剑桥大学团队开发的图像分割的开源项目，该项目可以对图像中的物体所在区域进行分割，例如车，马路，行人等，并且精确到像素级别
4、Deeplab V1 《Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs》(2015) 2015 年的ICLR上提出DeepLab V1是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。它将DenseCRFs作为网络的后处理方法。采用DenseCRFs作为后处理的方法，简单来说，就是对一个像素进行分类的时候，不仅考虑DCNN的输出，而且考虑该像素点周围像素点的值，这样语义分割结果边界清楚。
5、Deeplab V2 《DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs》(2017) 在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是重复的池化和下采样降低了分辨率。但是另一方面，重复的池化和下采样扩大了感受野，而感受野的扩大对语义分割任务来说也是至关重要的。针对这一问题，DeepLab v2采用的空洞卷积算法扩展感受野，与此同时不会降低特征图的分辨率。此外，deeplab v2基于空洞卷积，设计了ASPP模块。它组合了不同dilation rate的空洞卷积所产生的特征图。这样，不同空洞卷积产生的不同感受野的特征图被组合在了一起，从而获取了更加丰富的上下文信息。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>编解码架构</h5><p class="card-text post-summary">一、编码器-解码器 架构 机器翻译：是把一个序列转换为另一个序列。为处理这种类型的输入和输出，设计这样的架构：
编码器：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。
解码器：将固定形状的编码状态映射到长度可变的序列。
二、seq2seq Ilya Sutskever 等人设计的seq2seq：将编码器最后一时间步的state，作为解码器第一时间步的state使用。
Kyunghyun Cho 等人设计的seq2seq，将编码器最后一时间步的state，作为解码器每一个时间步的输入序列的一部分。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Bert家族</h5><p class="card-text post-summary">一、简介 1、为什么需要预训练 《Visualizing and Understanding the Effectiveness of BERT》 这篇文章指出:
首先，预训练能在下游任务中达到一个良好的初始点，与从头开始训练相比，预训练能带来更宽的最优点，更容易优化。尽管 BERT 对下游任务的参数设置过高，但微调程序对过拟合具有很强的鲁棒性。 其次，可视化结果表明，由于最佳值平坦且宽广，以及训练损失面和泛化误差面之间的一致性，微调 BERT 趋向于更好地泛化。 第三，在微调过程中，BERT 的低层更具不变性，这表明靠近输入的层学习到了更多可迁移的语言表征。 2、下游任务怎么Fine-tune 我们希望有一个预训练的模型，输入一串单词，输出一串嵌入向量，并且希望这些向量是可以考虑上下文的。那么要怎么做呢？
最早是由CoVe提出用翻译的方法，来得到可以考虑上下文的向量。那如何通过翻译的方法来得到这个预训练模型呢，就是把该模型当成翻译的编码器，输入一个A语言的序列，然后有一个解码器，结合编码器的注意力，得到B语言的输出。
虽然可以做到这件事，但是翻译任务需要大量的语言对数据，收集这么多语言对数据是比较困难的，所以我们期望可以用很容易得到的无标签文本得到一个这样的预训练模型。
过去这样的方法被叫做无监督学习，不过现在通常叫做自监督学习。在自监督学习中，模型学会用部分输入去预测另外一部分输入。换句话说，就是输入的一部分用于预测输入中的其他部分。这种预测下一个单词的方法就是我们训练语言模型的方式。那么要用什么样的网络结构来训练这个模型呢？
最早用的就是LSTM，比较知名的使用LSTM进行预训练的模型，就是​ ​ELMo​​。随着自注意的流行，很多人把LSTM换成Transformer。
问题：
为什么预训练下一个单词的方法，能让我们得到代表单词意思的嵌入向量呢？
语言学家John Rupert Firth说过，你想要知道某个单词的意思，只要知道它和哪些单词一起出现。预测下一个单词其实做的是类似的事情。
假设我们有一些特定任务的标签数据，那如何微调模型呢？
一种做法是预选练的模型训练好后就固定了，变成一个特征Extrator。输入一个单词序列，通过这个预训练模型抽取一大堆特征，把这些特征丢到特征任务模型中，然后进行微调； 另外一种做法是把预训练的模型和特定任务的模型接在一起，在微调的时候，同时微调预训练模型和特定任务的模型。 如果微调整个模型，会遇到什么问题呢? 现在有三个不同的任务，每个任务中都有一个预训练好的模型，然后都微调整个模型。
这三个预训练好的模型，在不同的任务微调里面，它们会变得不一样。每一个任务都需要存一个新的模型，包含微调的预训练模型和特定任务模型。这样的模型往往非常巨大，其中的参数非常多，导致需要占用特别多的空间。
怎么解决这个问题呢 有人提出 Adaptor 的概念，在预训练的模型中加入一些叫Apt(Adaptor)的层，在微调的时候，只微调Apt层。这篇文章中，将Adapter插在Feed-forward层之后，在预训练的时候是没有Adapter的，只有在微调的时候才插进去。并且在微调的时候，只调整Adapter层的参数。
二、bert家族 1、修改Mask范围 那在BERT里面，要盖住哪些单词呢，原始的BERT里面是随机的。也许随机的不够好，尤其对于中文来说，如果盖住中文中的某个字，还是很容易从它附近的字猜出，比如“奥x会”，只要看到“奥”和“会”就可以猜到中间是”运”了。所以
有人提出 Whole Word Masking ​​盖住整个单词(中文里的词语)的方法，这样得到的模型可以学到更长的依赖关系。 可能只是盖住几个单词还不够好，ERNIE​(Baidu) ​​就提出了盖住短语级别(多个单词组成一个短语)和实体级别(需要识别出实体，然后盖住)。 还有一种Masking的方法，SpanBert​​​，思想很简单，一次盖住一排单词(token)。不用考虑什么短语啊、单词啊、实体啊。在SpanBert里面还提出了一种训练方法，叫SBO(Span Boundary Objective)，一般我们盖住了一些单词后，我们要把盖住的部分预测出现。而SBO通过被盖住范围的左右两边的向量，然后给定一个数值，比如3，代表要还原被盖住的第3个单词。然后SBO就知道，现在要还原3个位置。 还有一种方法，XLNet，从输入的文本序列中，随机一部分，去预测mask的结果，就是让各种各样不同的信息去预测一个单词，模型可以学到比较多的依赖关系。具体 在预训练阶段，引入permutation language model 的训练目标，对句子中单词排列组合，把一部分下文单词排列到上文位置中。这种做法是采用 attention掩码的机制来实现的：当前输入句子是X，要预测的第i个单词，i前面的单词位置不变，但是在transformer内部，通过attention mask，把其他没有被选到的单词mask掉，不让他们在预测单词的时候发生作用，看上去就是把这些被选中用来做预测的单词放在了上文位置了。 2、生成式任务 一般讲到BERT，大家都会说BERT不适于用来做生成任务，因为BERT训练的时候，会看到MASK左右两边的单词，而在生成任务中，只能看到左边已经生成出来的单词，然后BERT就表现不好了。</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Bert综述</h5><p class="card-text post-summary">一、背景 在使用预训练模型，处理下游任务时，有两类策略：基于特征(feature-based)、基于微调(fine-tuning)
基于特征：比如：ELMo，在使用时，对每个下游任务，创建一个跟这个任务相关的神经网络；预训练作为额外的特征跟输入一起输入到模型，预训练的额外特征可能会对要训练的模型有指导作用。 基于微调：比如：GPT，预训练模型在下游使用时，不需要改动太多，类似于视觉模型的fine-tuning，预训练完成特征提取，预训练模型后面添加个简单的网络用于实现具体任务。 1、上下文敏感 在自然语言中，有丰富的多义现象，一个词到底是什么意思，需要参考上下文才能判断。流行的上下文敏感表示：
TagLM(language-model-augmented sequence tagger 语言模型增强的序列标记器) CoVe(Context Vectors 上下文向量) ELMo(Embeddings from Language Models 来自语言模型的嵌入) ELMo 将来自预训练LSTM的所有中间层表示组合为输出表示 ELMo的表示，将作为添加特征添加到下游任务的有监督模型中 2、从特定任务到通用任务 ELMo显著改进了自然语言任务，但每个解决方案仍然依赖于一个特定的任务架构。怎么设计一个模型，让各个自然语言任务通用呢？
GPT(Generative Pre Training 生成式预训练)：在Transformer的基础上，为上下文敏感设计了通用的模型。
预训练一个用于表示文本序列的语言模型 当将GPT应用于下游任务时，语言模型的后面接一个线性输出层，以预测任务的标签。GPT的下游任务的监督学习过程，只对预训练Transformer解码器中的所有参数做微调。 GPT只能从左到右 二、BERT BERT的全称是Bidirectional Encoder Representation from Transformers, 即双向Transformer的Encoder。Bert结合了ELMo和GPT的有点，其主要贡献：
双向的重要性 基于微调的掩码语言模型(Masked Language Modeling)：BERT随机遮掩词元，并使用来自双向上下文的词元以自监督的方式预测该遮掩词元。 1、构造输入 token embedding: 格式：&lt;CLS>第一个文本序列&lt;SEP>第二个文本序列&lt;SEP>
segment embedding: 用来区分句子
position embedding: 在bert中 位置嵌入 是可学习的
def get_tokens_and_segments(tokens_a, tokens_b=None): """获取输入序列的词元及其片段索引""" tokens = ['&lt;cls>'] + tokens_a + ['&lt;sep>'] # 0和1分别标记片段A和B segments = [0] * (len(tokens_a) + 2) if tokens_b is not None: tokens += tokens_b + ['&lt;sep>'] segments += [1] * (len(tokens_b) + 1) return tokens, segments 2、MLM 词元维度</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>NdArray使用</h5><p class="card-text post-summary">一、查阅文档 怎么查阅相关文档？ 官网
1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random)) __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。 2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。
help(nd.ones_like) 注意：
jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。 二、内存开销 原始操作 首先来个例子：Y = Y + X &ndash;> 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：
内存id_x &lt;&ndash; X 内存id_y &lt;&ndash; Y 内存id_x+y &lt;&ndash; Y
Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x &lt;&ndash; X 内存id_y &lt;&ndash; Y 内存id_x+y &ndash;> 把内存id_x+y中数值复制到内存id_y中</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>内置模块</h5><p class="card-text post-summary">一、os os.path.basename() os.path.dirname() os.path.join() os.path.exists() os.path.isfile() os.path.isdir() os.path.abspath(__file__) 获取当前执行文件的绝对路径 os.listdir() 遍历该目录下的文件，返回文件名列表 os.walk() 遍历该目录，返回的是一个三元组(root, dirs, files)
root: 指的是当前正在遍历的文件夹的地址
dirs: 是一个list，内容是该文件夹中所有的目录的名字，不包括子目录
files：内容是该文件夹中所有的文件，不包括子目录 os.makedirs() 创建文件夹 os.remove() 删除文件夹 os.environ() 获取环境变量，比如：os.environ(&lsquo;变量名&rsquo;, &lsquo;默认值&rsquo;) 二、sys sys.</p></div><div class=card-footer><span class=float-left>September 8, 2021</span>
<a href=/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/zh-cn/categories/basic/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/zh-cn/categories/basic/page/6/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/zh-cn/categories/basic/>1</a></li><li class=page-item><a class=page-link href=/zh-cn/categories/basic/page/2/>2</a></li><li class=page-item><a class=page-link href=/zh-cn/categories/basic/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/zh-cn/categories/basic/page/6/>6</a></li><li class="page-item active"><a class=page-link href=/zh-cn/categories/basic/page/7/>7</a></li><li class=page-item><a class=page-link href=/zh-cn/categories/basic/page/8/>8</a></li><li class=page-item><a class=page-link href=/zh-cn/categories/basic/page/9/>9</a></li><li class=page-item><a href=/zh-cn/categories/basic/page/8/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/zh-cn/categories/basic/page/9/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=/js/list.js></script></body></html>