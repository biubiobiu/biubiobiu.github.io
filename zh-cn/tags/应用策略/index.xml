<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>应用策略 on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/tags/%E5%BA%94%E7%94%A8%E7%AD%96%E7%95%A5/</link><description>Recent content in 应用策略 on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/tags/%E5%BA%94%E7%94%A8%E7%AD%96%E7%95%A5/index.xml" rel="self" type="application/rss+xml"/><item><title>模型应用策略</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</guid><description>一、简介 要想训练一个针对特定领域的大模型，如果采用全量参数微调（Full Parameter Futuing）的方法，一方面需要大量的高质量数据集、另一方需要较高的算力，那么，有没有不需要大量算力就能在特定领域数据上对大模型进行微调的方法呢？
下面，给大家介绍几种常见的大模型微调方法：
Adapter-Tuning Prefix-Tuning Prompt-Tuning(P-Tuning)、P-Tuning v2 LoRA 对于大语言模型应用的两种不同的使用方式：
“专才”：只精通指定任务。怎么让一个基础模型在指定任务上比较精通呢？有两种方式：
加外挂：比如：在bert后面添加几个fc层，完成指定任务 fine-tune： Adapter插件：固定原来模型，添加一个额外的模型插件。例如：Bitfit、AdapterBias、Houlsby、Prefix-tuning；ControlNet， LoRA，Text Inversion “全才”：模型有各种背景知识，用户可以通过使用prompt指令，来要求模型按照指令输出。
In-context Learning Instruction tuning Chain-of-Thought Prompting APE 1、Adapter插件 github: adapter-bert 有人提出 Adaptor 的概念，在预训练的模型中加入一些叫Apt(Adaptor)的层，在微调的时候，只微调Apt层。这篇文章中，将Adapter插在Feed-forward层之后，在预训练的时候是没有Adapter的，只有在微调的时候才插进去。并且在微调的时候，只调整Adapter层的参数。 2、Prefix-tuning github: PrefixTuning 根据《Prefix-Tuning》 ，前缀调整实现了与微调所有层相当的建模性能，同时只需要训练 0.1% 的参数——实验基于 GPT-2 模型。此外，在许多情况下，前缀调整甚至优于所有层的微调，这可能是因为涉及的参数较少，这有助于减少较小​​目标数据集上的过度拟合。 3、Prompt-tuning github: P-tuning 论文：《GPT Understands》 先将一些为prompt输入到LSTM中，用LSTM输出的向量来替换原始的Prompt token 然后一起输入到 预训练模型中 LSTM和预训练模型一起训练 github: P-Tuning v2 论文：《P-Tuning v2》 p-tuning的改进版：不同层中的提示作为前缀token加入到输入序列中，并独立于其他层间(而不是由之前的transformer层计算)。</description></item></channel></rss>