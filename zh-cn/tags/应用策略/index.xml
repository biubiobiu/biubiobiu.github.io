<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>应用策略 on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/tags/%E5%BA%94%E7%94%A8%E7%AD%96%E7%95%A5/</link><description>Recent content in 应用策略 on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/tags/%E5%BA%94%E7%94%A8%E7%AD%96%E7%95%A5/index.xml" rel="self" type="application/rss+xml"/><item><title>模型应用策略</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</guid><description>一、简介 对于大语言模型应用的两种不同的使用方式：
“专才”：只精通指定任务。怎么让一个基础模型在指定任务上比较精通呢？有两种方式：
加外挂：比如：在bert后面添加几个fc层，完成指定任务 fine-tune： Adapter插件：固定原来模型，添加一个额外的模型插件。例如：Bitfit、AdapterBias、Houlsby、Prefix-tuning；ControlNet， LoRA，Text Inversion “全才”：模型有各种背景知识，用户可以通过使用prompt指令，来要求模型按照指令输出。
In-context Learning Instruction tuning Chain-of-Thought Prompting APE 1、Adapter插件 有人提出 Adaptor 的概念，在预训练的模型中加入一些叫Apt(Adaptor)的层，在微调的时候，只微调Apt层。这篇文章中，将Adapter插在Feed-forward层之后，在预训练的时候是没有Adapter的，只有在微调的时候才插进去。并且在微调的时候，只调整Adapter层的参数。
二、大模型-使用策略 1、In-Context Learning 1. 解释1 《Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?》 In-context learning是一种学习范式，它允许语言模型通过以演示形式组织的若干个示例或者指令来学习任务。In-context learning（ICL）的核心在于从任务相关的类比样本中学习，ICL要求若干示例以特定形式进行演示，然后将当前输入x跟上述示例通过prompt拼接到一起作为语言模型的输入。本质上，它利用训练有素的语言模型根据演示的示例来估计候选答案的可能性。简单理解，就是通过若干个完整的示例，让语言模型更好地理解当前的任务，从而做出更加准确的预测。
实验结论：
ICL 中Ground Truth信息无关紧要。
作者实验对比：没有示例、多个示例-且label是一一对应的、多个示例-且label是随机的。对比发现： 随机label 与 正确label 的效果相当，性能只下降了 $ 0 - 5\%$。 没有示例，效果下降较多。 2. ICL的性能收益主要来自 独立规范的输入空间和标签空间，以及正确一致的演示格式。</description></item></channel></rss>