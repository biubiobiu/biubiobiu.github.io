<!doctype html><html><head><title>aigc</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/layouts/main.css><link rel=stylesheet href=/css/navigators/navbar.css><link rel=stylesheet href=/css/plyr.css><link rel=stylesheet href=/css/flag-icon.min.css><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600"><link rel=stylesheet href=/fontawesome/css/all.min.css><link rel=stylesheet href=/css/colortheme/colortheme.css><link rel=icon type=image/png href=/images/site/favicon_hu0d88336a9cbd3e68c7714efae786b0a9_38044_42x0_resize_box_2.png><meta property="og:title" content="aigc"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://biubiobiu.github.io/zh-cn/tags/aigc/"><meta property="og:updated_time" content="2023-08-05T12:30:40+08:00"><link rel=stylesheet href=/css/layouts/list.css><link rel=stylesheet href=/css/navigators/sidebar.css><link rel=stylesheet href=/css/style.css></head><body data-spy=scroll data-target=#TableOfContents data-offset=80><div class="container-fluid bg-dimmed wrapper"><nav class="navbar navbar-expand-xl top-navbar final-navbar shadow"><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span></button>
<a class=navbar-brand href=/zh-cn><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png alt=Logo>
biubiobiu's Blog</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse lang-selector" id=top-nav-items><ul class="navbar-nav ml-auto"><li class="nav-item dropdown"><div id=theme-initialization style=display:none default-theme=system></div><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg src=/icons/moon-svgrepo-com.svg width=20></a><div class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# onclick=enableLightTheme()><img class=menu-icon-center src=/icons/sun-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=enableDarkTheme()><img class=menu-icon-center src=/icons/moon-svgrepo-com.svg width=20></a>
<a class="dropdown-item nav-link" href=# onclick=useSystemTheme()><img class=menu-icon-center src=/icons/computer-svgrepo-com.svg width=20></a></div></li></ul></div></div><img src=/images/site/main-logo_hu245540b1d52c0d501ae7bc0752a15caf_34633_42x0_resize_box_2.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu547c3206082786c1d32d36034e2a655a_40863_42x0_resize_box_2.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/zh-cn/search><input type=text name=keyword placeholder=搜索 data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/zh-cn/tags data-filter=all>标签</a></li><div class="subtree taxonomy-terms"><li><a class="taxonomy-term active" href=https://biubiobiu.github.io/zh-cn/tags/aigc/ data-taxonomy-term=aigc><span class=taxonomy-label>aigc</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/attention/ data-taxonomy-term=attention><span class=taxonomy-label>attention</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/backbone/ data-taxonomy-term=backbone><span class=taxonomy-label>backbone</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/bart/ data-taxonomy-term=bart><span class=taxonomy-label>BART</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/bert/ data-taxonomy-term=bert><span class=taxonomy-label>BERT</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/can/ data-taxonomy-term=can><span class=taxonomy-label>CAN</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/chatglm/ data-taxonomy-term=chatglm><span class=taxonomy-label>ChatGLM</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/claude/ data-taxonomy-term=claude><span class=taxonomy-label>Claude</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/clip/ data-taxonomy-term=clip><span class=taxonomy-label>CLIP</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/cnn/ data-taxonomy-term=cnn><span class=taxonomy-label>cnn</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/cohere/ data-taxonomy-term=cohere><span class=taxonomy-label>Cohere</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/contrastive-learning/ data-taxonomy-term=contrastive-learning><span class=taxonomy-label>contrastive learning</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/cuda/ data-taxonomy-term=cuda><span class=taxonomy-label>cuda</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/cv/ data-taxonomy-term=cv><span class=taxonomy-label>CV</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/dall-e/ data-taxonomy-term=dall-e><span class=taxonomy-label>DALL-E</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/diffusion/ data-taxonomy-term=diffusion><span class=taxonomy-label>Diffusion</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/electra/ data-taxonomy-term=electra><span class=taxonomy-label>ELECTRA</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/falcon/ data-taxonomy-term=falcon><span class=taxonomy-label>Falcon</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/family/ data-taxonomy-term=family><span class=taxonomy-label>Family</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/gan/ data-taxonomy-term=gan><span class=taxonomy-label>GAN</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/gpt/ data-taxonomy-term=gpt><span class=taxonomy-label>GPT</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/gpt-1/ data-taxonomy-term=gpt-1><span class=taxonomy-label>GPT-1</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/gru/ data-taxonomy-term=gru><span class=taxonomy-label>GRU</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/imagen/ data-taxonomy-term=imagen><span class=taxonomy-label>Imagen</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/importlib/ data-taxonomy-term=importlib><span class=taxonomy-label>importlib</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/ipdb/ data-taxonomy-term=ipdb><span class=taxonomy-label>ipdb</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/latex/ data-taxonomy-term=latex><span class=taxonomy-label>Latex</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/llama/ data-taxonomy-term=llama><span class=taxonomy-label>llama</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/logging/ data-taxonomy-term=logging><span class=taxonomy-label>logging</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/lstm/ data-taxonomy-term=lstm><span class=taxonomy-label>LSTM</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/markdown/ data-taxonomy-term=markdown><span class=taxonomy-label>MarkDown</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/matting/ data-taxonomy-term=matting><span class=taxonomy-label>matting</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/midjourney/ data-taxonomy-term=midjourney><span class=taxonomy-label>Midjourney</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/mllm/ data-taxonomy-term=mllm><span class=taxonomy-label>MLLM</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/mxnet/ data-taxonomy-term=mxnet><span class=taxonomy-label>mxnet</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/ndarray/ data-taxonomy-term=ndarray><span class=taxonomy-label>NdArray</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/nlp/ data-taxonomy-term=nlp><span class=taxonomy-label>NLP</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/opencv/ data-taxonomy-term=opencv><span class=taxonomy-label>OpenCV</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/optimizer/ data-taxonomy-term=optimizer><span class=taxonomy-label>optimizer</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/palm/ data-taxonomy-term=palm><span class=taxonomy-label>PaLM</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/pil/ data-taxonomy-term=pil><span class=taxonomy-label>PIL</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/pip/ data-taxonomy-term=pip><span class=taxonomy-label>pip</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/python/ data-taxonomy-term=python><span class=taxonomy-label>python</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/request/ data-taxonomy-term=request><span class=taxonomy-label>request</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/shortcodes/ data-taxonomy-term=shortcodes><span class=taxonomy-label>shortcodes</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/summary/ data-taxonomy-term=summary><span class=taxonomy-label>summary</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/t5/ data-taxonomy-term=t5><span class=taxonomy-label>T5</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/tensor/ data-taxonomy-term=tensor><span class=taxonomy-label>Tensor</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/tf/ data-taxonomy-term=tf><span class=taxonomy-label>TF</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/toha/ data-taxonomy-term=toha><span class=taxonomy-label>Toha</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/torch/ data-taxonomy-term=torch><span class=taxonomy-label>torch</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/transformer/ data-taxonomy-term=transformer><span class=taxonomy-label>Transformer</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/vicuna/ data-taxonomy-term=vicuna><span class=taxonomy-label>Vicuna</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/video/ data-taxonomy-term=video><span class=taxonomy-label>video</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/vision-transformer/ data-taxonomy-term=vision-transformer><span class=taxonomy-label>vision transformer</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/vlp/ data-taxonomy-term=vlp><span class=taxonomy-label>vlp</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/vqgan/ data-taxonomy-term=vqgan><span class=taxonomy-label>VQGAN</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/word-embedding/ data-taxonomy-term=word-embedding><span class=taxonomy-label>word embedding</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86/ data-taxonomy-term=%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86><span class=taxonomy-label>中心极限定理</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81/ data-taxonomy-term=%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81><span class=taxonomy-label>位置编码</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/ data-taxonomy-term=%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C><span class=taxonomy-label>假设检验</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%85%AC%E5%BC%8F/ data-taxonomy-term=%E5%85%AC%E5%BC%8F><span class=taxonomy-label>公式</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97/ data-taxonomy-term=%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97><span class=taxonomy-label>内置模块</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%87%B8%E4%BC%98%E5%8C%96/ data-taxonomy-term=%E5%87%B8%E4%BC%98%E5%8C%96><span class=taxonomy-label>凸优化</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%88%86%E5%B8%83/ data-taxonomy-term=%E5%88%86%E5%B8%83><span class=taxonomy-label>分布</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%88%9D%E5%A7%8B%E5%8C%96/ data-taxonomy-term=%E5%88%9D%E5%A7%8B%E5%8C%96><span class=taxonomy-label>初始化</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%8D%9A%E6%96%87%E8%B7%AF%E5%BE%84/ data-taxonomy-term=%E5%8D%9A%E6%96%87%E8%B7%AF%E5%BE%84><span class=taxonomy-label>博文路径</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%8D%B7%E7%A7%AF/ data-taxonomy-term=%E5%8D%B7%E7%A7%AF><span class=taxonomy-label>卷积</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/ data-taxonomy-term=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C><span class=taxonomy-label>卷积神经网络</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/ data-taxonomy-term=%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90><span class=taxonomy-label>回归分析</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/ data-taxonomy-term=%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90><span class=taxonomy-label>图像生成</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/ data-taxonomy-term=%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5><span class=taxonomy-label>基本概念</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/ data-taxonomy-term=%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C><span class=taxonomy-label>基础操作</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%A0%86/ data-taxonomy-term=%E5%A0%86><span class=taxonomy-label>堆</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/ data-taxonomy-term=%E5%A4%9A%E6%A8%A1%E6%80%81><span class=taxonomy-label>多模态</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B/ data-taxonomy-term=%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B><span class=taxonomy-label>大数定律</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/ data-taxonomy-term=%E5%A4%A7%E6%A8%A1%E5%9E%8B><span class=taxonomy-label>大模型</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/ data-taxonomy-term=%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81><span class=taxonomy-label>字符编码</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%B0%8F%E5%9E%8B%E5%8C%96/ data-taxonomy-term=%E5%B0%8F%E5%9E%8B%E5%8C%96><span class=taxonomy-label>小型化</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%B9%B3%E7%A8%B3%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/ data-taxonomy-term=%E5%B9%B3%E7%A8%B3%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B><span class=taxonomy-label>平稳随机过程</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%B9%B6%E8%A1%8C/ data-taxonomy-term=%E5%B9%B6%E8%A1%8C><span class=taxonomy-label>并行</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%B9%BB%E8%A7%89/ data-taxonomy-term=%E5%B9%BB%E8%A7%89><span class=taxonomy-label>幻觉</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%BA%94%E7%94%A8%E7%AD%96%E7%95%A5/ data-taxonomy-term=%E5%BA%94%E7%94%A8%E7%AD%96%E7%95%A5><span class=taxonomy-label>应用策略</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%BC%82%E5%B8%B8/ data-taxonomy-term=%E5%BC%82%E5%B8%B8><span class=taxonomy-label>异常</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/ data-taxonomy-term=%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0><span class=taxonomy-label>强化学习</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%BD%92%E4%B8%80%E5%8C%96/ data-taxonomy-term=%E5%BD%92%E4%B8%80%E5%8C%96><span class=taxonomy-label>归一化</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/ data-taxonomy-term=%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C><span class=taxonomy-label>循环神经网络</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%95%99%E7%A8%8B/ data-taxonomy-term=%E6%95%99%E7%A8%8B><span class=taxonomy-label>教程</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97/ data-taxonomy-term=%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97><span class=taxonomy-label>数学计算</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/ data-taxonomy-term=%E6%95%B0%E6%8D%AE%E9%9B%86><span class=taxonomy-label>数据集</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%96%87%E4%BB%B6/ data-taxonomy-term=%E6%96%87%E4%BB%B6><span class=taxonomy-label>文件</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90/ data-taxonomy-term=%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90><span class=taxonomy-label>方差分析</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ data-taxonomy-term=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0><span class=taxonomy-label>机器学习</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/ data-taxonomy-term=%E6%A6%82%E7%8E%87%E8%AE%BA><span class=taxonomy-label>概率论</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%A8%A1%E5%9E%8B/ data-taxonomy-term=%E6%A8%A1%E5%9E%8B><span class=taxonomy-label>模型</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%AD%A3%E5%88%99/ data-taxonomy-term=%E6%AD%A3%E5%88%99><span class=taxonomy-label>正则</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ data-taxonomy-term=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0><span class=taxonomy-label>深度学习</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83/ data-taxonomy-term=%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83><span class=taxonomy-label>混合精度训练</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E7%94%9F%E6%88%90%E5%BC%8F/ data-taxonomy-term=%E7%94%9F%E6%88%90%E5%BC%8F><span class=taxonomy-label>生成式</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/ data-taxonomy-term=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B><span class=taxonomy-label>目标检测</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E7%AE%80%E4%BB%8B/ data-taxonomy-term=%E7%AE%80%E4%BB%8B><span class=taxonomy-label>简介</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E7%BB%BC%E8%BF%B0/ data-taxonomy-term=%E7%BB%BC%E8%BF%B0><span class=taxonomy-label>综述</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8-%E6%9E%B6%E6%9E%84/ data-taxonomy-term=%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8-%E6%9E%B6%E6%9E%84><span class=taxonomy-label>编码器-解码器 架构</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/ data-taxonomy-term=%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84><span class=taxonomy-label>网络结构</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E8%AE%AD%E7%BB%83/ data-taxonomy-term=%E8%AE%AD%E7%BB%83><span class=taxonomy-label>训练</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6/ data-taxonomy-term=%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6><span class=taxonomy-label>训练框架</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/ data-taxonomy-term=%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2><span class=taxonomy-label>语义分割</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E8%BF%9B%E9%98%B6%E6%93%8D%E4%BD%9C/ data-taxonomy-term=%E8%BF%9B%E9%98%B6%E6%93%8D%E4%BD%9C><span class=taxonomy-label>进阶操作</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E9%85%8D%E7%BD%AE/ data-taxonomy-term=%E9%85%8D%E7%BD%AE><span class=taxonomy-label>配置</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E9%87%87%E6%A0%B7/ data-taxonomy-term=%E9%87%87%E6%A0%B7><span class=taxonomy-label>采样</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/ data-taxonomy-term=%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F><span class=taxonomy-label>随机变量</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/ data-taxonomy-term=%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B><span class=taxonomy-label>随机过程</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E9%9D%99%E6%80%81%E5%9B%BE/ data-taxonomy-term=%E9%9D%99%E6%80%81%E5%9B%BE><span class=taxonomy-label>静态图</span></a></li><li><a class=taxonomy-term href=https://biubiobiu.github.io/zh-cn/tags/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE/ data-taxonomy-term=%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE><span class=taxonomy-label>马尔科夫链</span></a></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class="content container-fluid" id=content><div class="container-fluid post-card-holder" id=post-card-holder><div class=post-card><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Midjourney</h5><p class="card-text post-summary">一、简介 It is coming soon.</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>PaLM</h5><p class="card-text post-summary">一、简介 1、PaLM 1 《PaLM: Scaling Language Modeling with Pathways》 这篇文章87页，并没有深度的讨论模型算法的结构，数据的清洗技巧，或者是训练的方式（估计感觉这块的创新性不是特别明显，也不是文章的主要目的）。 而是花了大量的篇幅去评估这个模型在multi-task的能力，比如翻译，代码修改，生成，问答等等。
其中模型版本于训练集大小：
Google PaLM 是一个 540B 参数密集型 Transformer 语言模型，在 780B 高质量、多样化文本的标记上进行训练。 它已经针对 3 种不同的尺寸进行了训练：8B、62B 和 540B，使用 6144 TPU v4 芯片使用 Pathways，这是一种新的 ML 系统，可跨多个 TPU（张量处理单元）Pod 进行高效训练。 当它被引入时，它在数百个 NLU 和 NLG 基准测试中产生了 SOTA 小样本学习结果。 这包括 Big-Bench 任务的性能大幅提升，以及多语言 NLG 和源代码生成功能的显着改进。 它还被证明可以使用思维链提示来解释笑话或逻辑推理，从而产生很好的解释。
PaLM超越了许多之前的SOTA。作者归功于
更好的数据的清理， 更多的数据， 模型规模的进一步提升。 模型算法的改进比较少，从Model Architecture那一章看出，其实模型结构的变化并不明显，在激活层，ShareEmbedding，PosEmbedding等模块做了一些结构优选。核心的TransformerBlock的变种选择也更多是为了优化模型的训练效率。谷歌作为搜索技术的天花板，数据清洗的积累，以及对于数据的理解肯定是OpenAI这些公司无法比拟的。个人感觉这块是个比较明显的优势。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 2、PaLM 2 《PaLM 2 Technical Report》 这篇报告-总结：</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>Vicuna</h5><p class="card-text post-summary">一、简介 二、网络结构</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>VQGAN</h5><p class="card-text post-summary">一、简介 It is coming soon.</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>大模型训练框架</h5><p class="card-text post-summary">目前训练超大规模语言模型主要有两条技术路线：
TPU + XLA + TensorFlow/JAX GPU + PyTorch + Megatron-LM + DeepSpeed。 前者由Google主导，由于TPU和自家云平台GCP深度绑定，对于非Googler来说， 只可远观而不可把玩，后者背后则有NVIDIA、Meta、MS大厂加持，社区氛围活跃，也更受到群众欢迎。
一、简介 1、并行计算 模型并行：将模型参数分布到多个GPU上
数据并行(Data parallelism, DP)：复制多份模型，每个副本被放置在不同设备上，并输入数据分片。该过程是并行完成的，所有模型副本在每个训练step结束时同步。 张量并行(Tensor parallelism, TP)：这种方式，我们不把整个激活张量或者梯度张量放在单个GPU上，而是切分参数矩阵，每个GPU计算一部分。该技术有时被称为水平并行或者层内模型并行。缺点是：需要额外通信，降低计算粒度 流水线并行(Pipeline parallelism, PP)：将网络分成多段并行。这有时也称为垂直并行。缺点是：引入流水线气泡 Zero Redundancy Optimizer(ZeRO)：将参数分布到数据并行组中，计算之前先获取模型参数。缺点是：需要额外通信 为了能够提升训练的效率，目前都采用混合精度训练，然而混合精度训练，是非常不稳定的，很容易导致梯度爆炸。这个原因是：在做Forword或者Backword的时候，需要把FP32位，降低到FP16位。这个操作有可能会导致精度溢出，从而导致loss爆炸。
2、混合精度(AMP) 混合精度 (Automatically Mixed Precision, AMP)
为加速训练，模型的参数是以FP16半精度存储的； 然后，输入数据也是 FP16半精度，与模型参数 foreword计算，激活结果也是FP16半精度； 计算loss，然后backword。在backword之前，需要对loss进行缩放，让他变成Fp32位 3、训练时的空间量 a. 模型参数（parameter） 需要的空间大小：跟模型大小一致。
b. 梯度（gradient） 需要的空间大小：跟模型大小一致。
c. 中间状态 以线性层为例：
Forword: $y = Wx$ Backword: $\nabla x = W^T \nabla y, \nabla W = \nabla y x^T$ 利用梯度更新模型参数时，需要用到：模型输入、输出。所以这些数据是要一直保存，直到参数更新完毕。 需要的空间大小：</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>模型小型化</h5><p class="card-text post-summary">一、简介 目前小型化的方案：
剪枝 Network Pruning 蒸馏 Knowledge Distillation 量化 Parameter Quantization Architecture Design Dynamic Computation 1、蒸馏 Knowledge Distillation 2、量化 Parameter Quantization 3、剪枝 Network Pruning 在权重W中，有些值非常接近于0，这些值好像没有啥作用。说明这些参数是冗余的，可以去掉。
二、TensorRT</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>模型应用策略</h5><p class="card-text post-summary">一、简介 要想训练一个针对特定领域的大模型，如果采用全量参数微调（Full Parameter Futuing）的方法，一方面需要大量的高质量数据集、另一方需要较高的算力，那么，有没有不需要大量算力就能在特定领域数据上对大模型进行微调的方法呢？
下面，给大家介绍几种常见的大模型微调方法：
Adapter-Tuning Prefix-Tuning Prompt-Tuning(P-Tuning)、P-Tuning v2 LoRA 对于大语言模型应用的两种不同的使用方式：
“专才”：只精通指定任务。怎么让一个基础模型在指定任务上比较精通呢？有两种方式：
加外挂：比如：在bert后面添加几个fc层，完成指定任务 fine-tune： Adapter插件：固定原来模型，添加一个额外的模型插件。例如：Bitfit、AdapterBias、Houlsby、Prefix-tuning；ControlNet， LoRA，Text Inversion “全才”：模型有各种背景知识，用户可以通过使用prompt指令，来要求模型按照指令输出。
In-context Learning Instruction tuning Chain-of-Thought Prompting APE 1、Adapter插件 github: adapter-bert 有人提出 Adaptor 的概念，在预训练的模型中加入一些叫Apt(Adaptor)的层，在微调的时候，只微调Apt层。这篇文章中，将Adapter插在Feed-forward层之后，在预训练的时候是没有Adapter的，只有在微调的时候才插进去。并且在微调的时候，只调整Adapter层的参数。 2、Prefix-tuning github: PrefixTuning 根据《Prefix-Tuning》 ，前缀调整实现了与微调所有层相当的建模性能，同时只需要训练 0.1% 的参数——实验基于 GPT-2 模型。此外，在许多情况下，前缀调整甚至优于所有层的微调，这可能是因为涉及的参数较少，这有助于减少较小​​目标数据集上的过度拟合。 3、Prompt-tuning github: P-tuning 论文：《GPT Understands》 先将一些为prompt输入到LSTM中，用LSTM输出的向量来替换原始的Prompt token 然后一起输入到 预训练模型中 LSTM和预训练模型一起训练 github: P-Tuning v2 论文：《P-Tuning v2》 p-tuning的改进版：不同层中的提示作为前缀token加入到输入序列中，并独立于其他层间(而不是由之前的transformer层计算)。</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>混合精度训练</h5><p class="card-text post-summary">一、简介 目前，混合精度 (Automatically Mixed Precision, AMP) 训练已经成为了炼丹师的标配工具，仅仅只需几行代码，就能让显存占用减半，训练速度加倍。 AMP 技术是由百度和 NIVDIA 团队在 2017 年提出的 (Mixed Precision Training)，该成果发表在 ICLR 上。PyTorch 1.6之前，大家都是用 NVIDIA 的 apex 库来实现 AMP 训练。1.6 版本之后，PyTorch 出厂自带 AMP。
# 原代码 output = net(input) loss = loss_fn(output, target) loss.backward() optimizer.step() optimizer.zero_grad() # 使用混合精度训练 with torch.cuda.amp.autocast(): output = net(input) loss = loss_fn(output, target) scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() optimizer.zero_grad() 半精度浮点数 (FP16)： 是一种计算机使用的二进制浮点数数据类型，使用 2 字节 (16 位) 存储。而 PyTorch 默认使用 单精度浮点数 (FP32) 来进行网络模型的计算和权重存储。FP32 在内存中用 4 字节 (32 位) 存储。</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>生成式-问题</h5><p class="card-text post-summary">一、简介 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。 问题2：训练一个大模型，需要多少数据量呢？ 问题3：数据预处理，怎么过滤、去重 问题4：模型大小 与 数据大小 的关系？ 二、模型问题 1、Calibration 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。
产生幻觉的原因： LLM缺乏相关知识，或者内化了错误的知识 LLM有时高估了自己的能力 问题对齐过程误导LLM进入幻觉：在对齐过程中接受针对它们在预训练阶段尚未获得的知识的指示时，实际上是一种不对齐过程，鼓励LLMs产生幻觉。 LLMs采用的生成策略存在潜在风险：LLMs有时会过分坚持早期的错误，即使它们意识到这是不正确的。换句话说，LLMs可能更喜欢为了自身一致性而堆积幻觉，而不是从错误中恢复。 减轻幻觉的方案：
整理训练集：在预训练期间减轻幻觉主要集中在预训练语料库的策划上 SFT：监督训练，构建训练数据是减轻幻觉的一种方法 RLHF：人类监督强化学习。让模型学习到：诚实性、 在推理阶段： 设计解码策略 利用外部知识来减轻LLMs中的幻觉 《Language Models (Mostly) Know What They Know》 这篇论文发现：模型够大后，说谎才会心虚。
对于大模型，模型输出是正确的概率 VS 模型的自信度，这两个是相关的。当模型比较自信时，输出的结果是正确的概率就比较大。 对于小模型，模型输出是正确的概率 VS 模型的自信度，这两个是不相关的 其中，横轴：模型输出时的自信程度；纵轴：模型输出是正确的概率。黄色表示最大模型，自身表示最小模型。 三、数据问题 问题2：训练一个大模型，需要多少数据量呢？
训练一个大模型，需要多少数据量呢？《When Do You Need Billions of Words of Pretraining Data?》 问题3：数据预处理，怎么过滤、去重?
数据预处理：《Scaling Language Models: Methods, Analysis & Insights from Training Gopher》 过滤有害的内容，通过Google的审核接口 去掉一些 HTML 前端的一些tag 规则过滤，去掉低质量的文本。 去重 剔除测试数据 问题4：模型大小 与 数据大小 的关系？ 《Training Compute-Optimal Large Language Models》 这篇文章发现：</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>综述</h5><p class="card-text post-summary">AIGC 的技术分类按照处理的模态来看，可以分为一下几类：
文本类：
主要包括：文章生成、文本风格转换、问答对话等生成或者编辑文本内容的AIGC技术。 音频类：
包括：文本转音频、语音转换、语音属性编辑等生成或者编辑语音内容的AIGC技术；以及音乐合成、场景声音编辑等生成或者编辑非语言内容的AIGC技术。例如：智能配音主播、虚拟歌手演唱、自动配乐、歌曲生成等 图像视频类：
包括：人脸生成、人脸替换、人物属性编辑、人类操控、姿态操控等AIGC技术；以及编辑图像、视频内容、图像生成、图像增强、图像修复等AIGC技术 虚拟空间类：
主要包括：三维重建、数字仿真等AIGC技术，以及编辑数字任务、虚拟场景相关的AIGC技术，例如：元宇宙、数字孪生、游戏引擎、3D建模、VR等。 在大语言模型的训练中，如果增大数据量，相应的应该减少学习率，这个跟原来的经验相反。
模型大小与模型效果 《Emergent Abilities of Large Language Models》 这篇文章指出：随着模型大小的增大，模型效果先不会有明显提升；增加到一定程度，模型有个突然顿悟时刻。
为什么需要预训练 《Visualizing and Understanding the Effectiveness of BERT》 这篇文章指出:
首先，预训练能在下游任务中达到一个良好的初始点，与从头开始训练相比，预训练能带来更宽的最优点，更容易优化。尽管 BERT 对下游任务的参数设置过高，但微调程序对过拟合具有很强的鲁棒性。 其次，可视化结果表明，由于最佳值平坦且宽广，以及训练损失面和泛化误差面之间的一致性，微调 BERT 趋向于更好地泛化。 第三，在微调过程中，BERT 的低层更具不变性，这表明靠近输入的层学习到了更多可迁移的语言表征。 一、文本生成 1、GPT 参考
GPT-4: 参数量1800B，训练集：1.3T token 2、PaLM 《PaLM: Scaling Language Modeling with Pathways》 PaLM才是真正的“大”模型。它是迄今为止训练的最大的密集语言模型，参数为 540B，需要 6144 个 TPU 来训练（这是 3 个完整的 TPU pod，每个包含 2048 个 TPU）。这太贵了！可能只有谷歌拥有资源+基础设施来做到这一点。使用的Token高达7800亿。PaLM是使用Google新一代PathWay分布式训练框架训练出来。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 所以，有很多变化！同样，其中很多都是常见的，例如使用 GPT-3 的学习嵌入向量已经非常过时了，现在几乎没有人这样做。</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div><div class=post-card><a href=/zh-cn/posts/00300_aigc/0020_generate_image/1000_summary/ class=post-card-link><div class=card><div class=card-head><img class=card-img-top src=/images/default-hero.jpg alt="Hero Image"></div><div class=card-body><h5 class=card-title>综述</h5><p class="card-text post-summary">扩散模型 扩散模型通过向原始数据逐步加入噪声以破坏原始信息，然后在逆转这一过程来生成样本。相较于以往的深度生成模型，扩散模型生产的数据质量更高、更具多样性，并且扩散模型的结构更灵活。
用一个物理过程来通俗地解释扩散模型 把真实数据比作空气中的一团分子，它们相互交织，形成了具有特定结构的整体。由于分子团过于复杂，我们无法直接了解其结构。我们可以从无规则运动的某种粒子(服从标准高斯分布)出发，不断变换这些粒子的相对位置，将这些粒子的状态变换为我们想要的复杂的分子形态。也就是：从噪声开始，进行很多小的”噪声“变换，逐渐地将噪声的分布转换为数据的分布。这样就可以利用得到的数据分布进行采样，以便得到新的数据。
扩散模型发展历史 扩散模型：是一类生成式模型，用于高维复杂数据的概率分布的建模，核心思想：基于扩散过程描述数据的生成过程，通过逆向扩散过程从后验概率逐步推断出先验概率分布，从而实现对高维复杂数据的建模。该模型的发展历史：
郎之万动力学（Langevin Dynamics）：扩散模型最初的灵感来自郎之万动力学。郎之万动力学是一种用于模拟随机过程的方法，其中加入了随机噪声，类似与布朗运动。 去噪分数匹配（Denoising Score Matching）：2010年，Roux提出了一种名为 ”去噪分数匹配“ 的算法，利用郎之万动力学建立一个基于梯度的概率模型。这种方法利用加噪声的样本和其周围样本之间的梯度来训练模型，从而建立一个对高维数据建模的框架。 扩散过程（Diffusion Process）：2015年，Sohl-Dickstein等人提出了扩散模型，通过将郎之万动力学与扩散过程结合，建立了一个能够描述高维数据生成的模型。该模型使用扩散过程描述数据的生成过程，并通过逆向扩散过程推断出先验分布。 无参数扩散（Non-Parametric Diffusion）：2019年，Song等人提出了一种基于无参数扩散过程的生成模型，它将扩散模型过程嵌入流模型中，从而实现了对高维数据的建模。 扩散模型：2019年至今，深度学习快速发展，扩散模型先后出现了：DDPM、SGM、SDE等新的范式，大大提高了模型的生成效果。 得益于扩散模型的强大性能，目前实际生成中已经出现利用扩散模型进行创造性内容生成。
图像生成的应用包括：Stable Diffusion、DALL-E2、Midjourney等，这些模型，基于输入的引导生成符合条件的内容。这种引导可以是自然语句、部分图像，也可以用低分辨率的图像做为引导生成高分辨率的图像。 图像生成 1、GAN 2014年
2、CAN 2017年
3、DALL-E 2021年2月
根据文本描述绘画，绘画水平一般。
4、CLIP+VQGAN 2021年4月
根据文本描述绘画，绘画水平一般。
5、Disco Diffusion 2022年2月
根据文本描述绘画，具有原创性，图片精美，渲染时间长。
6、Midjourney 2022年3月
根据文本描述绘画，适合人像，细节突出
7、DALL-E2 2022年4月，OpenAI发布DALL-E 2，命名来源于著名画家Dali和机器人总动员Wall-E，是DALL-E的升级版，其分辨率是之前版本的4倍。
DALL-E 2 由三个模型组成：CLIP模型、先验模型、扩散模型。
CLIP模型主要是用来对齐文本和图像特征：获取文本编码 先验模型主要是将文本表征映射为图片表征：将文本编码映射为图片编码 扩散模型是根据图片表征来完成完整的图像：用图片编码生成完整的图片。 根据文本描述绘画，限制较多，对复杂文字理解准确，渲染快
8、Stable Diffusion 2022年8月，慕尼黑大学的Robin Rombach和Patrick Esser的团队提出的文本生成图像模型，交互简单，生成速度快。Stable Diffusion主要由三部分组成，分别是 VAE、U-Net、CLIP文本编码器：
首先使用CLIP模型将文本转换为表征形式 然后引导扩散模型U-Net在低维表征上进行扩散 最后将扩散后的低维表征送入VAE中的解码器，从而生成图像。 在GAN和CLIP的基础上，Stable Diffusion模型开源，直接推动了AIGC技术的突破性发展。
Stable Diffusion 扩散模型的原理是：先添加噪声后降噪。即：给现有的图像逐步添加噪声，直到图像被完全破坏，然后根据给定的高斯噪声，逆向逐步还原出原图。在模型训练完毕后，只需要输入一段随机的高斯噪声，就能生成一张图像。</p></div><div class=card-footer><span class=float-left>August 5, 2023</span>
<a href=/zh-cn/posts/00300_aigc/0020_generate_image/1000_summary/ class="float-right btn btn-outline-info btn-sm">阅读</a></div></div></a></div></div><div class=paginator><ul class=pagination><li class=page-item><a href=/zh-cn/tags/aigc/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/zh-cn/tags/aigc/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/zh-cn/tags/aigc/>1</a></li><li class="page-item active"><a class=page-link href=/zh-cn/tags/aigc/page/2/>2</a></li><li class="page-item disabled"><a class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/zh-cn/tags/aigc/page/2/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-left"><div class="col-md-4 col-sm-12"><h5>导航</h5><ul><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#about>关于</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#skills>技能</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#experiences>经验</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#projects>项目</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#education>教育</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#recent-posts>最新博客</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#accomplishments>造诣</a></li><li class=nav-item><a class=smooth-scroll href=https://biubiobiu.github.io/zh-cn/#achievements>业绩</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>联系方式:</h5><ul><li><span>电话:</span> <span>+0123456789</span></li><li><span>邮箱:</span> <span>bsgshyn8@163.com</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>免责声明:</strong> 这个主题是MIT许可的。因此，您可以将其用于非商业、商业或者私人用途。您可以修改或分发主题，而无须经 作者任何许可。但是，主题作者不对主题的任何问题提供任何保证或承担任何责任。</p></div><hr><div class=container><div class="row text-left"><div class=col-md-4><a id=theme href=https://github.com/hossainemruz/toha target=_blank rel=noopener><img src=/images/theme-logo_hu8376fd15465fef26ffe66b6bcf0ca686_13669_32x0_resize_box_2.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2021 Copyright.</div><div class="col-md-4 text-right"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script type=text/javascript src=/js/jquery-3.4.1.min.js></script><script type=text/javascript src=/js/popper.min.js></script><script type=text/javascript src=/js/bootstrap.min.js></script><script type=text/javascript src=/js/navbar.js></script><script type=text/javascript src=/js/plyr.js></script><script type=text/javascript src=/js/main.js></script><script type=text/javascript src=/js/darkreader.js></script><script type=text/javascript src=/js/darkmode-darkreader.js></script><script src=/js/list.js></script></body></html>