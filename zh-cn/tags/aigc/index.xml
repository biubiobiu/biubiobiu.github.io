<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>aigc on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/tags/aigc/</link><description>Recent content in aigc on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/tags/aigc/index.xml" rel="self" type="application/rss+xml"/><item><title>CAN</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/</guid><description>一、简介 It is coming soon.</description></item><item><title>ChatGLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/</guid><description>一、简介 二、网络结构</description></item><item><title>Claude</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/</guid><description>一、简介 Anthropic公司推出的Claude。
二、网络结构</description></item><item><title>Cohere</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/</guid><description>一、简介 二、网络结构</description></item><item><title>DALL-E</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/</guid><description>一、简介 It is coming soon.</description></item><item><title>Diffusion</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/</guid><description>一、简介 It is coming soon.</description></item><item><title>Falcon</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/</guid><description>一、简介 二、网络结构</description></item><item><title>GAN</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1000_gan_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1000_gan_summary/</guid><description>一、简介 It is coming soon.
hello</description></item><item><title>GPT</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/</guid><description>一、简介 二、InstructGPT InstructGPT 通过人类的反馈，在GPT3上做微调。
1、SFT模型 设计了一些prompt，人工写答案，搜集一批数据，用来fine-tune GPT3，得到一个SFT模型 (Supervised Fine-tune)，即：有监督的微调
2、RW模型： 由于SFT的标注数据，成本比较大。这搞一个便宜点的。
设计一批prompt，每条prompt用GPT3采用很多条结果（生成模型的输出是概率性的，每次结果大概率是不一样的，generate有参数可以控制这些概率性） 人工标注：每个prompt的生成结果的排序 （打分标注，可比写答案的标注快多了） 训练一个奖励模型，这个奖励模型 就是对GPT3-6B的输出 进行打分，这个输出的分数 满足 人工标注的顺序。
作者没有采用GPT-175B模型，是因为在训练的过程中175B的不稳定，loss容易爆炸。
由于标注的是排序，RW模型的输出是score，所以有一个排序到score的映射。比如：一个prompt有K个答案。从k个答案中选2个，有 $C^2_k$种 结果对。每个结果对都是有人工标注的顺序的，在计算loss的时候保证这个顺序就行。每个prompt有 $C^2_k$ 个结果对，在算loss的时候，这 $C^2_k$ 个结果对一起计算。
loss的话是一个标准的 Pairwise的 Ranking Loss $$loss(\theta) = - \frac{1}{C^2_k} E_{x,y_w,y_l \in D} log(\sigma[r_\theta (x, y_w) - r_\theta (x, y_l)])$$ 其中，$r_\theta ()$ 表示GPT3-6B的输出score值，$\sigma()$ 表示 Sigmoid函数。学习的目标是最大化这个loss。 3、强化学习SFT模型 在强化学习的框架下调整SFT模型：
用PPO强化学习方法，fine-tune 之前的SFT模型，得出的模型就是InstructGPT，大小只有1.3B。
作者尝试把预训练的梯度整合到PPO中，如下： $$ objective(\phi) = E_{(x,y) \in D_{\pi_\phi^{RL}}} [r_\theta(x, y) - \beta log(\frac{\pi^{RL}_\phi(y|x)}{\pi^{SFT}(y|x)})] + $$</description></item><item><title>Imagen</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/</guid><description>一、简介 It is coming soon.</description></item><item><title>LLaMa</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/</guid><description>一、简介 二、网络结构 1、LLaMa 2、LLaMa 2 数据方面
LLaMa2训练了2000B的tokens，训练语料比LLaMa多了40% 2000B 个token的预训练集，提供了良好的性能和成本权衡；对最真实的来源进行上采样，以增加知识并抑制幻觉，保持真实 调查数据，以便用户更好地了解模型的潜在能力和局限性，保证安全。 上下文长度从2048提升到了4096 LLaMa2-chat 模型还接受了超过100w的人类标注的训练数据 开源数据选了 LLaMa2 使用监督微调 LLaMa2-chat 使用人类反馈强化学习(RLHF)进行迭代细化；包括拒绝采样、近端策略优化 网络方面
RMSNorm 归一化 FFN中用swiGLU激活函数替换原来的Relu 旋转位置编码 RoPE 增加上下文长度 分组查询注意力 GQA 原始的 多头注意力：MHA 具有单个KV投影的原始多查询格式：MQA 具有8个KV投影的分组查询注意力变体：GQA 训练方面 预训练细节：
用AdamW优化器进行训练，其中： $β_1 =0.9，β_2 = 0.95，eps = 10−5$。 使用余弦调整学习率，预热2000steps，$lr$ 衰减到峰值的10% 使用0.1的权重衰减 、1.0的梯度裁剪 精调细节：
余弦学习率，$lr=2e-5$ 权重衰减0.1，batch_size=64，序列长度为4096 训练2个epoch 引入Ghost Attention 有助于控制多轮对话</description></item><item><title>Midjourney</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/</guid><description>一、简介 It is coming soon.</description></item><item><title>PaLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/</guid><description>一、简介 1、PaLM 1 《PaLM: Scaling Language Modeling with Pathways》 这篇文章87页，并没有深度的讨论模型算法的结构，数据的清洗技巧，或者是训练的方式（估计感觉这块的创新性不是特别明显，也不是文章的主要目的）。 而是花了大量的篇幅去评估这个模型在multi-task的能力，比如翻译，代码修改，生成，问答等等。
其中模型版本于训练集大小：
Google PaLM 是一个 540B 参数密集型 Transformer 语言模型，在 780B 高质量、多样化文本的标记上进行训练。 它已经针对 3 种不同的尺寸进行了训练：8B、62B 和 540B，使用 6144 TPU v4 芯片使用 Pathways，这是一种新的 ML 系统，可跨多个 TPU（张量处理单元）Pod 进行高效训练。 当它被引入时，它在数百个 NLU 和 NLG 基准测试中产生了 SOTA 小样本学习结果。 这包括 Big-Bench 任务的性能大幅提升，以及多语言 NLG 和源代码生成功能的显着改进。 它还被证明可以使用思维链提示来解释笑话或逻辑推理，从而产生很好的解释。
PaLM超越了许多之前的SOTA。作者归功于
更好的数据的清理， 更多的数据， 模型规模的进一步提升。 模型算法的改进比较少，从Model Architecture那一章看出，其实模型结构的变化并不明显，在激活层，ShareEmbedding，PosEmbedding等模块做了一些结构优选。核心的TransformerBlock的变种选择也更多是为了优化模型的训练效率。谷歌作为搜索技术的天花板，数据清洗的积累，以及对于数据的理解肯定是OpenAI这些公司无法比拟的。个人感觉这块是个比较明显的优势。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 2、PaLM 2 《PaLM 2 Technical Report》 这篇报告-总结：</description></item><item><title>Vicuna</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/</guid><description>一、简介 二、网络结构</description></item><item><title>VQGAN</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/</guid><description>一、简介 It is coming soon.</description></item><item><title>大模型训练框架</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/</guid><description>一、简介 二、Deepspeed 三、Megatron-LM 《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》 Megatron 是一篇极具影响力的论文，介绍了高效的模型并行架构。Megatron引入了张量并行(tensor parallelism)，这是一种模型并行的变体，它将模型分割成多块，以实现层内模型并行，从而达到与单个GPU基准线76%效率相当的水平（尽管基准线只有峰值FLOPS的30%）。
Megatron意识到如果，你有一个网络模型 $Y=f(XW)$，你沿着列拆分开了 $W=[W1, W2]$ ，然后 $Y=[f(XW1), f(XW2)]$，所以你不需要做任何操作来同步 $Y$，transformer中唯一需要同步（all-reduce）的点是：
正向传播中，在MLP块后拼接模型激活值之前添加dropout时需要同步。 反向传播中，在self-attention块的开始处需要进行同步。 通过在这两个关键点进行同步操作，可以保证Transformer模型在计算过程中的正确性和一致性。
《Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model》</description></item><item><title>模型小型化</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</guid><description>一、简介 目前小型化的方案：
剪枝 Network Pruning 蒸馏 Knowledge Distillation 量化 Parameter Quantization Architecture Design Dynamic Computation 二、TensorRT</description></item><item><title>模型应用策略</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</guid><description>一、简介 对于大语言模型应用的两种不同的使用方式：
“专才”：只精通指定任务。怎么让一个基础模型在指定任务上比较精通呢？有两种方式：
加外挂：比如：在bert后面添加几个fc层，完成指定任务 fine-tune： Adapter插件：固定原来模型，添加一个额外的模型插件。例如：Bitfit、AdapterBias、Houlsby、Prefix-tuning；ControlNet， LoRA，Text Inversion “全才”：模型有各种背景知识，用户可以通过使用prompt指令，来要求模型按照指令输出。
In-context Learning Instruction tuning Chain-of-Thought Prompting APE 二、大模型-使用策略 1、In-Context Learning 1. 解释1 《Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?》 In-context learning是一种学习范式，它允许语言模型通过以演示形式组织的若干个示例或者指令来学习任务。In-context learning（ICL）的核心在于从任务相关的类比样本中学习，ICL要求若干示例以特定形式进行演示，然后将当前输入x跟上述示例通过prompt拼接到一起作为语言模型的输入。本质上，它利用训练有素的语言模型根据演示的示例来估计候选答案的可能性。简单理解，就是通过若干个完整的示例，让语言模型更好地理解当前的任务，从而做出更加准确的预测。
实验结论：
ICL 中Ground Truth信息无关紧要。
作者实验对比：没有示例、多个示例-且label是一一对应的、多个示例-且label是随机的。对比发现： 随机label 与 正确label 的效果相当，性能只下降了 $ 0 - 5\%$。 没有示例，效果下降较多。 2. ICL的性能收益主要来自 独立规范的输入空间和标签空间，以及正确一致的演示格式。
作者实验了这4个因素：输入空间、标签空间、演示格式。对比实验：把输入换成外部语料；把标签换成英语单词；缺少输入或者label。实验发现： 1. 把输入换成外部语料；把标签换成英语单词；缺少输入或者label。这些操作都会使得效果明显下降。 个人理解：比如做情感分析，示例：输入label。这种格式很重要，label是否正确不重要。</description></item><item><title>生成式-问题</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/</guid><description>一、简介 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。 问题2：训练一个大模型，需要多少数据量呢？ 问题3：数据预处理，怎么过滤、去重 问题4：模型大小 与 数据大小 的关系？ 二、模型问题 1、Calibration 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。
《Language Models (Mostly) Know What They Know》 这篇论文发现：模型够大后，说谎才会心虚。 对于大模型，模型输出是正确的概率 VS 模型的自信度，这两个是相关的。当模型比较自信时，输出的结果是正确的概率就比较大。 对于小模型，模型输出是正确的概率 VS 模型的自信度，这两个是不相关的 其中，横轴：模型输出时的自信程度；纵轴：模型输出是正确的概率。黄色表示最大模型，自身表示最小模型。 三、数据问题 问题2：训练一个大模型，需要多少数据量呢？
训练一个大模型，需要多少数据量呢？《When Do You Need Billions of Words of Pretraining Data?》 问题3：数据预处理，怎么过滤、去重?
数据预处理：《Scaling Language Models: Methods, Analysis &amp;amp; Insights from Training Gopher》 过滤有害的内容，通过Google的审核接口 去掉一些 HTML 前端的一些tag 规则过滤，去掉低质量的文本。 去重 剔除测试数据 问题4：模型大小 与 数据大小 的关系？ 《Training Compute-Optimal Large Language Models》 这篇文章发现：</description></item><item><title>综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/</guid><description>在大语言模型的训练中，如果增大数据量，相应的应该减少学习率，这个跟原来的经验相反。
模型大小与模型效果：
《Emergent Abilities of Large Language Models》 这篇文章指出：随着模型大小的增大，模型效果先不会有明显提升；增加到一定程度，模型有个突然顿悟时刻。
一、文本生成 1、GPT 参考
2、PaLM 《PaLM: Scaling Language Modeling with Pathways》 PaLM才是真正的“大”模型。它是迄今为止训练的最大的密集语言模型，参数为 540B，需要 6144 个 TPU 来训练（这是 3 个完整的 TPU pod，每个包含 2048 个 TPU）。这太贵了！可能只有谷歌拥有资源+基础设施来做到这一点。使用的Token高达7800亿。PaLM是使用Google新一代PathWay分布式训练框架训练出来。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 所以，有很多变化！同样，其中很多都是常见的，例如使用 GPT-3 的学习嵌入向量已经非常过时了，现在几乎没有人这样做。
3、ChatGLM Layer Normalization的顺序和残差连接被重新排列， 用于输出标记预测的单个线性层； ReLU s替换为GELU s 二维位置编码
4、BLOOM 使用 ALiBi 位置嵌入，它根据键和查询的距离直接衰减注意力分数。 与原始的 Transformer 和 Rotary 嵌入相比，它可以带来更流畅的训练和更好的下游性能。ALiBi不会在词嵌入中添加位置嵌入；相反，它会使用与其距离成比例的惩罚来偏向查询键的注意力评分。 Embedding Layer Norm 在第一个嵌入层之后立即使用，以避免训练不稳定。 使用了 25 万个标记的词汇表。 使用字节级 BPE。 这样，标记化永远不会产生未知标记 两个全连接层：</description></item></channel></rss>