<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>生成式 on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/tags/%E7%94%9F%E6%88%90%E5%BC%8F/</link><description>Recent content in 生成式 on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/tags/%E7%94%9F%E6%88%90%E5%BC%8F/index.xml" rel="self" type="application/rss+xml"/><item><title>生成式-问题</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/</guid><description>一、简介 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。 问题2：训练一个大模型，需要多少数据量呢？ 问题3：数据预处理，怎么过滤、去重 问题4：模型大小 与 数据大小 的关系？ 二、模型问题 1、Calibration 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。
产生幻觉的原因： LLM缺乏相关知识，或者内化了错误的知识 LLM有时高估了自己的能力 问题对齐过程误导LLM进入幻觉：在对齐过程中接受针对它们在预训练阶段尚未获得的知识的指示时，实际上是一种不对齐过程，鼓励LLMs产生幻觉。 LLMs采用的生成策略存在潜在风险：LLMs有时会过分坚持早期的错误，即使它们意识到这是不正确的。换句话说，LLMs可能更喜欢为了自身一致性而堆积幻觉，而不是从错误中恢复。 减轻幻觉的方案：
整理训练集：在预训练期间减轻幻觉主要集中在预训练语料库的策划上 SFT：监督训练，构建训练数据是减轻幻觉的一种方法 RLHF：人类监督强化学习。让模型学习到：诚实性、 在推理阶段： 设计解码策略 利用外部知识来减轻LLMs中的幻觉 《Language Models (Mostly) Know What They Know》 这篇论文发现：模型够大后，说谎才会心虚。
对于大模型，模型输出是正确的概率 VS 模型的自信度，这两个是相关的。当模型比较自信时，输出的结果是正确的概率就比较大。 对于小模型，模型输出是正确的概率 VS 模型的自信度，这两个是不相关的 其中，横轴：模型输出时的自信程度；纵轴：模型输出是正确的概率。黄色表示最大模型，自身表示最小模型。 三、数据问题 问题2：训练一个大模型，需要多少数据量呢？
训练一个大模型，需要多少数据量呢？《When Do You Need Billions of Words of Pretraining Data?》 问题3：数据预处理，怎么过滤、去重?
数据预处理：《Scaling Language Models: Methods, Analysis &amp;amp; Insights from Training Gopher》 过滤有害的内容，通过Google的审核接口 去掉一些 HTML 前端的一些tag 规则过滤，去掉低质量的文本。 去重 剔除测试数据 问题4：模型大小 与 数据大小 的关系？ 《Training Compute-Optimal Large Language Models》 这篇文章发现：</description></item><item><title>生成模型-评估</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0025_aigc_eval/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0025_aigc_eval/</guid><description>一、 测评指标：
1、BLEU(Bilingual evaluation understudy) $$ BLEU = BP \times e^{\sum^n_{n=1}W_n \times \log P_n}, BP = e^{1-\frac{lr}{lc}} 如果 lc &amp;lt;= lr $$
2、PPL(perplexity) 3、ROUGE(Recall-Oriented Understudy for Gisting Evaluation) 4、Distance-base Metrics Edit Dist
二、</description></item></channel></rss>