<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>大模型 on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 大模型 on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>大模型训练框架</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/</guid><description>一、简介 二、Deepspeed 三、Megatron-LM 《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》 Megatron 是一篇极具影响力的论文，介绍了高效的模型并行架构。Megatron引入了张量并行(tensor parallelism)，这是一种模型并行的变体，它将模型分割成多块，以实现层内模型并行，从而达到与单个GPU基准线76%效率相当的水平（尽管基准线只有峰值FLOPS的30%）。
Megatron意识到如果，你有一个网络模型 $Y=f(XW)$，你沿着列拆分开了 $W=[W1, W2]$ ，然后 $Y=[f(XW1), f(XW2)]$，所以你不需要做任何操作来同步 $Y$，transformer中唯一需要同步（all-reduce）的点是：
正向传播中，在MLP块后拼接模型激活值之前添加dropout时需要同步。 反向传播中，在self-attention块的开始处需要进行同步。 通过在这两个关键点进行同步操作，可以保证Transformer模型在计算过程中的正确性和一致性。
《Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model》</description></item><item><title>模型小型化</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</guid><description>一、简介 目前小型化的方案：
剪枝 Network Pruning 蒸馏 Knowledge Distillation 量化 Parameter Quantization Architecture Design Dynamic Computation 二、TensorRT</description></item><item><title>模型应用策略</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</guid><description>一、简介 对于大语言模型应用的两种不同的使用方式：
“专才”：只精通指定任务。怎么让一个基础模型在指定任务上比较精通呢？有两种方式：
加外挂：比如：在bert后面添加几个fc层，完成指定任务 fine-tune： Adapter插件：固定原来模型，添加一个额外的模型插件。例如：Bitfit、AdapterBias、Houlsby、Prefix-tuning；ControlNet， LoRA，Text Inversion “全才”：模型有各种背景知识，用户可以通过使用prompt指令，来要求模型按照指令输出。
In-context Learning Instruction tuning Chain-of-Thought Prompting APE 二、大模型-使用策略 1、In-Context Learning 1. 解释1 《Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?》 In-context learning是一种学习范式，它允许语言模型通过以演示形式组织的若干个示例或者指令来学习任务。In-context learning（ICL）的核心在于从任务相关的类比样本中学习，ICL要求若干示例以特定形式进行演示，然后将当前输入x跟上述示例通过prompt拼接到一起作为语言模型的输入。本质上，它利用训练有素的语言模型根据演示的示例来估计候选答案的可能性。简单理解，就是通过若干个完整的示例，让语言模型更好地理解当前的任务，从而做出更加准确的预测。
实验结论：
ICL 中Ground Truth信息无关紧要。
作者实验对比：没有示例、多个示例-且label是一一对应的、多个示例-且label是随机的。对比发现： 随机label 与 正确label 的效果相当，性能只下降了 $ 0 - 5\%$。 没有示例，效果下降较多。 2. ICL的性能收益主要来自 独立规范的输入空间和标签空间，以及正确一致的演示格式。
作者实验了这4个因素：输入空间、标签空间、演示格式。对比实验：把输入换成外部语料；把标签换成英语单词；缺少输入或者label。实验发现： 1. 把输入换成外部语料；把标签换成英语单词；缺少输入或者label。这些操作都会使得效果明显下降。 个人理解：比如做情感分析，示例：输入label。这种格式很重要，label是否正确不重要。</description></item></channel></rss>