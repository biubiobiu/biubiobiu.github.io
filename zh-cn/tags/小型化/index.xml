<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>小型化 on biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/tags/%E5%B0%8F%E5%9E%8B%E5%8C%96/</link><description>Recent content in 小型化 on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Sat, 05 Aug 2023 12:30:40 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/tags/%E5%B0%8F%E5%9E%8B%E5%8C%96/index.xml" rel="self" type="application/rss+xml"/><item><title>模型小型化</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</guid><description>一、简介 目前小型化的方案：
剪枝 Network Pruning 蒸馏 Knowledge Distillation 量化 Parameter Quantization Architecture Design Dynamic Computation 1、蒸馏 Knowledge Distillation 2、量化 Parameter Quantization 3、剪枝 Network Pruning 在权重W中，有些值非常接近于0，这些值好像没有啥作用。说明这些参数是冗余的，可以去掉。
二、TensorRT</description></item></channel></rss>