<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>biubiobiu's Blog</title><link>https://biubiobiu.github.io/zh-cn/</link><description>Recent content on biubiobiu's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Everything is mine</copyright><lastBuildDate>Tue, 08 Aug 2023 06:00:20 +0800</lastBuildDate><atom:link href="https://biubiobiu.github.io/zh-cn/index.xml" rel="self" type="application/rss+xml"/><item><title>T5综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0120_t5/0010_t5_summary/</link><pubDate>Tue, 08 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0120_t5/0010_t5_summary/</guid><description>一、简介 T5 T5的主要贡献是：把NLP的不同任务，统一成一种任务形式：文本输入，文本输出。即：每个任务（包括翻译，问题解答和分类）都将模型文本作为输入，并对其进行训练以生成一些目标文本。这使我们可以在各种任务中使用相同的模型，损失函数，超参数等。“ T5”是指我们的模型，我们将其称为“文本到文本传输转换器”。
数据： “Colossal Clean Crawled Corpus” (C4) 巨大的干净爬行的语料库，这是我们创建的基于常见爬网的数据集，它是未标记文本数据的来源。
二、模型介绍 目前基于Transformer的模型架构主要有：
Encoder-Decoder结构（传统的Transformer结构）：Seq2Seq 常用模型，在编码器输入中可以看到序列中包括自己的全部字符，在解码器的输出只能看到当前字符及之前的字符。 Language model结构（GPT的结构）：Encoder-Decoder结构 的Decoder部分，单向结构，每次只能看到当前以及之前的部分。 Prefix LM 结构（UniLM的结构）：前面一部分文本可以看到前缀部分所有内容，后面剩下的内容只能看到自己以及之前的内容。 1、T5模型结构 通过T5的实验发现Encoder-Decoder结构的模型效果最好，所以T5模型本质上来说是一个基于Transformer的Encoder-Decoder模型。
2、位置编码 Transformer的 绝对位置编码，虽然有一定的外推性，但是没有方向性。
T5采用了相对位置编码：根据token与token之间的位置关系来生成权重。比如：$w_{-3}, w_{-2}, w_{-1}, w_{0}, w_1, w_2$ 其中，$w_0$ 表示自己位置的权重，$w_1$ 表示下一个位置的权重
3、自监督预训练方法 作者对比了3中训练方法：
语言模型式：单向的从左到右一次预测，就是GPT模型的方式 bert-style: 相bert一样随机破坏掉一部分，然后还原 顺序还原：打乱文本的顺序，输出恢复原来顺序。 经过作者实验对比，发现：bert-style 的训练方式，效果最好。
4、破坏策略 作者对比3中破坏策略：
Mask法：随机破坏一个token，用一个特殊字符替换。 Replace Span (小段替换): 将一小段token破坏掉，用一个特殊字符替换。 Drop法：没有替换操作，直接丢弃。 经过作者实验对比，发现：Replace Span (小段替换)，效果最好。
破坏比例，作者对比了：$10\%, 15\%, 25\%, 50\%$，实验发现：破坏 $15\%$，效果最好。
Span长度，作者对比了：$2, 3, 5, 10$，实验发现：破坏长度 $span = 3$，效果最好。</description></item><item><title>GPT-1</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/</link><pubDate>Tue, 08 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0080_gpt/0020_gpt1_detail/</guid><description>一、GPT-1的结构 当时的两个问题：
没有一个合适的目标函数，不同的子任务（比如：翻译、分类、理解等）有自己的目标函数 怎么有效的把学到的 表征 传递到下游的子任务重。因为，NLP的子任务差异还是挺大的。 1、输入输出 2、编码 对于输入的一句文本串，机器是操作不了的，需要把这段文字串中的每个字转变成数字向量。那么如何将单词变成向量呢？
构建词表：将所有单词都搜集起来，通过训练一个分词模型，把一句文本split成：单词、固定式语句、组词、等等。比如：GPT的词表大小为 50257。 one-hot编码：比如：每个单词的one-hot编码，就是一个词表(50257)大小的一个向量，该词位置上的值为1，其余全是0. embedding：对于one-hot编码，大部分都是0填充，就是卑鄙的浪费。为了解决这个问题，模型学习了一个embedding函数：一个神经网络，把50257长度的1、0向量，输出n长度的数字向量。即：模型试图将词表映射到较小的空间。(这也比较合理：因为词表中本来就存在：近义词、同义词、等等) 3、位置信息编码(Position Encoding) 文本的位置信息很重要，就想图像中每个像素点的位置信息，不过输入一句话，跟顺序打乱，attention输出都是可以是一样的（如果顺序有变动，相应的权重变动一下就行）。所以，需要手动加入文本的位置信息。位置信息的计算：
比如：GPT允许一句输入最长2048个token。每个token经过one-hot编码、embedding后 维度为12288。 位置编码的输出是：2048*12288 维的信息。其中，2048方向可以看成时间t(或者离散的n); 12288方向可以看成不同的频率。 假设：从1~12288，频率从：$f, &amp;hellip;, f^{12288}$，就可以理解为 $T = 1/f^{12288}$ 进制下的数字表示法。每个位置就是可以是不一样。 4、注意力机制 文本的embedding + 位置编码，作为注意力机制的输入 $\bf W_q, W_k, W_v$，三个可学习的矩阵，把输入的embedding向量，变换成向量：$\bf q, k, v$。 attention计算：用搜索向量$\bf q_i$，与所有key向量$\bf{k_i}$，$i\in(1,..N)$计算内积(表示相似度)。这个N个值分别作为$\bf v_i$ $i \in (1,&amp;hellip;,N)$ 的权重。最后计算出的向量就是一个head的attention输出 一个head的计算注意力后的向量维度为128，GPT采用96个head，拼接起来正好是12288维度。经过$\bf W_z$ 转换后，作为attention模块的输出，维度与输入一致。 5、layer normalization 6、前馈神经网络 7、解码 96个注意力机制/前馈网络 后，输出是是 2048*12288的向量信息。不过词表是50257大小，所以需要把embedding的逆变换，把12288维度映射回50257大小。对下一个字的预测：输出一个50257维的向量，这个向量中的值表示词表中每个字的概率值，通过softmax之后，选出最大概率的字，或者选出top-k个最有可能得词（想象力的体现）。</description></item><item><title>Midjourney</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1025_midjourney/</guid><description>一、简介 It is coming soon.</description></item><item><title>CAN</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1005_can_summary/</guid><description>一、简介 It is coming soon.</description></item><item><title>ChatGLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0025_chatglm/</guid><description>一、简介 《GLM: General Language Model Pretraining with Autoregressive Blank Infilling》 参考 ChatGLM-6B： ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。 ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。
ChatGLM2-6B： ChatGLM2-6B 是开源中英双语对话模型 ChatGLM-6B 的第二代版本，在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，ChatGLM2-6B 引入了如下新特性：
更强大的性能： 基于 ChatGLM 初代模型的开发经验，我们全面升级了 ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 GLM 的混合目标函数 经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，评测结果显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同尺寸开源模型中具有较强的竞争力。 更长的上下文：基于 FlashAttention 技术，我们将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使用 8K 的上下文长度训练。 更高效的推理：基于 Multi-Query Attention 技术，ChatGLM2-6B 有更高效的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了 42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。 二、网络结构 按照自动编码的思想从输入文本中随机删除连续的标记span，并按照自回归预训练的思想训练模型顺序重建span。</description></item><item><title>DALL-E</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1010_dall_e/</guid><description>一、简介 It is coming soon.</description></item><item><title>Claude</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0030_claude/</guid><description>一、简介 Anthropic公司推出的Claude。
二、网络结构</description></item><item><title>Diffusion</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1020_diffusion/</guid><description>一、简介 Diffusion 过程：每一步添加一次noise，经过很多步后，图片就接近白噪声了。
但是，我们的目的是：从白噪声中，根据输入的文字描述，生成一张图片。是上面Diffusion过程的逆过程。
所以，根据Diffusion过程生成训练数据，然后训练一个：noise 生成器
从noise中生成图片的过程，也是一步一步删除noise的过程。
所以，训练一个noise 生成器，根据输入的图片、步数，生成图片中的噪声，然后减去输入图片中的这部分噪声，就是去除噪声的图片。
为啥设计个 noise 生成器，而不是直接设计个图片生成器？
noise 生成器：生成噪声，总比一步生成最终的优质图片要容易得多。 需要根据输入的文字描述，来生成相应的图片，那么文字特征是怎么输入的呢？
在 noise 生成器 中添加一个文本输入。 二、Diffusion Model Diffusion 的常用范式：
文本编码器 生成模型：产出中间产物（图片的压缩版本） 图像解码器：生成高质量的图片 文本编码器：
可以是 《CLIP》 生成模型：
在对图片做Diffusion时，是对图片不断地添加noise。
对于生成模型，是对latent representation 不断地添加noise。
所以，在真实的生成模块里，是对latent representation 不断地删除噪声，生成可用的中间产物。
图像编码器：
-- 图像编码器，可以是把低分辨率的小图，生成高分辨率的大图，如下图：
也可以是，把中间产物，生成高分辨率的大图，如下图：
1、Stable Diffusion 《Stable Diffusion》 2、DALL-E 《Hierarchical Text-Conditional Image Generation with CLIP Latents》 《Zero-Shot Text-to-Image Generation》 3、Imagen Imagen Home 《Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding》 三、评估指标 a.</description></item><item><title>GAN</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1002_gan_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1002_gan_summary/</guid><description>一、简介 Discriminator
Generator
二、网络</description></item><item><title>Falcon</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0040_falcon/</guid><description>一、简介 二、网络结构</description></item><item><title>大模型训练框架</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0010_aigc_train_p/</guid><description>目前训练超大规模语言模型主要有两条技术路线：
TPU + XLA + TensorFlow/JAX GPU + PyTorch + Megatron-LM + DeepSpeed。 前者由Google主导，由于TPU和自家云平台GCP深度绑定，对于非Googler来说， 只可远观而不可把玩，后者背后则有NVIDIA、Meta、MS大厂加持，社区氛围活跃，也更受到群众欢迎。
一、简介 1、并行计算 模型并行：将模型参数分布到多个GPU上
数据并行(Data parallelism, DP)：复制多份模型，每个副本被放置在不同设备上，并输入数据分片。该过程是并行完成的，所有模型副本在每个训练step结束时同步。 张量并行(Tensor parallelism, TP)：这种方式，我们不把整个激活张量或者梯度张量放在单个GPU上，而是切分参数矩阵，每个GPU计算一部分。该技术有时被称为水平并行或者层内模型并行。缺点是：需要额外通信，降低计算粒度 流水线并行(Pipeline parallelism, PP)：将网络分成多段并行。这有时也称为垂直并行。缺点是：引入流水线气泡 Zero Redundancy Optimizer(ZeRO)：将参数分布到数据并行组中，计算之前先获取模型参数。缺点是：需要额外通信 为了能够提升训练的效率，目前都采用混合精度训练，然而混合精度训练，是非常不稳定的，很容易导致梯度爆炸。这个原因是：在做Forword或者Backword的时候，需要把FP32位，降低到FP16位。这个操作有可能会导致精度溢出，从而导致loss爆炸。
2、混合精度(AMP) 混合精度 (Automatically Mixed Precision, AMP)
为加速训练，模型的参数是以FP16半精度存储的； 然后，输入数据也是 FP16半精度，与模型参数 foreword计算，激活结果也是FP16半精度； 计算loss，然后backword。在backword之前，需要对loss进行缩放，让他变成Fp32位 3、训练时的空间量 a. 模型参数（parameter） 需要的空间大小：跟模型大小一致。
b. 梯度（gradient） 需要的空间大小：跟模型大小一致。
c. 中间状态 以线性层为例：
Forword: $y = Wx$ Backword: $\nabla x = W^T \nabla y, \nabla W = \nabla y x^T$ 利用梯度更新模型参数时，需要用到：模型输入、输出。所以这些数据是要一直保存，直到参数更新完毕。 需要的空间大小：</description></item><item><title>GPT</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0011_gpt/</guid><description>一、简介 二、GPT-1 GPT(2018-06) 详细参考
其创造性的提出以Transformer的解码器来训练生成式模型，后面Bert的作者估计是看到了这篇论文，据说两个月时间就发表了以Transformer编码器训练的Bert模型。总结下GPT-1模型：
GPT-1 使用了一个仅有解码器的 Transformer 结构，每一个作为一个Layer，共有12层； 使用了一个 768 维的嵌入向量来表示输入序列中的每个词或标记，使用了 12 个并行的注意力头（attention heads）； 使用Adam优化器进行模型训练，在训练过程中，使用了学习率的 warmup 阶段和余弦退火调度机制，以平衡训练速度和模型性能； 模型权重被初始化为均值为 0、标准差为 0.02 的正态分布（N(0, 0.02)），使用字节对编码（Byte Pair Encoding，BPE）来对文本进行分词处理，分词后得到的词汇表大小为 40000； 激活函数是 GELU； 文本输入序列固定长度是512； 参数量 117M; 使用了学习得到的位置嵌入向量(position embedding)，而不是Attention is All You Need中使用的正弦位置嵌入向量； 三、GPT-2 GPT-2(2019-02)
GPT-2的改进:
GPT-2 是GPT语言模型开始变大的地方，这是 OpenAI 第一次训练超过 1B 个参数的模型。 通过提升模型的规模，来凸显GPT的优势。在 GPT-1 中，作者训练了单个模型，但在这里，作者训练了一系列模型。 与GPT-1相比，架构上有如下差异：
层归一化操作，有原来的post-norm换成了pre-norm，以加速训练和提高模型性能。此外，在最后一个自注意力块的输出上添加了额外的层归一化； 在权重初始化时，通过 $\frac{1}{\sqrt n}$ 进行缩放。这种缩放有助于减少梯度更新的方差，使训练过程更加稳定； 扩大了其词汇表的大小，词汇表大小约为 50,000（相比于约 40,000）； 增大文本输入序列长度 1024（相比于 512）这使得模型能够更好地理解和生成更长的文本； batch size大小为 512（相比于 64）较大的批次大小有助于提高训练效率和模型并行计算的能力。 最大的模型具有约 15 亿个参数。 数据集：GPT-2 构造了一个新数据集，WebText。全部来自于 Reddit 的外链，而且是那些获得至少三个赞的外链，经过清洗、去重后，得到8百万网页共计 40GB 文本数据。 WebText 数据集的特点在于全面而干净。 GPT-2的不同版本:</description></item><item><title>Imagen</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1030_imagen/</guid><description>一、简介 It is coming soon.</description></item><item><title>LLaMa</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0015_llama/</guid><description>LLaMa2 翻译
一、简介 数据方面
LLaMa2训练了2000B的tokens，训练语料比LLaMa多了40% 2000B 个token的预训练集，提供了良好的性能和成本权衡；对最真实的来源进行上采样，以增加知识并抑制幻觉，保持真实 调查数据，以便用户更好地了解模型的潜在能力和局限性，保证安全。 上下文长度从2048提升到了4096 LLaMa2-chat 模型还接受了超过100w的人类标注的训练数据 开源数据选了 LLaMa2 使用监督微调 LLaMa2-chat 使用人类反馈强化学习(RLHF)进行迭代细化；包括拒绝采样、近端策略优化 网络方面
LLaMa2 vs LLaMa，主要改动体现在 GQA 和 FFN 上:
由MHA改成GQA：整体参数量会减少 FFN模块矩阵维度有扩充：增强泛化能力，整体参数量增加。 RMSNorm 归一化 FFN中用swiGLU激活函数替换原来的Relu 旋转位置编码 RoPE 增加上下文长度 分组查询注意力 GQA 原始的 多头注意力：MHA 具有单个KV投影的原始多查询格式：MQA 具有8个KV投影的分组查询注意力变体：GQA 训练方面 预训练细节：
用AdamW优化器进行训练，其中： $β_1 =0.9，β_2 = 0.95，eps = 10−5$。 使用余弦调整学习率，预热2000steps，$lr$ 衰减到峰值的10% 使用0.</description></item><item><title>LLM-数据集</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0002_aigc_data/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0002_aigc_data/</guid><description>Awesome-Chinese-LLM</description></item><item><title>综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1000_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1000_summary/</guid><description>扩散模型 扩散模型通过向原始数据逐步加入噪声以破坏原始信息，然后在逆转这一过程来生成样本。相较于以往的深度生成模型，扩散模型生产的数据质量更高、更具多样性，并且扩散模型的结构更灵活。
用一个物理过程来通俗地解释扩散模型 把真实数据比作空气中的一团分子，它们相互交织，形成了具有特定结构的整体。由于分子团过于复杂，我们无法直接了解其结构。我们可以从无规则运动的某种粒子(服从标准高斯分布)出发，不断变换这些粒子的相对位置，将这些粒子的状态变换为我们想要的复杂的分子形态。也就是：从噪声开始，进行很多小的”噪声“变换，逐渐地将噪声的分布转换为数据的分布。这样就可以利用得到的数据分布进行采样，以便得到新的数据。
扩散模型发展历史 扩散模型：是一类生成式模型，用于高维复杂数据的概率分布的建模，核心思想：基于扩散过程描述数据的生成过程，通过逆向扩散过程从后验概率逐步推断出先验概率分布，从而实现对高维复杂数据的建模。该模型的发展历史：
郎之万动力学（Langevin Dynamics）：扩散模型最初的灵感来自郎之万动力学。郎之万动力学是一种用于模拟随机过程的方法，其中加入了随机噪声，类似与布朗运动。 去噪分数匹配（Denoising Score Matching）：2010年，Roux提出了一种名为 ”去噪分数匹配“ 的算法，利用郎之万动力学建立一个基于梯度的概率模型。这种方法利用加噪声的样本和其周围样本之间的梯度来训练模型，从而建立一个对高维数据建模的框架。 扩散过程（Diffusion Process）：2015年，Sohl-Dickstein等人提出了扩散模型，通过将郎之万动力学与扩散过程结合，建立了一个能够描述高维数据生成的模型。该模型使用扩散过程描述数据的生成过程，并通过逆向扩散过程推断出先验分布。 无参数扩散（Non-Parametric Diffusion）：2019年，Song等人提出了一种基于无参数扩散过程的生成模型，它将扩散模型过程嵌入流模型中，从而实现了对高维数据的建模。 扩散模型：2019年至今，深度学习快速发展，扩散模型先后出现了：DDPM、SGM、SDE等新的范式，大大提高了模型的生成效果。 得益于扩散模型的强大性能，目前实际生成中已经出现利用扩散模型进行创造性内容生成。
图像生成的应用包括：Stable Diffusion、DALL-E2、Midjourney等，这些模型，基于输入的引导生成符合条件的内容。这种引导可以是自然语句、部分图像，也可以用低分辨率的图像做为引导生成高分辨率的图像。 图像生成 1、GAN 2014年
2、CAN 2017年
3、DALL-E 2021年2月
根据文本描述绘画，绘画水平一般。
4、CLIP+VQGAN 2021年4月
根据文本描述绘画，绘画水平一般。
5、Disco Diffusion 2022年2月
根据文本描述绘画，具有原创性，图片精美，渲染时间长。
6、Midjourney 2022年3月
根据文本描述绘画，适合人像，细节突出
7、DALL-E2 2022年4月，OpenAI发布DALL-E 2，命名来源于著名画家Dali和机器人总动员Wall-E，是DALL-E的升级版，其分辨率是之前版本的4倍。
DALL-E 2 由三个模型组成：CLIP模型、先验模型、扩散模型。
CLIP模型主要是用来对齐文本和图像特征：获取文本编码 先验模型主要是将文本表征映射为图片表征：将文本编码映射为图片编码 扩散模型是根据图片表征来完成完整的图像：用图片编码生成完整的图片。 根据文本描述绘画，限制较多，对复杂文字理解准确，渲染快
8、Stable Diffusion 2022年8月，慕尼黑大学的Robin Rombach和Patrick Esser的团队提出的文本生成图像模型，交互简单，生成速度快。Stable Diffusion主要由三部分组成，分别是 VAE、U-Net、CLIP文本编码器：
首先使用CLIP模型将文本转换为表征形式 然后引导扩散模型U-Net在低维表征上进行扩散 最后将扩散后的低维表征送入VAE中的解码器，从而生成图像。 在GAN和CLIP的基础上，Stable Diffusion模型开源，直接推动了AIGC技术的突破性发展。
Stable Diffusion 扩散模型的原理是：先添加噪声后降噪。即：给现有的图像逐步添加噪声，直到图像被完全破坏，然后根据给定的高斯噪声，逆向逐步还原出原图。在模型训练完毕后，只需要输入一段随机的高斯噪声，就能生成一张图像。</description></item><item><title>综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0001_aigc_summary/</guid><description>AIGC 的技术分类按照处理的模态来看，可以分为一下几类：
文本类：
主要包括：文章生成、文本风格转换、问答对话等生成或者编辑文本内容的AIGC技术。 音频类：
包括：文本转音频、语音转换、语音属性编辑等生成或者编辑语音内容的AIGC技术；以及音乐合成、场景声音编辑等生成或者编辑非语言内容的AIGC技术。例如：智能配音主播、虚拟歌手演唱、自动配乐、歌曲生成等 图像视频类：
包括：人脸生成、人脸替换、人物属性编辑、人类操控、姿态操控等AIGC技术；以及编辑图像、视频内容、图像生成、图像增强、图像修复等AIGC技术 虚拟空间类：
主要包括：三维重建、数字仿真等AIGC技术，以及编辑数字任务、虚拟场景相关的AIGC技术，例如：元宇宙、数字孪生、游戏引擎、3D建模、VR等。 在大语言模型的训练中，如果增大数据量，相应的应该减少学习率，这个跟原来的经验相反。
模型大小与模型效果 《Emergent Abilities of Large Language Models》 这篇文章指出：随着模型大小的增大，模型效果先不会有明显提升；增加到一定程度，模型有个突然顿悟时刻。
为什么需要预训练 《Visualizing and Understanding the Effectiveness of BERT》 这篇文章指出:
首先，预训练能在下游任务中达到一个良好的初始点，与从头开始训练相比，预训练能带来更宽的最优点，更容易优化。尽管 BERT 对下游任务的参数设置过高，但微调程序对过拟合具有很强的鲁棒性。 其次，可视化结果表明，由于最佳值平坦且宽广，以及训练损失面和泛化误差面之间的一致性，微调 BERT 趋向于更好地泛化。 第三，在微调过程中，BERT 的低层更具不变性，这表明靠近输入的层学习到了更多可迁移的语言表征。 一、文本生成 1、GPT 参考
GPT-4: 参数量1800B，训练集：1.3T token 2、PaLM 《PaLM: Scaling Language Modeling with Pathways》 PaLM才是真正的“大”模型。它是迄今为止训练的最大的密集语言模型，参数为 540B，需要 6144 个 TPU 来训练（这是 3 个完整的 TPU pod，每个包含 2048 个 TPU）。这太贵了！可能只有谷歌拥有资源+基础设施来做到这一点。使用的Token高达7800亿。PaLM是使用Google新一代PathWay分布式训练框架训练出来。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 所以，有很多变化！同样，其中很多都是常见的，例如使用 GPT-3 的学习嵌入向量已经非常过时了，现在几乎没有人这样做。</description></item><item><title>综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00033_reinforce/0001_reinforce_summary/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00033_reinforce/0001_reinforce_summary/</guid><description>一、简介 graph LR; A(动态规划) -- B(Monte Carlo) B -- C(TD) C -- D(Q学习) D -- E(SARSA) E -- F(DQN) F -- G(PPO) G -- H(AC/A2C/A3C) H -- I(DDPG) I -- J(SAC) 二、</description></item><item><title>生成模型-评估</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0025_aigc_eval/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0025_aigc_eval/</guid><description>一、 测评指标：
1、BLEU(Bilingual evaluation understudy) $$ BLEU = BP \times e^{\sum^n_{n=1}W_n \times \log P_n}, BP = e^{1-\frac{lr}{lc}} 如果 lc &amp;lt;= lr $$
2、PPL(perplexity) 3、ROUGE(Recall-Oriented Understudy for Gisting Evaluation) 4、Distance-base Metrics Edit Dist
二、</description></item><item><title>生成式-问题</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0020_aigc_error/</guid><description>一、简介 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。 问题2：训练一个大模型，需要多少数据量呢？ 问题3：数据预处理，怎么过滤、去重 问题4：模型大小 与 数据大小 的关系？ 二、模型问题 1、Calibration 问题1：在文本生成是，模型会一本正经的胡说八道，这种现象叫做模型的幻觉。
产生幻觉的原因： LLM缺乏相关知识，或者内化了错误的知识 LLM有时高估了自己的能力 问题对齐过程误导LLM进入幻觉：在对齐过程中接受针对它们在预训练阶段尚未获得的知识的指示时，实际上是一种不对齐过程，鼓励LLMs产生幻觉。 LLMs采用的生成策略存在潜在风险：LLMs有时会过分坚持早期的错误，即使它们意识到这是不正确的。换句话说，LLMs可能更喜欢为了自身一致性而堆积幻觉，而不是从错误中恢复。 减轻幻觉的方案：
整理训练集：在预训练期间减轻幻觉主要集中在预训练语料库的策划上 SFT：监督训练，构建训练数据是减轻幻觉的一种方法 RLHF：人类监督强化学习。让模型学习到：诚实性、 在推理阶段： 设计解码策略 利用外部知识来减轻LLMs中的幻觉 《Language Models (Mostly) Know What They Know》 这篇论文发现：模型够大后，说谎才会心虚。
对于大模型，模型输出是正确的概率 VS 模型的自信度，这两个是相关的。当模型比较自信时，输出的结果是正确的概率就比较大。 对于小模型，模型输出是正确的概率 VS 模型的自信度，这两个是不相关的 其中，横轴：模型输出时的自信程度；纵轴：模型输出是正确的概率。黄色表示最大模型，自身表示最小模型。 三、数据问题 问题2：训练一个大模型，需要多少数据量呢？
训练一个大模型，需要多少数据量呢？《When Do You Need Billions of Words of Pretraining Data?》 问题3：数据预处理，怎么过滤、去重?
数据预处理：《Scaling Language Models: Methods, Analysis &amp;amp; Insights from Training Gopher》 过滤有害的内容，通过Google的审核接口 去掉一些 HTML 前端的一些tag 规则过滤，去掉低质量的文本。 去重 剔除测试数据 问题4：模型大小 与 数据大小 的关系？ 《Training Compute-Optimal Large Language Models》 这篇文章发现：</description></item><item><title>混合精度训练</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0012_aigc_amp/</guid><description>一、简介 目前，混合精度 (Automatically Mixed Precision, AMP) 训练已经成为了炼丹师的标配工具，仅仅只需几行代码，就能让显存占用减半，训练速度加倍。 AMP 技术是由百度和 NIVDIA 团队在 2017 年提出的 (Mixed Precision Training)，该成果发表在 ICLR 上。PyTorch 1.6之前，大家都是用 NVIDIA 的 apex 库来实现 AMP 训练。1.6 版本之后，PyTorch 出厂自带 AMP。
# 原代码 output = net(input) loss = loss_fn(output, target) loss.backward() optimizer.step() optimizer.zero_grad() # 使用混合精度训练 with torch.cuda.amp.autocast(): output = net(input) loss = loss_fn(output, target) scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() optimizer.zero_grad() 半精度浮点数 (FP16)： 是一种计算机使用的二进制浮点数数据类型，使用 2 字节 (16 位) 存储。而 PyTorch 默认使用 单精度浮点数 (FP32) 来进行网络模型的计算和权重存储。FP32 在内存中用 4 字节 (32 位) 存储。</description></item><item><title>模型应用策略</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0005_aigc_application/</guid><description>首先区分一下：fine-tuning、prompt-tuning、instruction-tuning
fine-tuning: 一般是指：SFT（superviseed fine-tuning）全参数的微调。 prompt-tuning: 原模型冻结，只训练部分参数 instruction-tuning：原模型不冻结，训练全部参数 一、简介 要想训练一个针对特定领域的大模型，如果采用全量参数微调（Full Parameter Futuing）的方法，一方面需要大量的高质量数据集、另一方需要较高的算力，那么，有没有不需要大量算力就能在特定领域数据上对大模型进行微调的方法呢？
下面，给大家介绍几种常见的大模型微调方法：
Adapter-Tuning Prefix-Tuning Prompt-Tuning(P-Tuning)、P-Tuning v2 LoRA 对于大语言模型应用的两种不同的使用方式：
“专才”：只精通指定任务。怎么让一个基础模型在指定任务上比较精通呢？有两种方式：
加外挂：比如：在bert后面添加几个fc层，完成指定任务 fine-tune： Adapter插件：固定原来模型，添加一个额外的模型插件。例如：Bitfit、AdapterBias、Houlsby、Prefix-tuning；ControlNet， LoRA，Text Inversion “全才”：模型有各种背景知识，用户可以通过使用prompt指令，来要求模型按照指令输出。
In-context Learning Instruction tuning Chain-of-Thought Prompting APE 1、Adapter插件 github: adapter-bert 有人提出 Adaptor 的概念，在预训练的模型中加入一些叫Apt(Adaptor)的层，在微调的时候，只微调Apt层。这篇文章中，将Adapter插在Feed-forward层之后，在预训练的时候是没有Adapter的，只有在微调的时候才插进去。并且在微调的时候，只调整Adapter层的参数。 2、Prefix-tuning github: PrefixTuning 根据《Prefix-Tuning》 ，前缀调整实现了与微调所有层相当的建模性能，同时只需要训练 0.1% 的参数——实验基于 GPT-2 模型。此外，在许多情况下，前缀调整甚至优于所有层的微调，这可能是因为涉及的参数较少，这有助于减少较小​​目标数据集上的过度拟合。
思路：在原来模型前面，训练一些参数，让这些权重学习到根据prompt来控制模型的输出。 3、Prompt-tuning 4、P-tuning github: P-tuning 论文：《GPT Understands》 在原输入中添加Prompt，可能会因为添加了一些词，影响模型效果。所以作者用（BiLSTM+MLP）构建了一个prompt encoder</description></item><item><title>模型小型化</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0005_summary/0015_aigc_train_mini/</guid><description>一、简介 目前小型化的方案：
剪枝 Network Pruning 蒸馏 Knowledge Distillation 量化 Parameter Quantization Architecture Design Dynamic Computation 1、蒸馏 Knowledge Distillation 2、量化 Parameter Quantization 3、剪枝 Network Pruning 在权重W中，有些值非常接近于0，这些值好像没有啥作用。说明这些参数是冗余的，可以去掉。
二、TensorRT</description></item><item><title>初始化</title><link>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0020_deeplearing_init/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0020_deeplearing_init/</guid><description>一、初始化 不合适的权重初始化会使得隐藏层数据的方差过大（例如，随着输入数据量的增长，随机初始化的神经元的输出数据的分布中的方差也增大），从而在经过sigmoid这种非线性层时离中心较远(导数接近0)，因此过早地出现梯度消失。所以，在深度学习中，神经网络的权重初始化方法（weight initialization）对模型的收敛速度和性能有着至关重要的影响。一个好的权重初始化虽然不能完全解决梯度消失或梯度爆炸的问题，但是对于处理这两个问题是有很大帮助的，并且十分有利于提升模型的收敛速度和性能表现。
过大/过小 问题：
如果权值的初始值过大，则loss function相对于权值参数的梯度值很大，每次利用梯度下降更新参数的时，参数更新的幅度也会很大，这就导致loss function的值在其最小值附近震荡。 而过小的初值值则相反，loss关于权值参数的梯度很小，每次更新参数时，更新的幅度也很小，着就会导致loss的收敛很缓慢，或者在收敛到最小值前在某个局部的极小值收敛了。 Glorot条件 ：优秀的初始化应该保证以下两个条件：
各个层的激活值h（输出值）的方差要保持一致， 各个层对状态z的梯度的方差要保持一致， 一个事实：方差与Layer的关系： 参考
各个层激活值h（输出值）的方差与网络的层数有关，激活值的方差逐层递减，就是越来越集中到一定范围，这个范围的概率会较大； 关于状态z的梯度的方差与网络的层数有关，状态的梯度在反向传播过程中越往下梯度越小（因为方差越来越小）。； 各个层权重参数W的梯度的方差与层数无关； 初始化的要求
参数不能全部初始化为0，也不能全部初始化同一个值； 最好保证参数初始化的均值为0，正负交错，正负参数大致上数量相等； 初始化参数不能太大或者是太小，参数太小会导致特征在每层间逐渐缩小而难以产生作用，参数太大会导致数据在逐层间传递时逐渐放大而导致梯度消失发散，不能训练； 1、Xavier初始化 Xavier初始化的基本思想：保持输入和输出的方差一致（服从相同的分布），这样就避免了所有输出值都趋向于0。它为了保证前向传播和反向传播时每一层的方差一致。
在全连接层的Xavier初始化：用 $N(0, 1/m)$ 的随机分布初始化。
2、MSRA Xavier初始化适合用tanh激活函数，对于Relu激活函数比使用。何凯明大神提出了 MSRA，可以适用于Relu激活函数。 主要想要解决的问题是由于经过relu后，方差会发生变化，因此我们初始化权值的方法也应该变化。只考虑输入个数时，MSRA初始化是一个均值为0，方差为2/n的高斯分布：$N(0, \sqrt{2/n})$ 。在ReLU网络中，假定每一层有一半的神经元被激活，另一半为0（x负半轴中是不激活的），所以要保持方差不变，只需要在Xavier的基础上再除以2
3、NTK参数化 除了直接用这种方式初始化外，还可以使用 参数化的方式：用 $N(0, 1)$ 的随机分布来初始化，但需要将输出结果除以 $\sqrt{m}$，即： $$ y_j = b_j + \frac{1}{\sqrt{m}} \sum_i{x_i w_{ij}} $$
这个高斯过程被称为 &amp;ldquo;NTK参数化&amp;rdquo;，可以参考 《Neural Tangent Kernel: Convergence and Generalization in Neural Networks》，《On the infinite width limit of neural networks with a standard parameterization》。利用NTK参数化后，所有参数都可以用方差为1的分布初始化，这意味着每个参数的尺度大致是一个级别，这样的话我们就可以设置较大的学习率，加快收敛。</description></item><item><title>VQGAN</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0020_generate_image/1015_vqgan/</guid><description>一、简介 It is coming soon.</description></item><item><title>Vicuna</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0045_vicuna/</guid><description>一、简介 二、网络结构</description></item><item><title>PaLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0020_palm/</guid><description>一、简介 1、PaLM 1 《PaLM: Scaling Language Modeling with Pathways》 这篇文章87页，并没有深度的讨论模型算法的结构，数据的清洗技巧，或者是训练的方式（估计感觉这块的创新性不是特别明显，也不是文章的主要目的）。 而是花了大量的篇幅去评估这个模型在multi-task的能力，比如翻译，代码修改，生成，问答等等。
其中模型版本于训练集大小：
Google PaLM 是一个 540B 参数密集型 Transformer 语言模型，在 780B 高质量、多样化文本的标记上进行训练。 它已经针对 3 种不同的尺寸进行了训练：8B、62B 和 540B，使用 6144 TPU v4 芯片使用 Pathways，这是一种新的 ML 系统，可跨多个 TPU（张量处理单元）Pod 进行高效训练。 当它被引入时，它在数百个 NLU 和 NLG 基准测试中产生了 SOTA 小样本学习结果。 这包括 Big-Bench 任务的性能大幅提升，以及多语言 NLG 和源代码生成功能的显着改进。 它还被证明可以使用思维链提示来解释笑话或逻辑推理，从而产生很好的解释。
PaLM超越了许多之前的SOTA。作者归功于
更好的数据的清理， 更多的数据， 模型规模的进一步提升。 模型算法的改进比较少，从Model Architecture那一章看出，其实模型结构的变化并不明显，在激活层，ShareEmbedding，PosEmbedding等模块做了一些结构优选。核心的TransformerBlock的变种选择也更多是为了优化模型的训练效率。谷歌作为搜索技术的天花板，数据清洗的积累，以及对于数据的理解肯定是OpenAI这些公司无法比拟的。个人感觉这块是个比较明显的优势。
与GPT-3相比的变化：
多查询注意力（Multi-query attention）：在每个注意力头中共享K/V（Key/Value）嵌入，但使用独立的Q（Query）嵌入。这样做可以在推理阶段显著提高模型的速度。 并行Transformer块：使用并行的Transformer块来提高训练时间，相较于传统的串行设计，可以减少约15%的训练时间。 SwiGLU激活函数：与GPT-3使用的GELU激活函数不同，这里采用了SwiGLU激活函数。 旋转位置编码RoPE嵌入：使用RoPE（Relative Positional Encodings）嵌入代替学习得到的嵌入方式，在长文本上具有更好的性能 。 输入-输出嵌入共享：输入和输出embedding矩阵是共享的。 无偏置向量：在mlp、normlayer等算法中，都不使用bias，对于大模型，可以提高训练稳定性。 SentencePiece与256k标记：使用SentencePiece进行分词处理，标记数量为256k。 2、PaLM 2 《PaLM 2 Technical Report》 这篇报告-总结：</description></item><item><title>MLLM</title><link>https://biubiobiu.github.io/zh-cn/posts/00400_vlp/0010_mllm/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00400_vlp/0010_mllm/</guid><description>一、 MLLM</description></item><item><title>Cohere</title><link>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/</link><pubDate>Sat, 05 Aug 2023 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00300_aigc/0010_generate_text/0035_cohere/</guid><description>一、简介 二、网络结构</description></item><item><title>马尔科夫链</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0080_markov_process/</guid><description>一、基本概念 二、</description></item><item><title>基本概念</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0010_basic-conception/</guid><description>一、基本概念 随机实验：$E$ 样本空间：记为 $S$。随机实验 $E$ 的所有可能结果组成的集合，称为随机实验 $E$ 的样本空间。
样本点：样本空间的元素，即：随机实验 $E$ 的每个结果。
随机事件：随机实验 $E$ 的样本空间$S$的子集，称为 $E$ 的随机事件。
基本事件：由单个样本点组成的单点集，成为基本事件。
必然事件：样本空间 $S$ 集合，成为必然事件。
不可能事件：空集 $\varnothing$。 概率：随机实验 $E$，样本空间为 $S$。对于 $E$ 的每一件事 $A$，概率 记为 $P(A)$ 条件概率：事件 $A$ 已经发生的条件下，事件 $B$ 发生的概率。
划分：随机实验 $E$，样本空间为 $S$。$B_1, B_2, &amp;hellip;, B_n$ 为 $E$ 的一组事件，若
$B_iB_j= \varnothing , i \ne j, i,j=1,2,&amp;hellip;,n$ $B_1 \cup B_2 \cup &amp;hellip; \cup B_n = S$ 则，称 $B_1, B_2, &amp;hellip;, B_n$ 为样本空间 $S$ 的一个划分。</description></item><item><title>基本概念</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0020_math_convex_optimization_theory/0010_basic_conception/</guid><description>一、基本概念</description></item><item><title>平稳随机过程</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0090_stationary_stochastic_process/</guid><description>一、基本概念 二、</description></item><item><title>大数定律</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0030_law_of_large_numbers/</guid><description>一、基本概念 二、</description></item><item><title>样本及抽样分布</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0040_sample_distribution/</guid><description>一、基本概念 二、</description></item><item><title>随机变量及其分布</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0020_distribution_of_variables/</guid><description>一、一维随机变量 如何引入一个法则，将随机试验的每个结果（即：$S$ 中的每个元素 $e$）与实数 $x$ 对应起来 从而引入了随机变量的概念，即：定义域是：样本空间$S$，值域是：实数。
定义：设随机试验的样本空间为 $S=\{e\}, X=X(e)$ 是定义在样本空间 $S$ 上的实值单值函数。称 $X = X(e)$ 为随机变量。
例如：以 $X$ 记录三次投掷硬币得到正面的次数。$P(X=2) = 3/8$ 就表示：随机变量 $X=2$ 的概率，就是 $A=\{HHT,HTH,THH\}$ 这个事件的概率。
随机变量的引入，使得我们能用随机变量来描述各种随机现象，并能利用数学分析的方法对随机试验的结果进行深入广泛的研究和讨论。
1、离散型随机变量 离散型随机变量：随机变量，它全部可能取到的值是有限个或者可列无限多个。 可以用 分布律 来描述。
常见离散型随机变量：
(0-1)分布 期望：p，方差：p(1-p) 随机变量 $X$ 只能取 0 与 1 两个值。
伯努利实验、二项分布，记：$ \textcolor{#f00000} {X \sim b(n, p)，期望：np，方差：np(1-p)}$
设实验 $E$ 只有两个可能结果：$A$ 和 $\bar A$ ，则称 $E$ 为伯努利实验。
将实验 $E$ 独立重复地进行 $n$ 次，则称这一串重复的独立实验为 $n$ 重伯努利实验。</description></item><item><title>随机过程</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0070_stochastic_process/</guid><description>一、基本概念 二、</description></item><item><title>假设检验</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0050_parameter_estimation/</guid><description>一、基本概念 二、</description></item><item><title>方差分析及回归分析</title><link>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/</link><pubDate>Tue, 01 Aug 2023 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00025_math_knowledge/0010_math_probability_theory/0060_analysis_variance_regression/</guid><description>一、基本概念 二、</description></item><item><title>CAM</title><link>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0200_cam/</link><pubDate>Fri, 09 Sep 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0200_cam/</guid><description>一、简介 二、模型 1、gradient-based 1. GAP 《Learning Deep Features for Discriminative Localizatiion》
# 代码非常简单， 提取到特征图和目标类别全连接的权重，直接加权求和，再经过relu操作去除负值，最后归一化获取CAM，具体如下: # 获取全连接层的权重 self._fc_weights = self.model._modules.get(fc_layer).weight.data # 获取目标类别的权重作为特征权重 weights=self._fc_weights[class_idx, :] # 这里self.hook_a为最后一层特征图的输出 batch_cams = (weights.unsqueeze(-1).unsqueeze(-1) * self.hook_a.squeeze(0)).sum(dim=0) # relu操作,去除负值 batch_cams = F.relu(batch_cams, inplace=True) # 归一化操作 batch_cams = self._normalize(batch_cams) 2. Grad-CAM 《Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization》
2、gradient-free</description></item><item><title>CLIP</title><link>https://biubiobiu.github.io/zh-cn/posts/00400_vlp/0005_clip/</link><pubDate>Mon, 09 May 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00400_vlp/0005_clip/</guid><description>一、简介 参考， 论文， Gitlab
二、</description></item><item><title>contrastive learning</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/</link><pubDate>Mon, 09 May 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0020_contrastive_learning/contrastive_learning/</guid><description>从2019年中~2020年中，对比学习火了一段时间，到ViT出来后，大量的研究这才投身于ViT。
一、简介 什么是对比学习？
简单来说就是，只要模型把相似的数据跟其他不相似的数据区分开就可以。比如：$A_1, A_2, &amp;hellip;$ 是狗，$B_1, B_2, &amp;hellip;$ 是猫，只要模型能把这两批数据区分开就行。
所以，训练集中不需要明确的标签，只要能区分出那些数据之间是相似的，那些是与它们不相似的。
所以，训练集中不必人为标注，只需要设计一些规则生产出这种类型的训练集就行。
看下Hinton老爷子的《Self-organizing neural network that discovers surfaces in random-dot stereograms》 和 LeCun的《Dimensionality reduction by learning an invariant mapping》 对比学习为啥在cv领域被认为是无监督呢？：
通过设计一些巧妙的代理任务，就是pretext task：人为的定义一些规则，这些规则可以用来定义那些图片是相似的，那些图片是不相似的。
例如：instance discrimination：如果有N张图片的数据集，随机一张图片$x_i$，对这个图片随机裁剪+数据增广，从同一张图片中通过裁剪+增广产生的数据，虽然有差异但是语义信息是一样的，所以是正样本(它们之间是相似的)，负样本就是除了图$x_i$之外的所有样本。 1、代理任务 代理任务(pretext task)的目的: 生成一个自监督的信号，从而充当ground truth这个标签信息
有监督学习：训练时比较输出 $\hat{Y}$ 和 groud truth $Y$；
自监督学习：因为缺少groud truth，所以需要代理任务自己创建类似groud truth的信号。
2、对比学习的loss 1)、InfoNCE loss noise contrastive estimation loss：其实就是一个交叉熵 $$ L_q = -log\frac{exp(q\cdot k_+ / \tau)}{\sum_{i=0}^{K} exp(q\cdot k_i / \tau)} $$ 分母：一个正样本，K个负样本；$\tau$：温度超参数，值越大分布就越平缓，表示对每种的关注度越相似；值越小分布就越陡峭，表示比较关注比较困难的case，不容易收敛。</description></item><item><title>vision transformer</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/</link><pubDate>Mon, 09 May 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0030_vision_transformer/vision_transformer/</guid><description>一、简介 1、Transformer用在CV领域 在NLP中，Transformer的输入是一个时间步长为T的序列，比如：basic版bert，T=512，每个token embeding为768维特征。如何把二维图片转化为一维呢？
$\bf \color{red} \times$ 如果把每个像素点看做是一个样本，铺平后是一维序列。但是，图片大小 224*224=50176，远远大于Transformer的最大序列长度。 $\bf \color{red} \times$ 卷积和Transformer一起用：《Non-local Neural Networks》(2018)、《End-to-End Object Detection with Transformers》(2020) 为了减小序列的长度，不直接使用输入图片，而是使用feature map 转换为序列。比如：ResNet50在最后的阶段的输出尺寸为 14x14，拉平后序列长度只有196。 $\bf \color{red} \times$ 抛弃卷积使用定制化的自注意力机制：《Stand-Alone Self-Attention in Vision Models》(2019) 采用的是 孤立自注意力。用一个局部的小窗口做自注意力； 《Stand-alone axial-attention for panoptic segmentation》(2020) 采用的是轴注意力。在高度的方向上做自注意力、在宽度方向做自注意力。由于这些自注意力机制比较定制化，还没有在硬件上大规模加速计算，所以网络做不大。 $\color{green} \checkmark$ 对图片做些预处理，直接使用Transformer：将图片切分成一个个patch，然后每个patch作为一个token输入到Transformer中。 $224 \times 224$ 的图片，切分成一个个 $16 \times 16$ 的patch，最终切分出196个patch；每个patch的大小是：$16 \times 16 \times 3=768$，刚好是basic版bert每个token的维度。 多头注意力机制，12个头，每个头的k、q、v对应的维度是64维 二、网络 1、ViT ViT(2021) 直接把Transformer应用到图像处理，尽量改动最少，所以只对图像做预处理，让其符合NLP的输入形式， 思路：
图片尺寸 224x224，将图片切分成一个个patch，patch的大小16x16，每个patch作为一个token，即：14x14=196个patch，每个patch长16x16x3=768 学习一个线性矩阵$E$，尺寸为768x768，对每个patch做线性变换。多头注意力的话，basic版本12个头，所以12个196x64拼接起来，还是196x768。 位置编码：可学习的位置向量，尺寸为196x768 cls的输出作为提取的图片特征，用于后续的分类操作 实验结论：</description></item><item><title>简介</title><link>https://biubiobiu.github.io/zh-cn/posts/00500_video/vidio_summary/</link><pubDate>Mon, 09 May 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00500_video/vidio_summary/</guid><description>一、简介 It is coming soon.
二、网络 1、 2、 3、 4、</description></item><item><title>简介</title><link>https://biubiobiu.github.io/zh-cn/posts/00400_vlp/0001_vlp_summary/</link><pubDate>Mon, 09 May 2022 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00400_vlp/0001_vlp_summary/</guid><description>一、简介 多模态学习，英文全程MultiModal Machine Learning(MMML)，从1970年 起步，已经经历了多个发展阶段，在2010年后，全面进入深度学习的阶段。多模态机器学习，以机器学习实现处理和理解多源模态信息的能力。图像、视频、音频、语义之间的多模态学习比较热门。比如互联网大型视频平台，都会将多模态技术用于视频理解业务，可以加视频封面、视频抽帧、文本信息融合。当计算机能够看懂视频，就可以做很多事儿了，比如：视频分类、审核、推荐、搜索、特效。
多模态学习有5个研究方向：
多模态表示学习（Multimodal Representation） 模态转化（Translation） 对齐（Alignment） 多模态融合（Multimodal Fusion） 协同学习（Co-learning） 实际应用，比如：
视频网站上进度条，会显示那个时间段是高光时刻 自动驾驶领域，雷达、视觉与多传感器信息融合 视频的分类、审核、推荐、搜索、特效等等 1、VLP 微软发表的一篇文章《An Empirical Study of Training End-to-End Vision-and-Language Transformers》进行了大量的实验，对不同VLP模型、各个模块不同配置的效果。
VLP通常都会遵循同一个框架，包含5大模块：
Vision Encoder：主要有3中类型 使用object detection模型，比如：Faster R-CNN，识别图像中的目标区域，并生成每个目标区域的特征表示，输入到后续模型中 利用CNN模型提取grid feature作为图像输入 ViT采用的将图像分解成patch，每个patch生成embeding输入到模型。 随着Vision Transformer的发展，ViT的方式逐渐成为主流方式。 Text Encoder：包括BERT、RoBERTa、ELECTRA、ALBERT、DeBERTa等经典预训练语言模型结构。 Multimodel Fusion：主要指如何融合图像、文本，主要有2中： co-attention：图像、文本分别使用Transformer编码，在每个Transformer模块中加入图像、文本的cross attention merged attention model，图像、文本在开始就拼接在一起，输入到Transformer 模型结构：主要有2中： Encoder-only：这种比较常见 Encoder-Decoder 预训练任务：主要有3中： Masked Language Modeling（MLM）类似BERT，随机mask掉部分token，用剩余的预测出被mask掉的token Masked Image Modeling，对输入的部分图像patch进行mask，然后预测被mask的patchs Image-Text Matching（ITM），预测image和text的pair对是否匹配，对比学习的预训练方法可以属于这类。 二、网络 Open AI 在2021年1月份发布的DALL-E和CLIP，属于结合图像和文本的多模态模型，其中DALL-E是基于文本来生成模型的模型；CLIP是用文本作为监督信号来训练可迁移的视觉模型，这两个工作带动了一波新的研究高潮。</description></item><item><title>基础操作</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/</link><pubDate>Fri, 08 Apr 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0020_basic/</guid><description>一、数据类型 1、torch的数据类型 torch.Tensor 是默认的torch.FloatTensor 的简称。
剥离出一个Tensor参与计算，不参与求导：Tensor后加 .detach()
各个数据类型之间的转换：
方法一：在Tensor后加，.long(), .int(), .float(), .double() 方法二：可以用 .to()函数 数据类型 CPU tensor GPU tensor 32-bit float torch.FloatTensor torch.cuda.FloatTensor 64-big float torch.DoubleTensor torch.cuda.DoubleTensor 16-bit float N/A torch.cuda.HalfTensor 8-bit integer(unsigned) torch.ByteTensor torch.cuda.ByteTensor 8-bit integer(signed) torch.CharTensor torch.cuda.CharTensor 16-bit integer(signed) torch.ShortTensor torch.cuda.ShortTensor 32-bit integer(signed) torch.IntTensor torch.cuda.IntTensor 64-bit integer(signed) torch.</description></item><item><title>数学计算</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/</link><pubDate>Fri, 08 Apr 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0030_mathematical/</guid><description>一、数学计算 torch.abs(input)。 数学&amp;mdash;绝对值 torch.add(input, value)。数学&amp;mdash;对张量的每个元素加value值 torch.div(input, value)。数学&amp;mdash;逐元素除法，将input逐元素除以标量value torch.div(input, other)。数学&amp;mdash;逐元素除法。
两个张量input和other逐元素相除.这两个维度可以不同，但元素数量一定要一致。输出: 与input维度一致 torch.mul(input, value)。数学&amp;mdash;逐元素乘法 torch.mul(input, other)。数学&amp;mdash;逐元素乘法 torch.fmod(inpur, divisor, out)。数学&amp;mdash;取余 torch.remainder(input, divisor, out)。数学&amp;mdash;取余 相当于 %。
divisor: 标量或者张量 逐元素 torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None)。数学&amp;mdash; 像素点相除后相加。
out = tensor .+ value*(tensor1./tensor2) torch.addcmul(tensor, value=1, tensor1, tensor2, out=None)。数学&amp;mdash; 像素点相乘后相加。
out = tensor .+ value*(tensor1 .* tensor2) torch.neg(input)。数学&amp;mdash;取负。out = -1 * input。 torch.reciprocal(input)。数学&amp;mdash;倒数。out = 1.0 / input。 torch.sign(input)。数学&amp;mdash;取正负符号 torch.sin(Tensor)。数学&amp;mdash;正弦 torch.cos(Tensor)。数学&amp;mdash;余弦 torch.tan(Tensor)。数学&amp;mdash;正切 torch.sinh(Tensor)。数学&amp;mdash;双曲正弦 torch.cosh(Tensor)。数学&amp;mdash;双曲余弦 torch.tanh(Tensor)。数学&amp;mdash;双曲正切 torch.asin(Tensor)。数学&amp;mdash;反正弦 torch.acos(input)。数学&amp;mdash;反余弦 torch.</description></item><item><title>模型训练</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/</link><pubDate>Fri, 08 Apr 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0050_train_model/</guid><description>一、数据预处理 import torch from torch.utils.data import Dataset, DataLoader, TensorDataset from torch.autograd import Variable import numpy as np class MyDataset(Dataset): &amp;#34;&amp;#34;&amp;#34; 下载数据、初始化数据，都可以在这里完成 &amp;#34;&amp;#34;&amp;#34; def __init__(self): xy = np.loadtxt(&amp;#39;../dataSet/diabetes.csv.gz&amp;#39;, delimiter=&amp;#39;,&amp;#39;, dtype=np.float32) # 使用numpy读取数据 self.x_data = torch.from_numpy(xy[:, 0:-1]) self.y_data = torch.from_numpy(xy[:, [-1]]) self.len = xy.shape[0] def __getitem__(self, index): return self.x_data[index], self.y_data[index] def __len__(self): return self.len # 创建Dataset对象 dataset = MyDataset() # 创建DataLoadder对象 dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2) # 循环DataLoader对象 num_epoches = 100 for epoch in range(num_epoches) for img, label in dataloader: # 将数据从dataloader中读取出来，一次读取的样本数为32个 # class torch.</description></item><item><title>Tensor和变量</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/</link><pubDate>Fri, 08 Apr 2022 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0040_tensor/</guid><description>Tensor
每个张量Tensor都有一个相应的torch.Storage，用来保存数据。
torch.Storage: 是一个单一数据类型的连续一维数组。每个Tensor都有一个对应的相同数据类型的存储：class torch.FloatStorage 类tensor：提供了一个存储 多维的、横向视图，并定义了数值运算。 torch.Tensor.abs()：会在原地计算，并返回改变后的tensor
torch.Tensor.abd()：在一个新的tensor中计算结果 变量
Variable 在torch.autograd.Variable中，Variable的结构图：data：Variable的tensor数值 grad_fn：表示得到这个Variable的操作，
grad：表示Variable的反向传播梯度 示例1：x = Variable(torch.Tensor([1]), requires_grad=Ture) 其中：requires_grad=True ：这个参数表示是否对这个变量求梯度。
x.backward()：自动求导。自动求导不需要再去明确地写明那个函数对那个函数求导，直接通过这行代码就可以对所有的需要梯度的变量进行求导。
x.grad：存放的就是x的梯度值 示例2：y.backward(torch.FloatTensor([1,0.1,0.01]))，表示得到的梯度分别乘以1,0.1,0.01 Variable和Tensor本质上没有区别，不过Variable会被放入一个计算图中，然后进行前向传播、反向传播、自动求导。 tensor与Variable之间的转换： tensor —to—&amp;gt; Variable：b=Variable(a) 一、Tensor信息 torch.is_tensor(obj) 判断是否为tensor torch.is_storage(obj) 判断obj是一个pytorch storage对象 torch.set_default_tensor_type() torch.numel(Tensor) 返回张量中元素的个数 二、创建Tensor torch.Tensor([[1,2],[3,4]])。创建&amp;mdash;返回指定数值的张量 torch.randn(*sizes, out=None)。创建&amp;mdash;返回标准正态分布的随机数张量。标准正态分布，形状由sizes定义 torch.randperm(n, out=None)。创建&amp;mdash;返回0~n-1之间的随机整数1维张量。返回一个从0~n-1的随机整数排列 torch.rand(*sizes, out=None)。创建&amp;mdash;返回[0, 1)的均匀分布张量 torch.arange(start, end, step=1, out=None)。创建&amp;mdash;返回一个1维张量。[start, end) 以step为步长的一组序列值 torch.range(start, end, step=1, out=None)。创建&amp;mdash;返回一个1维张量。[start, end) 以step为步长的1维张量 torch.zeros(*sizes, out=None)。创建&amp;mdash;返回一个全为0的张量。生成一个tensor, 数值为0，形状由sizes定义 torch.</description></item><item><title>OpenCV</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0110_opencv/</guid><description>安装问题：在环境里安装OpenCV后，在pycharm上没有命令提示。这个可能是OpenCV版本的问题。
解决方案：python3 -m pip install &amp;ndash;force-reinstall &amp;ndash;no-cache -U opencv-python==4.5.5.62
一、连通域 cv2.connectedComponentsWithStats 示例：num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8, ltype=None)
输入参数：
* image: 二值图
* connectivity：可选值为4或者8，表示使用4联通还是8联通
* ltype：输出图像标记的类型，目前支持CV_32S、CV_16U
输出参数：
* num_labels: 所有连通域的数目
* labels：图像上每个像素的标记
* stats：每个标记的统计信息：是一个5列的矩阵[[x,y,width,height,面积]，]
* centroids：连通域的中心点
cv2.connectedComponents 示例：num_objects, labels = cv2.connectedComponents(image)
输入参数：
* image: 二值图，8bit单通道图像
输出参数：
* num_labels: 所有连通域的数目
二、画图</description></item><item><title>requests</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0070_request/</guid><description>一、request模块 requests模块：在python内置模块上进行了高度的封装，使得requests更方便。
url: uniform resource locator，统一资源定位符：互联网上标准资源的地址。
格式：
模式/协议，比如：https、http 服务器名称(或者IP地址)，比如：api.github.com 路径和文件名，比如：events requests.get(url) get请求 &amp;mdash; 不带参数 requests.get(url, params={&amp;ldquo;参数1&amp;rdquo;:&amp;ldquo;值1&amp;rdquo;}) get请求 &amp;mdash; 带参数 requests.get(url, headers=header, cookie=cookie) header = {&amp;ldquo;content-type&amp;rdquo;: &amp;ldquo;application/json&amp;rdquo;,&amp;ldquo;user-agent&amp;rdquo;: &amp;ldquo;&amp;quot;} 定制headers requests.get(url, proxies=proxies) proxies = {&amp;ldquo;http&amp;rdquo;: &amp;ldquo;ip1&amp;rdquo;, &amp;ldquo;https&amp;rdquo;: &amp;ldquo;ip2&amp;rdquo;} 代理 requests.post(url, data=json.dumps({&amp;quot;&amp;quot;:&amp;quot;&amp;quot;})) post请求 requests.</description></item><item><title>py-env</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0010_pip_env/</guid><description>一、anaconda环境 清华镜像源
可以通过从页面上下载，直接安装 可以是命令 wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-2022.10-MacOSX-x86_64.sh sh Anaconda3-2022.10-MacOSX-x86_64.sh 配置环境变量：export PATH=~/anaconda3/bin:$PATH 操作 说明 conda config --show 查看配置 conda config --add channels 网址 添加源
conda config &amp;ndash;add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config &amp;ndash;add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config &amp;ndash;set show_channel_urls yes conda info -e 查看conda的虚拟环境 conda list 查看该环境下，已经安装的包-版本 conda search 包名 查看安装包，是否可通过conda安装 安装 conda install -n 环境名 包名</description></item><item><title>logging</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0080_logging/</guid><description>一、logging模块 logging模块是Python内置的标准模块，主要用于输出运行日志，可以设置输出日志的等级、日志保存路径、日志文件回滚等；相比print，具备如下优点：
可以通过设置不同的日志等级，在release版本中只输出重要信息，而不必显示大量的调试信息； print将所有信息都输出到标准输出中，严重影响开发者从标准输出中查看其它数据；logging则可以由开发者决定将信息输出到什么地方，以及怎么输出； logging模块与log4j的机制是一样的，只是具体的实现细节不同。模块提供logger，handler，filter，formatter。
logger：提供日志接口，供应用代码使用。logger最长用的操作有两类：配置和发送日志消息。可以通过logging.getLogger(name)获取logger对象，如果不指定name则返回root对象，多次使用相同的name调用getLogger方法返回同一个logger对象。 handler：将日志记录（log record）发送到合适的目的地（destination），比如文件，socket等。一个logger对象可以通过addHandler方法添加到多个handler，每个handler又可以定义不同日志级别，以实现日志分级过滤显示。 filter：提供一种优雅的方式决定一个日志记录是否发送到handler。 formatter：指定日志记录输出的具体格式。formatter的构造方法需要两个参数：消息的格式字符串和日期字符串，这两个参数都是可选的。 与log4j类似，logger，handler和日志消息的调用可以有具体的日志级别（Level），只有在日志消息的级别大于logger和handler的级别。
import logging # logger = logging.getLogger(__name__) logger.setLevel(level = logging.INFO) # 创建一个FileHandler handler = logging.FileHandler(&amp;#39;log.txt&amp;#39;) # 设置等级: DEBUG &amp;lt; INFO &amp;lt; WARNING &amp;lt; ERROR &amp;lt; CRITICAL，而日志的信息量是依次减少的 handler.setLevel(logging.INFO) # 设置输出消息的格式 formatter = logging.Formatter(&amp;#39;%(asctime)s- %(name)s- %(levelname)s- %(message)s&amp;#39;) handler.setFormatter(formatter) # 添加到logger中 logger.addHandler(handler) # 写入消息 logger.info(&amp;#34;Hello&amp;#34;) 二、消息格式 输出消息的格式 解释 %(levelno)s 打印日志级别的数值 %(levelname)s 打印日志级别的名称 %(pathname)s 打印当前执行程序的路径，其实就是sys.</description></item><item><title>正则</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0050_re/</guid><description>一、字符 字符 中文-简体 \u4e00-\u9fa5 中文-繁体 \u9fa6-\u9fff 日文 \u3040-\u30fa 韩文 \uac00-\ud7ff 二、 三、</description></item><item><title>ipdb包</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0040_ipdb/</guid><description>一、ipdb 断点调试：
n(next) 下一条语句 s(step into) 进入函数调用的内部 b line_number(break) 给指定的行号位置加断点 c(continue) 给指定的文件（还没执行到的代码）中指定行号位置，打断点 r(return) 一直执行到下一个断点 j line_numver(jump) 可以跳过某段代码，直接执行指定行号所在的代码 cl(clear) 清楚断点，如果没有参数，则清除所有断点 restart 重新启动调试器 l first/second(list) 在ipdb调试环境中，默认只显示当前执行的代码行，以及上下各一行的代码，如果想要看到更多的上下文代码，可以使用该命令 w(where) 调试时可能会忘记自己目前做在的行号，可以使用w打印目前所在的行号位置，以及上下文信息 whatis variable_name 查看变量的类别，感觉有点鸡肋，用type也可以 a(argument) 当处于一个函数内部的时候，可以使用a打印传入函数的所有参数的值 p variable_name(print) 打印表达式的值 q 退出调试，并清楚所有信息</description></item><item><title>cuda</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0010_build_env/0020_cuda_env/</guid><description>一、简介 1、CUDA CUDA：英伟达开发的一个通用并行计算平台和编程模型，能让你调用GPU的指令集及其并行计算单元。基于cuda编程可以利用GPU的并行计算引擎来更高效地计算。
特点：
GPU有更多的计算核心，适合数据并行的计算密集型任务。 CPU有较少的运算核心，适合实现复杂的逻辑计算，用于控制密集型任务。 对比一下： CPU &amp;ndash; 线程是重量级的，上下文切换开销较大。 负责处理逻辑复杂的串行程序 GPU &amp;ndash; 由于存在较多核心，线程是轻量级的。负责处理数据密集型的并行机选程序 2、CUDA编程模型 CUDA编程模型是一个异构模型，需要CPU和GPU协同工作，在CUDA中有两个重要的概念：host和device。
host: CPU + 其内存
device: GPU + 其内存
典型的CUDA程序的执行流程：
分配host内存，并进行数据初始化 分配device内存，并从host将数据copy到device上 调用CUDA的核函数在device上完成指定的运算 将device上的运算结果copy到host上 释放device和host上分配的内存。 3、cuDNN cuDNN: CUDA Deep Neural Network软件库，是一个用于深度神经网络的GPU加速原语库。
TensorRT: 是一套用于高性能深度学习接口的SDK，其包含深度学习接口优化器、运行时优化器，能为深度学习接口提供低延迟和高通量的特性。
二、CUDA安装 1、驱动安装 NVIDIA驱动
关键点：CUDA和显卡驱动没有一一对应的关系，一般情况下安装最新的驱动。
2、CUDA安装 CUDA下载
CUDA: 只是一个工具包，在同一设备上可以安装多个不同的版本，比如：9.0，10.0，11.0。一般情况下安装最新的驱动，然后根据自己的需求选择不同CUDA工具包就行了。但在离线安装CUDA时会绑定CUDA和驱动程序，所以在使用多个CUDA的时候就不要选择离线安装CUDA了。
安装步骤:
不用选择太高的cuda版本，太高反而兼容性不好，要兼顾Tensorflow等架构的版本 安装包下载后，一路默认安装就好。检查是否安装成功：nvcc -V cuda的安装包中包含NVIDIA驱动，安装时取消勾选安装驱动，只安装工具包就行 CUDA安装后，配置环境变量：
CUDA10.1是之前安装的，CUDA11.1是之后安装的，所以默认CUDA10.1的环境变量在CUA11.1之前，CUDA_PATH环境变量被CUDA11.1覆盖
CUDA版本切换：
切换CUDA版本时，只需要切换环境变量中CUDA的顺序即可，比如让CUDA11.1生效，则CUDA11.1环境变量在CUDA10.1之前。
3、cuDNN安装 cuDNN下载
cuDNN：是一个SDK，是一个专门用于神经网路的加速包，它跟CUDA没有一一对应的关系。即：每个CUDA版本可能有好几个cuDNN版本，一般有一个最新版本的cuDNN版本与CUDA对应更好。
安装步骤：
根据cuda版本选择对应的cudnn版本；不同系统，选择不同的型号。 下载的不是安装包，而是压缩文件，解压后将对应的文件拷贝到cuda安装路径对应的目录中。默认安装的路径： 复制 cudnn\bin\cudnn64_5.</description></item><item><title>argparse</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0090_argparse/</guid><description>一、argparse模块 import argparse # 创建ArgumentParser()解析对象 parser = argparse.ArgumentParser() # 使用add_argument()方法，添加参数 parser.add_argument(&amp;#39;--integer&amp;#39;, type=int, default=0, help=&amp;#39;displayas integer&amp;#39;) parser.add_argument(&amp;#39;--string&amp;#39;, type=str, default=&amp;#39;&amp;#39;, help=&amp;#39;displayas string&amp;#39;) args = parser.parse_args() add_argument 的参数：
name or flags - 选项字符串的名字或者列表，例如 foo 或者 -f, &amp;ndash;foo。 action - 命令行遇到参数时的动作，默认值是 store。 store_const，表示赋值为const； append，将遇到的值存储成列表，也就是如果参数重复则会保存多个值; append_const，将参数规范中定义的一个值保存到一个列表； count，存储遇到的次数；此外，也可以继承 argparse.Action 自定义参数解析； nargs - 应该读取的命令行参数个数，可以是具体的数字，或者是?号，当不指定值时对于 Positional argument 使用 default，对于 Optional argument 使用 const；或者是 * 号，表示 0 &amp;gt; 或多个参数；或者是 + 号表示 1 或多个参数。 const - action 和 nargs 所需要的常量值。 default - 不指定参数时的默认值。 type - 命令行参数应该被转换成的类型。 choices - 参数可允许的值的一个容器。 required - 可选参数是否可以省略 (仅针对可选参数)。 help - 参数的帮助信息，当指定为 argparse.</description></item><item><title>堆-heapq</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0060_heapd/</guid><description>一、堆 import heapq 操作 解释 功能 例如：arr=[2, 9, 1, 4] heapq.heapify(arr) 建堆，对列表arr建堆。
也可以这样：
arr = [(5, &amp;lsquo;a&amp;rsquo;), (2, &amp;lsquo;b&amp;rsquo;), (8, &amp;lsquo;c&amp;rsquo;), (9, &amp;rsquo;d'), (6, &amp;lsquo;e&amp;rsquo;), (1, &amp;lsquo;f&amp;rsquo;)]
heapq.heapify(arr) 然后arr就变成：
[(1, &amp;lsquo;f&amp;rsquo;), (2, &amp;lsquo;b&amp;rsquo;), (5, &amp;lsquo;a&amp;rsquo;), (9, &amp;rsquo;d'), (6, &amp;lsquo;e&amp;rsquo;), (8, &amp;lsquo;c&amp;rsquo;)]
建堆 heapq.heappush(arr, 10) 添加元素，然后再向上调整堆。例如：在arr列表中添加5，然后在维持一个堆 添加 heapq.heappop(arr, 10) 提取堆顶，然后把堆尾放在堆顶，最后对堆顶做向下调整。把arr的堆顶元素提取出来。 pop heapq.heappushpop(arr, 10) 用新元素与堆顶做比较，如果堆顶大于新元素，直接返回新元素。否则返回堆顶，并把新元素放在堆顶后向下调整 heapq.</description></item><item><title>PIL</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/</link><pubDate>Wed, 08 Dec 2021 16:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0100_pil/</guid><description>一、PIL模块 PIL: Python Imaging Library 已经是python平台上的图像处理的标准库了，PIL功能非常强大。由于PIL仅支持python2.7，加上年久失修，于是一群志愿者在PIL的基础上创建了兼容的版本，名字叫Pillow，支持最新Python3.x，又加入了许多新特征。
from PIL import Image 操作 解释 Image.fromarray() 从一个numpy对象转换为一个PIL image对象 img = Image.open(&amp;lsquo;test.jpg&amp;rsquo;) 打开一个图像文件，返回值img是一个PIL图像对象。PIL是个足够智能的类库，可以根据文件扩展名来判断图像的格式。 img.save(&amp;lsquo;路径&amp;rsquo;) PIL会根据文件扩展名来判断图像的格式，如果图像文件不是该格式，会自动将其转换为该格式。 img.thumbnail((h,w)) 创建图像的缩略图, thumbnail()方法接受一个元组参数, 指定生成缩略图的尺寸. 然后将图像转换成指定尺寸的缩略图. region = img.crop((左, 上, 右, 下)) 裁剪指定区域 region = region.transpose(Image.ROTATE_180)
img.paste(region, (左,上,右,下)) 旋转180，然后将该区域放回去 img.resize((h, w)) 调整图像尺寸, resize()方法的参数是一个元组, 用来指定新图像的尺寸 img.rotate(45) 逆时针旋转图像</description></item><item><title>importlib包</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/</link><pubDate>Wed, 08 Dec 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0030_importlib/</guid><description>import_module()函数 背景：一个函数运行，需要根据不同项目的配置，动态导入对应的配置文件。 例如：如下路径，向a模块中导入c.py中的对象 a
├── a.py
├── __init__.py
b
├── b.py
├── c │　├── c.py　# 该文件中，有变量args=[]，class C
│　├── __init__.py
方案：
import importlib # 导入 params = importlib.import_module(&amp;#34;b.c.c&amp;#34;) # 对象中取出需要的对象 params.args # 取出变量 params.C # 取出类C</description></item><item><title>animal matting</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/</link><pubDate>Thu, 09 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0060_image-matting/image-matting-animal/</guid><description>Image Matting 《End-to-end Animal Image Matting》 1、先前算法的不足 流水线：全局分割和局部抠图
其中前者的目标是trimap生成或前景/背景生成，后者是基于从前一阶段生成的trimap或其他先验的图像抠图。这种流水线的不足归因于它的顺序性
因为它们可能产生错误的语义，该错误不能通过后续的抠图步骤来纠正。 两个阶段的单独训练方案可能由于它们之间的不匹配而导致次优解。 2、提出新结构 提出了一个新颖的 Glance and Focus Matting network (GFM)，它使用一个共享的编码器和两个独立的解码器来以协作的方式学习两个任务，用于端到端的动物图像抠图。
该结构可以粗略地描述为一个粗略的分割阶段和抠图阶段。请注意，这两个阶段可能是交织在一起的，因为在第一个阶段会有来自第二阶段的反馈来纠正错误的决定,将它们集成到单个模型中并明确地为协作建模是合理的。
网络结构是一个编码解码器的结构，编码器、两个平行的解码器（GD和FD）。
然后，以不同的表征域（RoSTa），连接 GD 和 FD 的输出结果。
最后，通过协同合作抠图（CM），将RoSTa中三个不同的表征域的结果，进行合并，获得最终的 alpha 预测
编码器：
以在 ImageNet 上预训练的 ResNet-34 或 DenseNet-121 作为编码器。将单个图像作为输入，通过五个 $E_0 - E_4$ 模块进行处理
解码器：
Glance Decoder（GD）：
旨在识别容易的语义部分，而将其他部分作为未知区域。模型采用了 $D^G_4 &amp;ndash; D^G_0$ ，每层的输出与编码器一一对应。为了进一步扩大感受野，在 $E_4$ 之后增加了一个金字塔汇集模块(PPM)以提取全局上下文。其损失函数为：交叉熵。 $$ L_{CE} = - \sum_{c=1}^C G^c_g log(G_p^c) $$
Focus Decoder (FD)：
FD旨在提取低层结构特征，即：非常有用的过渡区域的细节。模型采用了 $D^F_4 &amp;ndash; D^F_0$ ，每层的输出与编码器一一对应。使用一个bridge block(BB)来代替 $E_4$ 之后的PPM，以在不同的感受野中利用local context。来自 $E_4$ 和 $BB$ 的特征被连接，并馈入 $D^F_4$，遵循U-net风格，在每个编码器块 $E_i$ 和解码器块 $D^F_i$ 之间添加一个快捷方式，以保留精细细节。</description></item><item><title>backbone net</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/</link><pubDate>Thu, 09 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0010_backbone/d1_3_backbone_net/</guid><description>卷积神经网络的发展历程：
一、Backbone 1. LeNet 论文
LeNet：名字来源于第一作者Yann LeCun。是一个奠基性的网络，第一次将卷积神经网络推上舞台。
卷积层+最大池化：卷积层用来识别图像里的空间模式；最大池化用来降低卷积层对位置的敏感度。卷积层块由两个这样的基本单位重复堆叠构成。 LeNet可以在早起的小数据集上取得较好的效果，但是在更大的真实数据集上表现并不如人意。一方面：神经网络计算复杂，在GPU没有大量普及的20世纪90年代，训练一个多通道、多层、含有大量参数的卷积神经网络是很难完成的；另一方面：当年并没有深入研究参数初始化和非凸优化算法，导致复杂的神经网络的训练通常比较困难。 特征本身是由学习得来的，为了表征足够复杂的输入，特征本身应该分级表示。想要学习到复杂的多级特征，需要大量的带有标签的数据，这样才能表现得比其他经典方法要好。早期研究只基于小的公开数据集，自2009年ImageNet数据集创建以来，传统方法不再有优势。 输入：32*32 C1-卷积层：卷积层尺寸：6 * 28 * 28；卷积核尺寸：6 * 1 * 5 * 5；可训练参数：(5 * 5 + 1) * 6 S2-池化层：池化尺寸：2 * 2；步幅：2；方式：4个输入相加，然后乘以个可训练参数，加上个可训练参数，最后通过sigmoid；输出尺寸：6 * 14 * 14；可训练 参数：2 * 6 C3-卷积层：输出尺寸：16 * 10 * 10；卷积核尺寸: 16 * 6 * 5 * 5;
组合方式：前6个map - 以S2中3个相邻的feature map
再6个map - 以S2中4个相邻的feature map
再3个map - 以S2中不相邻的4个feature map
再1个map - 以S2中所有feature map S4-池化层：输出尺寸：16 * 5 * 5；池化尺寸：2 * 2；步幅：2</description></item><item><title>神经网络画图篇</title><link>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/</link><pubDate>Thu, 09 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0100_draw_map_for_dl/</guid><description>一、简介 一图抵万言！本篇介绍神经网络的可视化工具和绘图软件。
二、示意图 1、NN SVG 提供三种典型的神经网络绘图风格，个性化参数多；交互式绘图。 NN-SVG是由麻省理工学院弗兰克尔生物工程实验室开发的。可以绘制的图包括以节点形式展示的FCNN style，这个特别适合传统的全连接神经网络的绘制。
Github
Demo
2、PlotNeuralNet 底层基于latex的宏指令绘制，上层提供基于python的描述框架，绘制脚本简单。可以绘制复杂的网络结构。
PlotNeuralNet 是由萨尔大学计算机科学专业的一个学生开发的，目前主要支持的是卷积神经网络，其中卷积层、池化层、bottleneck、skip-connection、up-conv、Softmax等常规的层在代码中都有定义，但缺少RNN相关的可视化层展示。
Github
三、计算图 1、Netron Netron是一个神经网络可视化包，支持绝大多数神经网络操作。该功能包可以为不同节点显示不同的颜色，卷积层用蓝色显示，池化层和归一化层用绿色显示，数学操作用黑色显示。在使用方面，可以直接访问网页端，上传模型文件，就可以看到网络结构图，并可以进一步利用pip安装并引入到程序中通过浏览器查看模型的变化。
Github
Demo</description></item><item><title>CNN</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/</link><pubDate>Thu, 09 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0010_backbone/d1_1_backbone_cnn/</guid><description>一、卷积 实际上，卷积操作需要对卷积核进行上下/左右翻转，然后用卷积核对输入进行滑动计算。由于网络学习目的是要&amp;quot;学习&amp;quot;出一个近最优解的权重，即：近最优解情况下卷积核的值，所以在卷积操作时，也就没必要在做翻转操作，反正卷积核的值是要被&amp;quot;调教&amp;quot;的，最终的卷积核的状态：可以看成是已经被上下/左右翻转过了。卷积操作也就变成互相关运算。
卷积层解决的问题：
卷积层保留输入图片的形状，使图像的像素在高/宽两个方向上的相关性均可能被有效识别。 卷积层通过滑动窗口，将同一卷积核与不同位置的输入重复计算，参数共享，避免参数尺寸过大。 在卷积操作时，会有两个超参数：填充(padding)和步幅(stride)，根据输入尺寸和卷积核改变输出形状：
假设：输入尺寸：nh * nw，卷积核尺寸：kh * kw
填充(padding)：在输入高和宽的两侧填充元素(通常是0)，一般来说：在高的两侧一共填充ph行；在宽的两侧一同填充pw列，一般填充的是偶数，即：nn.Conv2D(padding=(ph/2, pw/2)) 步幅(stride)：在滑动计算时，每次滑动的步长，假设：在高上步幅为sh，在宽上步幅为sw 则：输出尺寸： $$ \tag{公式1} o_h = \frac{n_h-k_h+p_h+s_h} {s_h }, o_w = \frac{n_w-k_w+p_w+s_w} {s_w } $$
1. 1*1卷积层 1*1卷积层：被看作是卷积操作的全连接层。这是为什么呢？
1*1卷积的计算发生在通道维度上：输出的每个元素，来自输入中相同位置的元素在不同通道之间按权重叠加。假设我们将通道维度当作特征维度，将宽高维度上的元素看作数据样本，那么1*1卷积层的作用与全连接等价。 二、池化层 池化层(pooling)：缓解卷积层对位置的过渡敏感性。
浅层网络获取的是图像的细节信息，比如：纹理特征、边缘；高层网络获取的是图像的整体特征。池化层把感受野扩大，把图像的整体特征传递下去，网络越深感受野越大 池化层一般是最大池化或者平均池化，类比生物学的神经细胞：只有电解质信号超过一定阈值，才能激活下一个神经元，才能把信号传递下去。 三、批量归一化 batch normalization：在一个batch内，算出平均值a, 方差：b^2；然后对每个样本做归一化：c*(x-a)/b+d。其中c、d是需要训练的。
$$ x_{i+1} = \gamma \frac{x_i - \mu}{\sigma} + \beta $$ 由于数据的差异性，在卷积后可能会存在较大的波动。$\frac{x_i - \mu}{\sigma}$ 的作用就是把数据统一拉回N(0,1)的标准正态分布；但是每个特征的分布不一定是标准正态分布，所以添加了可学习的参数：$\gamma, \beta$。 通过训练来调节实际的均值 $\beta$ 和标准差 $\gamma$ ，不过 $\beta$ 和 $\gamma$ 是在一定的范围内，不能波动太大。</description></item><item><title>optimizer</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/</link><pubDate>Thu, 09 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0010_backbone/d1_2_optimizer/</guid><description>在深度学习中，通过最小化损失函数使得训练误差最小化，由于损失函数一般都会比较复杂，很难直接求解析解，而是需要基于数值方法的优化算法找到近似解，即：数值解。在局域数值方法的优化算法中，损失函数就是目标函数(Objective Function)，
1. 梯度下降法 梯度下降(gradient descent)的工作原理，以一维为例： 假设连续可导的函数 $f:\Reals \to \Reals$ 的输入和输出都是标量，给定绝对值足够小的数 $\epsilon$ ，根据泰勒展开式，近似： $$ f(x+\epsilon) \approx f(x) + \epsilon f'(x) $$ 其中 $f'(x)$ 表示函数在x处的梯度。找到一个常数 $\eta &amp;gt; 0$，使得 $\lvert \eta f'(x) \rvert$ 足够小，那么可以将 $\epsilon$ 提换为 $-\eta f'(x)$，得到： $$ f(x-\eta f'(x)) \approx f(x) - \eta f'(x)^{2} $$ 所以 $$ f(x-\eta f'(x)) \lesssim f(x) $$ 这就意味着，可以通过 $x \gets x-\eta f'(x)$ 来迭代x，函数 $f(x)$ 的值可能会降低。在梯度下降中，先取一个初始值 $x_0$ 和学习率 $\eta&amp;gt;0$，然后不断通过上式迭代x，直到停止条件。学习率 $\eta$ 是一个超参数，需要人工设定，如果学习率过小：会导致x更新缓慢从而需要更多的迭代次数；如果学习率过大，泰勒展开式不再成立，可能会出现振荡，无法保证会迭代出近似最优解。
在每次迭代中，由于训练集较大，不可能把所有样本都加载到内存中，通常是随机均匀采样多个样本组成一个小批量，然后使用这个小批量来计算梯度，完成一次迭代，即：小批量随机梯度下降(batch gradient descent)。
设：目标函数 $f(x): \Reals^{d} \to \Reals$ 小批量数据集 $\text{\ss}$ 梯度计算： $$ g_t \gets \nabla f_{\text{\ss}_{t}}=\frac {1} {\lvert \text{\ss} \rvert} \displaystyle\sum_{i \in \text{\ss}_{t}} \nabla f_i(x_{t-1}) $$</description></item><item><title>位置编码</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0030_transformer/0030_position/</link><pubDate>Wed, 08 Sep 2021 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0030_transformer/0030_position/</guid><description>位置编码 1、绝对位置编码 最早出现于Transformer文章中，目的是为了弥补模型中位置信息的缺失。
输入：$\bold{X} \in \R^{n \times d}$ 包含一个序列中n个词元的d维嵌入表示。
位置编码：$\bold{P} \in \R^{n \times d}$, 矩阵第i行 偶数列、奇数列：用不同的频率、偏移来记录位置信息。 $$p_{i,2j} = sin(\frac{i}{10000^{\frac{2j}{d}}})$$ $$p_{i,2j+1} = cos(\frac{i}{10000^{\frac{2j}{d}}})$$
在 $\bold{X} + \bold{P}$ 时，当$\bold{X}$的幅度值比$\bold{P}$小或者差不多时，可以增大$\bold{X}$的幅度值，以保证$\bold{X}$的主导性。 $$ \bold{X} \times M + \bold{P} $$
2、相对位置编码 Google于2018年提出的 《Self-Attention with Relative Position Representations》 。该方法出自Transformer的原班人马，通过在attention模块中加入可训练的参数，帮助模型来记住输入中的相对位置。
3、ALiBi ALiBi
4、旋转位置编码(RoPE) RoPE
个人理解：对embedding向量做一个角度旋转。由于d维的向量旋转太复杂，只对2维的向量做旋转。所以d维的向量，有d/2个小向量。 旋转的基本角度：
参考：苏剑林的blog def precompute_freqs_cis(dim: int, seq_len: int, theta: float = 10000.0): # 计算词向量元素两两分组之后，每组元素对应的旋转角度 freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].</description></item><item><title>简介</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0050_pytorch/0010_torch_summary/</guid><description>官方文档
torch目录下，树状图:
├── quasirandom.py
├── random.py random模块
├── serialization.py
├── storage.py
├── tensor.py Tensor模块
├── functional.py
│
├── cuda
│　├── comm.py
│　├── error.py
│　├── memory.py
│　├── nccl.py
│　├── nvtx.py
│　├── profiler.py
│　├── random.py
│　├── sparse.py
│　└── streams.py
│
├── nn
│　├── backends
│　├── cpp.py
│　├── functional.py
│　├── grad.py
│　├── init.py
│　├── intrinsic
│　│　├── modules</description></item><item><title>编解码架构</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/encode_decode/</guid><description>一、编码器-解码器 架构 机器翻译：是把一个序列转换为另一个序列。为处理这种类型的输入和输出，设计这样的架构：
编码器：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。
解码器：将固定形状的编码状态映射到长度可变的序列。
二、seq2seq Ilya Sutskever 等人设计的seq2seq：将编码器最后一时间步的state，作为解码器第一时间步的state使用。
Kyunghyun Cho 等人设计的seq2seq，将编码器最后一时间步的state，作为解码器每一个时间步的输入序列的一部分。</description></item><item><title>简介</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0055_semantic_segmentation/object_detection_summary/</guid><description>一、简介 It&amp;rsquo;s coming soon.
二、网络-基于编码器-解码器 1、FCN 《Fully Convolutional Networks for Semantic Segmentation》(2015) 要说语义分割整体实现精度大的跨越还是在FCN（全卷积神经网络）提出之后。它完全改变了之前需要一个窗口来将语义分割任务转变为图片分类任务的观念，FCN完全丢弃了图片分类任务中全连接层，从头到尾都只使用到了卷积层。从FCN后，基于编码器解码器结构的经典网络结构如同雨后春笋般冒了出来
2、U-Net 《U-Net: Convolutional Networks for Biomedical Image Segmentation》(2015) Unet网络是在医学影像分割中最常用的模型。它的典型特点是，它是U型对称结构，左侧是卷积层，右侧是上采样层（典型的编码器解码器结构）。
另一个特点是，Unet网络的每个卷积层得到的特征图都会concatenate到对应的上采样层，从而实现对每层特征图都有效使用到后续计算中。也就是文中所说的skip-connection。这样，同其他的一些网络结构比如FCN比较，Unet避免了直接在高级feature map中进行监督和loss计算，而是结合了低级feature map中的特征，从而可以使得最终所得到的feature map中既包含了high-level 的feature，也包含很多的low-level的feature，实现了不同scale下feature的融合，提高模型的结果精确度。
3、SegNet 《SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation》(2015) 是一个由剑桥大学团队开发的图像分割的开源项目，该项目可以对图像中的物体所在区域进行分割，例如车，马路，行人等，并且精确到像素级别
4、Deeplab V1 《Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs》(2015) 2015 年的ICLR上提出DeepLab V1是结合了深度卷积神经网络（DCNNs）和概率图模型（DenseCRFs）的方法。它将DenseCRFs作为网络的后处理方法。采用DenseCRFs作为后处理的方法，简单来说，就是对一个像素进行分类的时候，不仅考虑DCNN的输出，而且考虑该像素点周围像素点的值，这样语义分割结果边界清楚。
5、Deeplab V2 《DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs》(2017) 在实验中发现 DCNNs 做语义分割时精准度不够的问题，根本原因是重复的池化和下采样降低了分辨率。但是另一方面，重复的池化和下采样扩大了感受野，而感受野的扩大对语义分割任务来说也是至关重要的。针对这一问题，DeepLab v2采用的空洞卷积算法扩展感受野，与此同时不会降低特征图的分辨率。此外，deeplab v2基于空洞卷积，设计了ASPP模块。它组合了不同dilation rate的空洞卷积所产生的特征图。这样，不同空洞卷积产生的不同感受野的特征图被组合在了一起，从而获取了更加丰富的上下文信息。</description></item><item><title>简介</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0050_detect_object/object_detection_summary/</guid><description>一、简介 It&amp;rsquo;s coming soon.
二、网络 1、R-CNN 《Rich feature hierarchies for accurate object detection and semantic segmentation》(2013)
2、SPPNet 《Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition》(2014)
3、Fast R-CNN 《Fast R-CNN》(2015)
4、Faster R-CNN 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》(2016)
5、FPN 《Feature Pyramid Networks for Object Detection》(2017)
4、YOLO 《You Only Look Once: Unified, Real-Time Object Detection》(2016)
5、YOLO V2 《YOLO9000: Better, Faster, Stronger》(2016)
6、YOLO V3 《YOLOv3: An Incremental Improvement》(2018)</description></item><item><title>抠图综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00100_cv/0060_image-matting/image-matting-summary/</guid><description>It&amp;rsquo;s coming soon.</description></item><item><title>Transformer</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0030_transformer/0010_transformer_summary/</guid><description>一、简介 谷歌大脑、谷歌研究院等团队于2017年联合发表文章《Attention Is All You Need》，提出了一种新的注意力 Seq2Deq 模型，以取代之前以RNN作为编/解码器实现的 Seq2Seq 模型。模型采用的也是编码器-解码器架构，但是在该模型中，编码器和解码器不再是 RNN结构，取而代之的是编码器栈（encoder stack）和解码器栈（decoder stack）（注：所谓的“栈”就是将同一结构重复多次，“stack”翻译为“堆叠”更为合适）。编码器栈和解码器栈中分别为连续N个具有相同结构的编码器和解码器。
编码器：由两部分组成（自注意力模块 + 前馈神经网络）
自注意力模块：具体来说是“Multi-Head Attention”，即“多头注意力”模块
全连接前馈网络 每个子网络都具有残差连接，其输出形式为 $LayerNorm(Sublayer(x)+x)$ ，其中 $Sublayer(x)$ 表示子网络对输入特征x进行的具体映射操作；$LayerNorm()$ 表示归一化操作。
解码器：由三部分组成（自注意力模块 + 编码-解码注意力模块 + 前馈神经网络）
解码器中多了一个编码-解码注意力模块，用来利用当前已有的输出，来匹配输入特征（即：attention操作），然后拿计算出的新特征来计算当前时间步的输出。解码器中的自注意力模块与编码器不同是：这里只能看到当前时间步之前的输入，而不是全部的输入，所以需要有mask的操作。
论文中图： 二、Transformer 输入：序列的embeding表示 + 位置编码
编码器：
多头注意力 + 残差连接(residual connection) &amp;ndash;&amp;gt; 层归一化(layer normalization) 基于位置的前馈网络(positionwise feed-forward network) + 残差连接(residual connection) &amp;ndash;&amp;gt; 层归一化(layer normalization) class PositionWiseFFN(nn.Module): &amp;#34;&amp;#34;&amp;#34;基于位置的前馈网络&amp;#34;&amp;#34;&amp;#34; def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs): super(PositionWiseFFN, self).</description></item><item><title>BART综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0150_bart/bart_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0150_bart/bart_summary/</guid><description>一、背景 二、BART BART 是一个去噪自动编码器，用于预训练seq-to-seq模型。Bart是标准的Transformer架构，Bart的预训练过程是：
用噪声函数破坏文本 通过学习，让模型重建原始文本。 1、模型架构 同GPT一样，把ReLU激活函数修改为GeLU 用 $N(0, 0.02)$ 初始化参数。 基础版：采用6层编码器；large版：采用12层编码器。与bert的差异 解码器的每层，对编码器的最终隐藏层，做交叉attention BERT在进行预测之前，会有一个前馈网络，而BART没有。总体而言，BART的参数比同等大小的BERT模型多了10% 2、总结 BART提出了各种各样的破坏方法，比如：
删掉某些单词(Delete)； 打乱输入多个句子的顺序(permutation)； (❌: 效果不好) 交换序列中单词的位置(rotation)； (❌: 效果不好) 随机插入MASK(比如：原来AB单词之间没有其他单词，故意插入一个MASK去误导模型)或一个MASK盖多个单词(误导模型这里只有一个单词)(Text Infilling)。 (✅: 效果最好)</description></item><item><title>RNN综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/rnn_summary/</guid><description>一、文本预处理 1、词元-token 英文：在训练文本模型时，模型输入最小单元：可以是词元维度，也可以是字符维度(这样的话，模型还得学习怎么用字符组合成单词)
中文：一般是字符维度；如果是词元维度，在模型之前需要进行分词，如果要使用词元维度，需要先分词，用空格间隔开。
特殊词元：未知词元 &amp;lt;unk&amp;gt;，填充词元&amp;lt;pad&amp;gt;，序列开始词元 &amp;lt;bos&amp;gt;，序列结束词元 &amp;lt;eos&amp;gt;
2、词表-vocabulary 把token映射到：一个从0开始的数字索引，也就是：
token &amp;ndash;&amp;gt; idx：token_to_idx {0:then, 1:token, &amp;hellip;.}
idx &amp;ndash;&amp;gt; token：idx_to_token: [the, token, &amp;hellip;.] 例如：
tokens: 例如：一篇文章
例如：[[一句话按照空格split后], [], [], ....]
vocab：词表，代码里可以写成一个类，其元素有：
self.idx_to_token ：['&amp;lt;unk&amp;gt;', &amp;lsquo;the&amp;rsquo;, &amp;hellip;] token的列表，按照token的个数降序排列
self.token_to_idx ：{'&amp;lt;unk&amp;gt;': 0, &amp;lsquo;the&amp;rsquo;: 1, &amp;hellip;.} token&amp;ndash;&amp;gt;idx 的映射
corpus：语料库，先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计， 得到的统计结果称之为语料
例如：[('&amp;lt;unk&amp;gt;', 1000), ('the', 900), ....]
二、深度循环神经网络 循环神经网络(Recurrent Netural Networks)：是具有隐状态的神经网络。
类似于MLP多层感知机，RNNs只是添加了时间轴信息。比如，MLP的表示如下：
$$ H = \phi(XW_{xh} + b_h) $$ $$O = HW_{hq} + b_q $$</description></item><item><title>LSTM网络</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/lstm/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/lstm/</guid><description>一、简介 长短期记忆网络(LSTM)
忘记门：$F_t = sigmoid(X_tW_{xf}+H_{t-1}W_{hf}+b_f)$ 输入门：$I_t = sigmoid(X_tW_{xi}+H_{t-1}W_{hi}+b_i)$ 输出门：$O_t = sigmoid(X_tW_{xo}+H_{t-1}W_{ho}+b_o)$ 候选记忆单元：$\tilde{C_t} = tanh(X_tW_{xc} + (R_t \odot H_{t-1})W_{hc} + b_c)$ 记忆单元：$C_t = F_t \odot C_{t-1} + I_t\odot \tilde{C_t}$ 隐状态：$H_t = O_t \odot tanh(C_t)$ 其中，$F_t, I_t, O_t, C_t, H_t, \in \R^{n \times d}$</description></item><item><title>GPT综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0080_gpt/0010_gpt_summary/</guid><description>模型评估 评估指标：
困惑度：困惑度（perplexity）的基本思想是：给测试集的句子赋予较高概率值的语言模型较好,当语言模型训练完之后，测试集中的句子都是正常的句子，那么训练好的模型就是在测试集上的概率越高越好，公式如下 $PP(W)=P(w_1w_2&amp;hellip;w_N)^{\frac{-1}{N}}$ 。由公式可知，句子概率越大，语言模型越好，迷惑度越小。困惑度p可以理解为，如果每个时间步都根据语言模型计算的概率分布随机挑词，那么平均情况下，挑多少个词才能挑到正确的那个 Prompt ranking accuracy：这个指标的定义和评价方法，来自《Hierarchical Neural Story Generation》。主要是关注引导语和生成的故事之间的相关性。具体做法是：在测试集中选择一对（p，g），p表示引导语，g表示生成的故事，在随机选取其他的引导语p1-p9，然后计算p和g的likelihood。条件一：（p，g）的相似性比（p1，g）的相似性大。 那么就取10000个测试集中的（p，g），满足条件一的部分占比，就称为Prompt ranking accuracy。 句子嵌入的相似度：计算引导语和生成的故事的句子嵌入（用GloVe取每个词的平均嵌入值）的余弦相似度。 评价连贯性：连贯性的评价方法，来自《Modeling local coherence: An entity-based approach》，主要思想是，在测试数据集中，对于一个故事s0，选择前面15个句子，打乱顺序，生成14个乱序的故事s1-s14。然后用语言模型计算s0-s14的可能性。对于s1-s14，如果可能性大于s0，就称为反例。 错误率定义为反例的占比。 评价单词的重复性和rareness 一、简介 基于文本预训练的GPT-1，GPT-2，GPT-3三代模型都是采用的以Transformer为核心结构的模型，不同的是模型的层数和词向量长度等超参，它们具体的内容如下：
模型 发布时间 层数 head hidden 参数量 预训练数据量 GPT-1 2018年6月 12 12 768 1.17亿 5GB GPT-2 2019年2月 48 - 1600 15亿 40GB GPT-3 2020年5月 96 96 12888 175B 45TB 二、GPT GPT(2018-06) 其创造性的提出以Transformer的解码器来训练生成式模型，后面Bert的作者估计是看到了这篇论文，据说两个月时间就发表了以Transformer编码器训练的Bert模型。总结下GPT-1模型：</description></item><item><title>ELECTRA综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0200_electra/electra_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0200_electra/electra_summary/</guid><description>一、背景 二、ELECTRA ELECTRA的全称是Efficiently Learning an Encoder that Classifies Token Replacements Accurately。最主要的贡献是提出了新的预训练任务和框架，把生成式的Masked language model(MLM)预训练任务改成了判别式的Replaced token detection(RTD)任务，判断当前token是否被语言模型提换过。
之前的方法，都需要预测一些部分。或者是预测下一个单词，或者是预测被盖住的部分。其实预测的模型需要的训练量是很大的，ELECTRA不做预测，只回答是或者否。
比如: 上面原来的句子是“the chef cooked the meal”，现在把“cooked”换成了“ate”。ELECTRA需要判断输入的单词中，哪些被替换了。
这样的好处是：预测Y/N简单；并且每个输出都被用到，可以计算损失。不像训练BERT时，只要mask的部分才计算loss。
ELECTRA的效果还比较不错，从上图可以看到，在同样的运算量下，它的表现比其他模型要好，并且能更快地达到较好的效果。
结构
类似GAN的思路，生成器：随机mask，把mask位置的token随机替换成其他的token。 优势：
训练速度比bert快，充分训练后，准确率更高。比如：效果与RoBerta一致，计算量只用了1/4。 计算loss的时候，不但使用了mask部分，也使用了非mask的部分。 三、总结</description></item><item><title>code解析</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/1000_code/bart_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/1000_code/bart_summary/</guid><description>一、transformers Hugging Face公司发布的transformers包，能够超级方便的引入训练模型：BERT、GPT2、&amp;hellip; transformers英文文档 transformers中文文档
二、Tokenizer from transformers import BertTokenizerFast, BertTokenizer from transformers import GPT2TokenizerFast, GPT2LMHeadModel # 初始化tokenizer tokenizer = BertTokenizerFast(vocab_file=args.vocab_path, sep_token=&amp;#34;[SEP]&amp;#34;, pad_token=&amp;#34;[PAD]&amp;#34;, cls_token=&amp;#34;[CLS]&amp;#34;) # 对比 tokenizer.encode() 与 tokenizer.tokenize() sentence = &amp;#34;Hello, my son is cuting.&amp;#34; input_ids_1 = tokenizer.encode(sentence, add_special_tokens=False) # add_special_tokens=True 将句子转换成对应模型的输入形式，默认开启。就是首尾加上[cls]、[sep]。即：tensor([ 101, 7592, 1010, 2026, 2365, 2003, 3013, 2075, 1012, 102]) # add_special_tokens=False 首尾先不加[cls]、[sep] input_tokens = tokenizer.tokenize(sentence) # [&amp;#39;hello&amp;#39;, &amp;#39;,&amp;#39;, &amp;#39;my&amp;#39;, &amp;#39;son&amp;#39;, &amp;#39;is&amp;#39;, &amp;#39;cut&amp;#39;, &amp;#39;##ing&amp;#39;, &amp;#39;.&amp;#39;] input_ids_2 = tokenizer.</description></item><item><title>Attention</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0030_transformer/0001_attention/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0030_transformer/0001_attention/</guid><description>一、Attention机制 如何有选择地引导注意力：
非自主性提示： 基于环境中物体的突出性和易见性。比如 《辛德勒的名单》中的镜头：黑白镜头中的穿红衣服的小女孩。
自主性提示： 选择受到 认知、意识的控制。
在不受自我意识控制的情况下，与环境差别最大的事物，就越显眼、易见。
在受到自我意识控制的情况下，意识偏向那个，就选择那个
查询(query)：自主性提示，类似于自我意识。
键(key)：非自主提示，类似于事物的突出性、易见性。
值(value)：感官输入，类似于具体的事物-值。
attention机制可以认为是一个这样的函数：
$$ f(\bold{q_j}) = \sum_{i=1}^m \alpha(\bold{q}_j, \bold{k}_i) \bold{v}_i$$ 由$ \bold{V}$ 的各个向量的加权平均，组成一个新的向量 $f(q_j)$。其中，权重的计算是通过 query向量和每个key向量 计算出来的，这个计算方式可以有多种，比如：加性注意力、缩放点积注意力
$\bold{Q} \in \R^{n \times q}$: 查询矩阵，是由N个向量组成，每个向量有q个元素
K-V: M个键值对集合。
$\bold{K} \in \R^{m \times k}$: M个键向量组成的矩阵，每个键向量(k维)：就是每个字的标签信息
$\bold{V} \in \R^{m \times v}$: M个值向量组成的矩阵，每个值向量(v维)：就是每个字的embeding
1、加性注意力 $$\alpha(\bold{q}_j, \bold{k}_i) = \bold{w}_v^T tanh(\bold{W}_q \bold{q}_j + \bold{W}_k \bold{k}_i)$$ 其中，$\bold{w}_v^T \in \R^h, \bold{W}_q \in \R^{h \times q}, \bold{W}_k \in \R^{h \times k}$ 是需要训练的。</description></item><item><title>Word Embedding综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0010_word_embedding/word_embedding_summary/</guid><description>一、word embedding 词向量：是用来表示词的向量或者表征，也可被认为是词的特征向量。把词映射为实数域向量的技术 &amp;ndash; 词嵌入(word embedding)
最简单的方式：one-hot向量。
词库里假设有N个词，对所有词排序，用0~N-1作为每个词的索引。 每个词的one-hot向量：长度为N，在该次索引的位置为1，其他位置都是0 缺点：one-hot向量，不能表征两个词的相似度。比如我们常用余弦相似度，one-hot的向量都是相互垂直的。
词嵌入是一种无监督学习。机器通过阅读大量的文章来学习的单词的意思，通过上下文信息来理解一个单词。怎么挖掘上下文信息：
Count-based method。认为如果两个单词一起出现的频率很高，那么它们的word embedding feature应该很接近彼此，二者的内积就越接近这两个的单词在同一篇文章中出现的次数。GloVe 就是一种count-based的算法。 prediction-based method. ski-gram 和 CBOW 就是这种算法。 二、Count-based method 1、GloVe 《GloVe: Global Vectors for Word Representation》 上下文窗口内的词共现可以携带丰富的语义信息。例如，在一个大型语料库中，“固体”比“气体”更有可能与“冰”共现，但“气体”一词与“蒸汽”的共现频率可能比与“冰”的共现频率更高。此外，可以预先计算此类共现的全局语料库统计数据：这可以提高训练效率。
GloVe模型基于平方损失 (Pennington et al., 2014)对跳元模型做了三个修改：
使用变量 $p_{ij} = x_{ij}$ 和 $q_{ij} = e^{(u^T_j v_i)}$ 而非概率分布，并取两者的对数。所以平方损失项是 $(log p_{ij} - log q_{ij})^2 = (u^T_j v_i - log x_{ij})^2$ 为每个词 $w_i$ 添加两个标量模型参数：中心词偏置 $b_i$ 和上下文词偏置 $c_i$。 用权重函数 $h(x_{ij})$ 替换每个损失项的权重，其中 $h(x)$ 在 $[0, 1]$ 的间隔内递增。 整合代码，训练GloVe是为了尽量降低以下损失函数： $$ \sum_{i \in V} \sum_{j \in V} h(x_{ij})(u^T_j v_i + b_i + c_j - log x_{ij})^2 $$</description></item><item><title>GRU网络</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/gru/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0020_rnn/gru/</guid><description>一、简介 RNNs中，需要的信息都放在隐藏层，当序列太长时，隐藏层累积了太多的信息，对前面太久的信息，就不容易获取到了。
另外，有些信息不太重要，有些词比较重要，所以，设计了：
更新门： $Z_t$ 有助于捕获序列中的长期依赖关系。当$Z_t = 0$时，并不是就没有$H_{t-1}$的信息了，而是$H_{t-1}$的信息通过正常的计算$H_t$的途径进来；而当$Z_t &amp;gt; 0$时，$H_{t-1}$的信息可以绕过正常的计算途径，直接添加到$H_t$中。
重置门： $R_t$ 有助于捕获序列中的短期依赖关系。$\tilde{H_t}$ 的计算跟RNNs计算相似，就是加了 $R_t$ 来限制 $H_{t-1}$，本来RNNs对太久的信息就不容易获取，所以 $R_t$ 的作用：是否忘掉历史没用的信息。
$$R_t = sigmoid(X_tW_{xr}+H_{t-1}W_{hr}+b_r)$$ $$Z_t = sigmoid(X_tW_{xz}+H_{t-1}W_{hz}+b_z)$$ $$\tilde{H_t} = tanh(X_tW_{xh} + (R_t \odot H_{t-1})W_{hh} + b_h)$$ $$H_t = Z_t \odot H_{t-1} + (1-Z_t)\odot \tilde{H_t}$$
其中，$R_t$ ：表示在更新候选隐状态时，需要多少历史隐状态信息，$Z_t$ ：表示在算真正的隐状态时，需要多少新输入的$X_t$的信息，这两个的维度与隐状态是一致的。</description></item><item><title>静态图</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0010_tf_compat_summary/</guid><description>在TensorFlow 2中使用兼容性模块，必须使用tf.compat.v1替换tf，并且在导入TensorFlow软件包后添加一行tf.compat.v1.disable_eager_execution()函数来关闭eager执行模式。
import tensorflow as tf tf.compat.v1.disable_eager_execution() 简介 数据流是一种编程模型，被广泛地应用于并行计算中。TF使用数据流图来表示计算中各个运算之间的关系，在数据流图中，节点：表示计算单元(即：操作tf.Operation)；边：表示被计算单元消费/生产的数据(即：tf.Tensor)。 数据流图，可以被导出成一个可移植的、编程语言不相关的表示(ProtoBuf)，这种表示可以被其他语言使用，来创建一个图并在会话中使用它。
def graph_demo(): a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32) b = tf.constant([[10, 0, 0], [0, 0.5, 0], [0, 0, 2]]) c = tf.constant([[1, -1, 3]], dtype=tf.float32) y = tf.add(tf.matmul(a, b), c, name=&amp;#39;result&amp;#39;) writer = tf.summary.FileWriter(os.path.join(root_dir, &amp;#39;log/matmul&amp;#39;), tf.get_default_graph()) writer.close() return y # 在终端启动TensorBoard对图进行可视化 tensorboard --logdir log/matmul 上例中创建一个数据流图，然后用TensorBoard对这个图进行可视化。
tf.summary.FileWriter 创建了一个tf.summary.SummaryWriter来保存一个图像化表示，这个writer对象创建时，初始化参数包括：a.该图像化表示的存储路径；b.一个tf.Graph对象，可以使用tf.get_default_graph函数返回默认图 tf.get_default_graph 函数，返回默认图。 在执行时，调用TF API创建数据流图，这个阶段并没有进行计算。</description></item><item><title>进阶操作</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0030_advance_operator/</guid><description>一、环境变量 1、临时环境变量 操作 说明 os.environ['WORKON_HOME']=&amp;quot;变量&amp;quot; 设置环境变量 os.environ['CUDA_VISIBLE_DEVICES']=&amp;quot;1&amp;quot; 设置显卡设备 os.environ.get('WORKON_HOME') 获取环境变量-方法1 os.getenv('path') 获取环境变量-方法2-推荐 del os.environ['WORKON_HOME'] 删除环境变量 os.environ['HOMEPATH'] 当前用户主目录 os.environ['TEMP'] 临时目录路径 os.environ['PATHEXT'] 可以执行文件 os.environ['SYSTEMROOT'] 系统主目录 os.environ['LOGONSERVER'] 机器名 os.environ['PROMPT'] 设置提示符 2、永久环境变量 操作 说明 功能 path = r&amp;quot;路径&amp;quot;</description></item><item><title>模型训练</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0040_tf/w0010_compat/0020_tf_compat_train/</guid><description>一、tf.layers tf.layers模块在TensorFlow2.0中已经被完全移除了，用tf.keras.layers定义层是新的标准。
二、tf.losses tf.losses模块包含了经常使用的、能够实现独热编码的损失函数。
三、tf.train 1. Optimizer TensorFlow提供的优化器
优化器 功能 tf.train.Optimizer tf.train.GradientDescentOptimizer tf.train.AdadeltaOptimizer tf.train.AdagtadOptimizer tf.train.AdagradDAOptimizer tf.train.MomentumOptimizer tf.train.AdamOptimizer tf.train.FtrlOptimizer tf.train.ProximalGradientDescentOptimizer tf.train.ProximalAdagradOptimizer tf.train.RMSProOptimizer Optimizer类与其子类的继承关系：
def minimize(self, loss, # 损失值， tensor # 全局训练步数，随着模型迭代优化自增， variable global_step=None, # 待训练模型参数的列表， list var_list=None, # 计算梯度和更新参数模型时的并行化程度，可选值GATE_OP,GATE_NONE,GATE_GRAPH # GATE_NONE 无同步，最大化并行执行效率，将梯度计算和模型参数更新完全并行化。 # GATE_OP，操作级同步，对于每个操作，分别确保所有梯度在使用前都计算完成。 # GATE_GRAPH，图级同步，最小化并行执行效率，确保所有模型参数的梯度计算完成。 gate_gradients=GATE_OP, # 聚集梯度值的方法， Enum aggregation_methed=None, # 是否将梯度计算放置到对应操作所在同一个设备，默认否，Boolean colocate_gradients_with_ops=False, # 优化器在数据流图中的名称，string nmae=None, # 损失值的梯度 grad_loss=None) 属性 功能介绍 _name 表示优化器的名称 _use_locking 表示是否在并发更新模型参数时加锁 minimize 最小化损失函数，该方法会依次调用compute_gradients和apply_gradients compute_gradients 计算模型所有参数的梯度值,返回&amp;lt;梯度，响应参数&amp;gt;的键值对列表 apply_gradients 将梯度值更新到对应的模型参数，优化器的apply_gradients成员方法内部会调用tf.</description></item><item><title>文件读取</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0050_file/</guid><description>一、pandas import pandas as pd import pickle # 使用pandas对pickle进行操作 df = pd.DataFrame(np.arange(20).reshape(4, 5)) 操作 解释 pickle.load() pickle.dump() pd.DataFrame() df.to_pickle('**.pkl') to_pickle() 属性可以生成pickle文件，对数据进行永久存储 df.read_pickle('**.pkl') 从存储的pkl文件中，读取pickle数据 df.head(5) 查看前几行的数据，默认是前5行 df.tail(5) 查看后几行的数据，默认是前5行 df.values 查看DataFrame里的数据，返回是一个数组 df.iloc[k] 查看某一行的数据， df.shape 查看行列数 df[&amp;lsquo;a&amp;rsquo;:&amp;lsquo;b&amp;rsquo;] 切片，是表示的行切片 df.loc[:, &amp;lsquo;A&amp;rsquo;:&amp;lsquo;B&amp;rsquo;] 索引，表示的是列索引 df.</description></item><item><title>异常</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0040_error/</guid><description>一、异常名称 异常名称 描述 BaseException 所有异常的基类 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 SystemExit Python 解释器请求退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 KeyboardInterrupt 用户中断执行(通常是输入^C) LookupError 无效数据查询的基类 IndexError 序列中没有没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告</description></item><item><title>并行操作</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0050_sdk_lib/0020_multiprocessing/</guid><description>一、线程与进程 进程 线程 进程：是一个应用程序在处理机上的一次执行过程，是具有一定独立功能的程序在某数据集上的一次运行，是一个动态的概念。进程是系统进行资源分配和调度的独立单位。 线程：是进程中的一个实体，是CPU调度和分派的基本单位，线程自己基本上不拥有系统资源，它与同属于一个进程内的其他线程共享进程的全部资源。 地址空间 进程有自己独立的地址空间 进程中至少有一个线程，它们共享进程的地址空间 资源 进程是资源分配和拥有的单位 进程内的多个线程共享进程的资源 调度 线程是进程内的一个执行单元，也是进程内的可调度实体，也是处理器调度的基本单位 二、多线程 1、threading模块 python主要是通过thread和threading这两个模块来实现多线程，thread模块是比较底层的模块，threading模块是对thread做了一些封装，使用更方便。但是由于GIL的存在，无法使用threading充分利用CPU资源，如果想充分发挥多核CPU的计算能力，需要使用multiprocessing模块
python 3.x 已经摒弃了python 2.x中采用函数式thread模块来产生线程的方式。而是通过threading模块创建新的线程：
通过threading.Thread(Target=可执行方法)
import threading pro_list = [] mult_image_label_list = [] for index, img_list in enumerate(mult_image_label_list): # 创建线程 t1 = threading.Thread(target=函数名, args=(index, img_list)) pro_list.append(t1) for thread in pro_list: # 将线程设置为保护线程，否则会被无限挂起。 thread.setDaemon(True) thread.</description></item><item><title>字符编码</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0010_encode_mode/</guid><description>一、字符编码 ASCII：计算机是美国人发明的，所以最早只考虑了简单的26个字母和一些控制字符，所以只用7-bit组合出128个组合，编号0~127，存储的时候凑成了一个byte。这个组合没有考虑其他国家，比如汉字就不只128个，于是中国为汉字编码发明了GB2312编码，其他国家也有自己的各种编码，互不兼容。
为了统一，提出了unicode编码，包含了各个国家的文字，对每个字符都用2个byte来表示，英文的话就在前面加0。
unicode对于英文就会有些浪费，为了解决这个问题，为了节约硬盘空间/ 网络带宽，又发明了utf-8编码，1个字符可能会被编码成1~6个字节，英文还是1个字节，汉字变成了3个字节，只有在生僻字才会在4个字节。
字符 ASCII unicode utf-8 A 01000001 00000000 01000001 01000001 中 01001110 00101101 11100100 10111000 10101101 字符应用层的形式 字符在内存的形式 字符在硬盘/网络中的形式 二、解析/转换 图片在网络中获取下来是二进制的格式(bytes)；或者通过 open('***.jpg', &amp;lsquo;rb&amp;rsquo;) 读取的图片也是二进制的格式
bytes格式 &amp;lt;-&amp;gt; str
bytes: 是(二进制)数字序列，是utf-8的编码形式。该格式的变量是不可修改的。 str &amp;ndash;&amp;gt; bytes : 使用str.encode()方法 bytes &amp;ndash;&amp;gt; str : 使用bytes.decode()方法 bytearray(): 该格式的变量是可以修改的 a = &amp;#39;人生苦短&amp;#39; # 此时b的格式是bytes，是不能修改的，即不能操作：b[:6] = &amp;#39;生命&amp;#39;.</description></item><item><title>基础操作</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0020_basic_operator/</guid><description>一、数据类型与操作 操作 说明 del A[i] 删除列表A中下标为i的元素，其后的每个元素都前移一个位置 列表-删除 A.pop() 弹出列表尾部元素，相当于出栈 列表-删除 A.pop(i) 弹出列表中任何位置出的元素 列表-删除 A.remove('a') 有时候不知道索引号，只知道要删除的值；remove只删除第一个指定的值 列表-删除 A.sort(reverse=True) 对列表A从大到小排序，列表A被永久改变 列表-排序 B=sorted(A) 排序后，A没有被改变 列表-排序 A.reverse() A列表被永久的翻转了一下 列表-翻转 ord() 获取字符的ASCII码，比如：两个字符相减：ord(&amp;lsquo;a&amp;rsquo;) - ord(&amp;lsquo;b&amp;rsquo;) 二、*和**的作用 * 在函数定义/调用时的应用
在函数定义时：*让python创建一个名为topping的空元组，并将收到的所有值封装在这个元组中。 def make_pizza(size, *topping): # 定义 .</description></item><item><title>NdArray使用</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0060_mxnet/0010_ndarray/0010_ndarray_summary/</guid><description>一、查阅文档 怎么查阅相关文档？ 官网
1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random)) __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。 2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。
help(nd.ones_like) 注意：
jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。 二、内存开销 原始操作 首先来个例子：Y = Y + X &amp;ndash;&amp;gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：
内存id_x &amp;lt;&amp;ndash; X 内存id_y &amp;lt;&amp;ndash; Y 内存id_x+y &amp;lt;&amp;ndash; Y
Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x &amp;lt;&amp;ndash; X 内存id_y &amp;lt;&amp;ndash; Y 内存id_x+y &amp;ndash;&amp;gt; 把内存id_x+y中数值复制到内存id_y中</description></item><item><title>Bert综述</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0100_bert/0001_bert_summary/</guid><description>一、背景 在使用预训练模型，处理下游任务时，有两类策略：基于特征(feature-based)、基于微调(fine-tuning)
基于特征：比如：ELMo，在使用时，对每个下游任务，创建一个跟这个任务相关的神经网络；预训练作为额外的特征跟输入一起输入到模型，预训练的额外特征可能会对要训练的模型有指导作用。 基于微调：比如：GPT，预训练模型在下游使用时，不需要改动太多，类似于视觉模型的fine-tuning，预训练完成特征提取，预训练模型后面添加个简单的网络用于实现具体任务。 1、上下文敏感 在自然语言中，有丰富的多义现象，一个词到底是什么意思，需要参考上下文才能判断。流行的上下文敏感表示：
TagLM(language-model-augmented sequence tagger 语言模型增强的序列标记器) CoVe(Context Vectors 上下文向量) ELMo(Embeddings from Language Models 来自语言模型的嵌入) ELMo 将来自预训练LSTM的所有中间层表示组合为输出表示 ELMo的表示，将作为添加特征添加到下游任务的有监督模型中 2、从特定任务到通用任务 ELMo显著改进了自然语言任务，但每个解决方案仍然依赖于一个特定的任务架构。怎么设计一个模型，让各个自然语言任务通用呢？
GPT(Generative Pre Training 生成式预训练)：在Transformer的基础上，为上下文敏感设计了通用的模型。
预训练一个用于表示文本序列的语言模型 当将GPT应用于下游任务时，语言模型的后面接一个线性输出层，以预测任务的标签。GPT的下游任务的监督学习过程，只对预训练Transformer解码器中的所有参数做微调。 GPT只能从左到右 二、BERT BERT的全称是Bidirectional Encoder Representation from Transformers, 即双向Transformer的Encoder。Bert结合了ELMo和GPT的有点，其主要贡献：
双向的重要性 基于微调的掩码语言模型(Masked Language Modeling)：BERT随机遮掩词元，并使用来自双向上下文的词元以自监督的方式预测该遮掩词元。 1、构造输入 token embedding: 格式：&amp;lt;CLS&amp;gt;第一个文本序列&amp;lt;SEP&amp;gt;第二个文本序列&amp;lt;SEP&amp;gt;
segment embedding: 用来区分句子
position embedding: 在bert中 位置嵌入 是可学习的
def get_tokens_and_segments(tokens_a, tokens_b=None): &amp;#34;&amp;#34;&amp;#34;获取输入序列的词元及其片段索引&amp;#34;&amp;#34;&amp;#34; tokens = [&amp;#39;&amp;lt;cls&amp;gt;&amp;#39;] + tokens_a + [&amp;#39;&amp;lt;sep&amp;gt;&amp;#39;] # 0和1分别标记片段A和B segments = [0] * (len(tokens_a) + 2) if tokens_b is not None: tokens += tokens_b + [&amp;#39;&amp;lt;sep&amp;gt;&amp;#39;] segments += [1] * (len(tokens_b) + 1) return tokens, segments 2、MLM 词元维度</description></item><item><title>Bert家族</title><link>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00200_nlp/0100_bert/0020_bert_family/</guid><description>一、简介 1、为什么需要预训练 《Visualizing and Understanding the Effectiveness of BERT》 这篇文章指出:
首先，预训练能在下游任务中达到一个良好的初始点，与从头开始训练相比，预训练能带来更宽的最优点，更容易优化。尽管 BERT 对下游任务的参数设置过高，但微调程序对过拟合具有很强的鲁棒性。 其次，可视化结果表明，由于最佳值平坦且宽广，以及训练损失面和泛化误差面之间的一致性，微调 BERT 趋向于更好地泛化。 第三，在微调过程中，BERT 的低层更具不变性，这表明靠近输入的层学习到了更多可迁移的语言表征。 2、下游任务怎么Fine-tune 我们希望有一个预训练的模型，输入一串单词，输出一串嵌入向量，并且希望这些向量是可以考虑上下文的。那么要怎么做呢？
最早是由CoVe提出用翻译的方法，来得到可以考虑上下文的向量。那如何通过翻译的方法来得到这个预训练模型呢，就是把该模型当成翻译的编码器，输入一个A语言的序列，然后有一个解码器，结合编码器的注意力，得到B语言的输出。
虽然可以做到这件事，但是翻译任务需要大量的语言对数据，收集这么多语言对数据是比较困难的，所以我们期望可以用很容易得到的无标签文本得到一个这样的预训练模型。
过去这样的方法被叫做无监督学习，不过现在通常叫做自监督学习。在自监督学习中，模型学会用部分输入去预测另外一部分输入。换句话说，就是输入的一部分用于预测输入中的其他部分。这种预测下一个单词的方法就是我们训练语言模型的方式。那么要用什么样的网络结构来训练这个模型呢？
最早用的就是LSTM，比较知名的使用LSTM进行预训练的模型，就是​ ​ELMo​​。随着自注意的流行，很多人把LSTM换成Transformer。
问题：
为什么预训练下一个单词的方法，能让我们得到代表单词意思的嵌入向量呢？
语言学家John Rupert Firth说过，你想要知道某个单词的意思，只要知道它和哪些单词一起出现。预测下一个单词其实做的是类似的事情。
假设我们有一些特定任务的标签数据，那如何微调模型呢？
一种做法是预选练的模型训练好后就固定了，变成一个特征Extrator。输入一个单词序列，通过这个预训练模型抽取一大堆特征，把这些特征丢到特征任务模型中，然后进行微调； 另外一种做法是把预训练的模型和特定任务的模型接在一起，在微调的时候，同时微调预训练模型和特定任务的模型。 如果微调整个模型，会遇到什么问题呢? 现在有三个不同的任务，每个任务中都有一个预训练好的模型，然后都微调整个模型。
这三个预训练好的模型，在不同的任务微调里面，它们会变得不一样。每一个任务都需要存一个新的模型，包含微调的预训练模型和特定任务模型。这样的模型往往非常巨大，其中的参数非常多，导致需要占用特别多的空间。
怎么解决这个问题呢 有人提出 Adaptor 的概念，在预训练的模型中加入一些叫Apt(Adaptor)的层，在微调的时候，只微调Apt层。这篇文章中，将Adapter插在Feed-forward层之后，在预训练的时候是没有Adapter的，只有在微调的时候才插进去。并且在微调的时候，只调整Adapter层的参数。
二、bert家族 1、修改Mask范围 那在BERT里面，要盖住哪些单词呢，原始的BERT里面是随机的。也许随机的不够好，尤其对于中文来说，如果盖住中文中的某个字，还是很容易从它附近的字猜出，比如“奥x会”，只要看到“奥”和“会”就可以猜到中间是”运”了。所以
有人提出 Whole Word Masking ​​盖住整个单词(中文里的词语)的方法，这样得到的模型可以学到更长的依赖关系。 可能只是盖住几个单词还不够好，ERNIE​(Baidu) ​​就提出了盖住短语级别(多个单词组成一个短语)和实体级别(需要识别出实体，然后盖住)。 还有一种Masking的方法，SpanBert​​​，思想很简单，一次盖住一排单词(token)。不用考虑什么短语啊、单词啊、实体啊。在SpanBert里面还提出了一种训练方法，叫SBO(Span Boundary Objective)，一般我们盖住了一些单词后，我们要把盖住的部分预测出现。而SBO通过被盖住范围的左右两边的向量，然后给定一个数值，比如3，代表要还原被盖住的第3个单词。然后SBO就知道，现在要还原3个位置。 还有一种方法，XLNet，从输入的文本序列中，随机一部分，去预测mask的结果，就是让各种各样不同的信息去预测一个单词，模型可以学到比较多的依赖关系。具体 在预训练阶段，引入permutation language model 的训练目标，对句子中单词排列组合，把一部分下文单词排列到上文位置中。这种做法是采用 attention掩码的机制来实现的：当前输入句子是X，要预测的第i个单词，i前面的单词位置不变，但是在transformer内部，通过attention mask，把其他没有被选到的单词mask掉，不让他们在预测单词的时候发生作用，看上去就是把这些被选中用来做预测的单词放在了上文位置了。 2、生成式任务 一般讲到BERT，大家都会说BERT不适于用来做生成任务，因为BERT训练的时候，会看到MASK左右两边的单词，而在生成任务中，只能看到左边已经生成出来的单词，然后BERT就表现不好了。</description></item><item><title>内置模块</title><link>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/</link><pubDate>Wed, 08 Sep 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00035_programming_language/0035_python/0020_internal_lib/0025_internal_module/</guid><description>一、os os.path.basename() os.path.dirname() os.path.join() os.path.exists() os.path.isfile() os.path.isdir() os.path.abspath(__file__) 获取当前执行文件的绝对路径 os.listdir() 遍历该目录下的文件，返回文件名列表 os.walk() 遍历该目录，返回的是一个三元组(root, dirs, files)
root: 指的是当前正在遍历的文件夹的地址
dirs: 是一个list，内容是该文件夹中所有的目录的名字，不包括子目录
files：内容是该文件夹中所有的文件，不包括子目录 os.makedirs() 创建文件夹 os.remove() 删除文件夹 os.environ() 获取环境变量，比如：os.environ(&amp;lsquo;变量名&amp;rsquo;, &amp;lsquo;默认值&amp;rsquo;) 二、sys sys.</description></item><item><title>归一化</title><link>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0015_deeplearning_norm/</link><pubDate>Thu, 05 Aug 2021 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0015_deeplearning_norm/</guid><description>一、Normlization介绍 一般而言，样本特征由于来源及度量单位不同，其尺度往往差异很大。如果尺度差异很大，神经网络就比较难训练。为了提高训练效率，对输入特征做归一化，把不同的尺度压缩到一定范围内，尺度统一后，大部分位置的梯度方向近似于最优解搜索方向。这样，在用梯度下降法进行求解时，每一步梯度的方向都基本上指向最小值，训练效率会大大提高。
归一化：泛指把数据特征转换为相同尺度的方法，比如：
把数据特征映射到 [0, 1] 或者 [-1, 1] 区间 映射为服从 N(0, 1) 的标准正态分布 1、逐层归一化 逐层归一化可以有效提高训练效率的原因：
更好的尺度不变形
深度神经网路中，一个神经层的输入是之前神经层的输出。给定一个神经层 $l$，它之前的神经层 $1, 2, &amp;hellip;, l-1$，的参数变化会导致其输入的分布发生很大的变化。当使用随机梯度下降法训练网络时，每次参数更新都会导致该神经层的输入分布发生变化，层数越高，其输入分布会改变得越明显。
为了缓解这个问题，可以对每个神经层的输入进行归一化，使其分布保持稳定。不管底层的参数如何变化，高层的输入相对稳定。另外，尺度不变性，可以使我们更加高效地进行参数初始化以及超参数选择。
更平滑的优化地形
逐层归一化，一方面可以是大部分神经层的输入处于不饱和区域，从而让梯度变大，避免梯度消失问题；另一方面可以使得神经网络的优化地形（Optimization Landscape）更加平滑，并使梯度变得更加稳定，从而允许使用更高的学习率，并加快收敛速度。
1. 批量归一化 批量归一化（Batch Normalization）对神经网络中的任意中间层进行归一化。
$$ a^{(l)} = f(z^{(l)}) = f(Wa^{(l-1)}+b) $$ $f(·)$ 是激活函数，$W$ 和 $b$ 是可学习的参数。
为了提高优化效率，就要使净输入 $z^l$ 的分布一致，比如：都归一化为标准正态分布。虽然归一化操作可以应用在输入 $a^{(l-1)}$ 上，但归一化 $z^l$ 更加有利于优化。因此，在实践中，归一化操作一般应用在仿射变换之后，激活函数之前。
2. 层归一化 层归一化（Layer Normalization）是和批量归一化非常类似的方法，与批量归一化不同的是，层归一化是对一个中间层的所有神经元进行归一化。
二、Norm的位置 在目前大模型中 Normalization 的位置：
pre Norm 的状态： $x_{t+1} = x_t + F_t(Norm(x_t))$</description></item><item><title>深度学习开篇</title><link>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/</link><pubDate>Thu, 05 Aug 2021 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0005_deeplearning_summary/</guid><description>论文入口
一、机器学习 目前，人工智能研究领域主要体现在一下几个方面：
智能感知：通过模拟人的感知能力（视觉、听觉、嗅觉）对外部信息进行感知和识别，并能够对信息进行加工和处理，从而做出反应。
智能学习：学习是人工智能的主要标志和获取知识的重要手段，研究机器通过模拟人的学习能力，如何从小样本、大数据中学习，主要有：
监督学习：（Supervised Learning）表示机器学习的数据是带有标记的，这些标记可以包括：数据类别、数据属性、特征点位置等。这些标记作为预期效果，不断修正机器的预测结果。常见的监督学习有分类、回归、结构化学习。 半监督学习：（Semi-Supervised Learning）利用少量标注数据和大量无标注数据进行学习的方式。常用的半监督学习算法有：自训练、协同训练 非监督学习：（Unsupervised Learning）表示机器学习的数据是没有标记的。常见的无监督学习有：聚类、降维 强化学习：（Reinforcement Learning）通过智能体和环境的交互，不断学习并调整策略的机器学习算法。这种算法带有一种激励机制，如果智能体根据环境做出一个正确的动作，则施予一定的“正激励”；如果是错误的动作，则给与一定的“负激励”。通过不断地累加激励，以获取激励最大化的回报。做火热的应用就是 AlphaGo Zero 认知推理：模拟人的认知能力，主要研究知识表示、推理、规划、决策等，主要有自然语言处理、脑科学。
二、表征学习 表征：为了提高机器学习系统的准确率，需要将输入信息转化为有效的特征，或者更一般性地称为 表征（Representation） 表征学习：如果有一种算法可以自动地学习有效的特征，并提高最终机器学习模型的性能，那么这种学习就可以叫做 表征学习。 表征学习的关键是解决语义鸿沟（Semantic Gap）问题。即：输入数据的底层特征与高层语义信息之间的不一致性和差异性。
机器学习中经常用两种方式表示特征：局部表示(Local Representation)、分布式表示(Distributed Representation)。
比如：颜色的表示。
局部表示：也称为离散表示或者符号表示，比如：one-hot向量的形式。假设所有颜色 构成一个词表 $\bold V$，此时，可以用一个 $|\bold V|$ 维的one-hot向量来表示一中颜色。但是，one-hot向量的维数很高，且不能扩展，如果有一种新的颜色，就需要增加一维来表示。不同颜色之间的相似度都为0，无法直到“红色”和“中国红”的相似度要高于“红色”和“黑色”的相似度。 分布式表示：另一种表示颜色的方法是用RGB值来表示颜色，不同颜色对应RGB三维空间中的一个点。分布式表示通常可以表示低维的稠密向量。 嵌入：神经网络将高维的局部表示空间 $\R^{|\bold V|}$，映射到一个非常低维的分布式表示空间 $\R^{D}$。在这个低维空间中，每个特征不再是坐标轴上的点，而是分散在整个低维空间中，在机器学习中，这个过程也成为嵌入（Embedding）。比如：自然语言中词的分布式表示也经常叫做词嵌入。
要学习到一种好的高层次语义表示（一般为分布式表示），通常只有从底层特征开始，经过多步非线性转换才能得到。深层结构的优点是可以提高特征的重用性，从而指数级增强表示能力。因此，表示学习的关键是构建具有一定深度的多层次特征表示。
三、深度学习 深度学习是机器学习的一个重要的、新的研究领域，源于对神经网络的进一步研究，通常采用包含多个隐藏层的神经网络结构，目的是建立、模拟人脑学习过程。
在描述深度学习之前，先回顾下机器学习和深度学习的关系。
机器学习：研究如何使用计算机系统利用经验改善性能。在机器学习的众多研究方向中，表征学习关注如何自动找出表示数据的合适方式，以便更好地将输入变换为正确的输出。
深度学习：是具有多级表示的表征学习方法。在每一级，深度学习通过简单的函数将该级的表示变换为更高级的表示。因此，深度学习模型也可以看作是由许多简单函数复合而成的函数。当这些复合函数足够多时，就可以表达非常复杂的变换。
作为表征学习的一种，深度学习将自动找出每一级表示数据的合适方式。逐级表示越来越抽象的概念或模式。高层特征是由底层特征通过推演归纳得到。
深度学习可通过学习一种深层非线性网络结构来表征输入数据，实现复杂函数逼近，具有很强的从少数样本集中学习数据集本质特征的能力。深度学习的主要思想：通过自学习的方法，学习到训练数据的结构，并在该结构上进行有监督训练微调。 以图像为例，它的输入是一堆原始像素值，模型中逐级表示为： graph LR; A(特定位置和角度的边缘) -- B(由边缘组合得出的花纹) B -- C(由多种花纹进一步汇合得到的特定部位) C -- D(由特定部位组合得到的整个目标) 1、神经元 神经元模型：</description></item><item><title>深度学习-结构</title><link>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/</link><pubDate>Thu, 05 Aug 2021 12:30:40 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00030_deeplearning_summary/0010_deeplearning_problem/</guid><description>一、激活函数 为什么需要激活函数？
例如：两个感知机。 $h_1 = W_1 x + b_1, h_2 = W_2 h_1 + b_2$ 如果没有激活函数这个 非线性变换，由于感知机的计算时线性变换，可以转换为：$h_2 = W_2 W_1 x + W_2 b_1 + b_2$ 就是说：如果没有激活函数，模型就做不了太深。两层的权重完全可以用一层的权重来表示。
1、Sigmoid函数 logistic函数
$$ \varphi(v) = \frac{1}{1+e^{-av}} $$
tanh函数
$$ \varphi(v) = tanh(v) = \frac{1-e^{-v}}{1+e^{-v}} $$
分段线性函数
$ \varphi(v) = \begin{cases} 1 &amp;amp;\text{if } v \geqslant \theta \\ kv &amp;amp;\text{if } - \theta &amp;lt; v &amp;lt; \theta \\ 0 &amp;amp;\text{if } v \leqslant 0 \end{cases}$</description></item><item><title>Katex公式</title><link>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/</link><pubDate>Tue, 08 Jun 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0015_latax_formula/</guid><description>官方文档
线上工具
一、基础篇 1. 输入公式 行内公式： 格式：$数学公式$ 例如：$x^2=1$ : $x^2=1$
行间公式：
$$
数学公式
$$
例如: $$f(x)=\int_{-\infty}^\infty\widehat f\xi\ e^{2\pi i\xi x}\ d\xi$$ $$f(x)=\int_{-\infty}^\infty\widehat f\xi\ e^{2\pi i\xi x}\ d\xi$$
二、进阶篇 1. 声调/变音符号 \dot{a}, \ddot{a}, \acute{a}, \grave{a}
$\dot{a}, \ddot{a}, \acute{a}, \grave{a}$
\check{a}, \breve{a}, \tilde{a}, \bar{a}
$\check{a}, \breve{a}, \tilde{a}, \bar{a}$
\hat{a}, \widehat{a}, \vec{a}, \tilde{a}, \widetilde{a}
$\hat{a}, \widehat{a}, \vec{a}, \tilde{a}, \widetilde{a}$
a', a''
$a', a''$
2. 标准函数 指数/上下标</description></item><item><title>区域块-实例</title><link>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/</link><pubDate>Tue, 08 Jun 2021 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0020_shortcodes_samples/</guid><description>🤑
This is a sample post intended to test the followings:
Default hero image. Different shortcodes. 一、报警(Alert) The following alerts are available in this theme.
这是 type=&amp;quot;success&amp;quot;的报警样例.
格式:
{{&amp;lt; alert type=&amp;ldquo;success&amp;rdquo; &amp;gt; }}
内容
{{&amp;lt; /alert &amp;gt; }} 这是 type=&amp;quot;danger&amp;quot;的报警样例.
格式:
{{&amp;lt; alert type=&amp;ldquo;danger&amp;rdquo; &amp;gt; }}
内容
{{&amp;lt; /alert &amp;gt; }} 这是 type=&amp;quot;warning&amp;quot;的报警样例.
格式:
{{&amp;lt; alert type=&amp;ldquo;warning&amp;rdquo; &amp;gt; }}
内容
{{&amp;lt; /alert &amp;gt; }} 这是 type=&amp;quot;info&amp;quot;的报警样例.</description></item><item><title>MarkDown入门</title><link>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/</link><pubDate>Tue, 08 Jun 2021 06:00:20 +0800</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0013_markdown-tutorial/</guid><description>一、小技巧 可以使用html的标签
markdown中常用的html标签： 操作 标签 换行 测试&amp;lt;br&amp;gt;一下 标记 &amp;lt;mark&amp;gt;测试一下&amp;lt;/mark&amp;gt; 按钮 &amp;lt;kbd&amp;gt;测试一下&amp;lt;/kbd&amp;gt; 颜色 &amp;lt;font color=&amp;quot;#A020F0&amp;quot;&amp;gt;颜色&amp;lt;/font&amp;gt; 四号文字 &amp;lt;font size=&amp;quot;4&amp;quot;&amp;gt;四号文字&amp;lt;/font&amp;gt; 引用1 &amp;lt;cite&amp;gt;引用[^1]&amp;lt;/cite&amp;gt; 空格 &amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;&amp;amp;nbsp;测试一下 删除线 &amp;lt;s&amp;gt;测试一下&amp;lt;/s&amp;gt; 下划线 &amp;lt;u&amp;gt;测试一下&amp;lt;/u&amp;gt; 字体增大 &amp;lt;big&amp;gt;测试一下&amp;lt;/big&amp;gt; 字体减小 &amp;lt;small&amp;gt;测试一下&amp;lt;/small&amp;gt; 文字上标 测试&amp;lt;sup&amp;gt;一下&amp;lt;/sup&amp;gt; 文字下标 测试&amp;lt;sub&amp;gt;一下&amp;lt;/sub&amp;gt; 加n个空行 {{&amp;lt; vs n&amp;gt;}} 右对齐</description></item><item><title>Toha的配置</title><link>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0010_toha-config/</link><pubDate>Mon, 08 Jun 2020 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0010_toha-config/</guid><description>一、启动 模板项目: github
# --force 即使本文件夹不为空，也会强制创建站点 hugo new site myblog -f=yaml --force # 初始化本地仓库，因为部署时要把该文件的内容push到远端仓库 git init # 添加toha主题 git submodule add https://github.com/hugo-toha/toha.git themes/toha # 在本地启动站点，浏览器中打开: http://localhost:1313 hugo server -t toha -w Demo样例
Hugo文档
Github项目
二、配置 config.yaml: 配置样例
这个主题的大部分内容是由data目录中的一些 YAML 文件驱动的。 在本节中，我们将添加一些示例数据。 由于我们正在构建一个多语言站点，因此我们会将每种语言的数据保存在各自的语言环境文件夹中。首先，在data目录中创建 en 文件夹(英语环境)/zh-cn(汉语环境)。 我们将在这里添加英语语境数据。
1、主页配置 在目的环境文件夹中创建site.yaml
英语环境：/data/en/site.yaml 汉语环境：/data/zh-cn/site.yaml
# Copyright Notice copyright: © 2021 Copyright. # A disclaimer notice for the footer. Make sure you have set &amp;#34;params.footer.disclaimer.enable: true&amp;#34; in your `config.</description></item><item><title>撰写文章</title><link>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/</link><pubDate>Mon, 08 Jun 2020 06:00:20 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/posts/00020_toha-tutorial/0011_write-blogs/</guid><description>一、创建类别 1、创建文章 在content文件夹中创建posts文件夹，在该文件夹中创建一个_index.zh-cn.md文件(中文环境)/_index.en.md(英文环境)。在里面添加如下内容：
--- title: Posts --- 现在，假设你想写一篇文章。首先，创建一个文件，在末尾用markdown扩展名命名它。例如:我们创建了一个名为analytics-and-comments.en.md，并添加以下几行内容。如果在中文环境下创建，名字应该是analytics-and-comments.zh-cn.md:
--- title: &amp;#34;Analytics and Comments&amp;#34; date: 2020-06-08T06:00:23+06:00 hero: /images/posts/writing-posts/analytics.svg description: Adding analytics and disquss comment in hugo theme Toha menu: sidebar: name: Analytics &amp;amp; Comments identifier: analytics-and-comments weight: 500 --- ### Complete Post Coming Soon... 在文件的头部以3个-开始和结束，称为前置内容。我们写得每一篇博客文章都需要有前置内容，在前置内容之后，可以开始写文章内容了，前置内容的参数有：
参数 解释 title 贴子的标题 date 显示博客发布时间，第一部分 year-month-date format hero 文章封面图的位置路径。创建路径static/images/posts/writingposts/ 在其中放置图片文件 description 添加任意你喜欢的描述 menu 这个部分包含了另一个sidebar参数，该参数定义了侧边栏中文件结构的样子。该参数的子参数有：name,identifier,weight name: 定义了侧边栏文件层次结构中，文档的名称 identifier: 标识符。有助于将文件与其他文件区分开来，有助于分类 weight: 权重值，对于多个文件，文档将基于该权重值以升序出现在文件层次结构中。 parent: 2、创建子类 刚刚我们创建了一个_index.</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Resultados de Búsqueda</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.
No se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html
Establecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.
Esta implementación utiliza Fusejs, jquery y mark.js
Configuración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.</description></item><item><title>Resultados de Búsqueda</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.
No se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html
Establecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.
Esta implementación utiliza Fusejs, jquery y mark.js
Configuración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>অনুসন্ধানের ফলাফল</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>অনুসন্ধানের ফলাফল</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Tue, 08 Jun 2010 08:06:25 +0600</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>图的搜索</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0050_graph_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0050_graph_search/</guid><description>标题 -- 狄克斯特拉算法(Dijkstra) 参考算法解析 广度优先搜索：可以回答两类问题，即：适合非加权图
从节点A出发，有往节点B的路径吗？ 从节点A出发，前往节点B的那条路径最短。 狄克斯特拉算法(Dijkstra)：适合 没有负权边的加权图。
狄克斯特拉算法，假设：对于处理过的节点，没有前往该节点的更短路径。这种假设仅在没有负权边时才成立。 狄克斯特拉算法，是典型最短路径算法，用于计算一个结点到其他结点的最短路径。 它的主要特点是以起始点为中心向外层层扩展(广度优先搜索思想)，直到扩展到终点为止。 贝尔曼-福德算法：适合 包含负权边的加权图
狄克斯特拉算法(Dijkstra)包括4个步骤
找出”最便宜“的节点，即：可在最短时间内到达的节点 更新该节点的邻居的开销，检查是否有前往它们的更短路径，如果有，就更新其开销。 重复这个过程，直到对图中的每个节点都这样做了 计算最终路径 例如：乐谱 -换-&amp;gt; 钢琴
第一步：找出最便宜的节点。这里，换海报最便宜了，不需要支付额外的费用。
第二步：计算前往该节点的各个邻居的开销。
父节点：代表该节点的上一级最便宜节点。
第三步：目前条件(未遍历：黑胶唱片、吉他、架子鼓；已遍历：海报)，在目前未遍历节点中找下一个最便宜的节点是 ”黑胶唱片“；更新 ”黑胶唱片“ 的各个邻居的开销。
下一个最便宜的是 吉他，因此更新其邻居的开销： 下一个最便宜的是 架子鼓，因此更新其邻居的开销： 第四步：所有节点都已遍历完了，当前，我们直到最短路径的开销是35美元，但如何确定这条路径呢？为此，可以根据父节点寻找。
狄克斯特拉算法：python实例：乐谱 -换-&amp;gt; 钢琴 class Solution(object): def __init__(self): pass @staticmethod # 在未处理的节点中找出开销最小的节点 def find_lowest_cost_node(costs, processed): lowest_cost = float(&amp;#39;inf&amp;#39;) lowest_cost_node = None for node in costs: cost = costs[node] if cost &amp;lt; lowest_cost and node not in processed: lowest_cost = cost lowest_cost_node = node return lowest_cost_node def dikesi(self, graph): # 开销-散列表。未知节点的开销，先设置为无穷大 costs = { &amp;#39;A&amp;#39;: 0, &amp;#39;B&amp;#39;: 5, &amp;#39;C&amp;#39;: 0, &amp;#39;D&amp;#39;: float(&amp;#39;inf&amp;#39;), &amp;#39;E&amp;#39;: float(&amp;#39;inf&amp;#39;), &amp;#39;F&amp;#39;: float(&amp;#39;inf&amp;#39;) } # 父节点-散列表 parents = {&amp;#39;B&amp;#39;: &amp;#39;A&amp;#39;, &amp;#39;C&amp;#39;: &amp;#39;A&amp;#39;, &amp;#39;F&amp;#39;: None} # 已处理过的节点 processed = [] node = &amp;#39;A&amp;#39; while node is not None: cost = costs[node] neighbors = graph[node] # 遍历当前节点的所有邻居 for n in neighbors: new_cost = cost + neighbors[n] # 如果当前节点前往邻居更近，就更新该邻居的开销；同时更新该邻居的父节点 if costs[n] &amp;gt; new_cost: costs[n] = new_cost parents[n] = node processed.</description></item><item><title>Gluon实例</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0010_gluon_summary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0010_gluon_summary/</guid><description>实例-单层感知机 模型：o = w1*x1 + w2*x2 + b 输出o作为线性回归的输出，输入层是2维特征；输入层不涉及计算，该神经网络只有输出层1层。
神经元：输出层中负责计算o的单元。
该神经元，依赖于输入层的全部特征，也就是说输出层中的神经元和输入层中各个输入完全连接，所以，这里的输出层又叫作全连接层(fully connected layer)或者稠密层(dense layer)
生成数据集 目标： o = 2x1 - 3.4x2 + 4.2 其中： 样本集：features: [w1, w2]， labels: [真实值+噪声]
from IPython import display from matplotlib import pyplot as plt from mxnet import autograd, nd import random num_inputs = 2 num_examples = 1000 true_w = [2, -3.4] true_b = 4.2 features = nd.random.normal(scale=1, shape=(num_examples, num_inputs)) labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b labels += nd.</description></item><item><title>Gluon-nn模块</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0030_module_gluon_nn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0030_module_gluon_nn/</guid><description>模型基类-Block from mxnet.gluon import Block, nn from mxnet import ndarray as F class Model(Block): def __init__(self, **kwargs): super(Model, self).__init__(**kwargs) # use name_scope to give child Blocks appropriate names. with self.name_scope(): self.dense0 = nn.Dense(20) self.dense1 = nn.Dense(20) def forward(self, x): x = F.relu(self.dense0(x)) return F.relu(self.dense1(x)) model = Model() model.initialize(ctx=mx.cpu(0)) model(F.zeros((10, 10), ctx=mx.cpu(0))) class Block(builtins.object)
网络的最基础的类，搭建网络时必须继承此Block类 —————————————————
Block的两个参数：
prefix : str; 前缀的作用就像一个命名空间。在父模块的作用域下创建的子模块都有父模块的前缀(prefix). params : ParameterDict or None; 共享参数。
例如：dense1共享dense0的参数。
dense0 = nn.</description></item><item><title>NdArray技巧搜集</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0020_technic_gather/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0020_technic_gather/</guid><description>sum/mean等操作 - 保留原维度数 keepdims: 保留原维度数。例如：
from mxnet import nd def softmax(X): X_exp = X.exp() # shape = (n, m) # shape = (n, 1) 而并不是 (n,) partition = X_exp.sum(axis=1, keepdims=True) return X_exp / partition # 这里应用了广播机制 X = nd.random.normal(shape=(2, 5)) X_prob = softmax(X) B的值作为A的索引 - 取值 from mxnet import nd y_hat = nd.array([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]]) y = nd.array([0, 2], dtype=&amp;#39;int32&amp;#39;) nd.pick(y_hat, y) # 结果: [0.</description></item><item><title>二叉树-遍历</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0020_tree_search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0020_tree_search/</guid><description>Depth First Search(DFS)遍历 深度优先遍历：
使用递归，代码比较简单 如果不用递归，可以利用栈这种数据结构 # -*- coding: utf-8 -*- class TreeNode: def __init__(self, value): self.value = value self.left = None self.right = None class Tree_Method: def DFS(self, root): &amp;#39;&amp;#39;&amp;#39; 深度优先遍历，即先访问根节点，然后遍历左子树接着遍历右子树。 主要利用栈的特点，先将右子树压栈，再将左子树压栈，这样左子树就位于栈顶， 可以结点的左子树先与右子树被遍历。 &amp;#39;&amp;#39;&amp;#39; if root == None: return None stack = [] &amp;#39;&amp;#39;&amp;#39;用列表模仿入栈&amp;#39;&amp;#39;&amp;#39; stack.append(root) while stack: &amp;#39;&amp;#39;&amp;#39;将栈顶元素出栈&amp;#39;&amp;#39;&amp;#39; current_node = stack.pop() print(current_node.value, end=&amp;#39; &amp;#39;) &amp;#39;&amp;#39;&amp;#39;判断该节点是否有右孩子，有就入栈&amp;#39;&amp;#39;&amp;#39; if current_node.right: stack.append(current_node.right) &amp;#39;&amp;#39;&amp;#39;判断该节点是否有左孩子，有就入栈&amp;#39;&amp;#39;&amp;#39; if current_node.left: stack.append(current_node.left) def preOrder(self, root): &amp;#39;&amp;#39;&amp;#39;先序遍历&amp;#39;&amp;#39;&amp;#39; if root == None: return None print(root.</description></item><item><title>五大常用算法</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0030_five_algorithms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0030_five_algorithms/</guid><description>分治法 分治法(divide and conquer)的工作原理：
找出简单的基线条件。 确定如何缩小问题的规模，使其符合基线条件。 分治法：并非可用于解决问题的算法，而是一种解决问题的思路。
待解决复杂问题，能够简化为若干个小规模相同的问题，各个子问题独立存在，并且与原问题形式相同； 递归地解决各个子问题； 将各个子问题的解合并，得到原问题的解。 实例1：
N和M的最大公约数（把一块农田均分成方块，求方块最大值）
实例2:
快速排序：
基线条件：空数组或者只有一个元素的数组，直接返回 选中一个基准值后，小于基准值的放在左边，大于基准值的放在右边。 def quick_sort(nums): if len(nums) &amp;lt; 2: return nums else: pivot = nums[0] lesser, greater = [], [] for item in nums[1:]: if item &amp;lt;= pivot: lesser.append(item) else: greater.append(item) return quick_sort(lesser) + [pivot] + quick_sort(greater) 实例3：
归并排序
实例4：
数组中最大值
普通的做法：设置个变量记录当前的最大值，变量数组中的每个值，最终找到数组的最大值。这中做法的时间复杂度 $O(n)$ 分治法：把数组分成两半：分别找打这两个子数组的最大值，再从这两个值中选出最大值。以此类推。这种做法的时间复杂度 $O(\log n)$ 贪心算法 近似算法：approximation algorithm.</description></item><item><title>Gluon模块简介</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0020_module_gather/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/gluon/0020_module_gather/</guid><description>gluon模块-结构 路径.mxnet/gluon/下的树状结构:
│　block.py 类：Block, HybridBlock
│　loss.py 各种loss函数
│　parameter.py 类：Parameter, Constant, ParameterDict
│　trainer.py 类：Trainer
│　utils.py 优化操作
│　init.py
│
├─contrib
│　│
│　├─cnn
│　│　└─ conv_layers.py
│　├─data
│　│　└─ sampler.py
│　│
│　├─estimator
│　│　│　estimator.py
│　│　└─ event_handler.py
│　│
│　├─nn
│　│　└─ basic_layers.py
│　│
│　└─rnn
│　│　conv_rnn_cell.py
│　└─ rnn_cell.py
│
├─data 主要是数据处理操作</description></item><item><title>常见算法思路</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0015_comm_ideas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0015_comm_ideas/</guid><description>标题 -- 递归 Leigh Caldwell在Stack Overflow上说的一句话: “如果使用循环，程序的性能可能更高;如果使用递归，程序可能更容易理解。如何选择要看什么对你来说更重要。”
编写递归函数时，必须告诉它何时停止递归。正因为如此，每个递归函数都有两部分:
基线条件(base case)。指的是函数不再调用自己，从而避免形成无限循环。 递归条件(recursive case)。指的是函数调用自己。 二分查找 比如：从1~100的数字中，我认选一个，让你猜。我只会说：大了、小了、对了。需要猜多少次呢？
二分查找：一半一半的猜，每次都排除一半。所以需要的次数是：log2N。（向上取整）
class BinarySearch(object): # 迭代 def search_iterative(self, nums, item): low = 0 high = len(nums) - 1 while low&amp;lt;=high: mid = (low + high) // 2 guess = nums[mid] if guess == item: return mid elif guess &amp;gt; item: high = mid - 1 else: low = mid + 1 return None # 递归 def search_recursive(self, nums, low, high, item): if high &amp;gt;= low: mid = (high + low) // 2 guess = nums[mid] if guess == item: return mid elif guess &amp;gt; item: return self.</description></item><item><title>数据结果</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0010_data_struct/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0010_data_struct/</guid><description>数据结构 常见的数据结构可分为「线性数据结构」与「非线性数据结构」，具体为：「数组」、「链表」、「栈」、「队列」、「树」、「图」、「散列表」、「堆」。
数组与链表 数组： 在内存中是连续的一整块。
随机访问，数组在内存中是连续的一整块，所以支持随机访问。 增/删操作，费事。增加元素时，如果内存不够一整块，还得整体迁移 链表： 可以存储在内存的任何地方。
顺序访问，由于存在任何地方，每个元素都存储了下一个元素的地址，所以只能从头开始逐个查询。 增/删操作，不费事。只要修改一下 下一元素地址 就行。 栈 递归操作，就是使用的调用栈。即：把每个递归调用函数，都压入栈，完成一个弹出一个，直到空栈。
优先考虑用栈的 “信号”
有返回上一步的操作 成对匹配的问题，比如：（） 链表/list 的翻转问题，例如：K 个一组翻转链表 单调栈
柱状图中最大的矩形 最大矩形 基于 柱状图中最大的矩形 的 思路：计算每列的柱状图：就是从该到左边界，连续的1的个数，就类似于柱状图 接雨水 : 思路： 位置i处的雨水量，取决于左右两边的最大值。
队列 队列(First In First Out)：先进先出的数据结构。
图的广度优先搜索，就是先把1级元素压入队列，然后在一个一个出队遍历时，把其邻居压入队列 树 字典树</description></item><item><title>滑动窗口</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0040_sliding_window/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0040_sliding_window/</guid><description>滑动窗口算法 参考
个人理解，滑动窗口主要解决的问题特点：
连续性，一定是连续序列或者字符串的最长/最短 的问题。 滑动窗口算法：是在给定特定窗口大小的数组或字符串上执行要求的操作，该技术可以将一部分问题中的嵌套循环转变为一个单循环，可以减少时间复杂度。即：在一个特定大小的字符串/数组上进行操作，而不是在整个字符串/数组上操作，这样就降低了问题的复杂度。
滑动：说明这个窗口是移动的；
窗口：窗口大小并不是固定的，可以不断扩容直到满足一定的条件；也可以不断缩小，直到找到一个满足条件的最小窗口；也可以是固定大小。
滑动窗口算法的思路：
我们在字符串 S 中使用双指针中的左右指针技巧，初始化 left = right = 0，把索引闭区间 [left, right] 称为一个「窗口」。 我们先不断地增加 right 指针扩大窗口 [left, right]，直到窗口中的字符串符合要求（包含了 T 中的所有字符）。 此时，我们停止增加 right，转而不断增加 left 指针缩小窗口 [left, right]，直到窗口中的字符串不再符合要求（不包含 T 中的所有字符了）。同时，每次增加 left，我们都要更新一轮结果。 重复第 2 和第 3 步，直到 right 到达字符串 S 的尽头。 对于固定窗口大小，框架总结如下：
# 固定窗口大小为k # 在s中 寻找窗口大小为k时的所包含最大元音字母个数 right = 0 while right&amp;lt;len(s): window.append(s[right]) right += 1 # 如果符合要求，说明窗口构造完成 if right&amp;gt;=k: # 这已经是一个窗口了，根据条件做一些事情 .</description></item><item><title>Search Results</title><link>https://biubiobiu.github.io/zh-cn/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/search/</guid><description>This file exists solely to respond to /search URL with the related search layout template.
No content shown here is rendered, all content is based in the template layouts/page/search.html
Setting a very low sitemap priority will tell search engines this is not important content.
This implementation uses Fusejs, jquery and mark.js
Initial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [&amp;ldquo;HTML&amp;rdquo;, &amp;ldquo;JSON&amp;rdquo;] ```</description></item><item><title>NdArray使用</title><link>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0010_ndarray_summary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/mxnet/ndarray/0010_ndarray_summary/</guid><description>查阅文档 怎么查阅相关文档？ 官网
1. 查阅模块里的所有函数和类 from mxnet import nd print(dir(nd.random)) __开头和结尾的函数 (python的特别对象) 可以忽略 _开头的函数 (一般为内部函数) 可以忽略 其余成员，可以根据名字 大致猜出是什么意思。 2. 查阅特定函数和类的使用 想了解某个函数或者类的具体用法，可以使用help函数。以NDArray中的ones_like函数为例。
help(nd.ones_like) 注意：
jupyter记事本里，使用?来将文档显示在另外一个窗口中。例如：nd.ones_like? 与 help(nd.ones_like)效果一样。nd.ones_like??会额外显示该函数实现的代码。 内存开销 原始操作 首先来个例子：Y = Y + X &amp;ndash;&amp;gt; 每个操作会新开内存来存储运算结果。 上例中，X，Y 变量首先存储在内存中，相加的计算结果会另外开辟内存来存储；然后变量Y在指向新的内存。 内存使用情况：
内存id_x &amp;lt;&amp;ndash; X 内存id_y &amp;lt;&amp;ndash; Y 内存id_x+y &amp;lt;&amp;ndash; Y
Y[:] = X + Y 或者 Y += X 通过[:]把X+Y的结果写进Y对应的内存中。上述操作中，需要另外开辟内存来存储计算结果。 内存使用情况： 内存id_x &amp;lt;&amp;ndash; X 内存id_y &amp;lt;&amp;ndash; Y 内存id_x+y &amp;ndash;&amp;gt; 把内存id_x+y中数值复制到内存id_y中</description></item><item><title>LeedCode-经典</title><link>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0450_leedcode_classic.zh-ch/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://biubiobiu.github.io/zh-cn/notes/computer_algorithm/0450_leedcode_classic.zh-ch/</guid><description>标题 -- 数组 134. 加油站 关键点：每个加油站的 剩余=添加-消耗。 累积每个加油站的剩余量，剩余累积量达到最小值时（升高的拐点，注意累积量保持最小值不变的情况。），下一个加油站就是起点。 238. 除自身外数组的乘积 关键点：从左到右累积相乘，从右到左累积相乘。这样就不用除法，且避免了重复的计算。
189. 轮转数组 关键点：
方法一：环状替换：替换到下一个位置，直到回到原位置，完成一轮。如果有没有遍历的元素，偏移一个位置，继续环状替换操作。 方法二：多次翻转 &amp;ndash;达到&amp;ndash;&amp;gt; 旋转的效果 图 127. 单词接龙 关键点：单词与单词之间用“中间单词”连接。这样的设计是 降低了计算复杂度。
每个单词mask掉一个字母，单词与单词之间没有连接，是通过中间的单词相互连接 通过广度优先遍历，从起始单词开始，直到结束单词。由于路径中有一半的量是“中间单词”，所以总的步数N，应该缩小：N//2+1 class Solution(object): def __init__(self): self.nodeNum = 0 def ladderLength(self, beginWord, endWord, wordList): &amp;#34;&amp;#34;&amp;#34; :type beginWord: str :type endWord: str :type wordList: List[str] :rtype: int &amp;#34;&amp;#34;&amp;#34; def addWord(word): if word not in wordId: wordId[word] = self.</description></item></channel></rss>